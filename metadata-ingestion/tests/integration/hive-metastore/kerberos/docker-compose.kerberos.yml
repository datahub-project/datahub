# Standalone Kerberos Hive environment for integration tests
# Usage: docker compose -f kerberos/docker-compose.kerberos.yml up -d
#
# Customer Environment Simulation:
# - HMS with Kerberos SASL authentication (port 9083)
# - Custom service name support (default: "hive", configurable)
# - No HiveServer2 dependency for metadata extraction
#
# Key Fixes Applied:
# 1. HDFS proxy user configuration for HMS impersonation
# 2. Proper keytab synchronization between KDC and services
# 3. Python-based test data loading via HMS Thrift API

services:
  # MIT Kerberos KDC with automatic keytab initialization
  kdc:
    build:
      context: .
      dockerfile: Dockerfile.kdc
    hostname: kdc.test.local
    container_name: kdc
    environment:
      KRB5_REALM: TEST.LOCAL
      KRB5_KDC: kdc.test.local
      KRB5_PASS: admin
    volumes:
      - krb5-keytabs:/keytabs
    ports:
      - "88:88/udp"
      - "88:88/tcp"
      - "749:749"
    healthcheck:
      test: ["CMD", "test", "-f", "/keytabs/hive.keytab"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 20s

  # HDFS NameNode with proxy user configuration for HMS impersonation
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      CLUSTER_NAME: test
      # CRITICAL: Allow hive service to impersonate any user
      # Without this, HMS cannot create databases/tables on behalf of users
      CORE_CONF_hadoop_proxyuser_hive_hosts: "*"
      CORE_CONF_hadoop_proxyuser_hive_groups: "*"
    env_file:
      - ../setup/hadoop-hive.env
    ports:
      - "50070"

  # HDFS DataNode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ../setup/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"

  # Hive Metastore with Kerberos - PRIMARY target for the connector (port 9083)
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: "hive-metastore"
    hostname: hive-metastore
    command: /opt/hive/bin/hive --service metastore
    env_file:
      - ../setup/hadoop-hive.env
      - ./hive-kerberos.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432 kdc:88"
      # Enable Kerberos debug logging
      HIVE_OPTS: "-Dsun.security.krb5.debug=true -Djavax.security.auth.useSubjectCredsOnly=false"
    volumes:
      - krb5-keytabs:/keytabs:ro
      - ./krb5.conf:/etc/krb5.conf:ro
      - ./hive-site-kerberos.xml:/opt/hive/conf/hive-site.xml:ro
    ports:
      - "9083:9083"
    depends_on:
      kdc:
        condition: service_healthy

  # HiveServer2 - NOT used for customer scenario but kept for compatibility
  # HiveServer2 is disabled (authentication=NONE) since customer doesn't have it
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: "hiveserver2"
    hostname: hive-server
    env_file:
      - ../setup/hadoop-hive.env
      - ./hive-kerberos.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083 kdc:88"
    volumes:
      - krb5-keytabs:/keytabs:ro
      - ./krb5.conf:/etc/krb5.conf:ro
      - ./hive-site-kerberos.xml:/opt/hive/conf/hive-site.xml:ro
      - ../setup/hive_setup.sql:/hive_setup.sql
    ports:
      - "10000:10000"
    depends_on:
      kdc:
        condition: service_healthy

  # PostgreSQL backend for HMS metadata storage
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    ports:
      - "5432:5432"

  # Test client container for Kerberos testing and data loading
  # This simulates the DataHub ingestion environment
  kerberos-client:
    image: ubuntu:22.04
    container_name: kerberos-client
    hostname: client.test.local
    volumes:
      - krb5-keytabs:/keytabs:ro
      - ./krb5.conf:/tmp/krb5.conf:ro
      - ./test-connection.sh:/test-connection.sh:ro
      - ./setup-test-data.py:/setup-test-data.py:ro
    depends_on:
      - kdc
      - hive-metastore
    command: >
      bash -c "
        set -e &&
        cp /tmp/krb5.conf /etc/krb5.conf &&
        export DEBIAN_FRONTEND=noninteractive &&
        echo 'Installing packages...' &&
        apt-get update -qq &&
        apt-get install -y --no-install-recommends krb5-user libkrb5-dev python3 python3-pip python3-dev gcc netcat-openbsd > /dev/null 2>&1 &&
        pip3 install -q 'acryl-pyhive[hive-pure-sasl]' 'pymetastore>=0.4.2' kerberos &&
        echo 'Waiting for HMS to be ready...' &&
        sleep 30 &&
        echo 'Setting up test data...' &&
        kinit -kt /keytabs/testuser.keytab testuser@TEST.LOCAL &&
        python3 /setup-test-data.py &&
        echo 'Client ready!' &&
        tail -f /dev/null
      "
    environment:
      KRB5_CONFIG: /etc/krb5.conf
      DEBIAN_FRONTEND: noninteractive

volumes:
  namenode:
  datanode:
  krb5-keytabs:
