# Dataplex Integration Tests

This directory contains integration tests for the Dataplex source connector with mocked Google Cloud APIs and golden file validation.

## Test Structure

- `test_dataplex_integration.py`: Main integration test file with mocked API responses
- `golden/`: Directory for golden files (expected output JSON files)

## Running Tests

```bash
# Run all Dataplex integration tests
pytest tests/integration/dataplex/

# Run specific test
pytest tests/integration/dataplex/test_dataplex_integration.py::test_dataplex_integration_with_golden_file

# Update golden files (when making intentional changes)
pytest tests/integration/dataplex/ --update-golden-files
```

## Test Coverage

The integration tests cover:

1. **Basic ingestion**: Lakes, zones, assets, and entities
2. **Multiple lakes**: Hierarchical data across multiple lakes
3. **Mocked API**: All Google Cloud Dataplex API calls are mocked
4. **Golden file validation**: Output is validated against expected golden files

## Adding New Tests

1. Create a new test function in `test_dataplex_integration.py`
2. Mock the necessary Google Cloud API responses
3. Run the test with `--update-golden-files` to generate the golden file
4. Review the golden file to ensure correctness
5. Commit both the test and golden file

## Golden Files

Golden files are JSON files containing the expected metadata output from the Dataplex connector. They are stored in the `golden/` subdirectory and are used to validate that the connector produces consistent output.

**Note**: Golden files need to be generated by running the tests with the `--update-golden-files` flag. The files should be reviewed manually before committing to ensure correctness.
