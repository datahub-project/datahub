"""Unit tests for Snowflake Semantic View Usage Extraction."""

import datetime
from typing import Any, Dict, List
from unittest.mock import MagicMock, patch

import pytest

from datahub.configuration.time_window_config import BucketDuration
from datahub.ingestion.source.snowflake.snowflake_config import (
    SemanticViewsConfig,
    SnowflakeV2Config,
)
from datahub.ingestion.source.snowflake.snowflake_query import SnowflakeQuery
from datahub.ingestion.source.snowflake.snowflake_report import SnowflakeV2Report
from datahub.ingestion.source.snowflake.snowflake_schema import (
    SemanticViewProfileCounts,
    SemanticViewQuery,
    SemanticViewUsageRecord,
)
from datahub.ingestion.source.snowflake.snowflake_semantic_view_usage import (
    SemanticViewUsageExtractor,
)
from datahub.ingestion.source.snowflake.snowflake_utils import (
    SnowflakeIdentifierBuilder,
)


class TestSemanticViewsConfig:
    """Tests for SemanticViewsConfig configuration."""

    def test_default_config(self):
        """Test default configuration values."""
        config = SemanticViewsConfig()
        assert config.enabled is False
        assert config.column_lineage is False
        assert config.include_usage is False
        assert config.emit_query_entities is False
        assert config.emit_profile is False
        assert config.max_queries_per_view == 100

    def test_enabled_with_usage(self):
        """Test enabling usage tracking."""
        config = SemanticViewsConfig(
            enabled=True,
            include_usage=True,
            emit_query_entities=True,
            emit_profile=True,
        )
        assert config.enabled is True
        assert config.include_usage is True
        assert config.emit_query_entities is True
        assert config.emit_profile is True

    def test_warning_usage_without_enabled(self):
        """Test that warnings are logged when usage is enabled but semantic_views is not."""
        with patch(
            "datahub.ingestion.source.snowflake.snowflake_config.logger"
        ) as mock_logger:
            config = SemanticViewsConfig(
                enabled=False,
                include_usage=True,
            )
            # Validator should have been called and logged a warning
            assert config.include_usage is True
            mock_logger.warning.assert_called()

    def test_max_queries_per_view_validation(self):
        """Test that max_queries_per_view validation rejects invalid values."""
        from pydantic import ValidationError

        # Valid values should work
        config = SemanticViewsConfig(max_queries_per_view=1)
        assert config.max_queries_per_view == 1

        config = SemanticViewsConfig(max_queries_per_view=10000)
        assert config.max_queries_per_view == 10000

        # Zero should fail (ge=1)
        with pytest.raises(ValidationError):
            SemanticViewsConfig(max_queries_per_view=0)

        # Negative should fail
        with pytest.raises(ValidationError):
            SemanticViewsConfig(max_queries_per_view=-1)

        # Too large should fail (le=10000)
        with pytest.raises(ValidationError):
            SemanticViewsConfig(max_queries_per_view=10001)


class TestSnowflakeQuerySemanticViewUsage:
    """Tests for SQL query generation."""

    def test_semantic_view_usage_statistics_query_daily(self):
        """Test usage statistics query generation with daily buckets."""
        query = SnowflakeQuery.semantic_view_usage_statistics(
            start_time_millis=1704067200000,  # 2024-01-01
            end_time_millis=1704153600000,  # 2024-01-02
            time_bucket_size=BucketDuration.DAY,
        )

        # Verify QUERY_HISTORY with pattern matching is used
        # (Semantic views don't appear in ACCESS_HISTORY)
        assert "query_history" in query.lower()
        assert "SEMANTIC_VIEW(" in query
        # Verify aggregation settings
        assert "DAY" in query
        assert "bucket_start_time" in query.lower()
        # Verify Cortex Analyst detection
        assert "Generated by Cortex Analyst" in query
        assert "DIRECT_SQL_QUERIES" in query
        assert "CORTEX_ANALYST_QUERIES" in query

    def test_semantic_view_usage_statistics_query_hourly(self):
        """Test usage statistics query generation with hourly buckets."""
        query = SnowflakeQuery.semantic_view_usage_statistics(
            start_time_millis=1704067200000,
            end_time_millis=1704153600000,
            time_bucket_size=BucketDuration.HOUR,
        )

        assert "HOUR" in query
        # Verify QUERY_HISTORY approach is used
        assert "query_history" in query.lower()
        assert "SEMANTIC_VIEW(" in query

    def test_semantic_view_queries(self):
        """Test queries SQL generation."""
        query = SnowflakeQuery.semantic_view_queries(
            start_time_millis=1704067200000,
            end_time_millis=1704153600000,
            max_queries=50,
        )

        # Verify QUERY_HISTORY with pattern matching is used
        assert "query_history" in query.lower()
        assert "SEMANTIC_VIEW(" in query
        # Verify query source detection
        assert "QUERY_SOURCE" in query
        assert "Generated by Cortex Analyst" in query
        assert "LIMIT 50" in query

    def test_semantic_view_profile_counts(self):
        """Test profile counts SQL generation."""
        query = SnowflakeQuery.semantic_view_profile_counts("TEST_DB")

        assert "semantic_dimensions" in query.lower()
        assert "semantic_facts" in query.lower()
        assert "semantic_metrics" in query.lower()
        assert "semantic_tables" in query.lower()
        assert "TEST_DB" in query


class TestSemanticViewDataModels:
    """Tests for semantic view usage data models."""

    def test_semantic_view_usage_record(self):
        """Test SemanticViewUsageRecord creation."""
        record = SemanticViewUsageRecord(
            semantic_view_name="db.schema.sales_view",
            bucket_start_time=datetime.datetime(
                2024, 1, 1, tzinfo=datetime.timezone.utc
            ),
            total_queries=100,
            unique_users=10,
            direct_sql_queries=80,
            cortex_analyst_queries=20,
            avg_execution_time_ms=150.5,
            total_rows_produced=5000,
            user_counts=[{"user_name": "analyst", "query_count": 50}],
        )

        assert record.semantic_view_name == "db.schema.sales_view"
        assert record.total_queries == 100
        assert record.direct_sql_queries == 80
        assert record.cortex_analyst_queries == 20

    def test_semantic_view_query(self):
        """Test SemanticViewQuery creation."""
        query = SemanticViewQuery(
            query_id="query-123",
            query_text="SELECT * FROM SEMANTIC_VIEW(db.schema.view ...)",
            semantic_view_name="db.schema.view",
            user_name="analyst",
            role_name="ANALYST_ROLE",
            warehouse_name="COMPUTE_WH",
            start_time=datetime.datetime(
                2024, 1, 1, 10, 30, tzinfo=datetime.timezone.utc
            ),
            total_elapsed_time=1500,
            rows_produced=100,
            query_source="DIRECT_SQL",
        )

        assert query.query_id == "query-123"
        assert query.user_name == "analyst"
        assert query.total_elapsed_time == 1500
        assert query.query_source == "DIRECT_SQL"

    def test_semantic_view_profile_counts(self):
        """Test SemanticViewProfileCounts creation."""
        counts = SemanticViewProfileCounts(
            semantic_view_catalog="TEST_DB",
            semantic_view_schema="PUBLIC",
            semantic_view_name="sales_view",
            dimension_count=5,
            fact_count=3,
            metric_count=2,
            table_count=2,
            total_column_count=10,
        )

        assert counts.dimension_count == 5
        assert counts.fact_count == 3
        assert counts.metric_count == 2
        assert counts.total_column_count == 10


class TestSemanticViewUsageExtractor:
    """Tests for SemanticViewUsageExtractor."""

    @pytest.fixture
    def mock_config(self) -> SnowflakeV2Config:
        """Create a mock Snowflake config."""
        config = MagicMock(spec=SnowflakeV2Config)
        config.semantic_views = SemanticViewsConfig(
            enabled=True,
            include_usage=True,
            emit_query_entities=True,
            emit_profile=True,
            max_queries_per_view=100,
        )
        config.start_time = datetime.datetime(2024, 1, 1, tzinfo=datetime.timezone.utc)
        config.end_time = datetime.datetime(2024, 1, 2, tzinfo=datetime.timezone.utc)
        config.bucket_duration = BucketDuration.DAY
        config.email_domain = "test.com"
        return config

    @pytest.fixture
    def mock_connection(self) -> MagicMock:
        """Create a mock Snowflake connection."""
        return MagicMock()

    @pytest.fixture
    def mock_identifiers(self) -> MagicMock:
        """Create a mock identifier builder."""
        identifiers = MagicMock(spec=SnowflakeIdentifierBuilder)
        identifiers.gen_dataset_urn.return_value = (
            "urn:li:dataset:(urn:li:dataPlatform:snowflake,test.schema.view,PROD)"
        )
        identifiers.get_user_identifier.return_value = "analyst@test.com"
        return identifiers

    @pytest.fixture
    def extractor(
        self,
        mock_config: SnowflakeV2Config,
        mock_connection: MagicMock,
        mock_identifiers: MagicMock,
    ) -> SemanticViewUsageExtractor:
        """Create a SemanticViewUsageExtractor instance."""
        report = SnowflakeV2Report()
        return SemanticViewUsageExtractor(
            config=mock_config,
            report=report,
            connection=mock_connection,
            identifiers=mock_identifiers,
        )

    def test_normalize_semantic_view_name(self, extractor: SemanticViewUsageExtractor):
        """Test semantic view name normalization."""
        assert (
            extractor._normalize_semantic_view_name("DB.SCHEMA.VIEW")
            == "db.schema.view"
        )
        assert (
            extractor._normalize_semantic_view_name("db.schema.view")
            == "db.schema.view"
        )

    def test_generate_query_name_with_semantic_view(
        self, extractor: SemanticViewUsageExtractor
    ):
        """Test query name generation from SQL with SEMANTIC_VIEW."""
        query_text = (
            "SELECT * FROM SEMANTIC_VIEW(db.schema.sales_view DIMENSIONS region)"
        )
        name = extractor._generate_query_name(query_text)
        assert "Query on sales_view" in name

    def test_generate_query_name_fallback(self, extractor: SemanticViewUsageExtractor):
        """Test query name generation fallback."""
        query_text = "SELECT * FROM some_table"
        name = extractor._generate_query_name(query_text, max_length=20)
        assert len(name) <= 20
        assert name.endswith("...")

    def test_parse_usage_results(self, extractor: SemanticViewUsageExtractor):
        """Test parsing usage results from query."""
        mock_results: List[Dict[str, Any]] = [
            {
                "SEMANTIC_VIEW_NAME": "db.schema.sales_view",
                "BUCKET_START_TIME": datetime.datetime(
                    2024, 1, 1, tzinfo=datetime.timezone.utc
                ),
                "TOTAL_QUERIES": 50,
                "UNIQUE_USERS": 5,
                "DIRECT_SQL_QUERIES": 40,
                "CORTEX_ANALYST_QUERIES": 10,
                "AVG_EXECUTION_TIME_MS": 200.0,
                "TOTAL_ROWS_PRODUCED": 1000,
                "USER_COUNTS": '[{"user_name": "analyst", "query_count": 30}]',
                "TOP_SQL_QUERIES": '["SELECT * FROM SEMANTIC_VIEW(db.schema.sales_view)", "SELECT region FROM SEMANTIC_VIEW(db.schema.sales_view)"]',
            }
        ]

        records = extractor._parse_usage_results(mock_results)

        assert len(records) == 1
        assert records[0].semantic_view_name == "db.schema.sales_view"
        assert records[0].total_queries == 50
        assert records[0].direct_sql_queries == 40
        assert records[0].cortex_analyst_queries == 10
        assert len(records[0].user_counts) == 1
        assert len(records[0].top_sql_queries) == 2
        assert (
            "SELECT * FROM SEMANTIC_VIEW(db.schema.sales_view)"
            in records[0].top_sql_queries
        )

    def test_map_user_counts(self, extractor: SemanticViewUsageExtractor):
        """Test mapping user counts to DatasetUserUsageCounts."""
        user_counts = [
            {"user_name": "analyst1", "query_count": 30},
            {"user_name": "analyst2", "query_count": 20},
        ]

        result = extractor._map_user_counts(user_counts)

        assert len(result) == 2
        assert result[0].count == 30 or result[0].count == 20

    def test_get_semantic_view_usage_workunits_disabled(
        self, extractor: SemanticViewUsageExtractor
    ):
        """Test that no workunits are generated when usage is disabled."""
        extractor.config.semantic_views.include_usage = False

        workunits = list(
            extractor.get_semantic_view_usage_workunits({"db.schema.view"})
        )

        assert len(workunits) == 0

    def test_get_semantic_view_usage_workunits_empty_discovered(
        self, extractor: SemanticViewUsageExtractor
    ):
        """Test that no workunits are generated with empty discovered views."""
        workunits = list(extractor.get_semantic_view_usage_workunits(set()))

        assert len(workunits) == 0

    def test_get_semantic_view_query_workunits_disabled(
        self, extractor: SemanticViewUsageExtractor
    ):
        """Test that no query workunits are generated when disabled."""
        extractor.config.semantic_views.emit_query_entities = False

        workunits = list(
            extractor.get_semantic_view_query_workunits({"db.schema.view"})
        )

        assert len(workunits) == 0

    def test_get_semantic_view_profile_workunits_disabled(
        self, extractor: SemanticViewUsageExtractor
    ):
        """Test that no profile workunits are generated when disabled."""
        extractor.config.semantic_views.emit_profile = False

        workunits = list(
            extractor.get_semantic_view_profile_workunits("TEST_DB", {"db.schema.view"})
        )

        assert len(workunits) == 0

    def test_build_query_workunits(
        self,
        extractor: SemanticViewUsageExtractor,
    ):
        """Test building query workunits from a query."""
        query = SemanticViewQuery(
            query_id="query-123",
            query_text="SELECT * FROM SEMANTIC_VIEW(db.schema.view ...)",
            semantic_view_name="db.schema.view",
            user_name="analyst",
            role_name="ANALYST_ROLE",
            warehouse_name="COMPUTE_WH",
            start_time=datetime.datetime(
                2024, 1, 1, 10, 30, tzinfo=datetime.timezone.utc
            ),
            total_elapsed_time=1500,
            rows_produced=100,
            query_source="DIRECT_SQL",
        )

        workunits = list(extractor._build_query_workunits(query, "db.schema.view"))

        # Should emit QueryProperties and QuerySubjects
        assert len(workunits) == 2

        # Check QueryProperties
        query_props_wu = workunits[0]
        assert query_props_wu.metadata is not None
        assert "query" in query_props_wu.metadata.entityUrn

        # Check QuerySubjects
        query_subjects_wu = workunits[1]
        assert query_subjects_wu.metadata is not None

    def test_query_extraction_respects_max_queries_per_view_efficiently(
        self,
        mock_config: SnowflakeV2Config,
        mock_connection: MagicMock,
        mock_identifiers: MagicMock,
    ):
        """Test that query extraction limits during iteration to avoid memory issues."""
        # Set a low limit
        mock_config.semantic_views.emit_query_entities = True
        mock_config.semantic_views.max_queries_per_view = 2

        # Create many queries for the same view (simulating high volume)
        base_time = datetime.datetime(2024, 1, 1, 10, 0, tzinfo=datetime.timezone.utc)
        mock_query_results = [
            {
                "QUERY_ID": f"query-{i}",
                "QUERY_TEXT": f"SELECT {i} FROM SEMANTIC_VIEW(db.schema.view)",
                "SEMANTIC_VIEW_NAME": "db.schema.view",
                "USER_NAME": "analyst",
                "ROLE_NAME": "ROLE",
                "WAREHOUSE_NAME": "WH",
                "START_TIME": base_time + datetime.timedelta(seconds=i),
                "TOTAL_ELAPSED_TIME": 100,
                "ROWS_PRODUCED": 10,
                "QUERY_SOURCE": "DIRECT_SQL",
            }
            for i in range(100)  # 100 queries, but limit is 2
        ]
        mock_connection.query.return_value = mock_query_results

        report = SnowflakeV2Report()
        extractor = SemanticViewUsageExtractor(
            config=mock_config,
            report=report,
            connection=mock_connection,
            identifiers=mock_identifiers,
        )

        discovered = {"db.schema.view"}
        workunits = list(extractor.get_semantic_view_query_workunits(discovered))

        # Should emit exactly 2 queries * 2 aspects (QueryProperties + QuerySubjects)
        assert len(workunits) == 4


class TestSemanticViewUsageIntegration:
    """Integration tests for semantic view usage extraction."""

    @patch(
        "datahub.ingestion.source.snowflake.snowflake_semantic_view_usage.SnowflakeConnection"
    )
    def test_usage_extraction_end_to_end(self, mock_connection_class):
        """Test end-to-end usage extraction with mocked Snowflake."""
        # Setup mock config
        config = MagicMock(spec=SnowflakeV2Config)
        config.semantic_views = SemanticViewsConfig(
            enabled=True,
            include_usage=True,
            emit_query_entities=True,
            max_queries_per_view=10,
        )
        config.start_time = datetime.datetime(2024, 1, 1, tzinfo=datetime.timezone.utc)
        config.end_time = datetime.datetime(2024, 1, 2, tzinfo=datetime.timezone.utc)
        config.bucket_duration = BucketDuration.DAY
        config.email_domain = "test.com"

        # Setup mock connection
        mock_connection = MagicMock()
        mock_usage_results = MagicMock()
        mock_usage_results.__iter__ = lambda self: iter(
            [
                {
                    "SEMANTIC_VIEW_NAME": "test_db.public.sales_view",
                    "BUCKET_START_TIME": datetime.datetime(
                        2024, 1, 1, tzinfo=datetime.timezone.utc
                    ),
                    "TOTAL_QUERIES": 25,
                    "UNIQUE_USERS": 3,
                    "DIRECT_SQL_QUERIES": 20,
                    "CORTEX_ANALYST_QUERIES": 5,
                    "AVG_EXECUTION_TIME_MS": 150.0,
                    "TOTAL_ROWS_PRODUCED": 500,
                    "USER_COUNTS": "[]",
                    "TOP_SQL_QUERIES": [
                        "SELECT * FROM SEMANTIC_VIEW(test_db.public.sales_view)"
                    ],
                }
            ]
        )
        mock_connection.query.return_value = mock_usage_results

        # Setup mock identifiers
        mock_identifiers = MagicMock(spec=SnowflakeIdentifierBuilder)
        mock_identifiers.gen_dataset_urn.return_value = "urn:li:dataset:(urn:li:dataPlatform:snowflake,test_db.public.sales_view,PROD)"
        mock_identifiers.get_user_identifier.return_value = "test@test.com"

        # Create extractor
        report = SnowflakeV2Report()
        extractor = SemanticViewUsageExtractor(
            config=config,
            report=report,
            connection=mock_connection,
            identifiers=mock_identifiers,
        )

        # Run extraction
        discovered = {"test_db.public.sales_view"}
        workunits = list(extractor.get_semantic_view_usage_workunits(discovered))

        # Verify
        assert len(workunits) == 1
        assert workunits[0].metadata is not None
        assert "DatasetUsageStatistics" in str(type(workunits[0].metadata.aspect))
        # Verify topSqlQueries is emitted
        usage_stats = workunits[0].metadata.aspect
        assert usage_stats.topSqlQueries is not None
        assert len(usage_stats.topSqlQueries) == 1
        assert (
            "SELECT * FROM SEMANTIC_VIEW(test_db.public.sales_view)"
            in usage_stats.topSqlQueries
        )
