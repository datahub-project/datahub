### Setup

The artifacts used by this source are:

- [dbt manifest file](https://docs.getdbt.com/reference/artifacts/manifest-json)
  - This file contains model, source, tests and lineage data.
- [dbt catalog file](https://docs.getdbt.com/reference/artifacts/catalog-json)
  - This file contains schema data.
  - dbt does not record schema data for Ephemeral models, as such datahub will show Ephemeral models in the lineage, however there will be no associated schema for Ephemeral models
- [dbt sources file](https://docs.getdbt.com/reference/artifacts/sources-json)
  - This file contains metadata for sources with freshness checks.
  - We transfer dbt's freshness checks to DataHub's last-modified fields.
  - Note that this file is optional â€“ if not specified, we'll use time of ingestion instead as a proxy for time last-modified.
- [dbt run_results file](https://docs.getdbt.com/reference/artifacts/run-results-json)
  - This file contains metadata from the result of a dbt run, e.g. dbt test
  - When provided, we transfer dbt test run results into assertion run events to see a timeline of test runs on the dataset

### File Location Options

The dbt connector supports loading these artifact files from multiple locations:

#### Local File System (Default)

The traditional approach where files are stored locally on the machine running DataHub ingestion:

```yaml
manifest_path: "/path/to/target/manifest.json"
catalog_path: "/path/to/target/catalog.json"
```

#### Cloud Storage

Load files directly from cloud storage services:

- **Amazon S3**: `s3://bucket-name/path/to/manifest.json`
- **Google Cloud Storage**: `gs://bucket-name/path/to/catalog.json`
- **Azure Blob Storage**:
  - `https://account.blob.core.windows.net/container/sources.json`
  - `abfss://container@account.dfs.core.windows.net/path/to/file.json`

#### Git Repositories

Load files directly from Git repositories (useful for CI/CD workflows):

- **SSH**: `git@github.com:org/repo.git/target/manifest.json`
- **HTTPS**: `https://github.com/org/repo/raw/main/target/catalog.json`
- **GitLab**: `git@gitlab.com:org/repo.git/target/manifest.json`

#### HTTP/HTTPS URLs

Load files from any web server:

```yaml
manifest_path: "https://my-server.com/artifacts/manifest.json"
```

### External Connections Configuration

When using cloud storage or Git repositories, you need to configure the appropriate connections in the `external_connections` section:

#### AWS S3 Connection

```yaml
external_connections:
  aws_connection:
    aws_access_key_id: "${AWS_ACCESS_KEY_ID}"
    aws_secret_access_key: "${AWS_SECRET_ACCESS_KEY}"
    aws_region: "us-east-1"
    # Optional: Use IAM role instead of access keys
    # aws_role: "arn:aws:iam::123456789012:role/DataHubRole"
```

#### Google Cloud Storage Connection

```yaml
external_connections:
  gcs_connection:
    type: "service_account"
    project_id: "${GCP_PROJECT_ID}"
    private_key_id: "${GCP_PRIVATE_KEY_ID}"
    private_key: "${GCP_PRIVATE_KEY}"
    client_email: "${GCP_CLIENT_EMAIL}"
    client_id: "${GCP_CLIENT_ID}"
```

#### Azure Blob Storage Connection

```yaml
external_connections:
  azure_connection:
    account_name: "${AZURE_ACCOUNT_NAME}"
    account_key: "${AZURE_ACCOUNT_KEY}"
    # Alternative authentication methods:
    # account_url: "https://myaccount.blob.core.windows.net"
    # sas_token: "${AZURE_SAS_TOKEN}"
```

#### Git Repository Connection

```yaml
external_connections:
  git_info:
    repo: "git@github.com:my-org/dbt-project.git"
    branch: "main" # Optional, defaults to default branch
    # For private repositories, provide SSH deploy key:
    deploy_key: "${GITHUB_DEPLOY_KEY}"
    # Or path to deploy key file:
    # deploy_key_file: "/path/to/deploy_key"
```

**Note**: Git repositories are cloned locally during ingestion, so ensure sufficient disk space and network access.

**Important**: The `external_connections.git_info` configuration provides both file loading from Git repositories AND navigation links in the DataHub UI. For users migrating from the legacy `git_info` field, you won't lose navigation functionality.

To generate these files, we recommend this workflow for dbt build and datahub ingestion.

```sh
dbt source snapshot-freshness
dbt build
cp target/run_results.json target/run_results_backup.json
dbt docs generate
cp target/run_results_backup.json target/run_results.json

# Run datahub ingestion, pointing at the files in the target/ directory
```

The necessary artifact files will then appear in the `target/` directory of your dbt project.

We also have guides on handling more complex dbt orchestration techniques and multi-project setups below.

:::note Entity is in manifest but missing from catalog

This warning usually appears when the catalog.json file was not generated by a `dbt docs generate` command.
Most other dbt commands generate a partial catalog file, which may impact the completeness of the metadata in ingested into DataHub.

Following the above workflow should ensure that the catalog file is generated correctly.

:::
