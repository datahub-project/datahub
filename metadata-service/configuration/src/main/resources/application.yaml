# Hack to remove /
path-mappings:
  "/": ""

# Name of the data hub component or container (used for tracing)
spring.application.name: ${APPLICATION_NAME:datahub-gms}

# The base URL where DataHub is accessible to users.
baseUrl: ${DATAHUB_BASE_URL:http://localhost:9002}

# App Layer
authentication:
  # Enable if you want all requests to the Metadata Service to be authenticated.
  enabled: ${METADATA_SERVICE_AUTH_ENABLED:true}
  excludedPaths: /schema-registry/*,/health,/health/live,/config,/config/search/export,/public-iceberg/*,/actuator/prometheus

  # Disable if you want to skip validation of deleted user's tokens
  enforceExistenceEnabled: ${METADATA_SERVICE_AUTH_ENFORCE_EXISTENCE_ENABLED:true}

  # Required if enabled is true! A configurable chain of Authenticators
  authenticators:
    # Required for authenticating requests with DataHub-issued Access Tokens - best not to remove.
    - type: com.datahub.authentication.authenticator.DataHubTokenAuthenticator
      configs:
        # Key used to validate incoming tokens. Should typically be the same as authentication.tokenService.signingKey
        signingKey: ${DATAHUB_TOKEN_SERVICE_SIGNING_KEY:WnEdIeTG/VVCLQqGwC/BAkqyY0k+H8NEAtWGejrBI94=}
        salt: ${DATAHUB_TOKEN_SERVICE_SALT:ohDVbJBvHHVJh9S/UA4BYF9COuNnqqVhr9MLKEGXk1O=}
    # Required for unauthenticated health check endpoints - best not to remove.
    - type: com.datahub.authentication.authenticator.HealthStatusAuthenticator
    # OAuth/OIDC JWT token authenticator for service accounts
    # Uses static configuration only (no dynamic GlobalSettings)
    - type: com.datahub.authentication.authenticator.DataHubOAuthAuthenticator
      configs:
        # Enable/disable External OAuth authentication - Global disable switch.
        enabled: ${EXTERNAL_OAUTH_ENABLED:false}

        # Trusted JWT issuers - must match the 'iss' claim in JWT tokens (comma-separated)
        trustedIssuers: ${EXTERNAL_OAUTH_TRUSTED_ISSUERS:}

        # Allowed audiences - must match the 'aud' claim in JWT tokens (comma-separated)
        allowedAudiences: ${EXTERNAL_OAUTH_ALLOWED_AUDIENCES:}

        # Option 1: Direct JWKS URI for fetching JWT signing keys
        jwksUri: ${EXTERNAL_OAUTH_JWKS_URI:}

        # Option 2: Discovery URI to auto-derive JWKS URI (alternative to jwksUri)
        discoveryUri: ${EXTERNAL_OAUTH_DISCOVERY_URI:}

        # JWT claim to use as user identifier (defaults to 'sub')
        userIdClaim: ${EXTERNAL_OAUTH_USER_ID_CLAIM:sub}

        # JWT signing algorithm (defaults to 'RS256')
        algorithm: ${EXTERNAL_OAUTH_ALGORITHM:RS256}
    - type: com.datahub.authentication.authenticator.DataHubGuestAuthenticator
      configs:
        guestUser: ${GUEST_AUTHENTICATION_USER:guest}
        enabled: ${GUEST_AUTHENTICATION_ENABLED:false}

  # Normally failures are only warnings, enable this to throw them.
  logAuthenticatorExceptions: ${METADATA_SERVICE_AUTHENTICATOR_EXCEPTIONS_ENABLED:false}

  # Required separately from the DataHubTokenAuthenticator as this is used by the AuthServiceController to authorize token generation
  # at user login time.
  systemClientId: ${DATAHUB_SYSTEM_CLIENT_ID:__datahub_system}
  systemClientSecret: ${DATAHUB_SYSTEM_CLIENT_SECRET:JohnSnowKnowsNothing}

  # Configurations for DataHub token service
  tokenService:
    # Key used to sign new tokens.
    signingKey: ${DATAHUB_TOKEN_SERVICE_SIGNING_KEY:WnEdIeTG/VVCLQqGwC/BAkqyY0k+H8NEAtWGejrBI94=}
    salt: ${DATAHUB_TOKEN_SERVICE_SALT:ohDVbJBvHHVJh9S/UA4BYF9COuNnqqVhr9MLKEGXk1O=}
    issuer: ${DATAHUB_TOKEN_SERVICE_ISSUER:datahub-metadata-service}
    signingAlgorithm: ${DATAHUB_TOKEN_SERVICE_SIGNING_ALGORITHM:HS256}

  # The max duration of a UI session in milliseconds. Defaults to 1 day.
  sessionTokenDurationMs: ${SESSION_TOKEN_DURATION_MS:86400000}

# Authorization-related configurations.
authorization:
  # Configurations for the default DataHub policies-based authorizer.
  defaultAuthorizer:
    enabled: ${AUTH_POLICIES_ENABLED:true}
    cacheRefreshIntervalSecs: ${POLICY_CACHE_REFRESH_INTERVAL_SECONDS:120}
    cachePolicyFetchSize: ${POLICY_CACHE_FETCH_SIZE:1000}
  # Enables authorization of reads, writes, and deletes on REST APIs.
  restApiAuthorization: ${REST_API_AUTHORIZATION_ENABLED:true}
  view:
    # Controls whether entity pages can limit access based on policies. If disabled, all entity pages are visible. Does not control if entities show up in search or browse.
    enabled: ${VIEW_AUTHORIZATION_ENABLED:false}
    recommendations:
      # Currently limited to the actor only, see TODO: DataHubAuthorizer
      peerGroupEnabled: ${VIEW_AUTHORIZATION_RECOMMENDATIONS_PEER_GROUP_ENABLED:true}

ingestion:
  # The value of cliVersion is substituted in by the processResources Gradle task.
  enabled: ${UI_INGESTION_ENABLED:true}
  defaultCliVersion: "${UI_INGESTION_DEFAULT_CLI_VERSION:@cliVersion@}"
  maxSerializedStringLength: "${INGESTION_MAX_SERIALIZED_STRING_LENGTH:16000000}" # Indicates the maximum allowed JSON String length Jackson will handle, impacts the maximum size of ingested aspects
  batchRefreshCount: ${INGESTION_BATCH_REFRESH_COUNT:100} # The number of entities to refresh in a single batch when refreshing entities after ingestion
  scheduler:
    refreshIntervalSeconds: ${INGESTION_SOURCE_REFRESH_INTERVAL_SECONDS:43200} # The interval at which the ingestion source scheduler will check for new or updated ingestion sources

telemetry:
  enabledCli: ${CLI_TELEMETRY_ENABLED:true}
  enabledIngestion: ${INGESTION_REPORTING_ENABLED:false}
  enableThirdPartyLogging: ${ENABLE_THIRD_PARTY_LOGGING:false} # whether mixpanel tracking is enabled.
  enabledServer: ${DATAHUB_TELEMETRY_ENABLED:true}

secretService:
  encryptionKey: "#{systemEnvironment['SECRET_SERVICE_ENCRYPTION_KEY'] ?: 'ENCRYPTION_KEY'}"
  v1AlgorithmEnabled: "${SECRET_SERVICE_V1_ALGORITHM_ENABLED:true}" # Force only v2 algorithm, invalidates all existing v1 encrypted secrets

datahub:
  serverType: ${DATAHUB_SERVER_TYPE:prod}
  serverEnv: ${DATAHUB_SERVER_ENV:core}
  # The base path for the URL where DataHub will be deployed
  basePath: ${DATAHUB_BASE_PATH:}
  # For special deployment modes intended to point at read replicas. WARNING: THIS WILL DROP WRITE OPERATIONS WITHOUT ERRORS, intended for analytics based deploys to offload work from user serving deploys
  readOnly: ${DATAHUB_READ_ONLY:false}

  gms:
    host: ${DATAHUB_GMS_HOST:localhost}
    port: ${DATAHUB_GMS_PORT:8080}
    basePath: ${DATAHUB_GMS_BASE_PATH:}
    basePathEnabled: ${DATAHUB_GMS_BASE_PATH_ENABLED:false}
    useSSL: ${DATAHUB_GMS_USE_SSL:${GMS_USE_SSL:false}}
    truststore:
      path: ${DATAHUB_GMS_SSL_TRUSTSTORE_PATH:#{null}} # Required if useSSL is true
      password: ${DATAHUB_GMS_SSL_TRUSTSTORE_PASSWORD:#{null}} # Required if useSSL is true
      type: ${DATAHUB_GMS_SSL_TRUSTSTORE_TYPE:PKCS12}
    async:
      request-timeout-ms: ${DATAHUB_GMS_ASYNC_REQUEST_TIMEOUT_MS:55000}

    # URI instead of above host/port/ssl
    # Priority is given to the URI setting over separate host/port/useSSL parameters
    uri: ${DATAHUB_GMS_URI:#{null}}

    sslContext:
      protocol: ${DATAHUB_GMS_SSL_PROTOCOL:${GMS_SSL_PROTOCOL:#{null}}}

  plugin:
    pluginSecurityMode: ${PLUGIN_SECURITY_MODE:RESTRICTED} # Possible value RESTRICTED or LENIENT, default to RESTRICTED
    entityRegistry:
      path: ${ENTITY_REGISTRY_PLUGIN_PATH:/etc/datahub/plugins/models}
      loadDelaySeconds: ${ENTITY_REGISTRY_PLUGIN_LOAD_DELAY_SECONDS:60} # Rate at which plugin runnable executes, will run every N seconds.
      ignoreFailureWhenLoadingRegistry: ${IGNORE_FAILURE_WHEN_LOADING_ENTITY_REGISTRY_PLUGIN:true}
    retention:
      path: ${RETENTION_PLUGIN_PATH:/etc/datahub/plugins/retention}
    auth:
      path: ${AUTH_PLUGIN_PATH:/etc/datahub/plugins/auth}

  metrics:
    # measures the time from request to post-MCL hook
    hookLatency:
      percentiles: ${DATAHUB_METRICS_HOOK_LATENCY_PERCENTILES:0.5,0.95,0.99,0.999}
      slo: ${DATAHUB_METRICS_HOOK_LATENCY_SERVICE_LEVEL_OBJECTIVES:300,1800,3000,10800,21600,43200} # 5min, 30min, 1hr, 3hr, 6hr, 12h (seconds)
      maxExpectedValue: ${DATAHUB_METRICS_HOOK_LATENCY_MAX_EXPECTED_VALUE:86000} # 24h (seconds)

  policies:
    systemPolicyUrnList: ${DATAHUB_SYSTEM_POLICY_URN_LIST:} # Additional policy urns that should not allow deletion, comma separated list like urn:li:dataHubPolicy:my-policy

  s3:
    bucketName: ${DATAHUB_BUCKET_NAME:} # The S3 bucket name to use for storing data
    roleArn: ${DATAHUB_ROLE_ARN:} # The AWS IAM role ARN to assume for S3 access
    presignedUploadUrlExpirationSeconds: ${DATAHUB_PRESIGNED_UPLOAD_URL_EXPIRATION_SECONDS:3600} # 60 minutes
    presignedDownloadUrlExpirationSeconds: ${DATAHUB_PRESIGNED_DOWNLOAD_URL_EXPIRATION_SECONDS:3600} # 60 minutes
    assetPathPrefix: ${DATAHUB_S3_ASSET_PATH_PREFIX:product_assets}

  validation:
    aspectSize:
      prePatch:
        enabled: ${DATAHUB_VALIDATION_ASPECT_SIZE_PRE_PATCH_ENABLED:false}
        warnSizeBytes: ${DATAHUB_VALIDATION_ASPECT_SIZE_PRE_PATCH_WARN_SIZE_BYTES:}
        maxSizeBytes: ${DATAHUB_VALIDATION_ASPECT_SIZE_PRE_PATCH_MAX_SIZE_BYTES:16000000}
        oversizedRemediation: ${DATAHUB_VALIDATION_ASPECT_SIZE_PRE_PATCH_OVERSIZED_REMEDIATION:IGNORE}
      postPatch:
        enabled: ${DATAHUB_VALIDATION_ASPECT_SIZE_POST_PATCH_ENABLED:false}
        warnSizeBytes: ${DATAHUB_VALIDATION_ASPECT_SIZE_POST_PATCH_WARN_SIZE_BYTES:}
        maxSizeBytes: ${DATAHUB_VALIDATION_ASPECT_SIZE_POST_PATCH_MAX_SIZE_BYTES:16000000}
        oversizedRemediation: ${DATAHUB_VALIDATION_ASPECT_SIZE_POST_PATCH_OVERSIZED_REMEDIATION:IGNORE}

entityService:
  impl: ${ENTITY_SERVICE_IMPL:ebean}
  retention:
    enabled: ${ENTITY_SERVICE_ENABLE_RETENTION:true}
    applyOnBootstrap: ${ENTITY_SERVICE_APPLY_RETENTION_BOOTSTRAP:false}

graphService:
  type: ${GRAPH_SERVICE_IMPL:elasticsearch}
  limit:
    results:
      max: ${GRAPH_SERVICE_LIMIT_RESULTS_MAX:10000} # Maximum allowed result count for queries
      apiDefault: ${GRAPH_SERVICE_LIMIT_RESULTS_API_DEFAULT:5000}
      strict: ${GRAPH_SERVICE_LIMIT_RESULTS_STRICT:false} # Throw an exception if strict is true, otherwise override with default and warn

searchService:
  resultBatchSize: ${SEARCH_SERVICE_BATCH_SIZE:100}
  enableCache: ${SEARCH_SERVICE_ENABLE_CACHE:false}
  enableEviction: ${SEARCH_SERVICE_ENABLE_CACHE_EVICTION:false}
  cacheImplementation: ${SEARCH_SERVICE_CACHE_IMPLEMENTATION:caffeine}
  semanticSearchEnabled: ${SEARCH_SERVICE_SEMANTIC_SEARCH_ENABLED:false}
  cache:
    hazelcast:
      serviceName: ${SEARCH_SERVICE_HAZELCAST_SERVICE_NAME:hazelcast-service}
      kubernetes-api-retries: ${SEARCH_SERVICE_HAZELCAST_KUBERNETES_API_RETRIES:5} # Hazelcast defaults: 3 attempts.
      service-dns-timeout: ${SEARCH_SERVICE_HAZELCAST_SERVICE_DNS_TIMEOUT:10} # Hazelcast default: 5 seconds.
      resolve-not-ready-addresses: ${SEARCH_SERVICE_HAZELCAST_RESOLVE_NOT_READY_ADDRESSES:true} # Hazelcast default: true.
  queryFilterRewriter:
    containerExpansion:
      enabled: ${SEARCH_SERVICE_FILTER_CONTAINER_EXPANSION_ENABLED:true}
      pageSize: ${SEARCH_SERVICE_FILTER_CONTAINER_EXPANSION_PAGE_SIZE:100}
      limit: ${SEARCH_SERVICE_FILTER_CONTAINER_EXPANSION_LIMIT:100}
    domainExpansion:
      enabled: ${SEARCH_SERVICE_FILTER_DOMAIN_EXPANSION_ENABLED:true}
      pageSize: ${SEARCH_SERVICE_FILTER_DOMAIN_EXPANSION_PAGE_SIZE:100}
      limit: ${SEARCH_SERVICE_FILTER_DOMAIN_EXPANSION_LIMIT:100}
  limit:
    results:
      max: ${SEARCH_SERVICE_LIMIT_RESULTS_MAX:10000} # Maximum allowed result count for queries
      apiDefault: ${SEARCH_SERVICE_LIMIT_RESULTS_API_DEFAULT:5000}
      strict: ${SEARCH_SERVICE_LIMIT_RESULTS_STRICT:false} # Throw an exception if strict is true, otherwise override with default and warn

timeseriesAspectService:
  query:
    concurrency: ${TIMESERIES_ASPECT_SERVICE_QUERY_CONCURRENCY:10} # parallel threads
    queueSize: ${TIMESERIES_ASPECT_SERVICE_QUERY)QUEUE_SIZE:500}
    threadKeepAlive: ${TIMESERIES_ASPECT_SERVICE_QUERY_THREAD_KEEP_ALIVE:60}
  limit:
    results:
      max: ${TIMESERIES_ASPECT_SERVICE_LIMIT_RESULTS_MAX:10000} # Maximum allowed result count for queries
      apiDefault: ${TIMESERIES_ASPECT_SERVICE_LIMIT_RESULTS_API_DEFAULT:5000}
      strict: ${TIMESERIES_ASPECT_SERVICE_LIMIT_RESULTS_STRICT:false} # Throw an exception if strict is true, otherwise override with default and warn

systemMetadataService:
  limit:
    results:
      max: ${SYSTEM_METADATA_SERVICE_LIMIT_RESULTS_MAX:10000} # Maximum allowed result count for queries
      apiDefault: ${SYSTEM_METADATA_SERVICE_LIMIT_RESULTS_API_DEFAULT:5000}
      strict: ${SYSTEM_METADATA_SERVICE_LIMIT_RESULTS_STRICT:false} # Throw an exception if strict is true, otherwise override with default and warn

configEntityRegistry:
  path: ${ENTITY_REGISTRY_CONFIG_PATH:../../metadata-models/src/main/resources/entity-registry.yml}
  # Priority is given to the `path` setting above (outside jar)
  resource: ${ENTITY_REGISTRY_CONFIG_CLASSPATH:classpath:/entity-registry.yml}

platformAnalytics:
  enabled: ${DATAHUB_ANALYTICS_ENABLED:true}
  usageExport:
    enabled: ${DATAHUB_ANALYTICS_TRACING_ENABLED:true} # Enables/Disables backend usage tracing
    usageEventTypes: ${ANALYTICS_DATAHUB_USAGE_EVENT_TYPES:CreateAccessTokenEvent,CreatePolicyEvent,UpdatePolicyEvent,CreateIngestionSourceEvent,UpdateIngestionSourceEvent,RevokeAccessTokenEvent,CreateUserEvent,UpdateUserEvent,DeletePolicyEvent} # Comma separated list that determines which usage event types to listen to, See DataHubUsageEventType for list
    aspectTypes: ${ANALYTICS_GENERIC_ASPECT_TYPES:} # A filter list for the generic aspect events, i.e. events that don't fall into a typed bucket in the above specific event types
    userFilters: "${ANALYTICS_USER_FILTERS:}" # Filter out specific users' events from being published at all

mclProcessing:
  cdcSource:
    enabled: ${CDC_MCL_PROCESSING_ENABLED:false} # Enable CDC Processing.
    configureSource: ${CDC_CONFIGURE_SOURCE:false} # Set to false if externally configured.
    type: debezium-kafka-connector # Only supported type for now.
    debeziumConfig: # Debezium-specific configuration
      type: ${CDC_DB_TYPE:mysql} # Set to one of mysql or postgres to load additional db specific config.
      name: ${DATAHUB_CDC_CONNECTOR_NAME:datahub-cdc-connector}
      url: ${CDC_KAFKA_CONNECT_URL:http://kafka-connect:8083}
      requestTimeoutMillis: ${CDC_KAFKA_CONNECT_REQUEST_TIMEOUT:10000} # request timeout for config rest API calls.
      config: # Resulting config is the common config + the type specific config bassed on debeziumConfig.type
        tasks.max: 1
        topic.prefix: datahub
        database.user: ${CDC_USER:datahub_cdc}
        database.password: ${CDC_PASSWORD:datahub_cdc}
        schema.history.internal.kafka.topic: datahub.schema-changes
        value.converter.schemas.enable: false
        key.converter: org.apache.kafka.connect.storage.StringConverter
        value.converter: org.apache.kafka.connect.json.JsonConverter
        message.key.columns: ${CDC_URN_KEY_SPEC:datahub.metadata_aspect_v2:urn}
        transforms: route
        transforms.route.type: org.apache.kafka.connect.transforms.RegexRouter
        transforms.route.regex: ".*metadata_aspect_v2"
        transforms.route.replacement: ${CDC_TOPIC_NAME:datahub.metadata_aspect_v2}
        database.dbname: ${DATAHUB_DB_NAME:datahub}
        # Default configs injected by System Update. Any additional configs are applied on top of these.
        # Below are inferred from db connection config and injected by DebeziumCDCSetupStep.
        #datahub.hostname
        #database.port

        # Below are inferred from available kafka configs
        #schema.history.internal.kafka.bootstrap.servers: broker:29092

      postgresConfig: # Used then CDC_DB_TYPE is set to postgres
        connector.class: ${DEBEZIUM_CONNECTOR_CLASS:io.debezium.connector.postgresql.PostgresConnector}
        plugin.name: ${DEBEZIUM_PLUGIN_NAME:pgoutput}
        table.include.list: ${CDC_INCLUDE_TABLE:public.metadata_aspect_v2}
        schema.include.list: ${CDC_INCLUDE_SCHEMA:public}
        publication.autocreate.mode: disabled
        publication.name: dbz_publication
        message.key.columns: public.metadata_aspect_v2:urn
        slot.name: debezium
        database.server.name: datahub
      mysqlConfig: # Used then CDC_DB_TYPE is set to mysql
        connector.class: ${DEBEZIUM_CONNECTOR_CLASS:io.debezium.connector.mysql.MySqlConnector}
        plugin.name: ${DEBEZIUM_PLUGIN_NAME:decoderbufs} # Use pgoutput for PostgreSQL, decoderbufs for others
        table.include.list: ".*metadata_aspect_v2"
        database.server.id: ${CDC_SERVER_ID:184001} # unique db ID per connector instance for MYSQL only
        database.include.list: ${DATAHUB_DB_NAME:datahub} # For MYSQL only

visualConfig:
  queriesTab:
    # Experimental! This env var is subject to change and may be deprecated in the future. The Queries tab has a larger
    # overhaul coming.
    queriesTabResultSize: ${REACT_APP_QUERIES_TAB_RESULT_SIZE:5}
  theme:
    themeId: ${REACT_APP_CUSTOM_THEME_ID:} # we have an enum defined on the frontend that this themeId maps to to render a specific custom theme file
  assets:
    logoUrl: ${REACT_APP_LOGO_URL:assets/platforms/datahublogo.png}
    faviconUrl: ${REACT_APP_FAVICON_URL:assets/icons/favicon.ico}
  appTitle: ${REACT_APP_TITLE:}
  hideGlossary: ${REACT_APP_HIDE_GLOSSARY:false}
  showFullTitleInLineage: ${REACT_APP_SHOW_FULL_TITLE_IN_LINEAGE:false}
  entityProfile:
    # we only support default tab for domains right now. In order to implement for other entities, update React code
    domainDefaultTab: ${DOMAIN_DEFAULT_TAB:} # set to DOCUMENTATION_TAB to show documentation tab first
  application:
    # DEPRECATED: This is now controlled via the UI settings.
    showSidebarSectionWhenEmpty: ${APPLICATION_SHOW_SIDEBAR_SECTION_WHEN_EMPTY:false}
  searchResult:
    enableNameHighlight: ${SEARCH_RESULT_NAME_HIGHLIGHT_ENABLED:true} # Enables visual highlighting on search result names/descriptions.

# Storage Layer

# Only required if entityService.impl is ebean
ebean:
  username: ${EBEAN_DATASOURCE_USERNAME:datahub}
  password: ${EBEAN_DATASOURCE_PASSWORD:datahub}
  url: ${EBEAN_DATASOURCE_URL:jdbc:mysql://localhost:3306/datahub} # JDBC URL
  driver: ${EBEAN_DATASOURCE_DRIVER:com.mysql.jdbc.Driver} # JDBC Driver
  minConnections: ${EBEAN_MIN_CONNECTIONS:2}
  maxConnections: ${EBEAN_MAX_CONNECTIONS:50}
  maxInactiveTimeSeconds: ${EBEAN_MAX_INACTIVE_TIME_IN_SECS:120}
  maxAgeMinutes: ${EBEAN_MAX_AGE_MINUTES:120}
  leakTimeMinutes: ${EBEAN_LEAK_TIME_MINUTES:15}
  waitTimeoutMillis: ${EBEAN_WAIT_TIMEOUT_MILLIS:1000}
  autoCreateDdl: ${EBEAN_AUTOCREATE:false}
  postgresUseIamAuth: ${EBEAN_POSTGRES_USE_AWS_IAM_AUTH:false}
  useIamAuth: ${EBEAN_USE_IAM_AUTH:false} # Generic IAM auth for cross-cloud compatibility
  cloudProvider: ${EBEAN_CLOUD_PROVIDER:auto} # auto, aws, gcp, or traditional
  batchGetMethod: ${EBEAN_BATCH_GET_METHOD:IN} # Alternative UNION

# Only required if entityService.impl is cassandra
cassandra:
  datasourceUsername: ${CASSANDRA_DATASOURCE_USERNAME:cassandra}
  datasourcePassword: ${CASSANDRA_DATASOURCE_PASSWORD:cassandra}
  hosts: ${CASSANDRA_HOSTS:cassandra}
  port: ${CASSANDRA_PORT:9042}
  datacenter: ${CASSANDRA_DATACENTER:datacenter1}
  keyspace: ${CASSANDRA_KEYSPACE:datahub}
  useSsl: ${CASSANDRA_USE_SSL:false}

elasticsearch:
  host: ${ELASTICSEARCH_HOST:localhost}
  port: ${ELASTICSEARCH_PORT:9200}
  threadCount: ${ELASTICSEARCH_THREAD_COUNT:2}
  connectionRequestTimeout: ${ELASTICSEARCH_CONNECTION_REQUEST_TIMEOUT:5000}
  username: ${ELASTICSEARCH_USERNAME:#{null}}
  password: ${ELASTICSEARCH_PASSWORD:#{null}}
  pathPrefix: ${ELASTICSEARCH_PATH_PREFIX:}
  useSSL: ${ELASTICSEARCH_USE_SSL:false}
  opensearchUseAwsIamAuth: ${OPENSEARCH_USE_AWS_IAM_AUTH:false}
  region: ${AWS_REGION:#{null}}
  idHashAlgo: ${ELASTIC_ID_HASH_ALGO:MD5}
  dataNodeCount: ${ELASTICSEARCH_DATA_NODE_COUNT:1}
  entityIndex:
    v2:
      enabled: ${ELASTICSEARCH_ENTITY_INDEX_V2_ENABLED:true}
      cleanup: ${ELASTICSEARCH_ENTITY_INDEX_V2_CLEANUP:false}
    v3:
      enabled: ${ELASTICSEARCH_ENTITY_INDEX_V3_ENABLED:false}
      cleanup: ${ELASTICSEARCH_ENTITY_INDEX_V3_CLEANUP:false}
      analyzerConfig: ${ELASTICSEARCH_ENTITY_INDEX_V3_ANALYZER_CONFIG:search_entity_analyzer_config.yaml}
      mappingConfig: ${ELASTICSEARCH_ENTITY_INDEX_V3_MAPPING_CONFIG:search_entity_mapping_config.yaml}
      maxFieldsLimit: ${ELASTICSEARCH_ENTITY_INDEX_V3_MAX_FIELDS_LIMIT:5000}
    semanticSearch:
      enabled: ${ELASTICSEARCH_SEMANTIC_SEARCH_ENABLED:false}
      enabledEntities: ${ELASTICSEARCH_SEMANTIC_SEARCH_ENTITIES:document}
      # Multi-model configuration: map of model name to embedding config
      # Example with multiple models:
      # models:
      #   cohere_embed_v3:
      #     vectorDimension: 1024
      #     knnEngine: faiss
      #     spaceType: cosinesimil
      #     efConstruction: 128
      #     m: 16
      #   openai_text_embedding_3_small:
      #     vectorDimension: 1536
      #     knnEngine: faiss
      #     spaceType: cosinesimil
      #     efConstruction: 128
      #     m: 16
      models:
        cohere_embed_v3:
          vectorDimension: ${ELASTICSEARCH_SEMANTIC_VECTOR_DIMENSION:1024}
          knnEngine: ${ELASTICSEARCH_SEMANTIC_KNN_ENGINE:faiss}
          spaceType: ${ELASTICSEARCH_SEMANTIC_SPACE_TYPE:cosinesimil}
          efConstruction: ${ELASTICSEARCH_SEMANTIC_EF_CONSTRUCTION:128}
          m: ${ELASTICSEARCH_SEMANTIC_M:16}
      # Embedding provider configuration for generating query embeddings
      # Supports AWS Bedrock with automatic credential resolution (AWS_PROFILE, EC2 instance roles, etc.)
      embeddingProvider:
        # Provider type: "aws-bedrock" (currently only Bedrock is supported)
        type: ${EMBEDDING_PROVIDER_TYPE:aws-bedrock}
        # AWS region where Bedrock is available (e.g., us-west-2, us-east-1)
        awsRegion: ${EMBEDDING_PROVIDER_AWS_REGION:us-west-2}
        # Bedrock model ID for embeddings (Cohere Embed v3: 1024 dimensions)
        modelId: ${EMBEDDING_PROVIDER_MODEL_ID:cohere.embed-english-v3}
        # Maximum text length before truncation (Cohere enforces 2048 character limit)
        maxCharacterLength: ${EMBEDDING_PROVIDER_MAX_CHAR_LENGTH:2048}
  # Multi-client shim configuration
  shim:
    # Enable the search client shim (false = use legacy RestHighLevelClient)
    enabled: ${ELASTICSEARCH_SHIM_ENABLED:false}
    # Engine type: AUTO_DETECT, ELASTICSEARCH_7, ELASTICSEARCH_8, ELASTICSEARCH_9, OPENSEARCH_2
    engineType: ${ELASTICSEARCH_SHIM_ENGINE_TYPE:AUTO_DETECT}
    # Whether to auto-detect the engine type by connecting to the cluster
    autoDetectEngine: ${ELASTICSEARCH_SHIM_AUTO_DETECT:true}
  sslContext: # Required if useSSL is true
    protocol: ${ELASTICSEARCH_SSL_PROTOCOL:#{null}}
    secureRandomImplementation: ${ELASTICSEARCH_SSL_SECURE_RANDOM_IMPL:#{null}}
    trustStoreFile: ${ELASTICSEARCH_SSL_TRUSTSTORE_FILE:#{null}}
    trustStoreType: ${ELASTICSEARCH_SSL_TRUSTSTORE_TYPE:#{null}}
    trustStorePassword: ${ELASTICSEARCH_SSL_TRUSTSTORE_PASSWORD:#{null}}
    keyStoreFile: ${ELASTICSEARCH_SSL_KEYSTORE_FILE:#{null}}
    keyStoreType: ${ELASTICSEARCH_SSL_KEYSTORE_TYPE:#{null}}
    keyStorePassword: ${ELASTICSEARCH_SSL_KEYSTORE_PASSWORD:#{null}}
    keyPassword: ${ELASTICSEARCH_SSL_KEY_PASSWORD:#{null}}
  bulkDelete:
    batchSize: ${ES_BULK_DELETE_BATCH_SIZE:5000}
    slices: ${ES_BULK_DELETE_SLICES:auto}
    pollInterval: ${ES_BULK_DELETE_POLL_INTERVAL:30}
    pollIntervalUnit: ${ES_BULK_DELETE_POLL_UNIT:SECONDS}
    timeout: ${ES_BULK_DELETE_TIMEOUT:30}
    timeoutUnit: ${ES_BULK_DELETE_TIMEOUT_UNIT:MINUTES}
    numRetries: ${ES_BULK_DELETE_NUM_RETRIES:3}
  bulkProcessor:
    async: ${ES_BULK_ASYNC:true}
    requestsLimit: ${ES_BULK_REQUESTS_LIMIT:1000}
    flushPeriod: ${ES_BULK_FLUSH_PERIOD:1}
    numRetries: ${ES_BULK_NUM_RETRIES:3}
    retryInterval: ${ES_BULK_RETRY_INTERVAL:1}
    refreshPolicy: ${ES_BULK_REFRESH_POLICY:NONE}
    enableBatchDelete: ${ES_BULK_ENABLE_BATCH_DELETE:false}
  index:
    prefix: ${INDEX_PREFIX:}
    numShards: ${ELASTICSEARCH_NUM_SHARDS_PER_INDEX:${elasticsearch.dataNodeCount}}
    numReplicas: ${ELASTICSEARCH_NUM_REPLICAS_PER_INDEX:1}
    numRetries: ${ELASTICSEARCH_INDEX_BUILDER_NUM_RETRIES:3}
    refreshIntervalSeconds: ${ELASTICSEARCH_INDEX_BUILDER_REFRESH_INTERVAL_SECONDS:3} # increase to 30 if expected indexing rates to be greater than 100/s
    maxArrayLength: ${SEARCH_DOCUMENT_MAX_ARRAY_LENGTH:1000}
    maxObjectKeys: ${SEARCH_DOCUMENT_MAX_OBJECT_KEYS:1000}
    maxValueLength: ${SEARCH_DOCUMENT_MAX_VALUE_LENGTH:4096} # i.e. customProperty values
    mainTokenizer: ${ELASTICSEARCH_MAIN_TOKENIZER:}
    enableMappingsReindex: ${ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX:false}
    enableSettingsReindex: ${ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX:false}
    maxReindexHours: ${ELASTICSEARCH_INDEX_BUILDER_MAX_REINDEX_HOURS:0} # <= 0 - no timeout
    settingsOverrides: ${ELASTICSEARCH_INDEX_BUILDER_SETTINGS_OVERRIDES:#{null}}
    minSearchFilterLength: ${ELASTICSEARCH_MIN_SEARCH_FILTER_LENGTH:3}
    entitySettingsOverrides: ${ELASTICSEARCH_INDEX_BUILDER_ENTITY_SETTINGS_OVERRIDES:#{null}}
    docIds:
      schemaField:
        hashIdEnabled: ${ELASTICSEARCH_INDEX_DOC_IDS_SCHEMA_FIELD_HASH_ID_ENABLED:false}
  buildIndices:
    allowDocCountMismatch: ${ELASTICSEARCH_BUILD_INDICES_ALLOW_DOC_COUNT_MISMATCH:false} # when cloneIndices is also enabled
    cloneIndices: ${ELASTICSEARCH_BUILD_INDICES_CLONE_INDICES:true}
    retentionUnit: ${ELASTICSEARCH_BUILD_INDICES_RETENTION_UNIT:DAYS}
    retentionValue: ${ELASTICSEARCH_BUILD_INDICES_RETENTION_VALUE:60}
    reindexOptimizationEnabled: ${ELASTICSEARCH_BUILD_INDICES_REINDEX_OPTIMIZATION_ENABLED:true} # Disable when Multi-AZ zone replication is set to required, will prevent index from setting zero replicas during reindexing
  search:
    maxTermBucketSize: ${ELASTICSEARCH_QUERY_MAX_TERM_BUCKET_SIZE:60}
    pointInTimeCreationEnabled: ${POINT_IN_TIME_CREATION_ENABLED:false} # Enables creation of point in time snapshots for the scroll API, only works with OpenSearch >= 2.4 or ElasticSearch >= 7.10. Regardless of this flag's value, PIT will be created for sliced scrolls.
    # Defines the behavior of quoted searches, do they apply weights or exclude results
    exactMatch:
      exclusive: ${ELASTICSEARCH_QUERY_EXACT_MATCH_EXCLUSIVE:false} # if false will only apply weights, if true will exclude non-exact
      withPrefix: ${ELASTICSEARCH_QUERY_EXACT_MATCH_WITH_PREFIX:true} # include prefix exact matches
      exactFactor: ${ELASTICSEARCH_QUERY_EXACT_MATCH_FACTOR:16.0} # boost multiplier when exact with case
      prefixFactor: ${ELASTICSEARCH_QUERY_EXACT_MATCH_PREFIX_FACTOR:1.1} # boost multiplier when exact prefix
      caseSensitivityFactor: ${ELASTICSEARCH_QUERY_EXACT_MATCH_CASE_FACTOR:0.0} # stacked boost multiplier when case mismatch
      enableStructured: ${ELASTICSEARCH_QUERY_EXACT_MATCH_ENABLE_STRUCTURED:true} # enable exact match on structured search
    wordGram:
      twoGramFactor: ${ELASTICSEARCH_QUERY_TWO_GRAM_FACTOR:1.2} # boost multiplier when match on 2-gram tokens
      threeGramFactor: ${ELASTICSEARCH_QUERY_THREE_GRAM_FACTOR:1.5} # boost multiplier when match on 3-gram tokens
      fourGramFactor: ${ELASTICSEARCH_QUERY_FOUR_GRAM_FACTOR:1.8} # boost multiplier when match on 4-gram tokens
    # Field weight annotations are typically calibrated for exact match, if partial match is possible on the field use these adjustments
    partial:
      urnFactor: ${ELASTICSEARCH_QUERY_PARTIAL_URN_FACTOR:0.5} # multiplier on Urn token match, a partial match on Urn > non-Urn is assumed
      factor: ${ELASTICSEARCH_QUERY_PARTIAL_FACTOR:0.4} # multiplier on possible non-Urn token match
    custom:
      enabled: ${ELASTICSEARCH_QUERY_CUSTOM_CONFIG_ENABLED:true}
      file: ${ELASTICSEARCH_QUERY_CUSTOM_CONFIG_FILE:search_config.yaml}
      searchFieldConfigDefault: ${ELASTICSEARCH_QUERY_SEARCH_FIELD_CONFIG_DEFAULT:legacy} # which field configuration to use by default for search
      autoCompleteFieldConfigDefault: ${ELASTICSEARCH_QUERY_AUTOCOMPLETE_FIELD_CONFIG_DEFAULT:legacy} # which field configuration to use by default for autocomplete
    graph:
      timeoutSeconds: ${ELASTICSEARCH_SEARCH_GRAPH_TIMEOUT_SECONDS:50} # graph dao timeout seconds
      batchSize: ${ELASTICSEARCH_SEARCH_GRAPH_BATCH_SIZE:1000} # graph dao batch size
      enableMultiPathSearch: ${ELASTICSEARCH_SEARCH_GRAPH_MULTI_PATH_SEARCH:false} # allows a path to be retraversed to walk all paths to the node instead of just shortest, avoids cycles by not rewalking the visited edge
      boostViaNodes: ${ELASTICSEARCH_SEARCH_GRAPH_BOOST_VIA_NODES:true} # adds a boosting query that ranks graph edges with via nodes higher, used to allow via paths to be prioritized when multi path search is disabled
      graphStatusEnabled: ${ELASTICSEARCH_SEARCH_GRAPH_STATUS_ENABLED:false} # enable soft delete tracking of the urns on edges
      lineageMaxHops: ${ELASTICSEARCH_SEARCH_GRAPH_LINEAGE_MAX_HOPS:20} # the maximum hops to traverse lineage graph visualization
      pointInTimeCreationEnabled: ${ELASTICSEARCH_SEARCH_GRAPH_POINT_IN_TIME_CREATION_ENABLED:true} # enables creation of point in time snapshots for graph queries
      # Impact analysis configuration
      impact:
        maxHops: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_MAX_HOPS:1000} # the maximum hops to traverse for impact analysis
        maxRelations: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_MAX_RELATIONS:40000} # maximum number of relationships; use -1 or 0 for unlimited (only bound by time limit)
        slices: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_SLICES:${elasticsearch.dataNodeCount}} # number of slices for parallel search operations
        keepAlive: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_KEEP_ALIVE:55s} # Point-in-Time keepAlive duration for impact analysis queries
        partialResults: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_PARTIAL_RESULTS:false} # if true, return partial results when maxRelations is reached; if false (default), throw an error
        searchQueryTimeReservation: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_SEARCH_QUERY_TIME_RESERVATION:0.2} # fraction (0.0-1.0) of total timeout to reserve for second query phase when partialResults is enabled. Default: 0.2 (20%)
      maxThreads: ${ELASTICSEARCH_SEARCH_GRAPH_IMPACT_MAX_THREADS:16} # maximum parallel lineage graph queries
      queryOptimization: ${ELASTICSEARCH_SEARCH_GRAPH_QUERY_OPTIMIZATION:true} # reduce query nesting if possible
    validation:
      enabled: ${SEARCH_VALIDATION_ENABLED:true}
      maxLengthEnabled: ${SEARCH_VALIDATION_MAX_LENGTH_ENABLED:true}
      maxQueryLength: ${SEARCH_VALIDATION_MAX_QUERY_LENGTH:500}
      regex: ${SEARCH_VALIDATION_REGEX:.*[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]+.*|(?i).*\b(java|javax)\.(util|lang|io|naming|xml|security|beans|management|script|sql)\.(\w+\.)*\w+.*|(?i).*\b(org\.(springframework|apache|hibernate|jboss|codehaus|eclipse)|com\.sun)\.(\w+\.)*\w+.*|(?i).*(ldap://|rmi://|dns://|iiop://|corba:|jndi:|oastify\.com).*|.*(\u00ac\u00ed|\\xac\\xed).*}

# TODO: Kafka topic convention
kafka:
  setup:
    preCreateTopics: ${DATAHUB_PRECREATE_TOPICS:true}
    useConfluentSchemaRegistry: ${USE_CONFLUENT_SCHEMA_REGISTRY:false}

  # Topic defaults applied when individual topic configuration is missing
  topicDefaults:
    partitions: ${PARTITIONS:1}
    replicationFactor: ${REPLICATION_FACTOR:1}
    configProperties:
      max.message.bytes: ${MAX_MESSAGE_BYTES:5242880}

  topics:
    # Topic Dictionary Configuration - merged directly into topics section
    # Each topic can be created by iterating through this dictionary
    # The key name matches the programmatic identifier used in code
    metadataChangeProposal:
      name: ${METADATA_CHANGE_PROPOSAL_TOPIC_NAME:MetadataChangeProposal_v1}

    failedMetadataChangeProposal:
      name: ${FAILED_METADATA_CHANGE_PROPOSAL_TOPIC_NAME:FailedMetadataChangeProposal_v1}

    metadataChangeLogVersioned:
      name: ${METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME:MetadataChangeLog_Versioned_v1}

    metadataChangeLogTimeseries:
      name: ${METADATA_CHANGE_LOG_TIMESERIES_TOPIC_NAME:MetadataChangeLog_Timeseries_v1}
      configProperties:
        retention.ms: 7776000000

    platformEvent:
      name: ${PLATFORM_EVENT_TOPIC_NAME:PlatformEvent_v1}

    datahubUpgradeHistory:
      name: ${DATAHUB_UPGRADE_HISTORY_TOPIC_NAME:DataHubUpgradeHistory_v1}
      partitions: 1
      configProperties:
        retention.ms: -1

    datahubUsageEvent:
      name: ${DATAHUB_USAGE_EVENT_NAME:DataHubUsageEvent_v1}
      enabled: ${DATAHUB_ANALYTICS_ENABLED:true}

    cdcTopic:
      name: ${CDC_TOPIC_NAME:datahub.metadata_aspect_v2}
      enabled: ${CDC_MCL_PROCESSING_ENABLED:false}

    # Deprecated Topics (maintained for backward compatibility)
    metadataAuditEvent:
      name: ${METADATA_AUDIT_EVENT_NAME:MetadataAuditEvent_v4}
      enabled: false

    metadataChangeEvent:
      name: ${METADATA_CHANGE_EVENT_NAME:MetadataChangeEvent_v4}
      enabled: false

    failedMetadataChangeEvent:
      name: ${FAILED_METADATA_CHANGE_EVENT_NAME:FailedMetadataChangeEvent_v4}
      enabled: false

  listener:
    concurrency: ${KAFKA_LISTENER_CONCURRENCY:1}
  bootstrapServers: ${KAFKA_BOOTSTRAP_SERVER:http://localhost:9092}
  serde:
    usageEvent:
      key:
        serializer: ${KAFKA_SERDE_USAGE_EVENTS_KEY_SERIALIZER:org.apache.kafka.common.serialization.StringSerializer}
        deserializer: ${KAFKA_SERDE_USAGE_EVENTS_KEY_DESERIALIZER:org.apache.kafka.common.serialization.StringDeserializer}
      value:
        serializer: ${KAFKA_SERDE_USAGE_EVENTS_VALUE_SERIALIZER:org.apache.kafka.common.serialization.StringSerializer}
        deserializer: ${KAFKA_SERDE_USAGE_EVENTS_VALUE_DESERIALIZER:org.apache.kafka.common.serialization.StringDeserializer}
    event:
      key:
        serializer: ${KAFKA_SERDE_EVENT_KEY_SERIALIZER:org.apache.kafka.common.serialization.StringSerializer}
        deserializer: ${KAFKA_SERDE_EVENT_KEY_DESERIALIZER:org.springframework.kafka.support.serializer.ErrorHandlingDeserializer}
        delegateDeserializer: ${KAFKA_SERDE_EVENT_KEY_DELEGATE_DESERIALIZER:org.apache.kafka.common.serialization.StringDeserializer}
      value:
        serializer: ${KAFKA_SERDE_EVENT_VALUE_SERIALIZER:io.confluent.kafka.serializers.KafkaAvroSerializer}
        deserializer: ${KAFKA_SERDE_EVENT_VALUE_DESERIALIZER:org.springframework.kafka.support.serializer.ErrorHandlingDeserializer}
        delegateDeserializer: ${KAFKA_SERDE_EVENT_VALUE_DELEGATE_DESERIALIZER:io.confluent.kafka.serializers.KafkaAvroDeserializer}
    cdc:
      key:
        serializer: ${KAFKA_SERDE_CDC_KEY_SERIALIZER:org.apache.kafka.common.serialization.StringSerializer}
        deserializer: ${KAFKA_SERDE_CDC_KEY_DESERIALIZER:org.springframework.kafka.support.serializer.ErrorHandlingDeserializer}
        delegateDeserializer: ${KAFKA_SERDE_CDC_KEY_DELEGATE_DESERIALIZER:org.apache.kafka.common.serialization.StringDeserializer}
      value:
        serializer: ${KAFKA_SERDE_EVENT_VALUE_SERIALIZER:org.apache.kafka.common.serialization.StringSerializer}
        deserializer: ${KAFKA_SERDE_EVENT_VALUE_DESERIALIZER:org.springframework.kafka.support.serializer.ErrorHandlingDeserializer}
        delegateDeserializer: ${KAFKA_SERDE_EVENT_VALUE_DELEGATE_DESERIALIZER:org.apache.kafka.common.serialization.StringDeserializer}

  producer:
    bootstrapServers: ${KAFKA_PRODUCER_BOOTSTRAP_SERVER:} # Used as an override for the base setting for when split producer/consumer is desired
    retryCount: ${KAFKA_PRODUCER_RETRY_COUNT:3}
    deliveryTimeout: ${KAFKA_PRODUCER_DELIVERY_TIMEOUT:30000}
    requestTimeout: ${KAFKA_PRODUCER_REQUEST_TIMEOUT:3000}
    backoffTimeout: ${KAFKA_PRODUCER_BACKOFF_TIMEOUT:500}
    compressionType: ${KAFKA_PRODUCER_COMPRESSION_TYPE:snappy} # producer's compression algorithm
    maxRequestSize: ${KAFKA_PRODUCER_MAX_REQUEST_SIZE:5242880} # the max bytes sent by the producer, also see kafka-setup MAX_MESSAGE_BYTES for matching value
  consumer:
    bootstrapServers: ${KAFKA_CONSUMER_BOOTSTRAP_SERVER:} # Used as an override for the base setting for when split producer/consumer is desired
    maxPartitionFetchBytes: ${KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES:5242880} # the max bytes consumed per partition
    stopOnDeserializationError: ${KAFKA_CONSUMER_STOP_ON_DESERIALIZATION_ERROR:true} # Stops kafka listener container on deserialization error, allows user to fix problems before moving past problematic offset. If false will log and move forward past the offset
    healthCheckEnabled: ${KAFKA_CONSUMER_HEALTH_CHECK_ENABLED:true} # Sets the health indicator to down when a message listener container has stopped due to a deserialization failure, will force consumer apps to restart through k8s and docker-compose health mechanisms
    mcp:
      autoOffsetReset: ${KAFKA_CONSUMER_MCP_AUTO_OFFSET_RESET:earliest}
    mcl:
      autoOffsetReset: ${KAFKA_CONSUMER_MCL_AUTO_OFFSET_RESET:earliest}
      fineGrainedLoggingEnabled: ${KAFKA_CONSUMER_MCL_FINE_GRAINED_LOGGING_ENABLED:false}
      aspectsToDrop: ${KAFKA_CONSUMER_MCL_ASPECTS_TO_DROP:}
    pe:
      autoOffsetReset: ${KAFKA_CONSUMER_PE_AUTO_OFFSET_RESET:latest}
    metrics:
      percentiles: ${KAFKA_CONSUMER_PERCENTILES:0.5,0.95,0.99,0.999}
      slo: ${KAFKA_CONSUMER_SERVICE_LEVEL_OBJECTIVES:300,1800,3000,10800,21600,43200} # 5min, 30min, 1hr, 3hr, 6hr, 12h (seconds)
      maxExpectedValue: ${KAFKA_CONSUMER_MAX_EXPECTED_VALUE:86000} # 24h (seconds)

  # Consumer Pool - Used for Our Events API
  consumerPool:
    initialSize: ${KAFKA_CONSUMER_POOL_INITIAL_SIZE:1}
    maxSize: ${KAFKA_CONSUMER_POOL_MAX_SIZE:5}
    validationTimeoutSeconds: ${KAFKA_CONSUMER_POOL_VALIDATION_TIMEOUT_SECONDS:5}
    validationCacheIntervalMinutes: ${KAFKA_CONSUMER_POOL_VALIDATION_CACHE_INTERVAL_MINUTES:5}

  schemaRegistry:
    type: ${SCHEMA_REGISTRY_TYPE:KAFKA} # INTERNAL or KAFKA or AWS_GLUE
    url: ${KAFKA_SCHEMAREGISTRY_URL:http://localhost:8081}
    awsGlue:
      region: ${AWS_GLUE_SCHEMA_REGISTRY_REGION:us-east-1}
      registryName: ${AWS_GLUE_SCHEMA_REGISTRY_NAME:#{null}}
  schema:
    registry:
      security:
        protocol: ${KAFKA_PROPERTIES_SECURITY_PROTOCOL:PLAINTEXT}

# Only required if GraphService type is neo4j
neo4j:
  username: ${NEO4J_USERNAME:neo4j}
  password: ${NEO4J_PASSWORD:datahub}
  uri: ${NEO4J_URI:bolt://localhost}
  database: ${NEO4J_DATABASE:graph.db}
  maxConnectionPoolSize: ${NEO4J_MAX_CONNECTION_POOL_SIZE:100}
  maxConnectionAcquisitionTimeout: ${NEO4J_MAX_CONNECTION_ACQUISITION_TIMEOUT_IN_SECONDS:60}
  maxConnectionLifetimeInSeconds: ${NEO4j_MAX_CONNECTION_LIFETIME_IN_SECONDS:3600}
  maxTransactionRetryTime: ${NEO4J_MAX_TRANSACTION_RETRY_TIME_IN_SECONDS:30}
  connectionLivenessCheckTimeout: ${NEO4J_CONNECTION_LIVENESS_CHECK_TIMEOUT_IN_SECONDS:-1}

spring:
  error:
    include-message: never
    include-stacktrace: never
    include-exception: false
    whitelabel:
      enabled: false
  jmx:
    enabled: true
  web:
    resources:
      add-mappings: false # do not serve static files
  mvc:
    servlet:
      path: /
    throw-exception-if-no-handler-found: true # throw exception on 404 to be handled
  kafka:
    security:
      protocol: ${KAFKA_PROPERTIES_SECURITY_PROTOCOL:PLAINTEXT}
  autoconfigure:
    exclude:
      # We don't use these
      - org.springframework.boot.actuate.autoconfigure.cassandra.CassandraHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.cassandra.CassandraReactiveHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.elasticsearch.ElasticSearchRestHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.jms.JmsHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.ldap.LdapHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.mail.MailHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.mongo.MongoHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.mongo.MongoReactiveHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.neo4j.Neo4jHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.redis.RedisHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.redis.RedisReactiveHealthContributorAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.tracing.OpenTelemetryTracingAutoConfiguration
      # These are overridden with more complex configuration
      - org.springframework.boot.actuate.autoconfigure.tracing.otlp.OtlpAutoConfiguration
      - org.springframework.boot.actuate.autoconfigure.metrics.export.otlp.OtlpMetricsExportAutoConfiguration

management:
  health:
    defaults:
      enabled: false
  endpoints:
    web:
      exposure:
        include: prometheus,info,healthcheck,metrics
    jmx:
      enabled: true
  # Opentelemetry
  tracing:
    enabled: true
    propagation:
      type: W3C
  otlp:
    tracing:
      export:
        enabled: false
  # Micrometer Configuration
  metrics:
    cache:
      enabled: false
    export:
      jmx:
        enabled: ${MANAGEMENT_METRICS_EXPORT_JMX_ENABLED:true} # Enable jmx metrics export
      prometheus:
        enabled: ${MANAGEMENT_METRICS_EXPORT_PROMETHEUS_ENABLED:true} # Enable prometheus metrics export
    tags:
      application: ${spring.application.name}

# Useful to debug low-level Spring errors such as class version mismatches
#  error:
#    include-message: always
#    include-binding-errors: always
#    include-stacktrace: always

# GMS needs to have its context path, / is used when undefined, DATAHUB_GMS_BASE_PATH otherwise
server:
  server-header: false
  servlet:
    context-path: ${DATAHUB_GMS_BASE_PATH:/}

springdoc:
  cache:
    disabled: false
  swagger-ui:
    path: ${path-mappings.${datahub.basePath:}:${datahub.basePath:}}/openapi/swagger-ui
    disable-swagger-default-url: true
  api-docs:
    path: ${path-mappings.${datahub.basePath:}:${datahub.basePath:}}/openapi/v3/api-docs
    # Do not change this even though some APIs are using 3.1
    # Serialization of enum types will break
    version: openapi_3_0
  groups:
    enabled: true

metadataTests:
  enabled: ${METADATA_TESTS_ENABLED:false}

siblings:
  enabled: ${ENABLE_SIBLING_HOOK:true} # enable to turn on automatic sibling associations for dbt
  consumerGroupSuffix: ${SIBLINGS_HOOK_CONSUMER_GROUP_SUFFIX:}
updateIndices:
  enabled: ${ENABLE_UPDATE_INDICES_HOOK:true}
  consumerGroupSuffix: ${UPDATE_INDICES_CONSUMER_GROUP_SUFFIX:}
ingestionScheduler:
  enabled: ${ENABLE_INGESTION_SCHEDULER_HOOK:true} # enable to execute ingestion scheduling
  consumerGroupSuffix: ${INGESTION_SCHEDULER_HOOK_CONSUMER_GROUP_SUFFIX:}
incidents:
  hook:
    enabled: ${ENABLE_INCIDENTS_HOOK:true}
    maxIncidentHistory: ${MAX_INCIDENT_HISTORY:100}
    consumerGroupSuffix: ${INCIDENTS_HOOK_CONSUMER_GROUP_SUFFIX:}

bootstrap:
  policies:
    file: ${BOOTSTRAP_POLICIES_FILE:classpath:boot/policies.json}
    # eg for local file
    # file: "file:///datahub/datahub-gms/resources/custom-policies.json"
  servlets:
    waitTimeout: ${BOOTSTRAP_SERVLETS_WAITTIMEOUT:60} # Total waiting time in seconds for servlets to initialize

systemUpdate:
  initialBackOffMs: ${BOOTSTRAP_SYSTEM_UPDATE_INITIAL_BACK_OFF_MILLIS:5000}
  maxBackOffs: ${BOOTSTRAP_SYSTEM_UPDATE_MAX_BACK_OFFS:50}
  backOffFactor: ${BOOTSTRAP_SYSTEM_UPDATE_BACK_OFF_FACTOR:2} # Multiplicative factor for back off, default values will result in waiting 5min 15s
  waitForSystemUpdate: ${BOOTSTRAP_SYSTEM_UPDATE_WAIT_FOR_SYSTEM_UPDATE:true}
  cdcMode: ${SYSTEM_UPDATE_CDC_MODE:false}
  bootstrap:
    mcpConfig: ${SYSTEM_UPDATE_BOOTSTRAP_MCP_CONFIG:bootstrap_mcps.yaml}
  dataJobNodeCLL:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_DATA_JOB_NODE_CLL_ENABLED:false}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_DATA_JOB_NODE_CLL_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_DATA_JOB_NODE_CLL_DELAY_MS:30000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_DATA_JOB_NODE_CLL_LIMIT:0}
  domainDescription:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_DOMAIN_DESCRIPTION_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_DOMAIN_DESCRIPTION_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_DOMAIN_DESCRIPTION_DELAY_MS:30000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_DOMAIN_DESCRIPTION_CLL_LIMIT:0}
  chartInfo:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_CHART_INFO_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_CHART_INFO_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_CHART_INFO_DELAY_MS:30000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_CHART_INFO_CLL_LIMIT:0}
  mlModel:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_DELAY_MS:30000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_CLL_LIMIT:0}
  mlModelGroup:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_GROUP_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_GROUP_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_GROUP_DELAY_MS:30000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_ML_MODEL_GROUP_CLL_LIMIT:0}
  dashboardInfo:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_DASHBOARD_INFO_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_DASHBOARD_INFO_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_DASHBOARD_INFO_DELAY_MS:30000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_DASHBOARD_INFO_CLL_LIMIT:0}
  browsePathsV2:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_BROWSE_PATHS_V2_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_BROWSE_PATHS_V2_BATCH_SIZE:5000}
    reprocess:
      enabled: ${REPROCESS_DEFAULT_BROWSE_PATHS_V2:false}
  browsePathsV2Iceberg:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_BROWSE_PATHS_V2_ICEBERG_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_BROWSE_PATHS_V2_ICEBERG_BATCH_SIZE:5000}
  ingestionIndices:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_INGESTION_INDICES_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_INGESTION_INDICES_BATCH_SIZE:5000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_INGESTION_INDICES_DELAY_MS:1000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_INGESTION_INDICES_CLL_LIMIT:0}
  policyFields:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_POLICY_FIELDS_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_POLICY_FIELDS_BATCH_SIZE:5000}
    reprocess:
      enabled: ${REPROCESS_DEFAULT_POLICY_FIELDS:false}
  ownershipTypes:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_OWNERSHIP_TYPES_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_OWNERSHIP_TYPES_BATCH_SIZE:1000}
    reprocess:
      enabled: ${BOOTSTRAP_SYSTEM_UPDATE_OWNERSHIP_TYPES_REPROCESS:false}
  lineageIndexFields:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_LINEAGE_INDEX_FIELDS_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_LINEAGE_INDEX_FIELDS_BATCH_SIZE:100}
    reprocess:
      enabled: ${BOOTSTRAP_SYSTEM_UPDATE_LINEAGE_INDEX_FIELDS_REPROCESS:false}
  schemaFieldsFromSchemaMetadata:
    enabled: ${SYSTEM_UPDATE_SCHEMA_FIELDS_FROM_SCHEMA_METADATA_ENABLED:false}
    batchSize: ${SYSTEM_UPDATE_SCHEMA_FIELDS_FROM_SCHEMA_METADATA_BATCH_SIZE:500}
    delayMs: ${SYSTEM_UPDATE_SCHEMA_FIELDS_FROM_SCHEMA_METADATA_DELAY_MS:1000}
    limit: ${SYSTEM_UPDATE_SCHEMA_FIELDS_FROM_SCHEMA_METADATA_LIMIT:0}
  schemaFieldsDocIds:
    enabled: ${SYSTEM_UPDATE_SCHEMA_FIELDS_DOC_IDS_ENABLED:false}
    batchSize: ${SYSTEM_UPDATE_SCHEMA_FIELDS_DOC_IDS_BATCH_SIZE:500}
    delayMs: ${SYSTEM_UPDATE_SCHEMA_FIELDS_DOC_IDS_DELAY_MS:5000}
    limit: ${SYSTEM_UPDATE_SCHEMA_FIELDS_DOC_IDS_LIMIT:0}
  processInstanceHasRunEvents:
    enabled: ${SYSTEM_UPDATE_PROCESS_INSTANCE_HAS_RUN_EVENTS_ENABLED:true}
    batchSize: ${SYSTEM_UPDATE_PROCESS_INSTANCE_HAS_RUN_EVENTS_BATCH_SIZE:100}
    delayMs: ${SYSTEM_UPDATE_PROCESS_INSTANCE_HAS_RUN_EVENTS_DELAY_MS:1000}
    totalDays: ${SYSTEM_UPDATE_PROCESS_INSTANCE_HAS_RUN_EVENTS_TOTAL_DAYS:90}
    windowDays: ${SYSTEM_UPDATE_PROCESS_INSTANCE_HAS_RUN_EVENTS_WINDOW_DAYS:1}
    reprocess:
      enabled: ${SYSTEM_UPDATE_PROCESS_INSTANCE_HAS_RUN_EVENTS_REPROCESS:false}
  edgeStatus:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_EDGE_STATUS_ENABLED:false}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_EDGE_STATUS_BATCH_SIZE:1000}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_EDGE_STATUS_DELAY_MS:5000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_EDGE_STATUS_LIMIT:0}
  propertyDefinitions:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_PROPERTY_DEFINITIONS_ENABLED:true}
    batchSize: ${BOOTSTRAP_SYSTEM_UPDATE_PROPERTY_DEFINITIONS_BATCH_SIZE:500}
    delayMs: ${BOOTSTRAP_SYSTEM_UPDATE_PROPERTY_DEFINITIONS_DELAY_MS:1000}
    limit: ${BOOTSTRAP_SYSTEM_UPDATE_PROPERTY_DEFINITIONS_CLL_LIMIT:0}
  removeQueryEdges:
    enabled: ${BOOTSTRAP_SYSTEM_UPDATE_REMOVE_QUERY_EDGES_ENABLED:true}
    numRetries: ${BOOTSTRAP_SYSTEM_UPDATE_REMOVE_QUERY_EDGES_RETRIES:20}
  entityConsistency:
    enabled: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_ENABLED:true}
    dryRun: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_DRY_RUN:true}  # Set to false to apply fixes
    batchSize: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_BATCH_SIZE:100}
    delayMs: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_DELAY_MS:1000}
    gracePeriodSeconds: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_GRACE_PERIOD_SECONDS:14400}  # 4 hours - exclude recently modified entities to avoid eventual consistency false positives
    limit: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_LIMIT:0}
    entityTypes: []  # Entity types to check. Empty = all types with registered checks.
    checkIds: []  # Check IDs to run. Empty = all default checks for the entity types.
    reprocess:
      enabled: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_REPROCESS:false}
    systemMetadataFilterConfig:  # Optional filtering via system metadata index
      gePitEpochMs: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_GE_PIT_EPOCH_MS:}  # Only entities modified >= this timestamp (uses aspectModifiedTime/aspectCreatedTime)
      lePitEpochMs: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_LE_PIT_EPOCH_MS:}  # Only entities modified <= this timestamp (uses aspectModifiedTime/aspectCreatedTime)
      aspectFilters: []  # Only entities with ANY of these aspects (OR semantics)
      includeSoftDeleted: ${SYSTEM_UPDATE_ENTITY_CONSISTENCY_INCLUDE_SOFT_DELETED:false}  # Include soft-deleted entities (default: false)

structuredProperties:
  enabled: ${ENABLE_STRUCTURED_PROPERTIES_HOOK:true} # applies structured properties mappings
  writeEnabled: ${ENABLE_STRUCTURED_PROPERTIES_WRITE:true} # write structured property values
  systemUpdateEnabled: ${ENABLE_STRUCTURED_PROPERTIES_SYSTEM_UPDATE:false} # applies structured property mappings in system update job

# Consistency check configuration (shared by upgrade job and API endpoints)
consistencyChecks:
  gracePeriodSeconds: ${CONSISTENCY_CHECKS_GRACE_PERIOD_SECONDS:300}  # 5 minutes - default for API endpoints
  checks:
    # Per-check configuration, keyed by check ID
    assertion-monitor-missing:
      defaultCronSchedule: ${CONSISTENCY_CHECK_ASSERTION_MONITOR_MISSING_CRON:0 0 0 * * ?}
      defaultCronTimezone: ${CONSISTENCY_CHECK_ASSERTION_MONITOR_MISSING_TIMEZONE:UTC}

healthCheck:
  cacheDurationSeconds: ${HEALTH_CHECK_CACHE_DURATION_SECONDS:5}

featureFlags:
  showSimplifiedHomepageByDefault: ${SHOW_SIMPLIFIED_HOMEPAGE_BY_DEFAULT:false} # Deprecated in new UI. Shows a simplified homepage with just datasets, charts and dashboards by default to users. this can be configured in user settings
  lineageSearchCacheEnabled: ${LINEAGE_SEARCH_CACHE_ENABLED:true} # Enables in-memory cache for searchAcrossLineage query
  graphServiceDiffModeEnabled: ${GRAPH_SERVICE_DIFF_MODE_ENABLED:true} # Enables diff mode for graph writes, uses a different code path that produces a diff from previous to next to write relationships instead of wholesale deleting edges and reading
  alwaysEmitChangeLog: ${ALWAYS_EMIT_CHANGE_LOG:false} # Enables always emitting a MCL even when no changes are detected. Used for Time Based Lineage when no changes occur.
  cdcModeChangeLog: ${CDC_MCL_PROCESSING_ENABLED:false} # Enables CDCs to be used to generate MCLs. When false, GMS generates MCLs based on MCPs
  searchServiceDiffModeEnabled: ${SEARCH_SERVICE_DIFF_MODE_ENABLED:true} # Enables diff mode for search document writes, reduces amount of writes to ElasticSearch documents for no-ops
  readOnlyModeEnabled: ${READ_ONLY_MODE_ENABLED:false} # Enables read only mode for an instance. Right now this only affects ability to edit user profile image URL but can be extended
  showAccessManagement: ${SHOW_ACCESS_MANAGEMENT:false} #Whether we should show AccessManagement tab in the datahub UI.
  showSearchFiltersV2: ${SHOW_SEARCH_FILTERS_V2:true} # Enables showing the search filters V2 experience.
  showBrowseV2: ${SHOW_BROWSE_V2:true} # Enables showing the browse v2 sidebar experience.
  platformBrowseV2: ${PLATFORM_BROWSE_V2:true} # Enables the platform browse experience, instead of the entity-oriented browse default.
  lineageGraphV2: ${LINEAGE_GRAPH_V2:true} # Enables the new lineage visualization.
  preProcessHooks:
    uiEnabled: ${PRE_PROCESS_HOOKS_UI_ENABLED:true} # Circumvents Kafka for processing index updates for UI changes sourced from GraphQL to avoid processing delays
    reprocessEnabled: ${PRE_PROCESS_HOOKS_UI_ENABLED:false} # If enabled, will reprocess UI sourced events asynchronously when reading from Kafka after pre-processing them synchronously
  showAcrylInfo: ${SHOW_ACRYL_INFO:false} # Show different CTAs within DataHub around moving to DataHub Cloud. Set to true for the demo site.
  erModelRelationshipFeatureEnabled: ${ER_MODEL_RELATIONSHIP_FEATURE_ENABLED:false} # Enable Join Tables Feature and show within Dataset view as Relations
  nestedDomainsEnabled: ${NESTED_DOMAINS_ENABLED:true} # Enables the nested Domains feature that allows users to have sub-Domains. If this is off, Domains appear "flat" again
  schemaFieldEntityFetchEnabled: ${SCHEMA_FIELD_ENTITY_FETCH_ENABLED:true} # Enables fetching for schema field entities from the database when we hydrate them on schema fields
  businessAttributeEntityEnabled: ${BUSINESS_ATTRIBUTE_ENTITY_ENABLED:false} # Enables business attribute entity which can be associated with field of dataset
  dataContractsEnabled: ${DATA_CONTRACTS_ENABLED:true} # Enables the Data Contracts feature (Tab) in the UI
  alternateMCPValidation: ${ALTERNATE_MCP_VALIDATION:false} # Enables alternate MCP validation flow
  themeV2Enabled: ${THEME_V2_ENABLED:true} # Allows theme v2 to be turned on. One of themeV2Default and themeV2Toggleable must be false for this to have any effect.
  themeV2Default: ${THEME_V2_DEFAULT:true} # Sets the default theme for users. The default is the only available theme if theme is not toggleable.
  themeV2Toggleable: ${THEME_V2_TOGGLEABLE:true} # Acryl only! Allows theme v2 to be toggled on / off by users.
  schemaFieldCLLEnabled: ${SCHEMA_FIELD_CLL_ENABLED:false} # Enables links to schema field-level lineage on lineage explorer and columns tab
  schemaFieldLineageIgnoreStatus: ${SCHEMA_FIELD_LINEAGE_IGNORE_STATUS:true} # If turned on, schema field lineage will always fetch ghost entities
  showSeparateSiblings: ${SHOW_SEPARATE_SIBLINGS:false} # If turned on, all siblings will be separated with no way to get to a "combined" sibling view
  editableDatasetNameEnabled: ${EDITABLE_DATASET_NAME_ENABLED:false} # Enables the ability to edit the dataset name in the UI
  showManageStructuredProperties: ${SHOW_MANAGE_STRUCTURED_PROPERTIES:true} # If turned on, show the manage structured properties button on the govern dropdown
  hideDbtSourceInLineage: ${HIDE_DBT_SOURCE_IN_LINEAGE:false} # If turned on, dbt sources will not be shown in lineage
  showNavBarRedesign: ${SHOW_NAV_BAR_REDESIGN:true} # If turned on, show the newly designed nav bar in the V2 experience
  showAutoCompleteResults: ${SHOW_AUTO_COMPLETE_RESULTS:true} # If turned on, show the auto complete results in the search bar
  entityVersioning: ${ENTITY_VERSIONING_ENABLED:false} # Enables entity versioning APIs, validators, and side effects
  showHasSiblingsFilter: ${SHOW_HAS_SIBLINGS_FILTER:false} # If turned on, the "has siblings" filter will be visible in search results page
  showSearchBarAutocompleteRedesign: ${SHOW_SEARCH_BAR_AUTOCOMPLETE_REDESIGN:false} # If turned on, show the redesigned search bar's autocomplete
  showManageTags: ${SHOW_MANAGE_TAGS:true} # If turned on, allow users to manage tags in the UI
  showIntroducePage: ${SHOW_INTRODUCE_PAGE:true} # If turned on, we will show the introduce page in the V2 UI experience to add a title and select platforms
  showIngestionPageRedesign: ${SHOW_INGESTION_PAGE_REDESIGN:false} # If turned on, show the re-designed Ingestion page
  ingestionOnboardingRedesignV1: ${INGESTION_ONBOARDING_REDESIGN_V1:false} # If turned on, show the redesigned ingestion onboarding experience
  showLineageExpandMore: ${SHOW_LINEAGE_EXPAND_MORE:true} # If turned on, show the expand more button (>>) in the lineage graph
  showStatsTabRedesign: ${SHOW_STATS_TAB_REDESIGN:true} # If turned on, show the re-designed Stats tab on the entity page
  showHomePageRedesign: ${SHOW_HOME_PAGE_REDESIGN:false} # If turned on, show the re-designed home page
  lineageGraphV3: ${LINEAGE_GRAPH_V3:false} # Enables the redesign of the lineage v2 graph
  showProductUpdates: ${SHOW_PRODUCT_UPDATES:true} # Whether to show in-product update popover on new updates.
  productUpdatesJsonUrl: ${PRODUCT_UPDATES_JSON_URL:https://product.datahub.com/updates/datahub-core} # URL to fetch product updates JSON from remote source.
  # for Saas:
  #productUpdatesJsonUrl: ${PRODUCT_UPDATES_JSON_URL:https://product.datahub.com/updates/datahub-cloud} # URL to fetch product updates JSON from remote source.
  productUpdatesJsonFallbackResource: ${PRODUCT_UPDATES_JSON_FALLBACK_RESOURCE:product-update.json} # Classpath resource to use as fallback when remote fetch fails.
  logicalModelsEnabled: ${LOGICAL_MODELS_ENABLED:false} # Enables logical models feature
  showHomepageUserRole: ${SHOW_HOMEPAGE_USER_ROLE:false} # Enables displaying the homepage user role underneath the name. Only relevant for custom home page
  fineGrainedLineageNotAllowedForPlatforms: ${FINE_GRAINED_LINEAGE_NOT_ALLOWED_FOR_PLATFORMS:} # Comma separated list of platforms for which schemaFields entity edges will not be allowed to be created. for example: "hdfs, s3"
  assetSummaryPageV1: ${ASSET_SUMMARY_PAGE_V1:false} # Enables displaying the asset summary page
  datasetSummaryPageV1: ${DATASET_SUMMARY_PAGE_V1:false} # Enables displaying the dataset summary page
  showDefaultExternalLinks: ${SHOW_DEFAULT_EXTERNAL_LINKS:true} # If turned on, show the default external links on the entity page
  documentationFileUploadV1: ${DOCUMENTATION_FILE_UPLOAD_V1:false} # Enables uploading of files for documentation
  contextDocumentsEnabled: ${CONTEXT_DOCUMENTS_ENABLED:true} # Enables the context documents feature in the sidebar

entityChangeEvents:
  enabled: ${ENABLE_ENTITY_CHANGE_EVENTS_HOOK:true}
  consumerGroupSuffix: ${ECE_CONSUMER_GROUP_SUFFIX:}
  entityExclusions: ${ECE_ENTITY_EXCLUSIONS:schemaField} # provides a comma separated list of entities to exclude from the ECE hook

views:
  enabled: ${VIEWS_ENABLED:true}

searchBar:
  apiVariant: ${SEARCH_BAR_API_VARIANT:AUTOCOMPLETE_FOR_MULTIPLE}

searchCard:
  showDescription: ${SEARCH_CARD_SHOW_DESCRIPTION:false}

searchFlags:
  defaultSkipHighlighting: ${DEFAULT_SKIP_HIGHLIGHTING:false}

homePage:
  firstInPersonalSidebar: ${FIRST_IN_PERSONAL_SIDEBAR:YOUR_ASSETS}

entityClient:
  retryInterval: ${ENTITY_CLIENT_RETRY_INTERVAL:2}
  numRetries: ${ENTITY_CLIENT_NUM_RETRIES:3}
  java:
    get:
      batchSize: ${ENTITY_CLIENT_JAVA_GET_BATCH_SIZE:375} # matches EbeanAspectDao batch size
    ingest:
      batchSize: ${ENTITY_CLIENT_JAVA_INGEST_BATCH_SIZE:375}
  restli:
    get:
      batchSize: ${ENTITY_CLIENT_RESTLI_GET_BATCH_SIZE:100} # limited to prevent exceeding restli URI size limit
      batchConcurrency: ${ENTITY_CLIENT_RESTLI_GET_BATCH_CONCURRENCY:2} # parallel threads
      batchQueueSize: ${ENTITY_CLIENT_RESTLI_GET_BATCH_QUEUE_SIZE:500}
      batchThreadKeepAlive: ${ENTITY_CLIENT_RESTLI_GET_BATCH_THREAD_KEEP_ALIVE:60}
    ingest:
      batchSize: ${ENTITY_CLIENT_RESTLI_INGEST_BATCH_SIZE:50} # limited to prevent exceeding restli timeouts
      batchConcurrency: ${ENTITY_CLIENT_RESTLI_INGEST_BATCH_CONCURRENCY:2} # parallel threads
      batchQueueSize: ${ENTITY_CLIENT_RESTLI_INGEST_BATCH_QUEUE_SIZE:500}
      batchThreadKeepAlive: ${ENTITY_CLIENT_RESTLI_INGEST_BATCH_THREAD_KEEP_ALIVE:60}

usageClient:
  retryInterval: ${USAGE_CLIENT_RETRY_INTERVAL:2}
  numRetries: ${USAGE_CLIENT_NUM_RETRIES:0}
  timeoutMs: ${USAGE_CLIENT_TIMEOUT_MS:3000}

cache:
  primary:
    ttlSeconds: ${CACHE_TTL_SECONDS:600}
    maxSize: ${CACHE_MAX_SIZE:10000}
  homepage:
    entityCounts:
      ttlSeconds: ${CACHE_ENTITY_COUNTS_TTL_SECONDS:600}
  search:
    lineage:
      ttlSeconds: ${CACHE_SEARCH_LINEAGE_TTL_SECONDS:86400} # 1 day
      lightningThreshold: ${CACHE_SEARCH_LINEAGE_LIGHTNING_THRESHOLD:300}
  client:
    usageClient:
      enabled: ${CACHE_CLIENT_USAGE_CLIENT_ENABLED:true}
      statsEnabled: ${CACHE_CLIENT_USAGE_CLIENT_STATS_ENABLED:true}
      statsIntervalSeconds: ${CACHE_CLIENT_USAGE_CLIENT_STATS_INTERVAL_SECONDS:120}
      defaultTTLSeconds: ${CACHE_CLIENT_USAGE_CLIENT_TTL_SECONDS:86400} # 1 day
      maxBytes: ${CACHE_CLIENT_USAGE_CLIENT_MAX_BYTES:52428800} # 50MB
    entityClient:
      enabled: ${CACHE_CLIENT_ENTITY_CLIENT_ENABLED:true}
      statsEnabled: ${CACHE_CLIENT_ENTITY_CLIENT_STATS_ENABLED:true}
      statsIntervalSeconds: ${CACHE_CLIENT_ENTITY_CLIENT_STATS_INTERVAL_SECONDS:120}
      defaultTTLSeconds: ${CACHE_CLIENT_ENTITY_CLIENT_TTL_SECONDS:0} # do not cache entity/aspects by default
      maxBytes: ${CACHE_CLIENT_ENTITY_CLIENT_MAX_BYTES:104857600} # 100MB
      entityAspectTTLSeconds:
        # cache user aspects for 20s
        corpuser:
          corpUserKey: 300 # 5 min
          corpUserInfo: 20
          corpUserEditableInfo: 20
          corpUserStatus: 300 # 5 min
          globalTags: 20
          status: 300 # 5 min
          corpUserCredentials: 20
          corpUserSettings: 20
          roleMembership: 20
          groupMembership: 20
          nativeGroupMembership: 20
        structuredProperty:
          status: 300 # 5 min
          propertyDefinition: 300 # 5 min
          structuredPropertyKey: 86400 # 1 day
        chart:
          usageFeatures: 21600 # 6hrs
        dataset:
          usageFeatures: 21600 # 6hrs
          storageFeatures: 21600 # 6hrs
        dashboard:
          dashboardUsageStatistics: 21600 # 6hrs
        telemetry:
          telemetryClientId: 86400 # 1 day

graphQL:
  graphiql:
    # Enable/disable the GraphiQL interactive query interface at /api/graphiql
    enabled: ${GRAPHQL_GRAPHIQL_ENABLED:true}
  concurrency:
    separateThreadPool: ${GRAPHQL_CONCURRENCY_SEPARATE_THREAD_POOL:false} # Enable the separate thread pool, the following configurations only apply if enabled
    stackSize: ${GRAPHQL_CONCURRENCY_STACK_SIZE:256000} # Default to JVM default of 256 KB
    corePoolSize: ${GRAPHQL_CONCURRENCY_CORE_POOL_SIZE:-1} # Base thread pool size for GraphQL executor service, default 5 * # of cores
    maxPoolSize: ${GRAPHQL_CONCURRENCY_MAX_POOL_SIZE:-1} # Maximum thread pool size for GraphQL executor service, default 100 * # of cores
    keepAlive: ${GRAPHQL_CONCURRENCY_KEEP_ALIVE:60} # Number of seconds to keep inactive threads alive
  query:
    complexityLimit: ${GRAPHQL_QUERY_COMPLEXITY_LIMIT:2000}
    depthLimit: ${GRAPHQL_QUERY_DEPTH_LIMIT:50}
    introspectionEnabled: ${GRAPHQL_QUERY_INTROSPECTION_ENABLED:true}
  metrics:
    # Master switch for all GraphQL metrics collection via Micrometer
    # When false, no GraphQL metrics are collected (request-level or field-level)
    enabled: ${GRAPHQL_METRICS_ENABLED:true}
    percentiles: ${GRAPHQL_PERCENTILES:0.5,0.75,0.95,0.98,0.99,0.999} # set to legacy percentiles by default

    # Enable field-level resolver metrics collection
    # When true, timing metrics are collected for individual GraphQL field resolvers
    # This can add overhead for queries with many fields, so consider enabling selectively
    # Metrics include: graphql.field.duration, graphql.field.errors
    fieldLevelEnabled: ${GRAPHQL_METRICS_FIELD_LEVEL_ENABLED:false}

    # Comma-delimited list of GraphQL operation names to instrument at field level
    # When specified, only these operations will have field-level metrics collected
    # Empty or unset means all operations are instrumented (if fieldLevelEnabled=true)
    # Example: "getSearchResultsForMultiple,searchAcrossLineageStructure"
    # Use case: Enable detailed metrics only for known slow or critical operations
    fieldLevelOperations: ${GRAPHQL_METRICS_FIELD_LEVEL_OPERATIONS:getSearchResultsForMultiple,searchAcrossLineageStructure}

    # Include the field path as a tag in field-level metrics
    # WARNING: Can cause high cardinality if your schema has array fields
    # Paths are truncated to replace array indices with * (e.g., /users/0/name -> /users/*/name)
    # Only enable for debugging specific issues, not recommended for production
    fieldLevelPathEnabled: ${GRAPHQL_METRICS_FIELD_LEVEL_PATH_ENABLED:false}

    # Comma-delimited list of GraphQL field path patterns to instrument
    # Works in conjunction with fieldLevelOperations - both conditions must match if both are set
    # Pattern syntax:
    #   - /user/posts/* - matches direct children of posts (e.g., /user/posts/title)
    #   - /user/posts/** - matches posts and all descendants
    #   - /*/comments/* - matches comments under any parent
    # Empty or unset means all paths are instrumented (if fieldLevelEnabled=true)
    # Example: "/user/posts/**,/search/results/*,/**/comments"
    # Use case: Focus metrics on specific parts of your schema known to be slow
    fieldLevelPaths: ${GRAPHQL_METRICS_FIELD_LEVEL_PATHS:}

    # Include metrics for trivial data fetchers (simple property access from objects)
    # These are usually very fast and numerous, so excluding them reduces metric volume
    # Only enable if you suspect performance issues with object property access
    trivialDataFetchersEnabled: ${GRAPHQL_METRICS_TRIVIAL_DATA_FETCHERS_ENABLED:false}

chromeExtension:
  enabled: ${CHROME_EXTENSION_ENABLED:true}
  lineageEnabled: ${CHROME_EXTENSION_LINEAGE_ENABLED:true}

forms:
  hook:
    enabled: ${FORMS_HOOK_ENABLED:true}
    consumerGroupSuffix: ${FORMS_HOOK_CONSUMER_GROUP_SUFFIX:}

businessAttribute:
  fetchRelatedEntitiesCount: ${BUSINESS_ATTRIBUTE_RELATED_ENTITIES_COUNT:20000}
  fetchRelatedEntitiesBatchSize: ${BUSINESS_ATTRIBUTE_RELATED_ENTITIES_BATCH_SIZE:1000}
  threadCount: ${BUSINESS_ATTRIBUTE_PROPAGATION_CONCURRENCY_THREAD_COUNT:-1} # Thread Pool size, default 2 * # of cores
  keepAliveTime: ${BUSINESS_ATTRIBUTE_PROPAGATION_CONCURRENCY_KEEP_ALIVE:60} # Number of seconds to keep inactive threads alive

metadataChangeProposal:
  consumer:
    batch:
      enabled: ${MCP_CONSUMER_BATCH_ENABLED:false}
      size: ${MCP_CONSUMER_BATCH_SIZE:15744000}
  validation:
    ignoreUnknown: ${MCP_VALIDATION_IGNORE_UNKNOWN:true}
    privilegeConstraints:
      enabled: ${MCP_VALIDATION_PRIVILEGE_CONSTRAINTS:true}
    extensions:
      enabled: ${MCP_VALIDATION_EXTENSIONS_ENABLED:false}
  sideEffects:
    schemaField:
      enabled: ${MCP_SIDE_EFFECTS_SCHEMA_FIELD_ENABLED:false}
    dataProductUnset:
      enabled: ${MCP_SIDE_EFFECTS_DATA_PRODUCT_UNSET_ENABLED:true}
  throttle:
    updateIntervalMs: ${MCP_THROTTLE_UPDATE_INTERVAL_MS:60000}

    # What component is throttled
    components:
      mceConsumer:
        enabled: ${MCP_MCE_CONSUMER_THROTTLE_ENABLED:false}
      apiRequests:
        enabled: ${MCP_API_REQUESTS_THROTTLE_ENABLED:false}

    # How is it throttled
    # Versioned MCL topic settings
    versioned:
      # Whether to monitor MCL versioned backlog
      enabled: ${MCP_VERSIONED_THROTTLE_ENABLED:false}
      threshold: ${MCP_VERSIONED_THRESHOLD:4000} # throttle threshold
      maxAttempts: ${MCP_VERSIONED_MAX_ATTEMPTS:1000}
      initialIntervalMs: ${MCP_VERSIONED_INITIAL_INTERVAL_MS:100}
      multiplier: ${MCP_VERSIONED_MULTIPLIER:10}
      maxIntervalMs: ${MCP_VERSIONED_MAX_INTERVAL_MS:30000}

    # Timeseries MCL topic settings
    timeseries:
      # Whether to monitor MCL timeseries backlog
      enabled: ${MCP_TIMESERIES_THROTTLE_ENABLED:false}
      threshold: ${MCP_TIMESERIES_THRESHOLD:4000} # throttle threshold
      maxAttempts: ${MCP_TIMESERIES_MAX_ATTEMPTS:1000}
      initialIntervalMs: ${MCP_TIMESERIES_INITIAL_INTERVAL_MS:100}
      multiplier: ${MCP_TIMESERIES_MULTIPLIER:10}
      maxIntervalMs: ${MCP_TIMESERIES_MAX_INTERVAL_MS:30000}

metadataChangeLog:
  consumer:
    batch:
      enabled: ${MCL_CONSUMER_BATCH_ENABLED:false}
      size: ${MCL_CONSUMER_BATCH_SIZE:1048576}

eventsApi:
  enabled: ${EVENTS_API_ENABLED:true}

icebergCatalog:
  enablePublicRead: ${ENABLE_PUBLIC_READ:false}
  publiclyReadableTag: ${PUBLICLY_READABLE_TAG:PUBLICLY_READABLE}
