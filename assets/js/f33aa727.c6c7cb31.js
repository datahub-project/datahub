"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[84263],{15680:(e,n,t)=>{t.d(n,{xA:()=>d,yg:()=>p});var a=t(96540);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),c=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},d=function(e){var n=c(e.components);return a.createElement(l.Provider,{value:n},e.children)},g="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),g=c(t),u=r,p=g["".concat(l,".").concat(u)]||g[u]||m[u]||i;return t?a.createElement(p,o(o({ref:n},d),{},{components:t})):a.createElement(p,o({ref:n},d))}));function p(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=u;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[g]="string"==typeof e?e:r,o[1]=s;for(var c=2;c<i;c++)o[c]=t[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},36229:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>c,toc:()=>g});t(96540);var a=t(15680);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))})),e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}const s={title:"Semantic Search Architecture",slug:"/dev-guides/semantic-search/architecture",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/dev-guides/semantic-search/ARCHITECTURE.md"},l="Semantic Search Architecture",c={unversionedId:"docs/dev-guides/semantic-search/ARCHITECTURE",id:"docs/dev-guides/semantic-search/ARCHITECTURE",title:"Semantic Search Architecture",description:"This document provides a detailed explanation of DataHub's semantic search architecture, design decisions, and implementation details.",source:"@site/genDocs/docs/dev-guides/semantic-search/ARCHITECTURE.md",sourceDirName:"docs/dev-guides/semantic-search",slug:"/dev-guides/semantic-search/architecture",permalink:"/docs/dev-guides/semantic-search/architecture",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/dev-guides/semantic-search/ARCHITECTURE.md",tags:[],version:"current",frontMatter:{title:"Semantic Search Architecture",slug:"/dev-guides/semantic-search/architecture",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/dev-guides/semantic-search/ARCHITECTURE.md"},sidebar:"overviewSidebar",previous:{title:"Semantic Search",permalink:"/docs/dev-guides/semantic-search"},next:{title:"Semantic Search Configuration Guide",permalink:"/docs/dev-guides/semantic-search/configuration"}},d={},g=[{value:"Design Philosophy",id:"design-philosophy",level:2},{value:"Why Semantic Search?",id:"why-semantic-search",level:3},{value:"Core Principles",id:"core-principles",level:3},{value:"Index Architecture",id:"index-architecture",level:2},{value:"Dual-Index Strategy",id:"dual-index-strategy",level:3},{value:"Why Separate Indices? (Transitional Architecture)",id:"why-separate-indices-transitional-architecture",level:3},{value:"Embeddings Schema",id:"embeddings-schema",level:3},{value:"Multi-Model Support",id:"multi-model-support",level:3},{value:"Data Flow",id:"data-flow",level:2},{value:"Ingestion Flow",id:"ingestion-flow",level:3},{value:"Embedding Generation",id:"embedding-generation",level:3},{value:"MCP-Based Embedding Flow",id:"mcp-based-embedding-flow",level:4},{value:"SemanticContent Aspect",id:"semanticcontent-aspect",level:4},{value:"Privacy-Sensitive Use Cases",id:"privacy-sensitive-use-cases",level:4},{value:"Query Flow",id:"query-flow",level:3},{value:"Chunking Strategy",id:"chunking-strategy",level:2},{value:"Why Chunk Documents?",id:"why-chunk-documents",level:3},{value:"Chunking Algorithm",id:"chunking-algorithm",level:3},{value:"Chunk Metadata",id:"chunk-metadata",level:3},{value:"k-NN Search Configuration",id:"k-nn-search-configuration",level:2},{value:"OpenSearch k-NN Settings",id:"opensearch-k-nn-settings",level:3},{value:"HNSW Parameters",id:"hnsw-parameters",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"Data Privacy",id:"data-privacy",level:3},{value:"Access Control",id:"access-control",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Indexing Performance",id:"indexing-performance",level:3},{value:"Query Performance",id:"query-performance",level:3},{value:"Scaling Recommendations",id:"scaling-recommendations",level:3},{value:"Future Enhancements",id:"future-enhancements",level:2}],m={toc:g},u="wrapper";function p(e){var{components:n}=e,t=o(e,["components"]);return(0,a.yg)(u,i(function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{},a=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),a.forEach((function(n){r(e,n,t[n])}))}return e}({},m,t),{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"semantic-search-architecture"},"Semantic Search Architecture"),(0,a.yg)("p",null,"This document provides a detailed explanation of DataHub's semantic search architecture, design decisions, and implementation details."),(0,a.yg)("h2",{id:"design-philosophy"},"Design Philosophy"),(0,a.yg)("h3",{id:"why-semantic-search"},"Why Semantic Search?"),(0,a.yg)("p",null,"Traditional keyword search has limitations:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Vocabulary Mismatch"),": Users may use different terms than those in documents"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Synonym Blindness"),': "access request" won\'t match "permission request"'),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Context Ignorance"),": Keywords lack understanding of meaning")),(0,a.yg)("p",null,"Semantic search addresses these by understanding the ",(0,a.yg)("em",{parentName:"p"},"meaning")," of text through vector embeddings\u2014numerical representations that capture semantic similarity."),(0,a.yg)("h3",{id:"core-principles"},"Core Principles"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Non-invasive"),": Semantic search is additive; it doesn't replace keyword search"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Configurable"),": Organizations choose which entities and models to use"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Extensible"),": New embedding models can be added without architectural changes"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Async Processing"),": Embedding generation happens asynchronously to not block ingestion")),(0,a.yg)("h2",{id:"index-architecture"},"Index Architecture"),(0,a.yg)("h3",{id:"dual-index-strategy"},"Dual-Index Strategy"),(0,a.yg)("p",null,"For each entity type enabled for semantic search, two indices exist:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     documentindex_v2            \u2502  \u2502   documentindex_v2_semantic     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Standard OpenSearch index       \u2502  \u2502 OpenSearch index with k-NN     \u2502\n\u2502                                 \u2502  \u2502                                 \u2502\n\u2502 Fields:                         \u2502  \u2502 Fields:                         \u2502\n\u2502 - urn                           \u2502  \u2502 - urn                           \u2502\n\u2502 - title (text)                  \u2502  \u2502 - title (text)                  \u2502\n\u2502 - text (text)                   \u2502  \u2502 - text (text)                   \u2502\n\u2502 - browsePaths                   \u2502  \u2502 - browsePaths                   \u2502\n\u2502 - tags                          \u2502  \u2502 - tags                          \u2502\n\u2502 - ...                           \u2502  \u2502 - ...                           \u2502\n\u2502                                 \u2502  \u2502                                 \u2502\n\u2502                                 \u2502  \u2502 + embeddings (nested object):   \u2502\n\u2502                                 \u2502  \u2502   - cohere_embed_v3:            \u2502\n\u2502                                 \u2502  \u2502     - model_version             \u2502\n\u2502                                 \u2502  \u2502     - generated_at              \u2502\n\u2502                                 \u2502  \u2502     - chunks[] (nested):        \u2502\n\u2502                                 \u2502  \u2502       - position                \u2502\n\u2502                                 \u2502  \u2502       - text                    \u2502\n\u2502                                 \u2502  \u2502       - vector (knn_vector)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h3",{id:"why-separate-indices-transitional-architecture"},"Why Separate Indices? (Transitional Architecture)"),(0,a.yg)("p",null,"The dual-index approach is a ",(0,a.yg)("strong",{parentName:"p"},"transitional architecture"),". The long-term plan is to:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Phase 1 (Current)"),": Run both indices in parallel during transition"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Phase 2"),": Migrate all search traffic to semantic indices"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Phase 3"),": Retire ",(0,a.yg)("inlineCode",{parentName:"li"},"v2")," indices entirely")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Benefits of the transitional approach:")),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Zero Downtime Migration"),": Users continue using keyword search while semantic capabilities are built"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Gradual Validation"),": Semantic search quality can be validated before full rollout"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Rollback Safety"),": If issues arise, keyword search remains available"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Incremental Embedding Generation"),": Embeddings can be backfilled without blocking operations")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Future State:")),(0,a.yg)("p",null,"Once the transition is complete, the ",(0,a.yg)("inlineCode",{parentName:"p"},"_semantic")," indices will become the primary (and only) search indices. They will support both:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Keyword search"),": Using standard OpenSearch text matching on the same index"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Semantic search"),": Using k-NN vector similarity")),(0,a.yg)("p",null,"This unified index approach simplifies operations and reduces storage overhead."),(0,a.yg)("h3",{id:"embeddings-schema"},"Embeddings Schema"),(0,a.yg)("p",null,"The semantic index stores embeddings in a nested structure:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "urn": "urn:li:document:example-doc",\n  "title": "Data Access Guide",\n  "text": "How to request access to datasets...",\n  "embeddings": {\n    "cohere_embed_v3": {\n      "model_version": "bedrock/cohere.embed-english-v3",\n      "generated_at": "2024-01-15T10:30:00Z",\n      "chunking_strategy": "sentence_boundary_400t",\n      "total_chunks": 3,\n      "total_tokens": 850,\n      "chunks": [\n        {\n          "position": 0,\n          "text": "How to request access to datasets...",\n          "character_offset": 0,\n          "character_length": 450,\n          "token_count": 95,\n          "vector": [0.023, -0.041, 0.087, ...]  // 1024 dimensions\n        },\n        {\n          "position": 1,\n          "text": "For sensitive data, additional approval...",\n          "character_offset": 450,\n          "character_length": 380,\n          "token_count": 82,\n          "vector": [0.019, -0.055, 0.091, ...]\n        }\n      ]\n    }\n  }\n}\n')),(0,a.yg)("h3",{id:"multi-model-support"},"Multi-Model Support"),(0,a.yg)("p",null,"The embeddings structure supports multiple embedding models:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "embeddings": {\n    "cohere_embed_v3": { ... },\n    "openai_text_embedding_3": { ... },\n    "custom_model": { ... }\n  }\n}\n')),(0,a.yg)("p",null,"This allows:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"A/B testing different models"),(0,a.yg)("li",{parentName:"ul"},"Gradual migration between models"),(0,a.yg)("li",{parentName:"ul"},"Model-specific optimizations")),(0,a.yg)("h2",{id:"data-flow"},"Data Flow"),(0,a.yg)("h3",{id:"ingestion-flow"},"Ingestion Flow"),(0,a.yg)("p",null,"The ingestion connector generates document embeddings and sends them to GMS along with the document content:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Ingestion Flow                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                        \u2502\n\u2502  \u2502   Source    \u2502  1. Extract documents                                  \u2502\n\u2502  \u2502   System    \u2502                                                        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                        \u2502\n\u2502         \u2502                                                               \u2502\n\u2502         \u25bc                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                        \u2502\n\u2502  \u2502  Ingestion  \u2502  2. Generate embeddings for document content           \u2502\n\u2502  \u2502  Connector  \u2502     (using connector's embedding provider)             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                        \u2502\n\u2502         \u2502                                                               \u2502\n\u2502         \u25bc                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  3. Send document + embeddings to GMS                  \u2502\n\u2502  \u2502     GMS     \u2502                                                        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                        \u2502\n\u2502         \u2502                                                               \u2502\n\u2502         \u25bc                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                      OpenSearch                                  \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502  \u2502  \u2502 entityindex_v2      \u2502  \u2502 entityindex_v2_semantic         \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502 (keyword search)    \u2502  \u2502 (keyword + vector search)       \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502                     \u2502  \u2502                                 \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502 - urn               \u2502  \u2502 - urn                           \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502 - title             \u2502  \u2502 - title                         \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502 - text              \u2502  \u2502 - text                          \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502 - ...               \u2502  \u2502 - embeddings.model.chunks[].    \u2502   \u2502   \u2502\n\u2502  \u2502  \u2502                     \u2502  \u2502     vector                      \u2502   \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h3",{id:"embedding-generation"},"Embedding Generation"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Document Embeddings")," are generated by the ",(0,a.yg)("strong",{parentName:"p"},"ingestion connector")," at ingestion time and sent to GMS via MCP (Metadata Change Proposal). This ensures:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Consistency"),": Every ingested document has embeddings from the start"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Simplicity"),": No separate backfill job to manage"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Freshness"),": Embeddings are always up-to-date with document content"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Audit Trail"),": Embeddings are tracked in the Metadata Change Log (MCL)"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Privacy Support"),": Sensitive sources can generate embeddings locally and share only vectors")),(0,a.yg)("h4",{id:"mcp-based-embedding-flow"},"MCP-Based Embedding Flow"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Ingestion Pipeline                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502   Source     \u2502\u2500\u2500\u2500\u25b6\u2502  Ingestion   \u2502\u2500\u2500\u2500\u25b6\u2502    DataHub GMS       \u2502   \u2502\n\u2502  \u2502   System     \u2502    \u2502  Connector   \u2502    \u2502                      \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                             \u2502                       \u2502               \u2502\n\u2502                             \u25bc                       \u25bc               \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502                    \u2502 Generate document\u2502    \u2502 Process MCP and  \u2502    \u2502\n\u2502                    \u2502 embeddings       \u2502    \u2502 write to semantic \u2502    \u2502\n\u2502                    \u2502 (in connector)   \u2502    \u2502 search index      \u2502    \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                             \u2502                       \u25b2               \u2502\n\u2502                             \u2502    MCP with          \u2502               \u2502\n\u2502                             \u2514\u2500\u2500\u2500\u2500\u2500SemanticContent\u2500\u2518               \u2502\n\u2502                                    aspect                           \u2502\n\u2502                                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h4",{id:"semanticcontent-aspect"},"SemanticContent Aspect"),(0,a.yg)("p",null,"Embeddings are stored as a proper DataHub aspect (",(0,a.yg)("inlineCode",{parentName:"p"},"SemanticContent"),"), defined in PDL schema:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "entityType": "document",\n  "entityUrn": "urn:li:document:my-doc",\n  "aspectName": "semanticContent",\n  "aspect": {\n    "embeddings": {\n      "cohere_embed_v3": {\n        "modelVersion": "bedrock/cohere.embed-english-v3",\n        "generatedAt": 1702234567890,\n        "totalChunks": 2,\n        "chunks": [\n          { "position": 0, "vector": [...], "text": "..." },\n          { "position": 1, "vector": [...], "text": "..." }\n        ]\n      }\n    }\n  }\n}\n')),(0,a.yg)("h4",{id:"privacy-sensitive-use-cases"},"Privacy-Sensitive Use Cases"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"text")," field in each chunk is ",(0,a.yg)("strong",{parentName:"p"},"optional"),". This supports scenarios where:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Source data contains sensitive information (PII, trade secrets)"),(0,a.yg)("li",{parentName:"ul"},"Customers want semantic search without storing source text in DataHub"),(0,a.yg)("li",{parentName:"ul"},"Embeddings are generated locally at the data source")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Note:")," Embeddings are one-way\u2014original text cannot be reconstructed from vectors."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Query Embeddings")," are generated by GMS at search time using the configured embedding provider (e.g., AWS Bedrock):"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   GraphQL   \u2502\u2500\u2500\u2500\u25b6\u2502     GMS     \u2502\u2500\u2500\u2500\u25b6\u2502  Embedding  \u2502\u2500\u2500\u2500\u25b6\u2502 OpenSearch  \u2502\n\u2502   Client    \u2502    \u2502             \u2502    \u2502  Provider   \u2502    \u2502  k-NN Query \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n                   Query embedding\n                   generated here\n                   (for search only)\n")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Key Point:")," The GMS embedding provider is used ",(0,a.yg)("strong",{parentName:"p"},"only for query embedding"),", not for document embedding. The ingestion connector is responsible for document embeddings."),(0,a.yg)("h3",{id:"query-flow"},"Query Flow"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},'\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   GraphQL   \u2502\u2500\u2500\u2500\u25b6\u2502     GMS     \u2502\u2500\u2500\u2500\u25b6\u2502  Embedding  \u2502\u2500\u2500\u2500\u25b6\u2502 OpenSearch  \u2502\n\u2502   Client    \u2502    \u2502             \u2502    \u2502  Provider   \u2502    \u2502  k-NN Query \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                \u2502\n     semanticSearchAcrossEntities(                              \u2502\n       query: "how to access data"                              \u2502\n     )                                                          \u2502\n                                                                \u25bc\n                                            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                            \u2502  Nested k-NN Query:         \u2502\n                                            \u2502                             \u2502\n                                            \u2502  {                          \u2502\n                                            \u2502    "nested": {              \u2502\n                                            \u2502      "path": "embeddings    \u2502\n                                            \u2502        .cohere_embed_v3     \u2502\n                                            \u2502        .chunks",            \u2502\n                                            \u2502      "query": {             \u2502\n                                            \u2502        "knn": {             \u2502\n                                            \u2502          "...chunks.vector":\u2502\n                                            \u2502          { "vector": [...], \u2502\n                                            \u2502            "k": 10 }        \u2502\n                                            \u2502        }                    \u2502\n                                            \u2502      }                      \u2502\n                                            \u2502    }                        \u2502\n                                            \u2502  }                          \u2502\n                                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n')),(0,a.yg)("h2",{id:"chunking-strategy"},"Chunking Strategy"),(0,a.yg)("h3",{id:"why-chunk-documents"},"Why Chunk Documents?"),(0,a.yg)("p",null,"Embedding models have token limits (512 tokens for cohere's embed-english-v3.0). Long documents must be split into chunks:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Token Limits"),": Models can't process unlimited text"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Precision"),": Smaller chunks allow more precise matching"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Relevance"),": A document may have one highly relevant section")),(0,a.yg)("h3",{id:"chunking-algorithm"},"Chunking Algorithm"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'def chunk_text(text, max_tokens=400):\n    """\n    Chunk text at sentence boundaries, respecting token limits.\n\n    1. Split text into sentences\n    2. Accumulate sentences until approaching limit\n    3. Save chunk, start new accumulation\n    4. Handle oversized sentences by character splitting\n    """\n')),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Parameters:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"max_tokens"),": Target chunk size (default: 400)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"chars_per_token"),": Estimation ratio (default: 4 characters \u2248 1 token)")),(0,a.yg)("h3",{id:"chunk-metadata"},"Chunk Metadata"),(0,a.yg)("p",null,"Each chunk stores metadata for debugging and analysis:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "position": 0,           // Order in document\n  "text": "...",           // Chunk content\n  "character_offset": 0,   // Start position in original\n  "character_length": 450, // Length in characters\n  "token_count": 95,       // Estimated tokens\n  "vector": [...]          // Embedding vector\n}\n')),(0,a.yg)("h2",{id:"k-nn-search-configuration"},"k-NN Search Configuration"),(0,a.yg)("h3",{id:"opensearch-k-nn-settings"},"OpenSearch k-NN Settings"),(0,a.yg)("p",null,"The semantic index uses OpenSearch's k-NN plugin with FAISS engine:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "settings": {\n    "index.knn": true\n  },\n  "mappings": {\n    "properties": {\n      "embeddings": {\n        "type": "nested",\n        "properties": {\n          "cohere_embed_v3": {\n            "type": "nested",\n            "properties": {\n              "chunks": {\n                "type": "nested",\n                "properties": {\n                  "vector": {\n                    "type": "knn_vector",\n                    "dimension": 1024,\n                    "method": {\n                      "name": "hnsw",\n                      "engine": "faiss",\n                      "space_type": "cosinesimil",\n                      "parameters": {\n                        "ef_construction": 128,\n                        "m": 16\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n')),(0,a.yg)("h3",{id:"hnsw-parameters"},"HNSW Parameters"),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Parameter"),(0,a.yg)("th",{parentName:"tr",align:null},"Value"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"ef_construction")),(0,a.yg)("td",{parentName:"tr",align:null},"128"),(0,a.yg)("td",{parentName:"tr",align:null},"Build-time accuracy (higher = more accurate, slower build)")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"m")),(0,a.yg)("td",{parentName:"tr",align:null},"16"),(0,a.yg)("td",{parentName:"tr",align:null},"Number of connections per node (higher = more accurate, more memory)")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("inlineCode",{parentName:"td"},"space_type")),(0,a.yg)("td",{parentName:"tr",align:null},"cosinesimil"),(0,a.yg)("td",{parentName:"tr",align:null},"Similarity metric (cosine similarity)")))),(0,a.yg)("h2",{id:"security-considerations"},"Security Considerations"),(0,a.yg)("h3",{id:"data-privacy"},"Data Privacy"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Embedding Storage"),": Vectors are stored alongside documents; same access controls apply"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"External API Calls"),": Embedding providers receive document text; ensure compliance"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Credential Management"),": API keys/AWS credentials must be secured")),(0,a.yg)("h3",{id:"access-control"},"Access Control"),(0,a.yg)("p",null,"Semantic search respects DataHub's existing access controls:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Users only see results they have permission to view"),(0,a.yg)("li",{parentName:"ul"},"Entity-level permissions are enforced before returning results")),(0,a.yg)("h2",{id:"performance-considerations"},"Performance Considerations"),(0,a.yg)("h3",{id:"indexing-performance"},"Indexing Performance"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Dual-write Impact"),": ~10-20% increase in write latency"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Embedding Generation"),": Async; doesn't block ingestion"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Batch Processing"),": Embeddings generated in batches for efficiency")),(0,a.yg)("h3",{id:"query-performance"},"Query Performance"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"k-NN Overhead"),": ~50-200ms per query (depends on index size)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Embedding Generation"),": ~100-300ms for query embedding"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Total Latency"),": Typically 200-500ms end-to-end")),(0,a.yg)("h3",{id:"scaling-recommendations"},"Scaling Recommendations"),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Index Size"),(0,a.yg)("th",{parentName:"tr",align:null},"Recommendation"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"< 100K docs"),(0,a.yg)("td",{parentName:"tr",align:null},"Single node sufficient")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"100K - 1M docs"),(0,a.yg)("td",{parentName:"tr",align:null},"Consider dedicated k-NN nodes")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"> 1M docs"),(0,a.yg)("td",{parentName:"tr",align:null},"Sharding and replicas recommended")))),(0,a.yg)("h2",{id:"future-enhancements"},"Future Enhancements"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Hybrid Search"),": Combine keyword and semantic scores for improved relevance"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Model Fine-tuning"),": Domain-specific embedding models for better accuracy")))}p.isMDXComponent=!0}}]);