"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[14227],{42658:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>m,default:()=>h,frontMatter:()=>p,metadata:()=>g,toc:()=>d});t(96540);var n=t(15680),s=t(53720),i=t(5400);function l(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){return a=null!=a?a:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):function(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))})),e}function o(e,a){if(null==e)return{};var t,n,s=function(e,a){if(null==e)return{};var t,n,s={},i=Object.keys(e);for(n=0;n<i.length;n++)t=i[n],a.indexOf(t)>=0||(s[t]=e[t]);return s}(e,a);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)t=i[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}const p={sidebar_position:41,title:"Kafka",slug:"/generated/ingestion/sources/kafka",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/kafka.md"},m="Kafka",g={unversionedId:"docs/generated/ingestion/sources/kafka",id:"docs/generated/ingestion/sources/kafka",title:"Kafka",description:"Extract Topics & Schemas from Apache Kafka or Confluent Cloud.",source:"@site/genDocs/docs/generated/ingestion/sources/kafka.md",sourceDirName:"docs/generated/ingestion/sources",slug:"/generated/ingestion/sources/kafka",permalink:"/docs/generated/ingestion/sources/kafka",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/kafka.md",tags:[],version:"current",sidebarPosition:41,frontMatter:{sidebar_position:41,title:"Kafka",slug:"/generated/ingestion/sources/kafka",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/kafka.md"},sidebar:"overviewSidebar",previous:{title:"JSON Schemas",permalink:"/docs/generated/ingestion/sources/json-schema"},next:{title:"Kafka Connect",permalink:"/docs/generated/ingestion/sources/kafka-connect"}},c={},d=[{value:"Important Capabilities",id:"important-capabilities",level:3},{value:"CLI based Ingestion",id:"cli-based-ingestion",level:3},{value:"Starter Recipe",id:"starter-recipe",level:3},{value:"Config Details",id:"config-details",level:3},{value:"Connecting to Confluent Cloud",id:"connecting-to-confluent-cloud",level:3},{value:"Custom Schema Registry",id:"custom-schema-registry",level:3},{value:"OAuth Callback",id:"oauth-callback",level:3},{value:"Deploying Custom OAuth Callbacks",id:"deploying-custom-oauth-callbacks",level:4},{value:"Limitations of <code>PROTOBUF</code> schema types implementation",id:"limitations-of-protobuf-schema-types-implementation",level:3},{value:"Enriching DataHub metadata with automated meta mapping",id:"enriching-datahub-metadata-with-automated-meta-mapping",level:3},{value:"Simple tags",id:"simple-tags",level:4},{value:"meta mapping",id:"meta-mapping",level:4},{value:"Code Coordinates",id:"code-coordinates",level:3}],y={toc:d},u="wrapper";function h(e){var{components:a}=e,t=o(e,["components"]);return(0,n.yg)(u,r(function(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{},n=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),n.forEach((function(a){l(e,a,t[a])}))}return e}({},y,t),{components:a,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"kafka"},"Kafka"),(0,n.yg)("p",null,"Extract Topics & Schemas from Apache Kafka or Confluent Cloud.\n",(0,n.yg)("img",{parentName:"p",src:"https://img.shields.io/badge/support%20status-certified-brightgreen",alt:"Certified"})),(0,n.yg)("h3",{id:"important-capabilities"},"Important Capabilities"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Capability"),(0,n.yg)("th",{parentName:"tr",align:null},"Status"),(0,n.yg)("th",{parentName:"tr",align:null},"Notes"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Column-level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u274c"),(0,n.yg)("td",{parentName:"tr",align:null},"Not supported.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/sql_profiles"},"Data Profiling")),(0,n.yg)("td",{parentName:"tr",align:null},"\u274c"),(0,n.yg)("td",{parentName:"tr",align:null},"Not supported.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Descriptions"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Set dataset description to top level doc field for Avro schema.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/stateful#stale-entity-removal"},"Detect Deleted Entities")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default via stateful ingestion.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/platform-instances"},"Platform Instance")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"For multiple Kafka clusters, use the platform_instance configuration.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Schema Metadata"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Schemas associated with each topic are extracted from the schema registry. Avro and Protobuf (certified), JSON (incubating). Schema references are supported.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Table-Level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u274c"),(0,n.yg)("td",{parentName:"tr",align:null},"Not supported. If you use Kafka Connect, the kafka-connect source can generate lineage.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Test Connection"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")))),(0,n.yg)("p",null,"This plugin extracts the following:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Topics from the Kafka broker"),(0,n.yg)("li",{parentName:"ul"},"Schemas associated with each topic from the schema registry (Avro, Protobuf and JSON schemas are supported)")),(0,n.yg)("h3",{id:"cli-based-ingestion"},"CLI based Ingestion"),(0,n.yg)("h3",{id:"starter-recipe"},"Starter Recipe"),(0,n.yg)("p",null,"Check out the following recipe to get started with ingestion! See ",(0,n.yg)("a",{parentName:"p",href:"#config-details"},"below")," for full configuration options."),(0,n.yg)("p",null,"For general pointers on writing and running a recipe, see our ",(0,n.yg)("a",{parentName:"p",href:"/docs/metadata-ingestion#recipes"},"main recipe guide"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: "kafka"\n  config:\n    platform_instance: "YOUR_CLUSTER_ID"\n    connection:\n      bootstrap: "broker:9092"\n      schema_registry_url: http://localhost:8081\n\nsink:\n  # sink configs\n\n\n')),(0,n.yg)("h3",{id:"config-details"},"Config Details"),(0,n.yg)(s.A,{mdxType:"Tabs"},(0,n.yg)(i.A,{value:"options",label:"Options",default:!0,mdxType:"TabItem"},(0,n.yg)("p",null,"Note that a ",(0,n.yg)("inlineCode",{parentName:"p"},".")," is used to denote nested fields in the YAML recipe."),(0,n.yg)("div",{className:"config-table"},(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:"left"},"Field"),(0,n.yg)("th",{parentName:"tr",align:"left"},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"convert_urns_to_lowercase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to convert dataset urns to lowercase. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"disable_topic_record_naming_strategy"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Disables the utilization of the TopicRecordNameStrategy for Schema Registry subjects. For more information, visit: ",(0,n.yg)("a",{parentName:"td",href:"https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#handling-differences-between-preregistered-and-client-derived-schemas:~:text=io.confluent.kafka.serializers.subject.TopicRecordNameStrategy"},"https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#handling-differences-between-preregistered-and-client-derived-schemas:~:text=io.confluent.kafka.serializers.subject.TopicRecordNameStrategy")," ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, applies the mappings that are defined through the meta_mapping directives. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"external_url_base"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Base URL for external platform (e.g. Aiven) where topics can be viewed. The topic name will be appended to this base URL. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"field_meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against field-level schema properties. Refer to the section below on meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"ignore_warnings_on_schema_type"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Disables warnings reported for non-AVRO/Protobuf value or key schemas if set. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"ingest_schemas_as_entities"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Enables ingesting schemas from schema registry as separate entities, in addition to the topics ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against top-level schema properties. Refer to the section below on meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"platform_instance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.datahub.com/docs/platform-instances/"},"https://docs.datahub.com/docs/platform-instances/")," for more details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"schema_registry_class"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The fully qualified implementation class(custom) that implements the KafkaSchemaRegistryBase interface. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"datahub.ingestion.source.confluent","_","schema","_","registry...")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"schema_tags_field"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The field name in the schema metadata that contains the tags to be added to the dataset. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"tags")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"strip_user_ids_from_email"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to strip email id while adding owners using meta mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"tag_prefix"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prefix added to tags during ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"})))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"topic_subject_map"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"map(str,string)"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"env"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The environment that all assets produced by this connector belong to ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PROD")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"connection"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"KafkaConsumerConnectionConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Configuration class for holding connectivity information for Kafka consumers")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"connection."),(0,n.yg)("span",{className:"path-main"},"bootstrap"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"default-line "},"Default: ",(0,n.yg)("span",{className:"default-value"},"localhost:9092")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"connection."),(0,n.yg)("span",{className:"path-main"},"client_timeout_seconds"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The request timeout used when interacting with the Kafka APIs. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"60")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"connection."),(0,n.yg)("span",{className:"path-main"},"consumer_config"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Extra consumer config serialized as JSON. These options will be passed into Kafka's DeserializingConsumer. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#deserializingconsumer"},"https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#deserializingconsumer")," and ",(0,n.yg)("a",{parentName:"td",href:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md"},"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md")," .")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"connection."),(0,n.yg)("span",{className:"path-main"},"schema_registry_config"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Extra schema registry config serialized as JSON. These options will be passed into Kafka's SchemaRegistryClient. ",(0,n.yg)("a",{parentName:"td",href:"https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html?#schemaregistryclient"},"https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html?#schemaregistryclient"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"connection."),(0,n.yg)("span",{className:"path-main"},"schema_registry_url"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Schema registry URL. Can be overridden with KAFKA_SCHEMAREGISTRY_URL environment variable, or will use DATAHUB_GMS_BASE_PATH if not set.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"domain"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"map(str,AllowDenyPattern)"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),"."),(0,n.yg)("span",{className:"path-main"},"allow"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"List of regex patterns to include in ingestion ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","'",".","*","'","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),".allow."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),"."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),"."),(0,n.yg)("span",{className:"path-main"},"deny"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"List of regex patterns to exclude from ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),".deny."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"topic_patterns"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"topic_patterns."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"topic_patterns."),(0,n.yg)("span",{className:"path-main"},"allow"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"List of regex patterns to include in ingestion ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","'",".","*","'","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"topic_patterns.allow."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"topic_patterns."),(0,n.yg)("span",{className:"path-main"},"deny"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"List of regex patterns to exclude from ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"topic_patterns.deny."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"stateful_ingestion"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of StatefulStaleMetadataRemovalConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"default-line "},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or ",(0,n.yg)("inlineCode",{parentName:"td"},"datahub_api")," is specified, otherwise False ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"fail_safe_threshold"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"number"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the 'fail_safe_threshold'. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"75.0")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"remove_stale_metadata"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))))))),(0,n.yg)(i.A,{value:"schema",label:"Schema",mdxType:"TabItem"},(0,n.yg)("p",null,"The ",(0,n.yg)("a",{parentName:"p",href:"https://json-schema.org/"},"JSONSchema")," for this configuration is inlined below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "$defs": {\n    "AllowDenyPattern": {\n      "additionalProperties": false,\n      "description": "A class to store allow deny regexes",\n      "properties": {\n        "allow": {\n          "default": [\n            ".*"\n          ],\n          "description": "List of regex patterns to include in ingestion",\n          "items": {\n            "type": "string"\n          },\n          "title": "Allow",\n          "type": "array"\n        },\n        "deny": {\n          "default": [],\n          "description": "List of regex patterns to exclude from ingestion.",\n          "items": {\n            "type": "string"\n          },\n          "title": "Deny",\n          "type": "array"\n        },\n        "ignoreCase": {\n          "anyOf": [\n            {\n              "type": "boolean"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": true,\n          "description": "Whether to ignore case sensitivity during pattern matching.",\n          "title": "Ignorecase"\n        }\n      },\n      "title": "AllowDenyPattern",\n      "type": "object"\n    },\n    "KafkaConsumerConnectionConfig": {\n      "additionalProperties": false,\n      "description": "Configuration class for holding connectivity information for Kafka consumers",\n      "properties": {\n        "bootstrap": {\n          "default": "localhost:9092",\n          "title": "Bootstrap",\n          "type": "string"\n        },\n        "schema_registry_url": {\n          "description": "Schema registry URL. Can be overridden with KAFKA_SCHEMAREGISTRY_URL environment variable, or will use DATAHUB_GMS_BASE_PATH if not set.",\n          "title": "Schema Registry Url",\n          "type": "string"\n        },\n        "schema_registry_config": {\n          "additionalProperties": true,\n          "description": "Extra schema registry config serialized as JSON. These options will be passed into Kafka\'s SchemaRegistryClient. https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html?#schemaregistryclient",\n          "title": "Schema Registry Config",\n          "type": "object"\n        },\n        "client_timeout_seconds": {\n          "default": 60,\n          "description": "The request timeout used when interacting with the Kafka APIs.",\n          "title": "Client Timeout Seconds",\n          "type": "integer"\n        },\n        "consumer_config": {\n          "additionalProperties": true,\n          "description": "Extra consumer config serialized as JSON. These options will be passed into Kafka\'s DeserializingConsumer. See https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#deserializingconsumer and https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md .",\n          "title": "Consumer Config",\n          "type": "object"\n        }\n      },\n      "title": "KafkaConsumerConnectionConfig",\n      "type": "object"\n    },\n    "StatefulStaleMetadataRemovalConfig": {\n      "additionalProperties": false,\n      "description": "Base specialized config for Stateful Ingestion with stale metadata removal capability.",\n      "properties": {\n        "enabled": {\n          "default": false,\n          "description": "Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or `datahub_api` is specified, otherwise False",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "remove_stale_metadata": {\n          "default": true,\n          "description": "Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled.",\n          "title": "Remove Stale Metadata",\n          "type": "boolean"\n        },\n        "fail_safe_threshold": {\n          "default": 75.0,\n          "description": "Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the \'fail_safe_threshold\'.",\n          "maximum": 100.0,\n          "minimum": 0.0,\n          "title": "Fail Safe Threshold",\n          "type": "number"\n        }\n      },\n      "title": "StatefulStaleMetadataRemovalConfig",\n      "type": "object"\n    }\n  },\n  "additionalProperties": false,\n  "properties": {\n    "convert_urns_to_lowercase": {\n      "default": false,\n      "description": "Whether to convert dataset urns to lowercase.",\n      "title": "Convert Urns To Lowercase",\n      "type": "boolean"\n    },\n    "env": {\n      "default": "PROD",\n      "description": "The environment that all assets produced by this connector belong to",\n      "title": "Env",\n      "type": "string"\n    },\n    "platform_instance": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See https://docs.datahub.com/docs/platform-instances/ for more details.",\n      "title": "Platform Instance"\n    },\n    "stateful_ingestion": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/StatefulStaleMetadataRemovalConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null\n    },\n    "connection": {\n      "$ref": "#/$defs/KafkaConsumerConnectionConfig",\n      "default": {\n        "bootstrap": "localhost:9092",\n        "schema_registry_url": "http://localhost:8080/schema-registry/api/",\n        "schema_registry_config": {},\n        "client_timeout_seconds": 60,\n        "consumer_config": {}\n      }\n    },\n    "topic_patterns": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [\n          "^_.*"\n        ],\n        "ignoreCase": true\n      }\n    },\n    "domain": {\n      "additionalProperties": {\n        "$ref": "#/$defs/AllowDenyPattern"\n      },\n      "default": {},\n      "description": "A map of domain names to allow deny patterns. Domains can be urn-based (`urn:li:domain:13ae4d85-d955-49fc-8474-9004c663a810`) or bare (`13ae4d85-d955-49fc-8474-9004c663a810`).",\n      "title": "Domain",\n      "type": "object"\n    },\n    "topic_subject_map": {\n      "additionalProperties": {\n        "type": "string"\n      },\n      "default": {},\n      "description": "Provides the mapping for the `key` and the `value` schemas of a topic to the corresponding schema registry subject name. Each entry of this map has the form `<topic_name>-key`:`<schema_registry_subject_name_for_key_schema>` and `<topic_name>-value`:`<schema_registry_subject_name_for_value_schema>` for the key and the value schemas associated with the topic, respectively. This parameter is mandatory when the [RecordNameStrategy](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#how-the-naming-strategies-work) is used as the subject naming strategy in the kafka schema registry. NOTE: When provided, this overrides the default subject name resolution even when the `TopicNameStrategy` or the `TopicRecordNameStrategy` are used.",\n      "title": "Topic Subject Map",\n      "type": "object"\n    },\n    "schema_registry_class": {\n      "default": "datahub.ingestion.source.confluent_schema_registry.ConfluentSchemaRegistry",\n      "description": "The fully qualified implementation class(custom) that implements the KafkaSchemaRegistryBase interface.",\n      "title": "Schema Registry Class",\n      "type": "string"\n    },\n    "schema_tags_field": {\n      "default": "tags",\n      "description": "The field name in the schema metadata that contains the tags to be added to the dataset.",\n      "title": "Schema Tags Field",\n      "type": "string"\n    },\n    "enable_meta_mapping": {\n      "default": true,\n      "description": "When enabled, applies the mappings that are defined through the meta_mapping directives.",\n      "title": "Enable Meta Mapping",\n      "type": "boolean"\n    },\n    "meta_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against top-level schema properties. Refer to the section below on meta automated mappings.",\n      "title": "Meta Mapping",\n      "type": "object"\n    },\n    "field_meta_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against field-level schema properties. Refer to the section below on meta automated mappings.",\n      "title": "Field Meta Mapping",\n      "type": "object"\n    },\n    "strip_user_ids_from_email": {\n      "default": false,\n      "description": "Whether or not to strip email id while adding owners using meta mappings.",\n      "title": "Strip User Ids From Email",\n      "type": "boolean"\n    },\n    "tag_prefix": {\n      "default": "",\n      "description": "Prefix added to tags during ingestion.",\n      "title": "Tag Prefix",\n      "type": "string"\n    },\n    "ignore_warnings_on_schema_type": {\n      "default": false,\n      "description": "Disables warnings reported for non-AVRO/Protobuf value or key schemas if set.",\n      "title": "Ignore Warnings On Schema Type",\n      "type": "boolean"\n    },\n    "disable_topic_record_naming_strategy": {\n      "default": false,\n      "description": "Disables the utilization of the TopicRecordNameStrategy for Schema Registry subjects. For more information, visit: https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#handling-differences-between-preregistered-and-client-derived-schemas:~:text=io.confluent.kafka.serializers.subject.TopicRecordNameStrategy",\n      "title": "Disable Topic Record Naming Strategy",\n      "type": "boolean"\n    },\n    "ingest_schemas_as_entities": {\n      "default": false,\n      "description": "Enables ingesting schemas from schema registry as separate entities, in addition to the topics",\n      "title": "Ingest Schemas As Entities",\n      "type": "boolean"\n    },\n    "external_url_base": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Base URL for external platform (e.g. Aiven) where topics can be viewed. The topic name will be appended to this base URL.",\n      "title": "External Url Base"\n    }\n  },\n  "title": "KafkaSourceConfig",\n  "type": "object"\n}\n')))),(0,n.yg)("admonition",{type:"note"},(0,n.yg)("p",{parentName:"admonition"},"Stateful Ingestion is available only when a Platform Instance is assigned to this source.")),(0,n.yg)("h3",{id:"connecting-to-confluent-cloud"},"Connecting to Confluent Cloud"),(0,n.yg)("p",null,"If using Confluent Cloud you can use a recipe like this. In this ",(0,n.yg)("inlineCode",{parentName:"p"},"consumer_config.sasl.username")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"consumer_config.sasl.password")," are the API credentials that you get (in the Confluent UI) from your cluster -> Data Integration -> API Keys. ",(0,n.yg)("inlineCode",{parentName:"p"},"schema_registry_config.basic.auth.user.info")," has API credentials for Confluent schema registry which you get (in Confluent UI) from Schema Registry -> API credentials."),(0,n.yg)("p",null,"When creating API Key for the cluster ensure that the ACLs associated with the key are set like below. This is required for DataHub to read topic metadata from topics in Confluent Cloud."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"Topic Name = *\nPermission = ALLOW\nOperation = DESCRIBE\nPattern Type = LITERAL\n")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yml"},'source:\n  type: "kafka"\n  config:\n    platform_instance: "YOUR_CLUSTER_ID"\n    connection:\n      bootstrap: "abc-defg.eu-west-1.aws.confluent.cloud:9092"\n      consumer_config:\n        security.protocol: "SASL_SSL"\n        sasl.mechanism: "PLAIN"\n        sasl.username: "${CLUSTER_API_KEY_ID}"\n        sasl.password: "${CLUSTER_API_KEY_SECRET}"\n      schema_registry_url: "https://abc-defgh.us-east-2.aws.confluent.cloud"\n      schema_registry_config:\n        basic.auth.user.info: "${REGISTRY_API_KEY_ID}:${REGISTRY_API_KEY_SECRET}"\n\nsink:\n  # sink configs\n')),(0,n.yg)("p",null,"If you are trying to add domains to your topics you can use a configuration like below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yml"},'source:\n  type: "kafka"\n  config:\n    # ...connection block\n    domain:\n      "urn:li:domain:13ae4d85-d955-49fc-8474-9004c663a810":\n        allow:\n          - ".*"\n      "urn:li:domain:d6ec9868-6736-4b1f-8aa6-fee4c5948f17":\n        deny:\n          - ".*"\n')),(0,n.yg)("p",null,"Note that the ",(0,n.yg)("inlineCode",{parentName:"p"},"domain")," in config above can be either an ",(0,n.yg)("em",{parentName:"p"},"urn")," or a domain ",(0,n.yg)("em",{parentName:"p"},"id")," (i.e. ",(0,n.yg)("inlineCode",{parentName:"p"},"urn:li:domain:13ae4d85-d955-49fc-8474-9004c663a810")," or simply ",(0,n.yg)("inlineCode",{parentName:"p"},"13ae4d85-d955-49fc-8474-9004c663a810"),"). The Domain should exist in your DataHub instance before ingesting data into the Domain. To create a Domain on DataHub, check out the ",(0,n.yg)("a",{parentName:"p",href:"/docs/domains/"},"Domains User Guide"),"."),(0,n.yg)("p",null,"If you are using a non-default subject naming strategy in the schema registry, such as ",(0,n.yg)("a",{parentName:"p",href:"https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#how-the-naming-strategies-work"},"RecordNameStrategy"),", the mapping for the topic's key and value schemas to the schema registry subject names should be provided via ",(0,n.yg)("inlineCode",{parentName:"p"},"topic_subject_map")," as shown in the configuration below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yml"},'source:\n  type: "kafka"\n  config:\n    # ...connection block\n    # Defines the mapping for the key & value schemas associated with a topic & the subject name registered with the\n    # kafka schema registry.\n    topic_subject_map:\n      # Defines both key & value schema for topic \'my_topic_1\'\n      "my_topic_1-key": "io.acryl.Schema1"\n      "my_topic_1-value": "io.acryl.Schema2"\n      # Defines only the value schema for topic \'my_topic_2\' (the topic doesn\'t have a key schema).\n      "my_topic_2-value": "io.acryl.Schema3"\n')),(0,n.yg)("h3",{id:"custom-schema-registry"},"Custom Schema Registry"),(0,n.yg)("p",null,"The Kafka Source uses the schema registry to figure out the schema associated with both ",(0,n.yg)("inlineCode",{parentName:"p"},"key")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"value")," for the topic.\nBy default it uses the ",(0,n.yg)("a",{parentName:"p",href:"https://docs.confluent.io/platform/current/schema-registry/index.html"},"Confluent's Kafka Schema registry"),"\nand supports the ",(0,n.yg)("inlineCode",{parentName:"p"},"AVRO")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"PROTOBUF")," schema types."),(0,n.yg)("p",null,"If you're using a custom schema registry, or you are using schema type other than ",(0,n.yg)("inlineCode",{parentName:"p"},"AVRO")," or ",(0,n.yg)("inlineCode",{parentName:"p"},"PROTOBUF"),", then you can provide your own\ncustom implementation of the ",(0,n.yg)("inlineCode",{parentName:"p"},"KafkaSchemaRegistryBase")," class, and implement the ",(0,n.yg)("inlineCode",{parentName:"p"},"get_schema_metadata(topic, platform_urn)")," method that\ngiven a topic name would return object of ",(0,n.yg)("inlineCode",{parentName:"p"},"SchemaMetadata")," containing schema for that topic. Please refer\n",(0,n.yg)("inlineCode",{parentName:"p"},"datahub.ingestion.source.confluent_schema_registry::ConfluentSchemaRegistry")," for sample implementation of this class."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"class KafkaSchemaRegistryBase(ABC):\n    @abstractmethod\n    def get_schema_metadata(\n        self, topic: str, platform_urn: str\n    ) -> Optional[SchemaMetadata]:\n        pass\n")),(0,n.yg)("p",null,"The custom schema registry class can be configured using the ",(0,n.yg)("inlineCode",{parentName:"p"},"schema_registry_class")," config param of the ",(0,n.yg)("inlineCode",{parentName:"p"},"kafka")," source as shown below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: "kafka"\n  config:\n    # Set the custom schema registry implementation class\n    schema_registry_class: "datahub.ingestion.source.confluent_schema_registry.ConfluentSchemaRegistry"\n    # Coordinates\n    connection:\n      bootstrap: "broker:9092"\n      schema_registry_url: http://localhost:8081\n')),(0,n.yg)("h3",{id:"oauth-callback"},"OAuth Callback"),(0,n.yg)("p",null,"The OAuth callback function can be set up for both Kafka sources (consumers) and sinks (producers):"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"For sources: ",(0,n.yg)("inlineCode",{parentName:"li"},"config.connection.consumer_config.oauth_cb")),(0,n.yg)("li",{parentName:"ul"},"For sinks: ",(0,n.yg)("inlineCode",{parentName:"li"},"config.connection.producer_config.oauth_cb"))),(0,n.yg)("p",null,"You need to specify a Python function reference in the format ","<","python-module",">",":","<","function-name",">","."),(0,n.yg)("p",null,"For example, in the configuration ",(0,n.yg)("inlineCode",{parentName:"p"},"oauth:create_token"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"create_token")," is a function defined in ",(0,n.yg)("inlineCode",{parentName:"p"},"oauth.py"),", and ",(0,n.yg)("inlineCode",{parentName:"p"},"oauth.py")," must be accessible in the PYTHONPATH."),(0,n.yg)("h4",{id:"deploying-custom-oauth-callbacks"},"Deploying Custom OAuth Callbacks"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"For Built-in Callbacks (Recommended):")),(0,n.yg)("p",null,"DataHub includes pre-built OAuth callbacks for common use cases:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"AWS MSK IAM"),": ",(0,n.yg)("inlineCode",{parentName:"li"},"datahub_actions.utils.kafka_msk_iam:oauth_cb")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Azure Event Hubs"),": ",(0,n.yg)("inlineCode",{parentName:"li"},"datahub_actions.utils.kafka_eventhubs_auth:oauth_cb"))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Important:")," To use these built-in callbacks, you must install the ",(0,n.yg)("inlineCode",{parentName:"p"},"acryl-datahub-actions")," package:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},"pip install acryl-datahub-actions>=1.3.1.2\n")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"For Custom OAuth Callbacks:")),(0,n.yg)("p",null,"If you need to implement a custom OAuth callback, you must ensure your Python module is accessible to the DataHub process, e.g. adding it via ",(0,n.yg)("inlineCode",{parentName:"p"},"PYTHONPATH=/path/to/your/module:$PYTHONPATH")," or ",(0,n.yg)("inlineCode",{parentName:"p"},"pip install my-oauth-package"),"."),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Example for Kafka Source:")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: "kafka"\n  config:\n    # Set the custom schema registry implementation class\n    schema_registry_class: "datahub.ingestion.source.confluent_schema_registry.ConfluentSchemaRegistry"\n    # Coordinates\n    connection:\n      bootstrap: "broker:9092"\n      schema_registry_url: http://localhost:8081\n      consumer_config:\n        security.protocol: "SASL_PLAINTEXT"\n        sasl.mechanism: "OAUTHBEARER"\n        oauth_cb: "oauth:create_token"\n# sink configs\n')),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Example for Kafka Sink (e.g., MSK IAM authentication):")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'sink:\n  type: "datahub-kafka"\n  config:\n    connection:\n      bootstrap: "b-1.msk.us-west-2.amazonaws.com:9098"\n      schema_registry_url: "http://datahub-gms:8080/schema-registry/api/"\n      producer_config:\n        security.protocol: "SASL_SSL"\n        sasl.mechanism: "OAUTHBEARER"\n        sasl.oauthbearer.method: "default"\n        oauth_cb: "datahub_actions.utils.kafka_msk_iam:oauth_cb"\n')),(0,n.yg)("h3",{id:"limitations-of-protobuf-schema-types-implementation"},"Limitations of ",(0,n.yg)("inlineCode",{parentName:"h3"},"PROTOBUF")," schema types implementation"),(0,n.yg)("p",null,"The current implementation of the support for ",(0,n.yg)("inlineCode",{parentName:"p"},"PROTOBUF")," schema type has the following limitations:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Recursive types are not supported."),(0,n.yg)("li",{parentName:"ul"},"If the schemas of different topics define a type in the same package, the source would raise an exception.")),(0,n.yg)("p",null,"In addition to this, maps are represented as arrays of messages. The following message,"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"message MessageWithMap {\n  map<int, string> map_1 = 1;\n}\n")),(0,n.yg)("p",null,"becomes:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"message Map1Entry {\n  int key = 1;\n  string value = 2/\n}\nmessage MessageWithMap {\n  repeated Map1Entry map_1 = 1;\n}\n")),(0,n.yg)("h3",{id:"enriching-datahub-metadata-with-automated-meta-mapping"},"Enriching DataHub metadata with automated meta mapping"),(0,n.yg)("admonition",{type:"note"},(0,n.yg)("p",{parentName:"admonition"},"Meta mapping is currently only available for Avro schemas, and requires that those Avro schemas are pushed to the schema registry.")),(0,n.yg)("p",null,"Avro schemas are permitted to have additional attributes not defined by the specification as arbitrary metadata. A common pattern is to utilize this for business metadata. The Kafka source has the ability to transform this directly into DataHub Owners, Tags and Terms."),(0,n.yg)("h4",{id:"simple-tags"},"Simple tags"),(0,n.yg)("p",null,"If you simply have a list of tags embedded into an Avro schema (either at the top-level or for an individual field), you can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"schema_tags_field")," config."),(0,n.yg)("p",null,"Example Avro schema:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "name": "sampleRecord",\n  "type": "record",\n  "tags": ["tag1", "tag2"],\n  "fields": [\n    {\n      "name": "field_1",\n      "type": "string",\n      "tags": ["tag3", "tag4"]\n    }\n  ]\n}\n')),(0,n.yg)("p",null,"The name of the field containing a list of tags can be configured with the ",(0,n.yg)("inlineCode",{parentName:"p"},"schema_tags_field")," property:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"config:\n  schema_tags_field: tags\n")),(0,n.yg)("h4",{id:"meta-mapping"},"meta mapping"),(0,n.yg)("p",null,"You can also map specific Avro fields into Owners, Tags and Terms using meta\nmapping."),(0,n.yg)("p",null,"Example Avro schema:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "name": "sampleRecord",\n  "type": "record",\n  "owning_team": "@Data-Science",\n  "data_tier": "Bronze",\n  "fields": [\n    {\n      "name": "field_1",\n      "type": "string",\n      "gdpr": {\n        "pii": true\n      }\n    }\n  ]\n}\n')),(0,n.yg)("p",null,"This can be mapped to DataHub metadata with ",(0,n.yg)("inlineCode",{parentName:"p"},"meta_mapping")," config:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'config:\n  meta_mapping:\n    owning_team:\n      match: "^@(.*)"\n      operation: "add_owner"\n      config:\n        owner_type: group\n    data_tier:\n      match: "Bronze|Silver|Gold"\n      operation: "add_term"\n      config:\n        term: "{{ $match }}"\n  field_meta_mapping:\n    gdpr.pii:\n      match: true\n      operation: "add_tag"\n      config:\n        tag: "pii"\n')),(0,n.yg)("p",null,"The underlying implementation is similar to ",(0,n.yg)("a",{parentName:"p",href:"/docs/generated/ingestion/sources/dbt#dbt-meta-automated-mappings"},"dbt meta mapping"),", which has more detailed examples that can be used for reference."),(0,n.yg)("h3",{id:"code-coordinates"},"Code Coordinates"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Class Name: ",(0,n.yg)("inlineCode",{parentName:"li"},"datahub.ingestion.source.kafka.kafka.KafkaSource")),(0,n.yg)("li",{parentName:"ul"},"Browse on ",(0,n.yg)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/kafka/kafka.py"},"GitHub"))),(0,n.yg)("h2",null,"Questions"),(0,n.yg)("p",null,"If you've got any questions on configuring ingestion for Kafka, feel free to ping us on ",(0,n.yg)("a",{parentName:"p",href:"https://datahub.com/slack"},"our Slack"),"."))}h.isMDXComponent=!0}}]);