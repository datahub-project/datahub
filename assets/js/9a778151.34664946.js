"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[51324],{71444:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>p,default:()=>_,frontMatter:()=>u,metadata:()=>m,toc:()=>h});t(96540);var a=t(15680),s=t(53720),r=t(5400);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))})),e}function l(e,n){if(null==e)return{};var t,a,s=function(e,n){if(null==e)return{};var t,a,s={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(s[t]=e[t]);return s}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}const u={title:"Assertions",slug:"/api/tutorials/assertions",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/api/tutorials/assertions.md"},p="Assertions",m={unversionedId:"docs/api/tutorials/assertions",id:"docs/api/tutorials/assertions",title:"Assertions",description:"This guide specifically covers how to use the Assertion APIs for DataHub Cloud native assertions, including:",source:"@site/genDocs/docs/api/tutorials/assertions.md",sourceDirName:"docs/api/tutorials",slug:"/api/tutorials/assertions",permalink:"/docs/api/tutorials/assertions",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/api/tutorials/assertions.md",tags:[],version:"current",frontMatter:{title:"Assertions",slug:"/api/tutorials/assertions",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/api/tutorials/assertions.md"},sidebar:"overviewSidebar",previous:{title:"Custom Properties",permalink:"/docs/api/tutorials/custom-properties"},next:{title:"Custom Assertions",permalink:"/docs/api/tutorials/custom-assertions"}},d={},h=[{value:"Why Would You Use Assertions APIs?",id:"why-would-you-use-assertions-apis",level:2},{value:"Goal Of This Guide",id:"goal-of-this-guide",level:3},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Create Assertions",id:"create-assertions",level:2},{value:"Freshness Assertion",id:"freshness-assertion",level:3},{value:"Volume Assertions",id:"volume-assertions",level:3},{value:"Column Assertions",id:"column-assertions",level:3},{value:"Custom SQL Assertions",id:"custom-sql-assertions",level:3},{value:"Schema Assertions",id:"schema-assertions",level:3},{value:"Run Assertions",id:"run-assertions",level:2},{value:"Run Assertion",id:"run-assertion",level:3},{value:"Run Group of Assertions",id:"run-group-of-assertions",level:3},{value:"Run All Assertions for Table",id:"run-all-assertions-for-table",level:3},{value:"Run Group of Assertions for Table",id:"run-group-of-assertions-for-table",level:3},{value:"Step 1: Adding Tag to an Assertion",id:"step-1-adding-tag-to-an-assertion",level:4},{value:"Step 2: Run All Assertions for a Table with Tags",id:"step-2-run-all-assertions-for-a-table-with-tags",level:4},{value:"Run Assertion",id:"run-assertion-1",level:3},{value:"Run Group of Assertions",id:"run-group-of-assertions-1",level:3},{value:"Run All Assertions for Table",id:"run-all-assertions-for-table-1",level:3},{value:"Providing Dynamic Parameters to Assertions",id:"providing-dynamic-parameters-to-assertions",level:3},{value:"Get Assertion Details",id:"get-assertion-details",level:2},{value:"Get Assertions for Table",id:"get-assertions-for-table",level:3},{value:"Get Assertion Details",id:"get-assertion-details-1",level:3},{value:"Add Tag to Assertion",id:"add-tag-to-assertion",level:2},{value:"Delete Assertions",id:"delete-assertions",level:2},{value:"(Advanced) Create and Report Results for Custom Assertions",id:"advanced-create-and-report-results-for-custom-assertions",level:2},{value:"Create and Remove Subscriptions",id:"create-and-remove-subscriptions",level:2}],g=(c="FeatureAvailability",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.yg)("div",e)});var c;const y={toc:h},f="wrapper";function _(e){var{components:n}=e,t=l(e,["components"]);return(0,a.yg)(f,i(function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{},a=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),a.forEach((function(n){o(e,n,t[n])}))}return e}({},y,t),{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"assertions"},"Assertions"),(0,a.yg)(g,{saasOnly:!0,mdxType:"FeatureAvailability"}),(0,a.yg)("p",null,"This guide specifically covers how to use the Assertion APIs for ",(0,a.yg)("strong",{parentName:"p"},"DataHub Cloud")," native assertions, including:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/managed-datahub/observe/freshness-assertions"},"Freshness Assertions")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/managed-datahub/observe/volume-assertions"},"Volume Assertions")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/managed-datahub/observe/column-assertions"},"Column Assertions")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/managed-datahub/observe/schema-assertions"},"Schema Assertions")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/managed-datahub/observe/custom-sql-assertions"},"Custom SQL Assertions"))),(0,a.yg)("h2",{id:"why-would-you-use-assertions-apis"},"Why Would You Use Assertions APIs?"),(0,a.yg)("p",null,"The Assertions APIs allow you to create, schedule, run, and delete Assertions with DataHub Cloud. Additionally, you can manage subscriptions to receive notifications when assertions change state or when other entity changes occur."),(0,a.yg)("h3",{id:"goal-of-this-guide"},"Goal Of This Guide"),(0,a.yg)("p",null,"This guide will show you how to create, schedule, run and delete Assertions for a Table."),(0,a.yg)("h2",{id:"prerequisites"},"Prerequisites"),(0,a.yg)("p",null,"The actor making API calls must have the ",(0,a.yg)("inlineCode",{parentName:"p"},"Edit Assertions")," and ",(0,a.yg)("inlineCode",{parentName:"p"},"Edit Monitors")," privileges for the Tables at hand."),(0,a.yg)("p",null,"If you are using the Python examples in this guide, install the DataHub Cloud SDK extension:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"pip install acryl-datahub-cloud\n")),(0,a.yg)("h2",{id:"create-assertions"},"Create Assertions"),(0,a.yg)("p",null,"You can create new dataset Assertions to DataHub using the following APIs."),(0,a.yg)("h3",{id:"freshness-assertion"},"Freshness Assertion"),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"To create a new freshness assertion, use the ",(0,a.yg)("inlineCode",{parentName:"p"},"upsertDatasetFreshnessAssertionMonitor")," GraphQL Mutation."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetFreshnessAssertionMonitor {\n  upsertDatasetFreshnessAssertionMonitor(\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      schedule: {\n        type: FIXED_INTERVAL\n        fixedInterval: { unit: HOUR, multiple: 8 }\n      }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */8 * * *"\n      }\n      evaluationParameters: { sourceType: INFORMATION_SCHEMA }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,a.yg)("p",null,"This API will return a unique identifier (URN) for the new assertion if you were successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "upsertDatasetFreshnessAssertionMonitor": {\n      "urn": "urn:li:assertion:your-new-assertion-id"\n    }\n  },\n  "extensions": {}\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.sdk import DataHubClient\nfrom datahub.metadata.urns import DatasetUrn\n\n# Initialize the client\nclient = DataHubClient(server="<your_server>", token="<your_token>")\n\n# Create smart freshness assertion (AI-powered anomaly detection)\ndataset_urn = DatasetUrn.from_string("urn:li:dataset:(urn:li:dataPlatform:snowflake,database.schema.table,PROD)")\n\nsmart_freshness_assertion = client.assertions.sync_smart_freshness_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Smart Freshness Anomaly Monitor",\n    # Detection mechanism - information_schema is recommended\n    detection_mechanism="information_schema",\n    # Smart sensitivity setting\n    sensitivity="medium",  # options: "low", "medium", "high"\n    # Tags for grouping\n    tags=["automated", "freshness", "data_quality"],\n    # Enable the assertion\n    enabled=True\n)\n\nprint(f"Created smart freshness assertion: {smart_freshness_assertion.urn}")\n\n# Create traditional freshness assertion (fixed interval)\nfreshness_assertion = client.assertions.sync_freshness_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Fixed Interval Freshness Check",\n    # Fixed interval check - table should be updated within lookback window\n    freshness_schedule_check_type="fixed_interval",\n    # Lookback window - table should be updated within 8 hours\n    lookback_window={"unit": "HOUR", "multiple": 8},\n    # Detection mechanism\n    detection_mechanism="information_schema",\n    # Evaluation schedule - how often to check\n    schedule="0 */2 * * *",  # Check every 2 hours\n    # Tags\n    tags=["automated", "freshness", "fixed_interval"],\n    enabled=True\n)\n\nprint(f"Created freshness assertion: {freshness_assertion.urn}")\n\n# Create since-last-check freshness assertion\nsince_last_check_assertion = client.assertions.sync_freshness_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Since Last Check Freshness",\n    # Since last check - table should be updated since the last evaluation\n    freshness_schedule_check_type="since_the_last_check",\n    # Detection mechanism with last modified column\n    detection_mechanism={\n        "type": "last_modified_column",\n        "column_name": "updated_at",\n        "additional_filter": "status = \'active\'"\n    },\n    # Evaluation schedule - how often to check\n    schedule="0 */6 * * *",  # Check every 6 hours\n    # Tags\n    tags=["automated", "freshness", "since_last_check"],\n    enabled=True\n)\n\nprint(f"Created since last check assertion: {since_last_check_assertion.urn}")\n\n# Create freshness assertion with high watermark column\nwatermark_freshness_assertion = client.assertions.sync_freshness_assertion(\n    dataset_urn=dataset_urn,\n    display_name="High Watermark Freshness Check",\n    # Fixed interval check with specific lookback window\n    freshness_schedule_check_type="fixed_interval",\n    # Lookback window - check for updates in the last 24 hours\n    lookback_window={"unit": "DAY", "multiple": 1},\n    # Detection mechanism using high watermark column (e.g., auto-incrementing ID)\n    detection_mechanism={\n        "type": "high_watermark_column",\n        "column_name": "id",\n        "additional_filter": "status != \'deleted\'"\n    },\n    # Evaluation schedule\n    schedule="0 8 * * *",  # Check daily at 8 AM\n    # Tags\n    tags=["automated", "freshness", "high_watermark"],\n    enabled=True\n)\n\nprint(f"Created watermark freshness assertion: {watermark_freshness_assertion.urn}")\n')))),(0,a.yg)("p",null,"For more details, see the ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/freshness-assertions"},"Freshness Assertions")," guide."),(0,a.yg)("h3",{id:"volume-assertions"},"Volume Assertions"),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"To create a new volume assertion, use the ",(0,a.yg)("inlineCode",{parentName:"p"},"upsertDatasetVolumeAssertionMonitor")," GraphQL Mutation."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetVolumeAssertionMonitor {\n  upsertDatasetVolumeAssertionMonitor(\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      type: ROW_COUNT_TOTAL\n      rowCountTotal: {\n        operator: BETWEEN\n        parameters: {\n          minValue: { value: "10", type: NUMBER }\n          maxValue: { value: "20", type: NUMBER }\n        }\n      }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */8 * * *"\n      }\n      evaluationParameters: { sourceType: INFORMATION_SCHEMA }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,a.yg)("p",null,"This API will return a unique identifier (URN) for the new assertion if you were successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "upsertDatasetVolumeAssertionMonitor": {\n      "urn": "urn:li:assertion:your-new-assertion-id"\n    }\n  },\n  "extensions": {}\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.sdk import DataHubClient\nfrom datahub.metadata.urns import DatasetUrn\n\n# Initialize the client\nclient = DataHubClient(server="<your_server>", token="<your_token>")\n\n# Create smart volume assertion (AI-powered anomaly detection)\ndataset_urn = DatasetUrn.from_string("urn:li:dataset:(urn:li:dataPlatform:snowflake,database.schema.table,PROD)")\n\nsmart_volume_assertion = client.assertions.sync_smart_volume_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Smart Volume Check",\n    # Detection mechanism options\n    detection_mechanism="information_schema",\n    # Smart sensitivity setting\n    sensitivity="medium",  # options: "low", "medium", "high"\n    # Tags for grouping\n    tags=["automated", "volume", "data_quality"],\n    # Schedule (optional - defaults to hourly)\n    schedule="0 */6 * * *",  # Every 6 hours\n    # Enable the assertion\n    enabled=True\n)\n\nprint(f"Created smart volume assertion: {smart_volume_assertion.urn}")\n\n# Create traditional volume assertion (fixed threshold range)\nvolume_assertion = client.assertions.sync_volume_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Row Count Range Check",\n    criteria_condition="ROW_COUNT_IS_WITHIN_A_RANGE",\n    criteria_parameters=(1000, 10000),  # Between 1000 and 10000 rows\n    # Detection mechanism\n    detection_mechanism="information_schema",\n    # Evaluation schedule\n    schedule="0 */4 * * *",  # Every 4 hours\n    # Tags\n    tags=["automated", "volume", "threshold_check"],\n    enabled=True\n)\n\nprint(f"Created volume assertion: {volume_assertion.urn}")\n\n# Example with single threshold\nmin_volume_assertion = client.assertions.sync_volume_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Minimum Row Count Check",\n    criteria_condition="ROW_COUNT_IS_GREATER_THAN_OR_EQUAL_TO",\n    criteria_parameters=500,  # At least 500 rows\n    detection_mechanism="information_schema",\n    schedule="0 */2 * * *",  # Every 2 hours\n    tags=["automated", "volume", "minimum_check"],\n    enabled=True\n)\n\nprint(f"Created minimum volume assertion: {min_volume_assertion.urn}")\n\n# Example with growth-based assertion\ngrowth_volume_assertion = client.assertions.sync_volume_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Daily Growth Check",\n    criteria_condition="ROW_COUNT_GROWS_BY_AT_MOST_ABSOLUTE",\n    criteria_parameters=1000,  # Grows by at most 1000 rows between checks\n    detection_mechanism="information_schema",\n    schedule="0 6 * * *",  # Daily at 6 AM\n    tags=["automated", "volume", "growth_check"],\n    enabled=True\n)\n\nprint(f"Created growth volume assertion: {growth_volume_assertion.urn}")\n')))),(0,a.yg)("p",null,"For more details, see the ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/volume-assertions"},"Volume Assertions")," guide."),(0,a.yg)("h3",{id:"column-assertions"},"Column Assertions"),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"To create a new column assertion, use the ",(0,a.yg)("inlineCode",{parentName:"p"},"upsertDatasetFieldAssertionMonitor")," GraphQL Mutation."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetFieldAssertionMonitor {\n  upsertDatasetFieldAssertionMonitor(\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      type: FIELD_VALUES\n      fieldValuesAssertion: {\n        field: {\n          path: "<name of the column to be monitored>"\n          type: "NUMBER"\n          nativeType: "NUMBER(38,0)"\n        }\n        operator: GREATER_THAN\n        parameters: { value: { type: NUMBER, value: "10" } }\n        failThreshold: { type: COUNT, value: 0 }\n        excludeNulls: true\n      }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */8 * * *"\n      }\n      evaluationParameters: { sourceType: ALL_ROWS_QUERY }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,a.yg)("p",null,"This API will return a unique identifier (URN) for the new assertion if you were successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "upsertDatasetFieldAssertionMonitor": {\n      "urn": "urn:li:assertion:your-new-assertion-id"\n    }\n  },\n  "extensions": {}\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.sdk import DataHubClient\nfrom datahub.metadata.urns import DatasetUrn\n\n# Initialize the client\nclient = DataHubClient(server="<your_server>", token="<your_token>")\n\n# Create smart column metric assertion (AI-powered anomaly detection)\ndataset_urn = DatasetUrn.from_string("urn:li:dataset:(urn:li:dataPlatform:snowflake,database.schema.table,PROD)")\n\nsmart_column_assertion = client.assertions.sync_smart_column_metric_assertion(\n    dataset_urn=dataset_urn,\n    column_name="user_id",\n    metric_type="null_count",\n    display_name="Smart Null Count Check - user_id",\n    # Detection mechanism for column metrics\n    detection_mechanism="all_rows_query_datahub_dataset_profile",\n    # Smart sensitivity setting\n    sensitivity="medium",  # options: "low", "medium", "high"\n    # Tags\n    tags=["automated", "column_quality", "null_checks"],\n    enabled=True\n)\n\nprint(f"Created smart column assertion: {smart_column_assertion.urn}")\n\n# Create regular column metric assertion (fixed threshold on aggregated metric)\ncolumn_metric_assertion = client.assertions.sync_column_metric_assertion(\n    dataset_urn=dataset_urn,\n    column_name="price",\n    metric_type="min",\n    operator="greater_than_or_equal_to",\n    criteria_parameters=0,\n    display_name="Price Minimum Check",\n    # Evaluation schedule\n    schedule="0 */4 * * *",  # Every 4 hours\n    # Tags\n    tags=["automated", "column_quality", "price_validation"],\n    enabled=True\n)\n\nprint(f"Created column metric assertion: {column_metric_assertion.urn}")\n\n# ----------------------------\n# Column value assertions (row-level checks)\n# ----------------------------\n\n# Example 1: Simple email validation with regex pattern\n# Validates that all email values match a valid email format\nemail_regex_assertion = client.assertions.sync_column_value_assertion(\n    dataset_urn=dataset_urn,\n    column_name="email",\n    operator="regex_match",\n    criteria_parameters=r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$"\n)\n\nprint(f"Created email regex assertion: {email_regex_assertion.urn}")\n\n# Example 2: Detailed column value assertion with all parameters\n# Validates individual row values in a column against semantic constraints\ncolumn_value_assertion = client.assertions.sync_column_value_assertion(\n    dataset_urn=dataset_urn,\n    column_name="quantity",\n    display_name="Quantity Positive Check",\n    # Operator applied to each row\'s value (e.g., "greater_than", "between", "regex_match", "not_null")\n    operator="greater_than",\n    criteria_parameters=0,  # Each quantity must be > 0\n    # Optional: Apply a transform before validation (currently supports "length" for strings)\n    # transform="length",\n    # Fail threshold configuration\n    fail_threshold_type="count",  # How to count failures: "count" (absolute number) or "percentage"\n    fail_threshold_value=0,  # Assertion fails if this many rows fail (0 = zero tolerance)\n    # Whether to exclude null values from validation\n    exclude_nulls=True,\n    # Evaluation schedule - how often to check\n    schedule="0 */4 * * *",  # Every 4 hours (cron format)\n    # Tags for grouping and categorization\n    tags=["automated", "column_quality", "value_validation"],\n    # Enable the assertion\n    enabled=True\n)\n\nprint(f"Created column value assertion: {column_value_assertion.urn}")\n')))),(0,a.yg)("p",null,"For more details, see the ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/column-assertions"},"Column Assertions")," guide."),(0,a.yg)("h3",{id:"custom-sql-assertions"},"Custom SQL Assertions"),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"To create a new custom SQL assertion, use the ",(0,a.yg)("inlineCode",{parentName:"p"},"upsertDatasetSqlAssertionMonitor")," GraphQL Mutation."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetSqlAssertionMonitor {\n  upsertDatasetSqlAssertionMonitor(\n    assertionUrn: "<urn of assertion created in earlier query>"\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      type: METRIC\n      description: "<description of the custom assertion>"\n      statement: "<SQL query to be evaluated>"\n      operator: GREATER_THAN_OR_EQUAL_TO\n      parameters: { value: { value: "100", type: NUMBER } }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */6 * * *"\n      }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,a.yg)("p",null,"This API will return a unique identifier (URN) for the new assertion if you were successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "upsertDatasetSqlAssertionMonitor": {\n      "urn": "urn:li:assertion:your-new-assertion-id"\n    }\n  },\n  "extensions": {}\n}\n')),(0,a.yg)("hr",null),(0,a.yg)("p",null,"To create a new ",(0,a.yg)("strong",{parentName:"p"},"smart SQL")," assertion (AI anomaly detection), use the same mutation with ",(0,a.yg)("inlineCode",{parentName:"p"},"inferWithAI: true"),"."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetSqlAssertionMonitor {\n  upsertDatasetSqlAssertionMonitor(\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      type: METRIC\n      description: "<description of the smart SQL assertion>"\n      statement: "<SQL query to be evaluated>"\n      inferWithAI: true\n      inferenceSettings: { sensitivity: { level: 5 } }\n      # Placeholder operator and parameters (AI will infer actual thresholds)\n      operator: GREATER_THAN_OR_EQUAL_TO\n      parameters: { value: { value: "0", type: NUMBER } }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */6 * * *"\n      }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.sdk import DataHubClient\nfrom datahub.metadata.urns import DatasetUrn\n\n# Initialize the client\nclient = DataHubClient(server="<your_server>", token="<your_token>")\n\n# Create custom SQL assertion\ndataset_urn = DatasetUrn.from_string("urn:li:dataset:(urn:li:dataPlatform:snowflake,database.schema.table,PROD)")\n\nsql_assertion = client.assertions.sync_sql_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Revenue Quality Check",\n    statement="SELECT SUM(revenue) FROM database.schema.table WHERE date >= CURRENT_DATE - INTERVAL \'1 day\'",\n    criteria_condition="IS_GREATER_THAN_OR_EQUAL_TO",\n    criteria_parameters=1000,\n    # Evaluation schedule\n    schedule="0 6 * * *",  # Daily at 6 AM\n    # Tags\n    tags=["automated", "revenue", "data_quality"],\n    enabled=True\n)\n\nprint(f"Created SQL assertion: {sql_assertion.urn}")\n\n# Example with range check\nrange_sql_assertion = client.assertions.sync_sql_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Daily Order Count Range Check",\n    statement="SELECT COUNT(*) FROM database.schema.orders WHERE DATE(created_at) = CURRENT_DATE",\n    criteria_condition="IS_WITHIN_A_RANGE",\n    criteria_parameters=(50, 500),  # Between 50 and 500 orders per day\n    schedule="0 */6 * * *",  # Every 6 hours\n    tags=["automated", "orders", "volume_check"],\n    enabled=True\n)\n\nprint(f"Created range SQL assertion: {range_sql_assertion.urn}")\n\n# ----------------------------\n# Smart SQL assertions (AI anomaly detection)\n# ----------------------------\n\nsmart_sql_assertion = client.assertions.sync_smart_sql_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Smart Revenue Monitor",\n    # The SQL statement to evaluate - should return a single numeric value\n    statement="SELECT SUM(revenue) FROM database.schema.table WHERE date >= CURRENT_DATE - INTERVAL \'1 day\'",\n    # AI sensitivity setting\n    sensitivity="medium",  # options: "low", "medium", "high"\n    # Evaluation schedule\n    schedule="0 */6 * * *",  # Every 6 hours\n    # Optional: training data lookback\n    training_data_lookback_days=60,\n    # Tags\n    tags=["automated", "revenue", "smart_sql"],\n    enabled=True\n)\n\nprint(f"Created smart SQL assertion: {smart_sql_assertion.urn}")\n')))),(0,a.yg)("p",null,"For more details, see the ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/custom-sql-assertions"},"Custom SQL Assertions")," guide."),(0,a.yg)("h3",{id:"schema-assertions"},"Schema Assertions"),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"To create a new schema assertion, use the ",(0,a.yg)("inlineCode",{parentName:"p"},"upsertDatasetSchemaAssertionMonitor")," GraphQL Mutation."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetSchemaAssertionMonitor {\n  upsertDatasetSchemaAssertionMonitor(\n    assertionUrn: "urn:li:assertion:existing-assertion-id"\n    input: {\n      entityUrn: "<urn of the table to be monitored>"\n      assertion: {\n        compatibility: EXACT_MATCH\n        fields: [\n          { path: "id", type: STRING }\n          { path: "count", type: NUMBER }\n          { path: "struct", type: STRUCT }\n          { path: "struct.nestedBooleanField", type: BOOLEAN }\n        ]\n      }\n      description: "<description of the schema assertion>"\n      mode: ACTIVE\n    }\n  )\n}\n')),(0,a.yg)("p",null,"This API will return a unique identifier (URN) for the new assertion if you were successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "upsertDatasetSchemaAssertionMonitor": {\n      "urn": "urn:li:assertion:your-new-assertion-id"\n    }\n  },\n  "extensions": {}\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.sdk import DataHubClient\nfrom datahub.metadata.urns import DatasetUrn\n\n# Initialize the client\nclient = DataHubClient(server="<your_server>", token="<your_token>")\n\n# Create schema assertion with exact match compatibility\ndataset_urn = DatasetUrn.from_string("urn:li:dataset:(urn:li:dataPlatform:snowflake,database.schema.table,PROD)")\n\nschema_assertion = client.assertions.sync_schema_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Expected Schema Check",\n    # Compatibility mode - how strictly to match the schema\n    compatibility="EXACT_MATCH",  # options: "EXACT_MATCH", "SUPERSET", "SUBSET"\n    # Expected schema fields\n    fields=[\n        {"path": "id", "type": "STRING"},\n        {"path": "count", "type": "NUMBER"},\n        {"path": "created_at", "type": "TIME"},\n        {"path": "is_active", "type": "BOOLEAN"},\n    ],\n    # Tags for grouping\n    tags=["automated", "schema", "data_quality"],\n    # Enable the assertion\n    enabled=True\n)\n\nprint(f"Created schema assertion: {schema_assertion.urn}")\n\n# Create schema assertion with superset compatibility\n# (actual schema must contain at least these fields, but can have more)\nsuperset_assertion = client.assertions.sync_schema_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Required Fields Check",\n    compatibility="SUPERSET",\n    fields=[\n        {"path": "id", "type": "STRING"},\n        {"path": "name", "type": "STRING"},\n    ],\n    # Evaluation schedule\n    schedule="0 */6 * * *",  # Every 6 hours\n    tags=["automated", "schema", "required_fields"],\n    enabled=True\n)\n\nprint(f"Created superset schema assertion: {superset_assertion.urn}")\n\n# Create schema assertion with native type specification\ndetailed_schema_assertion = client.assertions.sync_schema_assertion(\n    dataset_urn=dataset_urn,\n    display_name="Detailed Schema Validation",\n    compatibility="EXACT_MATCH",\n    fields=[\n        {"path": "id", "type": "STRING", "native_type": "VARCHAR(255)"},\n        {"path": "amount", "type": "NUMBER", "native_type": "DECIMAL(10,2)"},\n        {"path": "metadata", "type": "STRUCT"},\n        {"path": "metadata.key", "type": "STRING"},\n        {"path": "tags", "type": "ARRAY"},\n    ],\n    enabled=True\n)\n\nprint(f"Created detailed schema assertion: {detailed_schema_assertion.urn}")\n')))),(0,a.yg)("p",null,"For more details, see the ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/schema-assertions"},"Schema Assertions")," guide."),(0,a.yg)("h2",{id:"run-assertions"},"Run Assertions"),(0,a.yg)("p",null,"You can use the following APIs to trigger the assertions you've created to run on-demand. This is\nparticularly useful for running assertions on a custom schedule, for example from your production\ndata pipelines."),(0,a.yg)("blockquote",null,(0,a.yg)("p",{parentName:"blockquote"},(0,a.yg)("strong",{parentName:"p"},"Long-Running Assertions"),": The timeout for synchronously running an assertion is currently limited to a maximum of 30 seconds.\nEach of the following APIs support an ",(0,a.yg)("inlineCode",{parentName:"p"},"async")," parameter, which can be set to ",(0,a.yg)("inlineCode",{parentName:"p"},"true")," to run the assertion asynchronously.\nWhen set to ",(0,a.yg)("inlineCode",{parentName:"p"},"true"),", the API will kick off the assertion run and return null immediately. To view the result of the assertion,\nsimply fetching the runEvents field of the ",(0,a.yg)("inlineCode",{parentName:"p"},"assertion(urn: String!)")," GraphQL query.")),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("h3",{id:"run-assertion"},"Run Assertion"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation runAssertion {\n  runAssertion(urn: "urn:li:assertion:your-assertion-id", saveResult: true) {\n    type\n    nativeResults {\n      key\n      value\n    }\n  }\n}\n')),(0,a.yg)("p",null,"Where ",(0,a.yg)("strong",{parentName:"p"},"type")," will contain the Result of the assertion run, either ",(0,a.yg)("inlineCode",{parentName:"p"},"SUCCESS"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"FAILURE"),", or ",(0,a.yg)("inlineCode",{parentName:"p"},"ERROR"),"."),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"saveResult")," argument determines whether the result of the assertion will be saved to DataHub's backend,\nand available to view through the DataHub UI. If this is set to false, the result will NOT be stored in DataHub's\nbackend. ",(0,a.yg)("strong",{parentName:"p"},"Default: ",(0,a.yg)("inlineCode",{parentName:"strong"},"true"))," (results are saved when not specified)."),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"async")," argument controls whether the assertion runs asynchronously. When set to ",(0,a.yg)("inlineCode",{parentName:"p"},"true"),", the API will kick off\nthe assertion run and return immediately. When set to ",(0,a.yg)("inlineCode",{parentName:"p"},"false")," or omitted, the assertion runs synchronously with a\n30-second timeout. ",(0,a.yg)("strong",{parentName:"p"},"Default: ",(0,a.yg)("inlineCode",{parentName:"strong"},"false"))," (synchronous execution when not specified)."),(0,a.yg)("p",null,"If the assertion is external (not natively executed by DataHub), this API will return an error."),(0,a.yg)("p",null,"If running the assertion is successful, the result will be returned as follows:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "runAssertion": {\n      "type": "SUCCESS",\n      "nativeResults": [\n        {\n          "key": "Value",\n          "value": "1382"\n        }\n      ]\n    }\n  },\n  "extensions": {}\n}\n')),(0,a.yg)("h3",{id:"run-group-of-assertions"},"Run Group of Assertions"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation runAssertions {\n  runAssertions(\n    urns: [\n      "urn:li:assertion:your-assertion-id-1"\n      "urn:li:assertion:your-assertion-id-2"\n    ]\n    saveResults: true\n  ) {\n    passingCount\n    failingCount\n    errorCount\n    results {\n      urn\n      result {\n        type\n        nativeResults {\n          key\n          value\n        }\n      }\n    }\n  }\n}\n')),(0,a.yg)("p",null,"Where ",(0,a.yg)("strong",{parentName:"p"},"type")," will contain the Result of the assertion run, either ",(0,a.yg)("inlineCode",{parentName:"p"},"SUCCESS"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"FAILURE"),", or ",(0,a.yg)("inlineCode",{parentName:"p"},"ERROR"),"."),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"saveResults")," argument determines whether the result of the assertion will be saved to DataHub's backend,\nand available to view through the DataHub UI. If this is set to false, the result will NOT be stored in DataHub's\nbackend. ",(0,a.yg)("strong",{parentName:"p"},"Default: ",(0,a.yg)("inlineCode",{parentName:"strong"},"true"))," (results are saved when not specified)."),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"async")," argument controls whether the assertions run asynchronously. When set to ",(0,a.yg)("inlineCode",{parentName:"p"},"true"),", the API will kick off\nthe assertion runs and return immediately. When set to ",(0,a.yg)("inlineCode",{parentName:"p"},"false")," or omitted, the assertions run synchronously with a\n30-second timeout per assertion. ",(0,a.yg)("strong",{parentName:"p"},"Default: ",(0,a.yg)("inlineCode",{parentName:"strong"},"false"))," (synchronous execution when not specified)."),(0,a.yg)("p",null,"If any of the assertion are external (not natively executed by DataHub), they will simply be omitted from the result set."),(0,a.yg)("p",null,"If running the assertions is successful, the results will be returned as follows:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "runAssertions": {\n      "passingCount": 2,\n      "failingCount": 0,\n      "errorCount": 0,\n      "results": [\n        {\n          "urn": "urn:li:assertion:your-assertion-id-1",\n          "result": {\n            "type": "SUCCESS",\n            "nativeResults": [\n              {\n                "key": "Value",\n                "value": "1382"\n              }\n            ]\n          }\n        },\n        {\n          "urn": "urn:li:assertion:your-assertion-id-2",\n          "result": {\n            "type": "FAILURE",\n            "nativeResults": [\n              {\n                "key": "Value",\n                "value": "12323"\n              }\n            ]\n          }\n        }\n      ]\n    }\n  },\n  "extensions": {}\n}\n')),(0,a.yg)("p",null,"Where you should see one result object for each assertion."),(0,a.yg)("h3",{id:"run-all-assertions-for-table"},"Run All Assertions for Table"),(0,a.yg)("p",null,"You can also run all assertions for a specific data asset using the ",(0,a.yg)("inlineCode",{parentName:"p"},"runAssertionsForAsset")," mutation."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation runAssertionsForAsset {\n  runAssertionsForAsset(\n    urn: "urn:li:dataset:(urn:li:dataPlatform:snowflake,purchase_events,PROD)"\n    saveResults: true\n  ) {\n    passingCount\n    failingCount\n    errorCount\n    results {\n      urn\n      result {\n        type\n        nativeResults {\n          key\n          value\n        }\n      }\n    }\n  }\n}\n')),(0,a.yg)("p",null,"Where ",(0,a.yg)("inlineCode",{parentName:"p"},"type")," will contain the Result of the assertion run, either ",(0,a.yg)("inlineCode",{parentName:"p"},"SUCCESS"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"FAILURE"),", or ",(0,a.yg)("inlineCode",{parentName:"p"},"ERROR"),"."),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"saveResults")," argument determines whether the result of the assertion will be saved to DataHub's backend,\nand available to view through the DataHub UI. If this is set to false, the result will NOT be stored in DataHub's\nbackend. ",(0,a.yg)("strong",{parentName:"p"},"Default: ",(0,a.yg)("inlineCode",{parentName:"strong"},"true"))," (results are saved when not specified)."),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"async")," argument controls whether the assertions run asynchronously. When set to ",(0,a.yg)("inlineCode",{parentName:"p"},"true"),", the API will kick off\nthe assertion runs and return immediately. When set to ",(0,a.yg)("inlineCode",{parentName:"p"},"false")," or omitted, the assertions run synchronously with a\n30-second timeout per assertion. ",(0,a.yg)("strong",{parentName:"p"},"Default: ",(0,a.yg)("inlineCode",{parentName:"strong"},"false"))," (synchronous execution when not specified)."),(0,a.yg)("p",null,"If any of the assertion are external (not natively executed by DataHub), they will simply be omitted from the result\nset."),(0,a.yg)("p",null,"If running the assertions is successful, the results will be returned as follows:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "runAssertionsForAsset": {\n      "passingCount": 2,\n      "failingCount": 0,\n      "errorCount": 0,\n      "results": [\n        {\n          "urn": "urn:li:assertion:your-assertion-id-1",\n          "result": {\n            "type": "SUCCESS",\n            "nativeResults": [\n              {\n                "key": "Value",\n                "value": "1382"\n              }\n            ]\n          }\n        },\n        {\n          "urn": "urn:li:assertion:your-assertion-id-2",\n          "result": {\n            "type": "FAILURE",\n            "nativeResults": [\n              {\n                "key": "Value",\n                "value": "12323"\n              }\n            ]\n          }\n        }\n      ]\n    }\n  },\n  "extensions": {}\n}\n')),(0,a.yg)("p",null,"Where you should see one result object for each assertion."),(0,a.yg)("h3",{id:"run-group-of-assertions-for-table"},"Run Group of Assertions for Table"),(0,a.yg)("p",null,"If you don't always want to run ",(0,a.yg)("em",{parentName:"p"},"all")," assertions for a given table, you can also opt to run a subset of the\ntable's assertions using ",(0,a.yg)("em",{parentName:"p"},"Assertion Tags"),". First, you'll add tags to your assertions to group and categorize them,\nthen you'll call the ",(0,a.yg)("inlineCode",{parentName:"p"},"runAssertionsForAsset")," mutation with the ",(0,a.yg)("inlineCode",{parentName:"p"},"tagUrns")," argument to filter for assertions having those tags."),(0,a.yg)("h4",{id:"step-1-adding-tag-to-an-assertion"},"Step 1: Adding Tag to an Assertion"),(0,a.yg)("p",null,"Currently, you can add tags to an assertion only via the DataHub GraphQL API. You can do this using the following mutation:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation addTags {\n  addTag(\n    input: {\n      resourceUrn: "urn:li:assertion:your-assertion"\n      tagUrn: "urn:li:tag:my-important-tag"\n    }\n  )\n}\n')),(0,a.yg)("h4",{id:"step-2-run-all-assertions-for-a-table-with-tags"},"Step 2: Run All Assertions for a Table with Tags"),(0,a.yg)("p",null,"Now, you can run all assertions for a table with a specific tag(s) using the ",(0,a.yg)("inlineCode",{parentName:"p"},"runAssertionsForAsset")," mutation with the\n",(0,a.yg)("inlineCode",{parentName:"p"},"tagUrns")," input parameter:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation runAssertionsForAsset {\n  runAssertionsForAsset(\n    urn: "urn:li:dataset:(urn:li:dataPlatform:snowflake,purchase_events,PROD)"\n    tagUrns: ["urn:li:tag:my-important-tag"]\n  ) {\n    passingCount\n    failingCount\n    errorCount\n    results {\n      urn\n      result {\n        type\n        nativeResults {\n          key\n          value\n        }\n      }\n    }\n  }\n}\n')),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Coming Soon"),": Support for adding tags to assertions through the DataHub UI.")),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("h3",{id:"run-assertion-1"},"Run Assertion"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/run_assertion.py\nimport logging\n\nfrom datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph\n\nlog = logging.getLogger(__name__)\n\ngraph = DataHubGraph(\n    config=DatahubClientConfig(\n        server="http://localhost:8080",\n    )\n)\n\nassertion_urn = "urn:li:assertion:6e3f9e09-1483-40f9-b9cd-30e5f182694a"\n\n# Run the assertion\nassertion_result = graph.run_assertion(urn=assertion_urn, save_result=True)\n\nlog.info(\n    f"Assertion result (SUCCESS / FAILURE / ERROR): {assertion_result.get(\'type\')}"\n)\n\n')),(0,a.yg)("h3",{id:"run-group-of-assertions-1"},"Run Group of Assertions"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/run_assertions.py\nimport logging\n\nfrom datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph\n\nlog = logging.getLogger(__name__)\n\ngraph = DataHubGraph(\n    config=DatahubClientConfig(\n        server="http://localhost:8080",\n    )\n)\n\nassertion_urns = [\n    "urn:li:assertion:6e3f9e09-1483-40f9-b9cd-30e5f182694a",\n    "urn:li:assertion:9e3f9e09-1483-40f9-b9cd-30e5f182694g",\n]\n\n# Run the assertions\nassertion_results = graph.run_assertions(urns=assertion_urns, save_result=True).get(\n    "results"\n)\n\nif assertion_results is not None:\n    assertion_result_1 = assertion_results.get(\n        "urn:li:assertion:6e3f9e09-1483-40f9-b9cd-30e5f182694a"\n    )\n    assertion_result_2 = assertion_results.get(\n        "urn:li:assertion:9e3f9e09-1483-40f9-b9cd-30e5f182694g"\n    )\n\n    log.info(f"Assertion results: {assertion_results}")\n    log.info(\n        f"Assertion result 1 (SUCCESS / FAILURE / ERROR): {assertion_result_1.get(\'type\')}"\n    )\n    log.info(\n        f"Assertion result 2 (SUCCESS / FAILURE / ERROR): {assertion_result_2.get(\'type\')}"\n    )\n\n')),(0,a.yg)("h3",{id:"run-all-assertions-for-table-1"},"Run All Assertions for Table"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/run_assertions_for_asset.py\nimport logging\n\nfrom datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph\n\nlog = logging.getLogger(__name__)\n\ngraph = DataHubGraph(\n    config=DatahubClientConfig(\n        server="http://localhost:8080",\n    )\n)\n\ndataset_urn = "urn:li:dataset:(urn:li:dataPlatform:snowflake,my_snowflake_table,PROD)"\n\n# Run all native assertions for the dataset\nassertion_results = graph.run_assertions_for_asset(urn=dataset_urn).get("results")\n\nif assertion_results is not None:\n    assertion_result_1 = assertion_results.get(\n        "urn:li:assertion:6e3f9e09-1483-40f9-b9cd-30e5f182694a"\n    )\n    assertion_result_2 = assertion_results.get(\n        "urn:li:assertion:9e3f9e09-1483-40f9-b9cd-30e5f182694g"\n    )\n\n    log.info(f"Assertion results: {assertion_results}")\n    log.info(\n        f"Assertion result 1 (SUCCESS / FAILURE / ERROR): {assertion_result_1.get(\'type\')}"\n    )\n    log.info(\n        f"Assertion result 2 (SUCCESS / FAILURE / ERROR): {assertion_result_2.get(\'type\')}"\n    )\n\n# Run a subset of native assertions having a specific tag\nimportant_assertion_tag = "urn:li:tag:my-important-assertion-tag"\nassertion_results = graph.run_assertions_for_asset(\n    urn=dataset_urn, tag_urns=[important_assertion_tag]\n).get("results")\n\n')))),(0,a.yg)("h3",{id:"providing-dynamic-parameters-to-assertions"},"Providing Dynamic Parameters to Assertions"),(0,a.yg)("p",null,"You can provide ",(0,a.yg)("strong",{parentName:"p"},"dynamic parameters")," to your assertions to customize their behavior. This is particularly useful for\nassertions that require dynamic parameters, such as a threshold value that changes based on the time of day."),(0,a.yg)("p",null,"Dynamic parameters can be injected into the SQL fragment portion of any Assertion. For example, it can appear\nin any part of the SQL statement in a ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/custom-sql-assertions"},"Custom SQL")," Assertion,\nor it can appear in the ",(0,a.yg)("strong",{parentName:"p"},"Advanced > Filter")," section of a ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/column-assertions"},"Column"),",\n",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/volume-assertions"},"Volume"),", or ",(0,a.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/freshness-assertions"},"Freshness")," Assertion."),(0,a.yg)("p",null,"To do so, you'll first need to edit the SQL fragment to include the dynamic parameter. Dynamic parameters appear\nas ",(0,a.yg)("inlineCode",{parentName:"p"},"${parameterName}")," in the SQL fragment."),(0,a.yg)("p",null,"Next, you'll call the ",(0,a.yg)("inlineCode",{parentName:"p"},"runAssertion"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"runAssertions"),", or ",(0,a.yg)("inlineCode",{parentName:"p"},"runAssertionsForAsset")," mutations with the ",(0,a.yg)("inlineCode",{parentName:"p"},"parameters")," input argument.\nThis argument is a list of key-value tuples, where the key is the parameter name and the value is the parameter value:"),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation runAssertion {\n  runAssertion(\n    urn: "urn:li:assertion:your-assertion-id"\n    parameters: [{ key: "parameterName", value: "parameterValue" }]\n  ) {\n    type\n    nativeResults {\n      key\n      value\n    }\n  }\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/run_assertion_with_parameters.py\nimport logging\n\nfrom datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph\n\nlog = logging.getLogger(__name__)\n\ngraph = DataHubGraph(\n    config=DatahubClientConfig(\n        server="http://localhost:8080",\n    )\n)\n\nassertion_urn = "urn:li:assertion:6e3f9e09-1483-40f9-b9cd-30e5f182694a"\n\n# Define dynamic parameters to inject into the assertion\'s SQL fragment.\n# These parameters will replace ${parameterName} placeholders in the SQL.\nparameters = {\n    "min_threshold": "100",\n    "max_threshold": "1000",\n}\n\n# Run the assertion with dynamic parameters\nassertion_result = graph.run_assertion(\n    urn=assertion_urn,\n    save_result=True,\n    parameters=parameters,\n)\n\nlog.info(\n    f"Assertion result (SUCCESS / FAILURE / ERROR): {assertion_result.get(\'type\')}"\n)\n\n')))),(0,a.yg)("p",null,"At runtime, the ",(0,a.yg)("inlineCode",{parentName:"p"},"${parameterName}")," placeholder in the SQL fragment will be replaced with the provided ",(0,a.yg)("inlineCode",{parentName:"p"},"parameterValue")," before the query\nis sent to the database for execution."),(0,a.yg)("h2",{id:"get-assertion-details"},"Get Assertion Details"),(0,a.yg)("p",null,"You can use the following APIs to"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"Fetch existing assertion definitions + run history"),(0,a.yg)("li",{parentName:"ol"},"Fetch the assertions associated with a given table + their run history.")),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("h3",{id:"get-assertions-for-table"},"Get Assertions for Table"),(0,a.yg)("p",null,"To retrieve all the assertions for a table, you can use the following GraphQL Query."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'query dataset {\n  dataset(\n    urn: "urn:li:dataset:(urn:li:dataPlatform:snowflake,purchases,PROD)"\n  ) {\n    assertions(start: 0, count: 1000) {\n      start\n      count\n      total\n      assertions {\n        urn\n        # Fetch the last run of each associated assertion.\n        runEvents(status: COMPLETE, limit: 1) {\n          total\n          failed\n          succeeded\n          runEvents {\n            timestampMillis\n            status\n            result {\n              type\n              nativeResults {\n                key\n                value\n              }\n            }\n          }\n        }\n        info {\n          type\n          description\n          lastUpdated {\n            time\n            actor\n          }\n          datasetAssertion {\n            datasetUrn\n            scope\n            aggregation\n            operator\n            parameters {\n              value {\n                value\n                type\n              }\n              minValue {\n                value\n                type\n              }\n              maxValue {\n                value\n                type\n              }\n            }\n            fields {\n              urn\n              path\n            }\n            nativeType\n            nativeParameters {\n              key\n              value\n            }\n            logic\n          }\n          freshnessAssertion {\n            type\n            entityUrn\n            schedule {\n              type\n              cron {\n                cron\n                timezone\n              }\n              fixedInterval {\n                unit\n                multiple\n              }\n            }\n            filter {\n              type\n              sql\n            }\n          }\n          sqlAssertion {\n            type\n            entityUrn\n            statement\n            changeType\n            operator\n            parameters {\n              value {\n                value\n                type\n              }\n              minValue {\n                value\n                type\n              }\n              maxValue {\n                value\n                type\n              }\n            }\n          }\n          fieldAssertion {\n            type\n            entityUrn\n            filter {\n              type\n              sql\n            }\n            fieldValuesAssertion {\n              field {\n                path\n                type\n                nativeType\n              }\n              transform {\n                type\n              }\n              operator\n              parameters {\n                value {\n                  value\n                  type\n                }\n                minValue {\n                  value\n                  type\n                }\n                maxValue {\n                  value\n                  type\n                }\n              }\n              failThreshold {\n                type\n                value\n              }\n              excludeNulls\n            }\n            fieldMetricAssertion {\n              field {\n                path\n                type\n                nativeType\n              }\n              metric\n              operator\n              parameters {\n                value {\n                  value\n                  type\n                }\n                minValue {\n                  value\n                  type\n                }\n                maxValue {\n                  value\n                  type\n                }\n              }\n            }\n          }\n          volumeAssertion {\n            type\n            entityUrn\n            filter {\n              type\n              sql\n            }\n            rowCountTotal {\n              operator\n              parameters {\n                value {\n                  value\n                  type\n                }\n                minValue {\n                  value\n                  type\n                }\n                maxValue {\n                  value\n                  type\n                }\n              }\n            }\n            rowCountChange {\n              type\n              operator\n              parameters {\n                value {\n                  value\n                  type\n                }\n                minValue {\n                  value\n                  type\n                }\n                maxValue {\n                  value\n                  type\n                }\n              }\n            }\n          }\n          schemaAssertion {\n            entityUrn\n            compatibility\n            fields {\n              path\n              type\n              nativeType\n            }\n            schema {\n              fields {\n                fieldPath\n                type\n                nativeDataType\n              }\n            }\n          }\n          source {\n            type\n            created {\n              time\n              actor\n            }\n          }\n        }\n      }\n    }\n  }\n}\n')),(0,a.yg)("h3",{id:"get-assertion-details-1"},"Get Assertion Details"),(0,a.yg)("p",null,"You can use the following GraphQL query to fetch the details for an assertion along with its evaluation history by URN."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'query getAssertion {\n  assertion(urn: "urn:li:assertion:assertion-id") {\n    urn\n    # Fetch the last 10 runs for the assertion.\n    runEvents(status: COMPLETE, limit: 10) {\n      total\n      failed\n      succeeded\n      runEvents {\n        timestampMillis\n        status\n        result {\n          type\n          nativeResults {\n            key\n            value\n          }\n        }\n      }\n    }\n    info {\n      type\n      description\n      lastUpdated {\n        time\n        actor\n      }\n      datasetAssertion {\n        datasetUrn\n        scope\n        aggregation\n        operator\n        parameters {\n          value {\n            value\n            type\n          }\n          minValue {\n            value\n            type\n          }\n          maxValue {\n            value\n            type\n          }\n        }\n        fields {\n          urn\n          path\n        }\n        nativeType\n        nativeParameters {\n          key\n          value\n        }\n        logic\n      }\n      freshnessAssertion {\n        type\n        entityUrn\n        schedule {\n          type\n          cron {\n            cron\n            timezone\n          }\n          fixedInterval {\n            unit\n            multiple\n          }\n        }\n        filter {\n          type\n          sql\n        }\n      }\n      sqlAssertion {\n        type\n        entityUrn\n        statement\n        changeType\n        operator\n        parameters {\n          value {\n            value\n            type\n          }\n          minValue {\n            value\n            type\n          }\n          maxValue {\n            value\n            type\n          }\n        }\n      }\n      fieldAssertion {\n        type\n        entityUrn\n        filter {\n          type\n          sql\n        }\n        fieldValuesAssertion {\n          field {\n            path\n            type\n            nativeType\n          }\n          transform {\n            type\n          }\n          operator\n          parameters {\n            value {\n              value\n              type\n            }\n            minValue {\n              value\n              type\n            }\n            maxValue {\n              value\n              type\n            }\n          }\n          failThreshold {\n            type\n            value\n          }\n          excludeNulls\n        }\n        fieldMetricAssertion {\n          field {\n            path\n            type\n            nativeType\n          }\n          metric\n          operator\n          parameters {\n            value {\n              value\n              type\n            }\n            minValue {\n              value\n              type\n            }\n            maxValue {\n              value\n              type\n            }\n          }\n        }\n      }\n      volumeAssertion {\n        type\n        entityUrn\n        filter {\n          type\n          sql\n        }\n        rowCountTotal {\n          operator\n          parameters {\n            value {\n              value\n              type\n            }\n            minValue {\n              value\n              type\n            }\n            maxValue {\n              value\n              type\n            }\n          }\n        }\n        rowCountChange {\n          type\n          operator\n          parameters {\n            value {\n              value\n              type\n            }\n            minValue {\n              value\n              type\n            }\n            maxValue {\n              value\n              type\n            }\n          }\n        }\n      }\n      schemaAssertion {\n        entityUrn\n        compatibility\n        fields {\n          path\n          type\n          nativeType\n        }\n        schema {\n          fields {\n            fieldPath\n            type\n            nativeDataType\n          }\n        }\n      }\n      source {\n        type\n        created {\n          time\n          actor\n        }\n      }\n    }\n  }\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},"Python support coming soon!\n")))),(0,a.yg)("h2",{id:"add-tag-to-assertion"},"Add Tag to Assertion"),(0,a.yg)("p",null,"You can add tags to individual assertions to group and categorize them, for example by its priority or severity.\nNote that the tag should already exist in DataHub, or the operation will fail."),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation addTags {\n  addTag(\n    input: {\n      resourceUrn: "urn:li:assertion:your-assertion"\n      tagUrn: "urn:li:tag:my-important-tag"\n    }\n  )\n}\n')),(0,a.yg)("p",null,"If you see the following response, the operation was successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "addTag": true\n  },\n  "extensions": {}\n}\n')),(0,a.yg)("p",null,"You can create new tags using the ",(0,a.yg)("inlineCode",{parentName:"p"},"createTag")," mutation or via the UI."))),(0,a.yg)("h2",{id:"delete-assertions"},"Delete Assertions"),(0,a.yg)("p",null,"You can use delete dataset operations to DataHub using the following APIs."),(0,a.yg)(s.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation deleteAssertion {\n  deleteAssertion(urn: "urn:li:assertion:test")\n}\n')),(0,a.yg)("p",null,"If you see the following response, the operation was successful:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "data": {\n    "deleteAssertion": true\n  },\n  "extensions": {}\n}\n'))),(0,a.yg)(r.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/assertion_delete.py\nimport logging\n\nfrom datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph\n\nlog = logging.getLogger(__name__)\n\ngraph = DataHubGraph(\n    config=DatahubClientConfig(\n        server="http://localhost:8080",\n    )\n)\n\nassertion_urn = "urn:li:assertion:my-assertion"\n\n# Delete the Assertion\ngraph.delete_entity(urn=assertion_urn, hard=True)\n\nlog.info(f"Deleted assertion {assertion_urn}")\n\n')))),(0,a.yg)("h2",{id:"advanced-create-and-report-results-for-custom-assertions"},"(Advanced) Create and Report Results for Custom Assertions"),(0,a.yg)("p",null,"If you'd like to create and report results for your own custom assertions, e.g. those which are run and\nevaluated outside of DataHub Cloud, you need to generate 2 important Assertion Entity aspects, and give the assertion a unique\nURN of the following format:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"Generate a unique URN for your assertion")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-plaintext"},"urn:li:assertion:<unique-assertion-id>\n")),(0,a.yg)("ol",{start:2},(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"Generate the ",(0,a.yg)("a",{parentName:"p",href:"/docs/generated/metamodel/entities/assertion#assertion-info"},(0,a.yg)("strong",{parentName:"a"},"AssertionInfo"))," aspect for the assertion. You can do this using the Python SDK. Give your assertion a ",(0,a.yg)("inlineCode",{parentName:"p"},"type")," and a ",(0,a.yg)("inlineCode",{parentName:"p"},"source"),"\nwith type ",(0,a.yg)("inlineCode",{parentName:"p"},"EXTERNAL")," to mark it as an external assertion, not run by DataHub itself.")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"Generate the ",(0,a.yg)("a",{parentName:"p",href:"/docs/generated/metamodel/entities/assertion#assertionrunevent-timeseries"},(0,a.yg)("strong",{parentName:"a"},"AssertionRunEvent"))," timeseries aspect using the Python SDK. This aspect should contain the result of the assertion\nrun at a given timestamp and will be shown on the results graph in DataHub's UI."))),(0,a.yg)("h2",{id:"create-and-remove-subscriptions"},"Create and Remove Subscriptions"),(0,a.yg)("p",null,"Reference the ",(0,a.yg)("a",{parentName:"p",href:"/docs/api/tutorials/subscriptions"},"Subscriptions SDK")," for more information on how to create and remove subscriptions on Datasets or Assertions."))}_.isMDXComponent=!0}}]);