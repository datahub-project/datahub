"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[2601],{55372:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>d,default:()=>h,frontMatter:()=>p,metadata:()=>g,toc:()=>u});n(96540);var a=n(15680),r=n(53720),i=n(5400);function s(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})),e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}const p={sidebar_position:4,title:"DataProcess",slug:"/generated/metamodel/entities/dataprocess",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/dataProcess.md"},d="DataProcess",g={unversionedId:"docs/generated/metamodel/entities/dataProcess",id:"docs/generated/metamodel/entities/dataProcess",title:"DataProcess",description:"DEPRECATED: This entity is deprecated and should not be used for new implementations.",source:"@site/genDocs/docs/generated/metamodel/entities/dataProcess.md",sourceDirName:"docs/generated/metamodel/entities",slug:"/generated/metamodel/entities/dataprocess",permalink:"/docs/generated/metamodel/entities/dataprocess",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/dataProcess.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,title:"DataProcess",slug:"/generated/metamodel/entities/dataprocess",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/dataProcess.md"},sidebar:"overviewSidebar",previous:{title:"DataFlow",permalink:"/docs/generated/metamodel/entities/dataflow"},next:{title:"DataProcessInstance",permalink:"/docs/generated/metamodel/entities/dataprocessinstance"}},m={},u=[{value:"Deprecation Notice",id:"deprecation-notice",level:2},{value:"Why was it deprecated?",id:"why-was-it-deprecated",level:3},{value:"Identity (Historical Reference)",id:"identity-historical-reference",level:2},{value:"Example URNs",id:"example-urns",level:3},{value:"Important Capabilities (Historical Reference)",id:"important-capabilities-historical-reference",level:2},{value:"DataProcessInfo Aspect",id:"dataprocessinfo-aspect",level:3},{value:"Common Aspects",id:"common-aspects",level:3},{value:"Migration Guide",id:"migration-guide",level:2},{value:"When to use DataFlow vs DataJob",id:"when-to-use-dataflow-vs-datajob",level:3},{value:"Conceptual Mapping",id:"conceptual-mapping",level:3},{value:"Migration Steps",id:"migration-steps",level:3},{value:"Migration Examples",id:"migration-examples",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Querying Existing DataProcess Entities",id:"querying-existing-dataprocess-entities",level:3},{value:"Creating Equivalent DataFlow and DataJob (Recommended)",id:"creating-equivalent-dataflow-and-datajob-recommended",level:3},{value:"Complete Migration Example",id:"complete-migration-example",level:3},{value:"Integration Points",id:"integration-points",level:2},{value:"Historical Usage",id:"historical-usage",level:3},{value:"Modern Replacements",id:"modern-replacements",level:3},{value:"DataProcessInstance",id:"dataprocessinstance",level:3},{value:"Notable Exceptions",id:"notable-exceptions",level:2},{value:"Timeline for Removal",id:"timeline-for-removal",level:3},{value:"Reading Existing Data",id:"reading-existing-data",level:3},{value:"No New Writes Recommended",id:"no-new-writes-recommended",level:3},{value:"Upgrade Path",id:"upgrade-path",level:3},{value:"GraphQL API",id:"graphql-api",level:3},{value:"Additional Resources",id:"additional-resources",level:2},{value:"Technical Reference Guide",id:"technical-reference-guide",level:2},{value:"Reading the Field Tables",id:"reading-the-field-tables",level:3},{value:"Aspects",id:"aspects",level:3},{value:"dataProcessKey",id:"dataprocesskey",level:4},{value:"ownership",id:"ownership",level:4},{value:"dataProcessInfo",id:"dataprocessinfo",level:4},{value:"status",id:"status",level:4},{value:"testResults",id:"testresults",level:4},{value:"subTypes",id:"subtypes",level:4},{value:"Common Types",id:"common-types",level:3},{value:"AuditStamp",id:"auditstamp",level:4},{value:"TestResult",id:"testresult",level:4},{value:"Relationships",id:"relationships",level:3},{value:"Outgoing",id:"outgoing",level:4},{value:"Global Metadata Model",id:"global-metadata-model",level:3}],c={toc:u},y="wrapper";function h(e){var{components:t}=e,n=o(e,["components"]);return(0,a.yg)(y,l(function(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{},a=Object.keys(n);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(n).filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})))),a.forEach((function(t){s(e,t,n[t])}))}return e}({},c,n),{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"dataprocess"},"DataProcess"),(0,a.yg)("blockquote",null,(0,a.yg)("p",{parentName:"blockquote"},(0,a.yg)("strong",{parentName:"p"},"DEPRECATED"),": This entity is deprecated and should not be used for new implementations."),(0,a.yg)("p",{parentName:"blockquote"},(0,a.yg)("strong",{parentName:"p"},"Use ",(0,a.yg)("a",{parentName:"strong",href:"/docs/generated/metamodel/entities/dataflow"},"dataFlow")," and ",(0,a.yg)("a",{parentName:"strong",href:"/docs/generated/metamodel/entities/datajob"},"dataJob")," instead.")),(0,a.yg)("p",{parentName:"blockquote"},"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcess")," entity was an early attempt to model data processing tasks but has been superseded by the more robust and flexible ",(0,a.yg)("inlineCode",{parentName:"p"},"dataFlow")," and ",(0,a.yg)("inlineCode",{parentName:"p"},"dataJob")," entities which better represent the hierarchical nature of modern data pipelines.")),(0,a.yg)("h2",{id:"deprecation-notice"},"Deprecation Notice"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcess")," entity was deprecated to provide a clearer separation between:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DataFlow"),": Represents the overall pipeline/workflow (e.g., an Airflow DAG, dbt project, Spark application)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DataJob"),": Represents individual tasks within a pipeline (e.g., an Airflow task, dbt model, Spark job)")),(0,a.yg)("p",null,"This two-level hierarchy better matches how modern orchestration systems organize data processing work and provides more flexibility for lineage tracking, ownership assignment, and operational monitoring."),(0,a.yg)("h3",{id:"why-was-it-deprecated"},"Why was it deprecated?"),(0,a.yg)("p",null,"The original ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcess")," entity had several limitations:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"No hierarchical structure"),": It couldn't represent the relationship between a pipeline and its constituent tasks"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Limited orchestrator support"),": The flat structure didn't map well to DAG-based orchestration platforms like Airflow, Prefect, or Dagster"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Unclear semantics"),": It was ambiguous whether a dataProcess represented a whole pipeline or a single task"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Poor lineage modeling"),": Without task-level granularity, lineage relationships were less precise")),(0,a.yg)("p",null,"The new ",(0,a.yg)("inlineCode",{parentName:"p"},"dataFlow")," and ",(0,a.yg)("inlineCode",{parentName:"p"},"dataJob")," model addresses these limitations by providing a clear parent-child relationship that mirrors real-world data processing architectures."),(0,a.yg)("h2",{id:"identity-historical-reference"},"Identity (Historical Reference)"),(0,a.yg)("p",null,"DataProcess entities were identified by three components:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Name"),": The process name (typically an ETL job name)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Orchestrator"),": The workflow management platform (e.g., ",(0,a.yg)("inlineCode",{parentName:"li"},"airflow"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"azkaban"),")"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Origin (Fabric)"),": The environment where the process runs (PROD, DEV, etc.)")),(0,a.yg)("p",null,"The URN structure was:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"urn:li:dataProcess:(<name>,<orchestrator>,<origin>)\n")),(0,a.yg)("h3",{id:"example-urns"},"Example URNs"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"urn:li:dataProcess:(customer_etl_job,airflow,PROD)\nurn:li:dataProcess:(sales_aggregation,azkaban,DEV)\n")),(0,a.yg)("h2",{id:"important-capabilities-historical-reference"},"Important Capabilities (Historical Reference)"),(0,a.yg)("h3",{id:"dataprocessinfo-aspect"},"DataProcessInfo Aspect"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInfo")," aspect captured inputs and outputs of the process:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Inputs"),": Array of dataset URNs consumed by the process"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Outputs"),": Array of dataset URNs produced by the process")),(0,a.yg)("p",null,'This established basic lineage relationships through "Consumes" relationships with datasets.'),(0,a.yg)("h3",{id:"common-aspects"},"Common Aspects"),(0,a.yg)("p",null,"Like other entities, dataProcess supported:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Ownership"),": Assigning owners to processes"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Status"),": Marking processes as removed"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Global Tags"),": Categorization and classification"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Institutional Memory"),": Links to documentation")),(0,a.yg)("h2",{id:"migration-guide"},"Migration Guide"),(0,a.yg)("h3",{id:"when-to-use-dataflow-vs-datajob"},"When to use DataFlow vs DataJob"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Use DataFlow when representing:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Airflow DAGs"),(0,a.yg)("li",{parentName:"ul"},"dbt projects"),(0,a.yg)("li",{parentName:"ul"},"Prefect flows"),(0,a.yg)("li",{parentName:"ul"},"Dagster pipelines"),(0,a.yg)("li",{parentName:"ul"},"Azkaban workflows"),(0,a.yg)("li",{parentName:"ul"},"Any container of related data processing tasks")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Use DataJob when representing:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Airflow tasks within a DAG"),(0,a.yg)("li",{parentName:"ul"},"dbt models within a project"),(0,a.yg)("li",{parentName:"ul"},"Prefect tasks within a flow"),(0,a.yg)("li",{parentName:"ul"},"Dagster ops/assets within a pipeline"),(0,a.yg)("li",{parentName:"ul"},"Individual processing steps")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Use both together:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Create a DataFlow for the pipeline"),(0,a.yg)("li",{parentName:"ul"},"Create DataJobs for each task within that pipeline"),(0,a.yg)("li",{parentName:"ul"},"Link DataJobs to their parent DataFlow")),(0,a.yg)("h3",{id:"conceptual-mapping"},"Conceptual Mapping"),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"DataProcess Concept"),(0,a.yg)("th",{parentName:"tr",align:null},"New Model Equivalent"),(0,a.yg)("th",{parentName:"tr",align:null},"Notes"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Process with tasks"),(0,a.yg)("td",{parentName:"tr",align:null},"DataFlow + DataJobs"),(0,a.yg)("td",{parentName:"tr",align:null},"Split into two entities")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Process name"),(0,a.yg)("td",{parentName:"tr",align:null},"DataFlow flowId"),(0,a.yg)("td",{parentName:"tr",align:null},"Becomes the parent identifier")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Single-step process"),(0,a.yg)("td",{parentName:"tr",align:null},"DataFlow + 1 DataJob"),(0,a.yg)("td",{parentName:"tr",align:null},"Still requires both entities")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Orchestrator"),(0,a.yg)("td",{parentName:"tr",align:null},"DataFlow orchestrator"),(0,a.yg)("td",{parentName:"tr",align:null},"Same concept, better modeling")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Origin/Fabric"),(0,a.yg)("td",{parentName:"tr",align:null},"DataFlow cluster"),(0,a.yg)("td",{parentName:"tr",align:null},"Often matches environment")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Inputs/Outputs"),(0,a.yg)("td",{parentName:"tr",align:null},"DataJob dataJobInputOutput"),(0,a.yg)("td",{parentName:"tr",align:null},"Moved to job level for precision")))),(0,a.yg)("h3",{id:"migration-steps"},"Migration Steps"),(0,a.yg)("p",null,"To migrate from ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcess")," to ",(0,a.yg)("inlineCode",{parentName:"p"},"dataFlow"),"/",(0,a.yg)("inlineCode",{parentName:"p"},"dataJob"),":"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"Identify your process structure"),": Determine if your dataProcess represents a pipeline (has multiple steps) or a single task")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"Create a DataFlow"),": This represents the overall pipeline/workflow"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Use the same orchestrator value"),(0,a.yg)("li",{parentName:"ul"},"Use the process name as the flow ID"),(0,a.yg)("li",{parentName:"ul"},"Use a cluster identifier (often matches the origin/fabric)"))),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"Create DataJob(s)"),": Create one or more jobs within the flow"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"For single-step processes: create one job named after the process"),(0,a.yg)("li",{parentName:"ul"},"For multi-step processes: create a job for each step"),(0,a.yg)("li",{parentName:"ul"},"Link each job to its parent DataFlow"))),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"Migrate lineage"),": Move input/output dataset relationships from the process level to the job level")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"Migrate metadata"),": Transfer ownership, tags, and documentation to the appropriate entity (typically the DataFlow for pipeline-level metadata, or specific DataJobs for task-level metadata)"))),(0,a.yg)("h3",{id:"migration-examples"},"Migration Examples"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Example 1: Simple single-task process")),(0,a.yg)("p",null,"Old dataProcess:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"urn:li:dataProcess:(daily_report,airflow,PROD)\n")),(0,a.yg)("p",null,"New structure:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"DataFlow: urn:li:dataFlow:(airflow,daily_report,prod)\nDataJob:  urn:li:dataJob:(urn:li:dataFlow:(airflow,daily_report,prod),daily_report_task)\n")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Example 2: Multi-step ETL pipeline")),(0,a.yg)("p",null,"Old dataProcess:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"urn:li:dataProcess:(customer_pipeline,airflow,PROD)\n")),(0,a.yg)("p",null,"New structure:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"DataFlow: urn:li:dataFlow:(airflow,customer_pipeline,prod)\nDataJob:  urn:li:dataJob:(urn:li:dataFlow:(airflow,customer_pipeline,prod),extract_customers)\nDataJob:  urn:li:dataJob:(urn:li:dataFlow:(airflow,customer_pipeline,prod),transform_customers)\nDataJob:  urn:li:dataJob:(urn:li:dataFlow:(airflow,customer_pipeline,prod),load_customers)\n")),(0,a.yg)("h2",{id:"code-examples"},"Code Examples"),(0,a.yg)("h3",{id:"querying-existing-dataprocess-entities"},"Querying Existing DataProcess Entities"),(0,a.yg)("p",null,"If you need to query existing dataProcess entities for migration purposes:"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Query a dataProcess entity"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/dataprocess_query_deprecated.py\n"""\nExample: Query an existing (deprecated) dataProcess entity for migration purposes.\n\nThis example shows how to read a deprecated dataProcess entity from DataHub\nto understand its structure before migrating it to dataFlow and dataJob entities.\n\nNote: This is only for reading existing data. Do NOT create new dataProcess entities.\nUse dataFlow and dataJob instead for all new implementations.\n"""\n\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\n\n# Create emitter to read from DataHub\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\n# URN of the deprecated dataProcess entity to query\ndataprocess_urn = "urn:li:dataProcess:(customer_etl_job,airflow,PROD)"\n\n# Fetch the entity using the REST API\ntry:\n    entity = emitter._session.get(\n        f"{emitter._gms_server}/entities/{dataprocess_urn}"\n    ).json()\n\n    print(f"Found dataProcess: {dataprocess_urn}")\n    print("\\n=== Entity Aspects ===")\n\n    # Extract key information for migration\n    if "aspects" in entity:\n        aspects = entity["aspects"]\n\n        # Key aspect (identity)\n        if "dataProcessKey" in aspects:\n            key = aspects["dataProcessKey"]\n            print("\\nIdentity:")\n            print(f"  Name: {key.get(\'name\')}")\n            print(f"  Orchestrator: {key.get(\'orchestrator\')}")\n            print(f"  Origin (Fabric): {key.get(\'origin\')}")\n\n        # Core process information\n        if "dataProcessInfo" in aspects:\n            info = aspects["dataProcessInfo"]\n            print("\\nProcess Info:")\n            if "inputs" in info:\n                print(f"  Input Datasets: {len(info[\'inputs\'])}")\n                for inp in info["inputs"]:\n                    print(f"    - {inp}")\n            if "outputs" in info:\n                print(f"  Output Datasets: {len(info[\'outputs\'])}")\n                for out in info["outputs"]:\n                    print(f"    - {out}")\n\n        # Ownership information\n        if "ownership" in aspects:\n            ownership = aspects["ownership"]\n            print("\\nOwnership:")\n            for owner in ownership.get("owners", []):\n                print(f"  - {owner[\'owner\']} (type: {owner.get(\'type\', \'UNKNOWN\')})")\n\n        # Tags\n        if "globalTags" in aspects:\n            tags = aspects["globalTags"]\n            print("\\nTags:")\n            for tag in tags.get("tags", []):\n                print(f"  - {tag[\'tag\']}")\n\n        # Status\n        if "status" in aspects:\n            status = aspects["status"]\n            print(f"\\nStatus: {status.get(\'removed\', False)}")\n\n    print("\\n=== Migration Recommendation ===")\n    print("Replace this dataProcess with:")\n    print(\n        f"  DataFlow URN: urn:li:dataFlow:({key.get(\'orchestrator\')},{key.get(\'name\')},{key.get(\'origin\', \'PROD\').lower()})"\n    )\n    print(\n        f"  DataJob URN: urn:li:dataJob:(urn:li:dataFlow:({key.get(\'orchestrator\')},{key.get(\'name\')},{key.get(\'origin\', \'PROD\').lower()}),main_task)"\n    )\n    print("\\nSee dataprocess_migrate_to_flow_job.py for migration code examples.")\n\nexcept Exception as e:\n    print(f"Error querying dataProcess: {e}")\n    print("\\nThis is expected if the entity doesn\'t exist.")\n    print("DataProcess is deprecated - use dataFlow and dataJob instead.")\n\n'))),(0,a.yg)("h3",{id:"creating-equivalent-dataflow-and-datajob-recommended"},"Creating Equivalent DataFlow and DataJob (Recommended)"),(0,a.yg)("p",null,"Instead of using dataProcess, create the modern equivalent:"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Create DataFlow and DataJob to replace dataProcess"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/dataprocess_migrate_to_flow_job.py\n"""\nExample: Migrate from deprecated dataProcess to modern dataFlow and dataJob entities.\n\nThis example shows how to create the modern dataFlow and dataJob entities\nthat replace the deprecated dataProcess entity.\n\nThe dataProcess entity used a flat structure:\n  dataProcess -> inputs/outputs\n\nThe new model uses a hierarchical structure:\n  dataFlow (pipeline) -> dataJob (task) -> inputs/outputs\n\nThis provides better organization and more precise lineage tracking.\n"""\n\nfrom datahub.metadata.urns import DatasetUrn\nfrom datahub.sdk import DataFlow, DataHubClient, DataJob\n\nclient = DataHubClient.from_env()\n\n# Old dataProcess would have been:\n# urn:li:dataProcess:(customer_etl_job,airflow,PROD)\n# with inputs and outputs at the process level\n\n# New approach: Create a DataFlow for the pipeline\ndataflow = DataFlow(\n    platform="airflow",  # Same as the old \'orchestrator\' field\n    name="customer_etl_job",  # Same as the old \'name\' field\n    platform_instance="prod",  # Based on old \'origin\' field\n    description="ETL pipeline for customer data processing",\n)\n\n# Create DataJob(s) within the flow\n# For a simple single-task process, create one job\n# For complex multi-step processes, create multiple jobs\ndatajob = DataJob(\n    name="customer_etl_task",  # Task name within the flow\n    flow=dataflow,  # Link to parent flow\n    description="Main ETL task for customer data",\n    # Inputs and outputs now live at the job level for precise lineage\n    inlets=[\n        DatasetUrn(platform="mysql", name="raw_db.customers", env="PROD"),\n        DatasetUrn(platform="mysql", name="raw_db.orders", env="PROD"),\n    ],\n    outlets=[\n        DatasetUrn(platform="postgres", name="analytics.customer_summary", env="PROD"),\n    ],\n)\n\n# Upsert both entities\nclient.entities.upsert(dataflow)\nclient.entities.upsert(datajob)\n\nprint("Successfully migrated from dataProcess to dataFlow + dataJob!")\nprint(f"DataFlow URN: {dataflow.urn}")\nprint(f"DataJob URN: {datajob.urn}")\nprint("\\nKey improvements over dataProcess:")\nprint("- Clear separation between pipeline (DataFlow) and task (DataJob)")\nprint("- Support for multi-step pipelines with multiple DataJobs")\nprint("- More precise lineage at the task level")\nprint("- Better integration with modern orchestration platforms")\n\n'))),(0,a.yg)("h3",{id:"complete-migration-example"},"Complete Migration Example"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Full migration from dataProcess to dataFlow/dataJob"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Inlined from /metadata-ingestion/examples/library/dataprocess_full_migration.py\n"""\nExample: Complete migration from dataProcess to dataFlow/dataJob with metadata preservation.\n\nThis example demonstrates a full migration path that:\n1. Reads an existing deprecated dataProcess entity\n2. Extracts all its metadata (inputs, outputs, ownership, tags)\n3. Creates equivalent dataFlow and dataJob entities\n4. Preserves all metadata relationships\n\nUse this as a template for migrating multiple dataProcess entities in bulk.\n"""\n\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import (\n    GlobalTagsClass,\n    OwnerClass,\n    OwnershipClass,\n    OwnershipTypeClass,\n    TagAssociationClass,\n)\nfrom datahub.sdk import DataFlow, DataHubClient, DataJob\n\n# Initialize clients\nrest_emitter = DatahubRestEmitter(gms_server="http://localhost:8080")\nclient = DataHubClient.from_env()\n\n# Step 1: Define the dataProcess to migrate\nold_dataprocess_urn = "urn:li:dataProcess:(sales_pipeline,airflow,PROD)"\n\nprint(f"Migrating: {old_dataprocess_urn}")\n\ntry:\n    # Step 2: Fetch the existing dataProcess entity\n    entity = rest_emitter._session.get(\n        f"{rest_emitter._gms_server}/entities/{old_dataprocess_urn}"\n    ).json()\n\n    aspects = entity.get("aspects", {})\n\n    # Extract identity information\n    key = aspects.get("dataProcessKey", {})\n    name = key.get("name", "unknown_process")\n    orchestrator = key.get("orchestrator", "unknown")\n    origin = key.get("origin", "PROD")\n\n    # Extract process info\n    process_info = aspects.get("dataProcessInfo", {})\n    input_datasets = process_info.get("inputs", [])\n    output_datasets = process_info.get("outputs", [])\n\n    # Extract ownership\n    ownership_aspect = aspects.get("ownership", {})\n    owners = ownership_aspect.get("owners", [])\n\n    # Extract tags\n    tags_aspect = aspects.get("globalTags", {})\n    tags = tags_aspect.get("tags", [])\n\n    print("\\n=== Extracted Metadata ===")\n    print(f"Name: {name}")\n    print(f"Orchestrator: {orchestrator}")\n    print(f"Environment: {origin}")\n    print(f"Inputs: {len(input_datasets)} datasets")\n    print(f"Outputs: {len(output_datasets)} datasets")\n    print(f"Owners: {len(owners)}")\n    print(f"Tags: {len(tags)}")\n\n    # Step 3: Create the new DataFlow\n    dataflow = DataFlow(\n        platform=orchestrator,\n        name=name,\n        platform_instance=origin.lower(),\n        description=f"Migrated from dataProcess {name}",\n    )\n\n    # Step 4: Create the DataJob(s)\n    # For simplicity, creating one job. In practice, you might split into multiple jobs.\n    datajob = DataJob(\n        name=f"{name}_main",\n        flow=dataflow,\n        description=f"Main task for {name}",\n        inlets=[inp for inp in input_datasets],  # These should be dataset URNs\n        outlets=[out for out in output_datasets],  # These should be dataset URNs\n    )\n\n    # Step 5: Upsert the entities\n    client.entities.upsert(dataflow)\n    client.entities.upsert(datajob)\n\n    print("\\n=== Created New Entities ===")\n    print(f"DataFlow: {dataflow.urn}")\n    print(f"DataJob: {datajob.urn}")\n\n    # Step 6: Migrate ownership to DataFlow\n    if owners:\n        ownership_to_add = OwnershipClass(\n            owners=[\n                OwnerClass(\n                    owner=owner.get("owner"),\n                    type=getattr(OwnershipTypeClass, owner.get("type", "DATAOWNER")),\n                )\n                for owner in owners\n            ]\n        )\n        rest_emitter.emit_mcp(\n            MetadataChangeProposalWrapper(\n                entityUrn=str(dataflow.urn),\n                aspect=ownership_to_add,\n            )\n        )\n        print(f"Migrated {len(owners)} owner(s) to DataFlow")\n\n    # Step 7: Migrate tags to DataFlow\n    if tags:\n        tags_to_add = GlobalTagsClass(\n            tags=[TagAssociationClass(tag=tag.get("tag")) for tag in tags]\n        )\n        rest_emitter.emit_mcp(\n            MetadataChangeProposalWrapper(\n                entityUrn=str(dataflow.urn),\n                aspect=tags_to_add,\n            )\n        )\n        print(f"Migrated {len(tags)} tag(s) to DataFlow")\n\n    print("\\n=== Migration Complete ===")\n    print("Next steps:")\n    print("1. Verify the new entities in DataHub UI")\n    print("2. Update any downstream systems to reference the new URNs")\n    print("3. Consider soft-deleting the old dataProcess entity")\n\nexcept Exception as e:\n    print(f"Error during migration: {e}")\n    print("\\nCommon issues:")\n    print("- DataProcess entity doesn\'t exist (already migrated or never created)")\n    print("- Network connectivity to DataHub GMS")\n    print("- Permission issues writing to DataHub")\n\n'))),(0,a.yg)("h2",{id:"integration-points"},"Integration Points"),(0,a.yg)("h3",{id:"historical-usage"},"Historical Usage"),(0,a.yg)("p",null,"The dataProcess entity was previously used by:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Early ingestion connectors"),": Original Airflow, Azkaban connectors before they migrated to dataFlow/dataJob"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Custom integrations"),": User-built integrations that haven't been updated"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Legacy metadata"),": Historical data in existing DataHub instances")),(0,a.yg)("h3",{id:"modern-replacements"},"Modern Replacements"),(0,a.yg)("p",null,"All modern DataHub connectors use dataFlow and dataJob:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Airflow"),": DAGs \u2192 DataFlow, Tasks \u2192 DataJob"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"dbt"),": Projects \u2192 DataFlow, Models \u2192 DataJob"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Prefect"),": Flows \u2192 DataFlow, Tasks \u2192 DataJob"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Dagster"),": Pipelines \u2192 DataFlow, Ops/Assets \u2192 DataJob"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Fivetran"),": Connectors \u2192 DataFlow, Sync operations \u2192 DataJob"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"AWS Glue"),": Jobs \u2192 DataFlow, Steps \u2192 DataJob"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Azure Data Factory"),": Pipelines \u2192 DataFlow, Activities \u2192 DataJob")),(0,a.yg)("h3",{id:"dataprocessinstance"},"DataProcessInstance"),(0,a.yg)("p",null,"Note that ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstance")," is ",(0,a.yg)("strong",{parentName:"p"},"NOT deprecated"),". It represents a specific execution/run of either:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"A dataJob (recommended)"),(0,a.yg)("li",{parentName:"ul"},"A legacy dataProcess (for backward compatibility)")),(0,a.yg)("p",null,"DataProcessInstance continues to be used for tracking pipeline run history, status, and runtime information."),(0,a.yg)("h2",{id:"notable-exceptions"},"Notable Exceptions"),(0,a.yg)("h3",{id:"timeline-for-removal"},"Timeline for Removal"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Deprecated"),": Early 2021 (with introduction of dataFlow/dataJob)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Status"),": Still exists in the entity registry for backward compatibility"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Current State"),": No active ingestion sources create dataProcess entities"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Removal"),": No specific timeline, maintained for existing data")),(0,a.yg)("h3",{id:"reading-existing-data"},"Reading Existing Data"),(0,a.yg)("p",null,"The dataProcess entity remains readable through all DataHub APIs for backward compatibility. Existing dataProcess entities in your instance will continue to function and display in the UI."),(0,a.yg)("h3",{id:"no-new-writes-recommended"},"No New Writes Recommended"),(0,a.yg)("p",null,"While technically possible to create new dataProcess entities, it is ",(0,a.yg)("strong",{parentName:"p"},"strongly discouraged"),". All new integrations should use dataFlow and dataJob."),(0,a.yg)("h3",{id:"upgrade-path"},"Upgrade Path"),(0,a.yg)("p",null,"There is no automatic migration tool. Organizations with significant dataProcess data should:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"Use the Python SDK to query existing dataProcess entities"),(0,a.yg)("li",{parentName:"ol"},"Create equivalent dataFlow and dataJob entities"),(0,a.yg)("li",{parentName:"ol"},"Preserve URN mappings for lineage continuity"),(0,a.yg)("li",{parentName:"ol"},"Consider soft-deleting old dataProcess entities once migration is verified")),(0,a.yg)("h3",{id:"graphql-api"},"GraphQL API"),(0,a.yg)("p",null,"The dataProcess entity is minimally exposed in the GraphQL API. Modern GraphQL queries and mutations focus on dataFlow and dataJob entities."),(0,a.yg)("h2",{id:"additional-resources"},"Additional Resources"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/generated/metamodel/entities/dataflow"},"DataFlow Entity Documentation")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/generated/metamodel/entities/datajob"},"DataJob Entity Documentation")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/features/feature-guides/lineage"},"Lineage Documentation")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"/docs/lineage/airflow"},"Airflow Integration Guide"))),(0,a.yg)("h2",{id:"technical-reference-guide"},"Technical Reference Guide"),(0,a.yg)("p",null,"The sections above provide an overview of how to use this entity. The following sections provide detailed technical information about how metadata is stored and represented in DataHub."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Aspects")," are the individual pieces of metadata that can be attached to an entity. Each aspect contains specific information (like ownership, tags, or properties) and is stored as a separate record, allowing for flexible and incremental metadata updates."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Relationships")," show how this entity connects to other entities in the metadata graph. These connections are derived from the fields within each aspect and form the foundation of DataHub's knowledge graph."),(0,a.yg)("h3",{id:"reading-the-field-tables"},"Reading the Field Tables"),(0,a.yg)("p",null,"Each aspect's field table includes an ",(0,a.yg)("strong",{parentName:"p"},"Annotations")," column that provides additional metadata about how fields are used:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u26a0\ufe0f Deprecated"),": This field is deprecated and may be removed in a future version. Check the description for the recommended alternative"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Searchable"),": This field is indexed and can be searched in DataHub's search interface"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Searchable (fieldname)"),": When the field name in parentheses is shown, it indicates the field is indexed under a different name in the search index. For example, ",(0,a.yg)("inlineCode",{parentName:"li"},"dashboardTool")," is indexed as ",(0,a.yg)("inlineCode",{parentName:"li"},"tool")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u2192 RelationshipName"),": This field creates a relationship to another entity. The arrow indicates this field contains a reference (URN) to another entity, and the name indicates the type of relationship (e.g., ",(0,a.yg)("inlineCode",{parentName:"li"},"\u2192 Contains"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"\u2192 OwnedBy"),")")),(0,a.yg)("p",null,"Fields with complex types (like ",(0,a.yg)("inlineCode",{parentName:"p"},"Edge"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"AuditStamp"),") link to their definitions in the ",(0,a.yg)("a",{parentName:"p",href:"#common-types"},"Common Types")," section below."),(0,a.yg)("h3",{id:"aspects"},"Aspects"),(0,a.yg)("h4",{id:"dataprocesskey"},"dataProcessKey"),(0,a.yg)("p",null,"Key for a Data Process"),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"name"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Process name i.e. an ETL job name"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"orchestrator"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Standardized Orchestrator where data process is defined. TODO: Migrate towards something that can..."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"origin"),(0,a.yg)("td",{parentName:"tr",align:null},"FabricType"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Fabric type where dataset belongs to or where it was generated."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable"))))),(0,a.yg)(i.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessKey"\n  },\n  "name": "DataProcessKey",\n  "namespace": "com.linkedin.metadata.key",\n  "fields": [\n    {\n      "Searchable": {\n        "boostScore": 4.0,\n        "enableAutocomplete": true,\n        "fieldType": "WORD_GRAM"\n      },\n      "type": "string",\n      "name": "name",\n      "doc": "Process name i.e. an ETL job name"\n    },\n    {\n      "Searchable": {\n        "enableAutocomplete": true,\n        "fieldType": "TEXT_PARTIAL"\n      },\n      "type": "string",\n      "name": "orchestrator",\n      "doc": "Standardized Orchestrator where data process is defined.\\nTODO: Migrate towards something that can be validated like DataPlatform urn"\n    },\n    {\n      "Searchable": {\n        "fieldType": "TEXT_PARTIAL",\n        "queryByDefault": false\n      },\n      "type": {\n        "type": "enum",\n        "symbolDocs": {\n          "CORP": "Designates corporation fabrics",\n          "DEV": "Designates development fabrics",\n          "EI": "Designates early-integration fabrics",\n          "NON_PROD": "Designates non-production fabrics",\n          "PRD": "Alternative Prod spelling",\n          "PRE": "Designates pre-production fabrics",\n          "PROD": "Designates production fabrics",\n          "QA": "Designates quality assurance fabrics",\n          "RVW": "Designates review fabrics",\n          "SANDBOX": "Designates sandbox fabrics",\n          "SBX": "Alternative spelling for sandbox",\n          "SIT": "System Integration Testing",\n          "STG": "Designates staging fabrics",\n          "TEST": "Designates testing fabrics",\n          "TST": "Alternative Test spelling",\n          "UAT": "Designates user acceptance testing fabrics"\n        },\n        "name": "FabricType",\n        "namespace": "com.linkedin.common",\n        "symbols": [\n          "DEV",\n          "TEST",\n          "QA",\n          "UAT",\n          "EI",\n          "PRE",\n          "STG",\n          "NON_PROD",\n          "PROD",\n          "CORP",\n          "RVW",\n          "PRD",\n          "TST",\n          "SIT",\n          "SBX",\n          "SANDBOX"\n        ],\n        "doc": "Fabric group type"\n      },\n      "name": "origin",\n      "doc": "Fabric type where dataset belongs to or where it was generated."\n    }\n  ],\n  "doc": "Key for a Data Process"\n}\n')))),(0,a.yg)("h4",{id:"ownership"},"ownership"),(0,a.yg)("p",null,"Ownership information of an entity."),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"owners"),(0,a.yg)("td",{parentName:"tr",align:null},"Owner[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"List of owners of the entity."),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"ownerTypes"),(0,a.yg)("td",{parentName:"tr",align:null},"map"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Ownership type to Owners map, populated via mutation hook."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"lastModified"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#auditstamp"},"AuditStamp")),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Audit stamp containing who last modified the record and when. A value of 0 in the time field indi..."),(0,a.yg)("td",{parentName:"tr",align:null}))))),(0,a.yg)(i.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "ownership"\n  },\n  "name": "Ownership",\n  "namespace": "com.linkedin.common",\n  "fields": [\n    {\n      "type": {\n        "type": "array",\n        "items": {\n          "type": "record",\n          "name": "Owner",\n          "namespace": "com.linkedin.common",\n          "fields": [\n            {\n              "Relationship": {\n                "entityTypes": [\n                  "corpuser",\n                  "corpGroup"\n                ],\n                "name": "OwnedBy"\n              },\n              "Searchable": {\n                "addToFilters": true,\n                "fieldName": "owners",\n                "fieldType": "URN",\n                "filterNameOverride": "Owned By",\n                "hasValuesFieldName": "hasOwners",\n                "queryByDefault": false\n              },\n              "java": {\n                "class": "com.linkedin.common.urn.Urn"\n              },\n              "type": "string",\n              "name": "owner",\n              "doc": "Owner URN, e.g. urn:li:corpuser:ldap, urn:li:corpGroup:group_name, and urn:li:multiProduct:mp_name\\n(Caveat: only corpuser is currently supported in the frontend.)"\n            },\n            {\n              "deprecated": true,\n              "type": {\n                "type": "enum",\n                "symbolDocs": {\n                  "BUSINESS_OWNER": "A person or group who is responsible for logical, or business related, aspects of the asset.",\n                  "CONSUMER": "A person, group, or service that consumes the data\\nDeprecated! Use TECHNICAL_OWNER or BUSINESS_OWNER instead.",\n                  "CUSTOM": "Set when ownership type is unknown or a when new one is specified as an ownership type entity for which we have no\\nenum value for. This is used for backwards compatibility",\n                  "DATAOWNER": "A person or group that is owning the data\\nDeprecated! Use TECHNICAL_OWNER instead.",\n                  "DATA_STEWARD": "A steward, expert, or delegate responsible for the asset.",\n                  "DELEGATE": "A person or a group that overseas the operation, e.g. a DBA or SRE.\\nDeprecated! Use TECHNICAL_OWNER instead.",\n                  "DEVELOPER": "A person or group that is in charge of developing the code\\nDeprecated! Use TECHNICAL_OWNER instead.",\n                  "NONE": "No specific type associated to the owner.",\n                  "PRODUCER": "A person, group, or service that produces/generates the data\\nDeprecated! Use TECHNICAL_OWNER instead.",\n                  "STAKEHOLDER": "A person or a group that has direct business interest\\nDeprecated! Use TECHNICAL_OWNER, BUSINESS_OWNER, or STEWARD instead.",\n                  "TECHNICAL_OWNER": "person or group who is responsible for technical aspects of the asset."\n                },\n                "deprecatedSymbols": {\n                  "CONSUMER": true,\n                  "DATAOWNER": true,\n                  "DELEGATE": true,\n                  "DEVELOPER": true,\n                  "PRODUCER": true,\n                  "STAKEHOLDER": true\n                },\n                "name": "OwnershipType",\n                "namespace": "com.linkedin.common",\n                "symbols": [\n                  "CUSTOM",\n                  "TECHNICAL_OWNER",\n                  "BUSINESS_OWNER",\n                  "DATA_STEWARD",\n                  "NONE",\n                  "DEVELOPER",\n                  "DATAOWNER",\n                  "DELEGATE",\n                  "PRODUCER",\n                  "CONSUMER",\n                  "STAKEHOLDER"\n                ],\n                "doc": "Asset owner types"\n              },\n              "name": "type",\n              "doc": "The type of the ownership"\n            },\n            {\n              "Relationship": {\n                "entityTypes": [\n                  "ownershipType"\n                ],\n                "name": "ownershipType"\n              },\n              "java": {\n                "class": "com.linkedin.common.urn.Urn"\n              },\n              "type": [\n                "null",\n                "string"\n              ],\n              "name": "typeUrn",\n              "default": null,\n              "doc": "The type of the ownership\\nUrn of type O"\n            },\n            {\n              "type": [\n                "null",\n                {\n                  "type": "record",\n                  "name": "OwnershipSource",\n                  "namespace": "com.linkedin.common",\n                  "fields": [\n                    {\n                      "type": {\n                        "type": "enum",\n                        "symbolDocs": {\n                          "AUDIT": "Auditing system or audit logs",\n                          "DATABASE": "Database, e.g. GRANTS table",\n                          "FILE_SYSTEM": "File system, e.g. file/directory owner",\n                          "ISSUE_TRACKING_SYSTEM": "Issue tracking system, e.g. Jira",\n                          "MANUAL": "Manually provided by a user",\n                          "OTHER": "Other sources",\n                          "SERVICE": "Other ownership-like service, e.g. Nuage, ACL service etc",\n                          "SOURCE_CONTROL": "SCM system, e.g. GIT, SVN"\n                        },\n                        "name": "OwnershipSourceType",\n                        "namespace": "com.linkedin.common",\n                        "symbols": [\n                          "AUDIT",\n                          "DATABASE",\n                          "FILE_SYSTEM",\n                          "ISSUE_TRACKING_SYSTEM",\n                          "MANUAL",\n                          "SERVICE",\n                          "SOURCE_CONTROL",\n                          "OTHER"\n                        ]\n                      },\n                      "name": "type",\n                      "doc": "The type of the source"\n                    },\n                    {\n                      "type": [\n                        "null",\n                        "string"\n                      ],\n                      "name": "url",\n                      "default": null,\n                      "doc": "A reference URL for the source"\n                    }\n                  ],\n                  "doc": "Source/provider of the ownership information"\n                }\n              ],\n              "name": "source",\n              "default": null,\n              "doc": "Source information for the ownership"\n            },\n            {\n              "Searchable": {\n                "/actor": {\n                  "fieldName": "ownerAttributionActors",\n                  "fieldType": "URN",\n                  "queryByDefault": false\n                },\n                "/source": {\n                  "fieldName": "ownerAttributionSources",\n                  "fieldType": "URN",\n                  "queryByDefault": false\n                },\n                "/time": {\n                  "fieldName": "ownerAttributionDates",\n                  "fieldType": "DATETIME",\n                  "queryByDefault": false\n                }\n              },\n              "type": [\n                "null",\n                {\n                  "type": "record",\n                  "name": "MetadataAttribution",\n                  "namespace": "com.linkedin.common",\n                  "fields": [\n                    {\n                      "type": "long",\n                      "name": "time",\n                      "doc": "When this metadata was updated."\n                    },\n                    {\n                      "java": {\n                        "class": "com.linkedin.common.urn.Urn"\n                      },\n                      "type": "string",\n                      "name": "actor",\n                      "doc": "The entity (e.g. a member URN) responsible for applying the assocated metadata. This can\\neither be a user (in case of UI edits) or the datahub system for automation."\n                    },\n                    {\n                      "java": {\n                        "class": "com.linkedin.common.urn.Urn"\n                      },\n                      "type": [\n                        "null",\n                        "string"\n                      ],\n                      "name": "source",\n                      "default": null,\n                      "doc": "The DataHub source responsible for applying the associated metadata. This will only be filled out\\nwhen a DataHub source is responsible. This includes the specific metadata test urn, the automation urn."\n                    },\n                    {\n                      "type": {\n                        "type": "map",\n                        "values": "string"\n                      },\n                      "name": "sourceDetail",\n                      "default": {},\n                      "doc": "The details associated with why this metadata was applied. For example, this could include\\nthe actual regex rule, sql statement, ingestion pipeline ID, etc."\n                    }\n                  ],\n                  "doc": "Information about who, why, and how this metadata was applied"\n                }\n              ],\n              "name": "attribution",\n              "default": null,\n              "doc": "Information about who, why, and how this metadata was applied"\n            }\n          ],\n          "doc": "Ownership information"\n        }\n      },\n      "name": "owners",\n      "doc": "List of owners of the entity."\n    },\n    {\n      "Searchable": {\n        "/*": {\n          "fieldType": "MAP_ARRAY",\n          "queryByDefault": false\n        }\n      },\n      "type": [\n        {\n          "type": "map",\n          "values": {\n            "type": "array",\n            "items": "string"\n          }\n        },\n        "null"\n      ],\n      "name": "ownerTypes",\n      "default": {},\n      "doc": "Ownership type to Owners map, populated via mutation hook."\n    },\n    {\n      "type": {\n        "type": "record",\n        "name": "AuditStamp",\n        "namespace": "com.linkedin.common",\n        "fields": [\n          {\n            "type": "long",\n            "name": "time",\n            "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."\n          },\n          {\n            "java": {\n              "class": "com.linkedin.common.urn.Urn"\n            },\n            "type": "string",\n            "name": "actor",\n            "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."\n          },\n          {\n            "java": {\n              "class": "com.linkedin.common.urn.Urn"\n            },\n            "type": [\n              "null",\n              "string"\n            ],\n            "name": "impersonator",\n            "default": null,\n            "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."\n          },\n          {\n            "type": [\n              "null",\n              "string"\n            ],\n            "name": "message",\n            "default": null,\n            "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."\n          }\n        ],\n        "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."\n      },\n      "name": "lastModified",\n      "default": {\n        "actor": "urn:li:corpuser:unknown",\n        "impersonator": null,\n        "time": 0,\n        "message": null\n      },\n      "doc": "Audit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data."\n    }\n  ],\n  "doc": "Ownership information of an entity."\n}\n')))),(0,a.yg)("h4",{id:"dataprocessinfo"},"dataProcessInfo"),(0,a.yg)("p",null,"The inputs and outputs of this data process"),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"inputs"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"the inputs of the data process"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 Consumes")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"outputs"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"the outputs of the data process"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 Consumes"))))),(0,a.yg)(i.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessInfo"\n  },\n  "name": "DataProcessInfo",\n  "namespace": "com.linkedin.dataprocess",\n  "fields": [\n    {\n      "Relationship": {\n        "/*": {\n          "entityTypes": [\n            "dataset"\n          ],\n          "isLineage": true,\n          "name": "Consumes"\n        }\n      },\n      "Searchable": {\n        "/*": {\n          "fieldName": "inputs",\n          "fieldType": "URN",\n          "numValuesFieldName": "numInputDatasets",\n          "queryByDefault": false\n        }\n      },\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": "string"\n        }\n      ],\n      "name": "inputs",\n      "default": null,\n      "doc": "the inputs of the data process"\n    },\n    {\n      "Relationship": {\n        "/*": {\n          "entityTypes": [\n            "dataset"\n          ],\n          "isLineage": true,\n          "name": "Consumes"\n        }\n      },\n      "Searchable": {\n        "/*": {\n          "fieldName": "outputs",\n          "fieldType": "URN",\n          "numValuesFieldName": "numOutputDatasets",\n          "queryByDefault": false\n        }\n      },\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": "string"\n        }\n      ],\n      "name": "outputs",\n      "default": null,\n      "doc": "the outputs of the data process"\n    }\n  ],\n  "doc": "The inputs and outputs of this data process"\n}\n')))),(0,a.yg)("h4",{id:"status"},"status"),(0,a.yg)("p",null,"The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\nThis aspect is used to represent soft deletes conventionally."),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"removed"),(0,a.yg)("td",{parentName:"tr",align:null},"boolean"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Whether the entity has been removed (soft-deleted)."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable"))))),(0,a.yg)(i.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "status"\n  },\n  "name": "Status",\n  "namespace": "com.linkedin.common",\n  "fields": [\n    {\n      "Searchable": {\n        "fieldType": "BOOLEAN"\n      },\n      "type": "boolean",\n      "name": "removed",\n      "default": false,\n      "doc": "Whether the entity has been removed (soft-deleted)."\n    }\n  ],\n  "doc": "The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\\nThis aspect is used to represent soft deletes conventionally."\n}\n')))),(0,a.yg)("h4",{id:"testresults"},"testResults"),(0,a.yg)("p",null,"Information about a Test Result"),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"failing"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#testresult"},"TestResult"),"[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Results that are failing"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 IsFailing")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"passing"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#testresult"},"TestResult"),"[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Results that are passing"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 IsPassing"))))),(0,a.yg)(i.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "testResults"\n  },\n  "name": "TestResults",\n  "namespace": "com.linkedin.test",\n  "fields": [\n    {\n      "Relationship": {\n        "/*/test": {\n          "entityTypes": [\n            "test"\n          ],\n          "name": "IsFailing"\n        }\n      },\n      "Searchable": {\n        "/*/test": {\n          "fieldName": "failingTests",\n          "fieldType": "URN",\n          "hasValuesFieldName": "hasFailingTests",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": {\n          "type": "record",\n          "name": "TestResult",\n          "namespace": "com.linkedin.test",\n          "fields": [\n            {\n              "java": {\n                "class": "com.linkedin.common.urn.Urn"\n              },\n              "type": "string",\n              "name": "test",\n              "doc": "The urn of the test"\n            },\n            {\n              "type": {\n                "type": "enum",\n                "symbolDocs": {\n                  "FAILURE": " The Test Failed",\n                  "SUCCESS": " The Test Succeeded"\n                },\n                "name": "TestResultType",\n                "namespace": "com.linkedin.test",\n                "symbols": [\n                  "SUCCESS",\n                  "FAILURE"\n                ]\n              },\n              "name": "type",\n              "doc": "The type of the result"\n            },\n            {\n              "type": [\n                "null",\n                "string"\n              ],\n              "name": "testDefinitionMd5",\n              "default": null,\n              "doc": "The md5 of the test definition that was used to compute this result.\\nSee TestInfo.testDefinition.md5 for more information."\n            },\n            {\n              "type": [\n                "null",\n                {\n                  "type": "record",\n                  "name": "AuditStamp",\n                  "namespace": "com.linkedin.common",\n                  "fields": [\n                    {\n                      "type": "long",\n                      "name": "time",\n                      "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."\n                    },\n                    {\n                      "java": {\n                        "class": "com.linkedin.common.urn.Urn"\n                      },\n                      "type": "string",\n                      "name": "actor",\n                      "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."\n                    },\n                    {\n                      "java": {\n                        "class": "com.linkedin.common.urn.Urn"\n                      },\n                      "type": [\n                        "null",\n                        "string"\n                      ],\n                      "name": "impersonator",\n                      "default": null,\n                      "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."\n                    },\n                    {\n                      "type": [\n                        "null",\n                        "string"\n                      ],\n                      "name": "message",\n                      "default": null,\n                      "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."\n                    }\n                  ],\n                  "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."\n                }\n              ],\n              "name": "lastComputed",\n              "default": null,\n              "doc": "The audit stamp of when the result was computed, including the actor who computed it."\n            }\n          ],\n          "doc": "Information about a Test Result"\n        }\n      },\n      "name": "failing",\n      "doc": "Results that are failing"\n    },\n    {\n      "Relationship": {\n        "/*/test": {\n          "entityTypes": [\n            "test"\n          ],\n          "name": "IsPassing"\n        }\n      },\n      "Searchable": {\n        "/*/test": {\n          "fieldName": "passingTests",\n          "fieldType": "URN",\n          "hasValuesFieldName": "hasPassingTests",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "com.linkedin.test.TestResult"\n      },\n      "name": "passing",\n      "doc": "Results that are passing"\n    }\n  ],\n  "doc": "Information about a Test Result"\n}\n')))),(0,a.yg)("h4",{id:"subtypes"},"subTypes"),(0,a.yg)("p",null,"Sub Types. Use this aspect to specialize a generic Entity\ne.g. Making a Dataset also be a View or also be a LookerExplore"),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"typeNames"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"The names of the specific types."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable"))))),(0,a.yg)(i.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "subTypes"\n  },\n  "name": "SubTypes",\n  "namespace": "com.linkedin.common",\n  "fields": [\n    {\n      "Searchable": {\n        "/*": {\n          "addToFilters": true,\n          "fieldType": "KEYWORD",\n          "filterNameOverride": "Sub Type",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "string"\n      },\n      "name": "typeNames",\n      "doc": "The names of the specific types."\n    }\n  ],\n  "doc": "Sub Types. Use this aspect to specialize a generic Entity\\ne.g. Making a Dataset also be a View or also be a LookerExplore"\n}\n')))),(0,a.yg)("h3",{id:"common-types"},"Common Types"),(0,a.yg)("p",null,"These types are used across multiple aspects in this entity."),(0,a.yg)("h4",{id:"auditstamp"},"AuditStamp"),(0,a.yg)("p",null,"Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Fields:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"time")," (long): When did the resource/association/sub-resource move into the specific lifecyc..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"actor")," (string): The entity (e.g. a member URN) which will be credited for moving the resource..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"impersonator")," (string?): The entity (e.g. a service URN) which performs the change on behalf of the Ac..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"message")," (string?): Additional context around how DataHub was informed of the particular change. ...")),(0,a.yg)("h4",{id:"testresult"},"TestResult"),(0,a.yg)("p",null,"Information about a Test Result"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Fields:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"test")," (string): The urn of the test"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"type")," (TestResultType): The type of the result"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"testDefinitionMd5")," (string?): The md5 of the test definition that was used to compute this result. See Test..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"lastComputed")," (AuditStamp?): The audit stamp of when the result was computed, including the actor who comp...")),(0,a.yg)("h3",{id:"relationships"},"Relationships"),(0,a.yg)("h4",{id:"outgoing"},"Outgoing"),(0,a.yg)("p",null,"These are the relationships stored in this entity's aspects"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"OwnedBy"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Corpuser via ",(0,a.yg)("inlineCode",{parentName:"li"},"ownership.owners.owner")),(0,a.yg)("li",{parentName:"ul"},"CorpGroup via ",(0,a.yg)("inlineCode",{parentName:"li"},"ownership.owners.owner")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"ownershipType"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"OwnershipType via ",(0,a.yg)("inlineCode",{parentName:"li"},"ownership.owners.typeUrn")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Consumes"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInfo.inputs")),(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInfo.outputs")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"IsFailing"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Test via ",(0,a.yg)("inlineCode",{parentName:"li"},"testResults.failing")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"IsPassing"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Test via ",(0,a.yg)("inlineCode",{parentName:"li"},"testResults.passing"))))),(0,a.yg)("h3",{id:"global-metadata-model"},(0,a.yg)("a",{parentName:"h3",href:"https://github.com/datahub-project/static-assets/raw/main/imgs/datahub-metadata-model.png"},"Global Metadata Model")),(0,a.yg)("p",null,(0,a.yg)("img",{parentName:"p",src:"https://github.com/datahub-project/static-assets/raw/main/imgs/datahub-metadata-model.png",alt:"Global Graph"})))}h.isMDXComponent=!0}}]);