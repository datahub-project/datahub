"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[45183],{7653:(e,t,a)=>{a.d(t,{A:()=>n});const n={icon:{tag:"svg",attrs:{"fill-rule":"evenodd",viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M512 64c247.4 0 448 200.6 448 448S759.4 960 512 960 64 759.4 64 512 264.6 64 512 64zm127.98 274.82h-.04l-.08.06L512 466.75 384.14 338.88c-.04-.05-.06-.06-.08-.06a.12.12 0 00-.07 0c-.03 0-.05.01-.09.05l-45.02 45.02a.2.2 0 00-.05.09.12.12 0 000 .07v.02a.27.27 0 00.06.06L466.75 512 338.88 639.86c-.05.04-.06.06-.06.08a.12.12 0 000 .07c0 .03.01.05.05.09l45.02 45.02a.2.2 0 00.09.05.12.12 0 00.07 0c.02 0 .04-.01.08-.05L512 557.25l127.86 127.87c.04.04.06.05.08.05a.12.12 0 00.07 0c.03 0 .05-.01.09-.05l45.02-45.02a.2.2 0 00.05-.09.12.12 0 000-.07v-.02a.27.27 0 00-.05-.06L557.25 512l127.87-127.86c.04-.04.05-.06.05-.08a.12.12 0 000-.07c0-.03-.01-.05-.05-.09l-45.02-45.02a.2.2 0 00-.09-.05.12.12 0 00-.07 0z"}}]},name:"close-circle",theme:"filled"}},4732:(e,t,a)=>{a.d(t,{A:()=>l});var n=a(89379),o=a(96540),r=a(7653),s=a(89990),i=function(e,t){return o.createElement(s.A,(0,n.A)((0,n.A)({},e),{},{ref:t,icon:r.A}))};const l=o.forwardRef(i)},15680:(e,t,a)=>{a.d(t,{xA:()=>p,yg:()=>h});var n=a(96540);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),u=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),m=u(a),g=o,h=m["".concat(l,".").concat(g)]||m[g]||c[g]||r;return a?n.createElement(h,s(s({ref:t},p),{},{components:a})):n.createElement(h,s({ref:t},p))}));function h(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=g;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[m]="string"==typeof e?e:o,s[1]=i;for(var u=2;u<r;u++)s[u]=a[u];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},43655:(e,t,a)=>{a.d(t,{A:()=>f});var n=a(96540),o=a(20053);const r="availabilityCard_P5od",s="managedIcon_AxXO",i="platform_wqXv",l="platformAvailable_Y8lN";var u=a(4732),p=a(89379);const m={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64zm193.5 301.7l-210.6 292a31.8 31.8 0 01-51.7 0L318.5 484.9c-3.8-5.3 0-12.7 6.5-12.7h46.9c10.2 0 19.9 4.9 25.9 13.3l71.2 98.8 157.2-218c6-8.3 15.6-13.3 25.9-13.3H699c6.5 0 10.3 7.4 6.5 12.7z"}}]},name:"check-circle",theme:"filled"};var c=a(89990),g=function(e,t){return n.createElement(c.A,(0,p.A)((0,p.A)({},e),{},{ref:t,icon:m}))};const h=n.forwardRef(g);const d={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M811.4 418.7C765.6 297.9 648.9 212 512.2 212S258.8 297.8 213 418.6C127.3 441.1 64 519.1 64 612c0 110.5 89.5 200 199.9 200h496.2C870.5 812 960 722.5 960 612c0-92.7-63.1-170.7-148.6-193.3zm36.3 281a123.07 123.07 0 01-87.6 36.3H263.9c-33.1 0-64.2-12.9-87.6-36.3A123.3 123.3 0 01140 612c0-28 9.1-54.3 26.2-76.3a125.7 125.7 0 0166.1-43.7l37.9-9.9 13.9-36.6c8.6-22.8 20.6-44.1 35.7-63.4a245.6 245.6 0 0152.4-49.9c41.1-28.9 89.5-44.2 140-44.2s98.9 15.3 140 44.2c19.9 14 37.5 30.8 52.4 49.9 15.1 19.3 27.1 40.7 35.7 63.4l13.8 36.5 37.8 10c54.3 14.5 92.1 63.8 92.1 120 0 33.1-12.9 64.3-36.3 87.7z"}}]},name:"cloud",theme:"outlined"};var y=function(e,t){return n.createElement(c.A,(0,p.A)((0,p.A)({},e),{},{ref:t,icon:d}))};const b=n.forwardRef(y),f=({saasOnly:e,ossOnly:t})=>n.createElement("div",{className:(0,o.A)(r,"card")},n.createElement("strong",null,"Feature Availability"),n.createElement("div",null,n.createElement("span",{className:(0,o.A)(i,!e&&l)},"Self-Hosted DataHub ",e?n.createElement(u.A,null):n.createElement(h,null))),n.createElement("div",null,n.createElement(b,{className:s}),n.createElement("span",{className:(0,o.A)(i,!t&&l)},"DataHub Cloud ",t?n.createElement(u.A,null):n.createElement(h,null))))},4789:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>u,default:()=>d,frontMatter:()=>l,metadata:()=>p,toc:()=>c});a(96540);var n=a(15680),o=a(43655);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}const l={description:"This page provides an overview of working with DataHub Volume Assertions",title:"Volume Assertions",slug:"/managed-datahub/observe/volume-assertions",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/managed-datahub/observe/volume-assertions.md"},u="Volume Assertions",p={unversionedId:"docs/managed-datahub/observe/volume-assertions",id:"docs/managed-datahub/observe/volume-assertions",title:"Volume Assertions",description:"This page provides an overview of working with DataHub Volume Assertions",source:"@site/genDocs/docs/managed-datahub/observe/volume-assertions.md",sourceDirName:"docs/managed-datahub/observe",slug:"/managed-datahub/observe/volume-assertions",permalink:"/docs/managed-datahub/observe/volume-assertions",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/managed-datahub/observe/volume-assertions.md",tags:[],version:"current",frontMatter:{description:"This page provides an overview of working with DataHub Volume Assertions",title:"Volume Assertions",slug:"/managed-datahub/observe/volume-assertions",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/managed-datahub/observe/volume-assertions.md"},sidebar:"overviewSidebar",previous:{title:"Schema Assertions",permalink:"/docs/managed-datahub/observe/schema-assertions"},next:{title:"Smart Assertions (AI Anomaly Detection) \u26a1",permalink:"/docs/managed-datahub/observe/smart-assertions"}},m={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Support",id:"support",level:2},{value:"What is a Volume Assertion?",id:"what-is-a-volume-assertion",level:2},{value:"Anatomy of a Volume Assertion",id:"anatomy-of-a-volume-assertion",level:3},{value:"1. Evaluation Schedule",id:"1-evaluation-schedule",level:4},{value:"2. Volume Condition",id:"2-volume-condition",level:4},{value:"3. Volume Source",id:"3-volume-source",level:4},{value:"Creating a Volume Assertion",id:"creating-a-volume-assertion",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Steps",id:"steps",level:3},{value:"Anomaly Detection with Smart Assertions \u26a1",id:"anomaly-detection-with-smart-assertions-",level:2},{value:"Stopping a Volume Assertion",id:"stopping-a-volume-assertion",level:2},{value:"Creating Volume Assertions via API",id:"creating-volume-assertions-via-api",level:2},{value:"GraphQL",id:"graphql",level:4},{value:"Examples",id:"examples",level:5},{value:"Tips",id:"tips",level:3}],g={toc:c},h="wrapper";function d(e){var{components:t}=e,a=i(e,["components"]);return(0,n.yg)(h,s(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){r(e,t,a[t])}))}return e}({},g,a),{components:t,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"volume-assertions"},"Volume Assertions"),(0,n.yg)(o.A,{saasOnly:!0,mdxType:"FeatureAvailability"}),(0,n.yg)("blockquote",null,(0,n.yg)("p",{parentName:"blockquote"},"The ",(0,n.yg)("strong",{parentName:"p"},"Volume Assertions")," feature is available as part of the ",(0,n.yg)("strong",{parentName:"p"},"DataHub Cloud Observe")," module of DataHub Cloud.\nIf you are interested in learning more about ",(0,n.yg)("strong",{parentName:"p"},"DataHub Cloud Observe")," or trying it out, please ",(0,n.yg)("a",{parentName:"p",href:"https://datahub.com/products/data-observability/"},"visit our website"),".")),(0,n.yg)("h2",{id:"introduction"},"Introduction"),(0,n.yg)("p",null,"Can you remember a time when the meaning of Data Warehouse Table that you depended on fundamentally changed, with little or no notice?\nIf the answer is yes, how did you find out? We'll take a guess - someone looking at an internal reporting dashboard or worse, a user using your your product, sounded an alarm when\na number looked a bit out of the ordinary. Perhaps your table initially tracked purchases made on your company's e-commerce web store, but suddenly began to include purchases made\nthrough your company's new mobile app."),(0,n.yg)("p",null,"There are many reasons why an important Table on Snowflake, Redshift, BigQuery, or Databricks may change in its meaning - application code bugs, new feature rollouts,\nchanges to key metric definitions, etc. Often times, these changes break important assumptions made about the data used in building key downstream data products\nlike reporting dashboards or data-driven product features."),(0,n.yg)("p",null,"What if you could reduce the time to detect these incidents, so that the people responsible for the data were made aware of data\nissues ",(0,n.yg)("em",{parentName:"p"},"before")," anyone else? With DataHub Cloud ",(0,n.yg)("strong",{parentName:"p"},"Volume Assertions"),", you can."),(0,n.yg)("p",null,"DataHub Cloud allows users to define expectations about the normal volume, or size, of a particular warehouse Table,\nand then monitor those expectations over time as the table grows and changes."),(0,n.yg)("p",null,"In this article, we'll cover the basics of monitoring Volume Assertions - what they are, how to configure them, and more - so that you and your team can\nstart building trust in your most important data assets."),(0,n.yg)("p",null,"Let's get started!"),(0,n.yg)("h2",{id:"support"},"Support"),(0,n.yg)("p",null,"Volume Assertions are currently supported for:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Snowflake"),(0,n.yg)("li",{parentName:"ol"},"Redshift"),(0,n.yg)("li",{parentName:"ol"},"BigQuery"),(0,n.yg)("li",{parentName:"ol"},"Databricks"),(0,n.yg)("li",{parentName:"ol"},"DataHub Dataset Profile (collected via ingestion)")),(0,n.yg)("p",null,"Note that an Ingestion Source ",(0,n.yg)("em",{parentName:"p"},"must")," be configured with the data platform of your choice in DataHub Cloud's ",(0,n.yg)("strong",{parentName:"p"},"Ingestion"),"\ntab."),(0,n.yg)("blockquote",null,(0,n.yg)("p",{parentName:"blockquote"},"Note that Volume Assertions are not yet supported if you are connecting to your warehouse\nusing the DataHub CLI.")),(0,n.yg)("h2",{id:"what-is-a-volume-assertion"},"What is a Volume Assertion?"),(0,n.yg)("p",null,"A ",(0,n.yg)("strong",{parentName:"p"},"Volume Assertion"),' is a configurable Data Quality rule used to monitor a Data Warehouse Table\nfor unexpected or sudden changes in "volume", or row count. Volume Assertions can be particularly useful when you have frequently-changing\nTables which have a relatively stable pattern of growth or decline.'),(0,n.yg)("p",null,'For example, imagine that we work for a company with a Snowflake Table that stores user clicks collected from our e-commerce website.\nThis table is updated with new data on a specific cadence: once per hour (In practice, daily or even weekly are also common).\nIn turn, there is a downstream Business Analytics Dashboard in Looker that shows important metrics like\nthe number of people clicking our "Daily Sale" banners, and this dashboard is generated from data stored in our "clicks" table.\nIt is important that our clicks Table is updated with the correct number of rows each hour, else it could mean\nthat our downstream metrics dashboard becomes incorrect. The risk of this situation is obvious: our organization\nmay make bad decisions based on incomplete information.'),(0,n.yg)("p",null,"In such cases, we can use a ",(0,n.yg)("strong",{parentName:"p"},"Volume Assertion"),' that checks whether the Snowflake "clicks" Table is growing in an expected\nway, and that there are no sudden increases or sudden decreases in the rows being added or removed from the table.\nIf too many rows are added or removed within an hour, we can notify key stakeholders and begin to root cause before the problem impacts stakeholders of the data.'),(0,n.yg)("h3",{id:"anatomy-of-a-volume-assertion"},"Anatomy of a Volume Assertion"),(0,n.yg)("p",null,"At the most basic level, ",(0,n.yg)("strong",{parentName:"p"},"Volume Assertions")," consist of a few important parts:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"An ",(0,n.yg)("strong",{parentName:"li"},"Evaluation Schedule")),(0,n.yg)("li",{parentName:"ol"},"A ",(0,n.yg)("strong",{parentName:"li"},"Volume Condition")),(0,n.yg)("li",{parentName:"ol"},"A ",(0,n.yg)("strong",{parentName:"li"},"Volume Source"))),(0,n.yg)("p",null,"In this section, we'll give an overview of each."),(0,n.yg)("h4",{id:"1-evaluation-schedule"},"1. Evaluation Schedule"),(0,n.yg)("p",null,"The ",(0,n.yg)("strong",{parentName:"p"},"Evaluation Schedule"),": This defines how often to check a given warehouse Table for its volume. This should usually\nbe configured to match the expected change frequency of the Table, although it can also be less frequently depending\non the requirements. You can also specify specific days of the week, hours in the day, or even\nminutes in an hour."),(0,n.yg)("h4",{id:"2-volume-condition"},"2. Volume Condition"),(0,n.yg)("p",null,"The ",(0,n.yg)("strong",{parentName:"p"},"Volume Condition"),": This defines the type of condition that we'd like to monitor, or when the Assertion\nshould result in failure."),(0,n.yg)("p",null,"There are a 2 different categories of conditions: ",(0,n.yg)("strong",{parentName:"p"},"Total")," Volume and ",(0,n.yg)("strong",{parentName:"p"},"Change")," Volume."),(0,n.yg)("p",null,(0,n.yg)("em",{parentName:"p"},"Total")," volume conditions are those which are defined against the point-in-time total row count for a table. They allow you to specify conditions like:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Table has too many rows"),": The table should always have less than 1000 rows"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Table has too few rows"),": The table should always have more than 1000 rows"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Table row count is outside a range"),": The table should always have between 1000 and 2000 rows.")),(0,n.yg)("p",null,(0,n.yg)("em",{parentName:"p"},"Change")," volume conditions are those which are defined against the growth or decline rate of a table, measured between subsequent checks\nof the table volume. They allow you to specify conditions like:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Table growth is too fast"),": When the table volume is checked, it should have < 1000 more rows than it had during the previous check."),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Table growth is too slow"),": When the table volume is checked, it should have > 1000 more rows than it had during the previous check."),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Table growth is outside a range"),": When the table volume is checked, it should have between 1000 and 2000 more rows than it had during the previous check.")),(0,n.yg)("p",null,"For change volume conditions, both ",(0,n.yg)("em",{parentName:"p"},"absolute")," row count deltas and relative percentage deltas are supported for identifying\ntable that are following an abnormal pattern of growth."),(0,n.yg)("h4",{id:"3-volume-source"},"3. Volume Source"),(0,n.yg)("p",null,"The ",(0,n.yg)("strong",{parentName:"p"},"Volume Source"),": This is the mechanism that DataHub Cloud should use to determine the table volume (row count). The supported\nsource types vary by the platform, but generally fall into these categories:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Information Schema"),": A system Table that is exposed by the Data Warehouse which contains live information about the Databases\nand Tables stored inside the Data Warehouse, including their row count. It is usually efficient to check, but can in some cases be slightly delayed to update\nonce a change has been made to a table. This is the optimal balance between cost and accuracy for most Data Platforms.")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Query"),": A ",(0,n.yg)("inlineCode",{parentName:"p"},"COUNT(*)")," query is used to retrieve the latest row count for a table, with optional SQL filters applied (depending on platform).\nThis can be less efficient to check depending on the size of the table. This approach is more portable, as it does not involve\nsystem warehouse tables, it is also easily portable across Data Warehouse and Data Lake providers. This issues a query to the table, which can be more expensive than Information Schema.")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"DataHub Dataset Profile"),": The DataHub Dataset Profile aspect is used to retrieve the latest row count information for a table.\nUsing this option avoids contacting your data platform, and instead uses the DataHub Dataset Profile metadata to evaluate Volume Assertions.\nNote if you have not configured a managed ingestion source through DataHub, then this may be the only option available. This is the cheapest option, but requires that Dataset Profiles are reported to DataHub. By default, Ingestion will report Dataset Profiles to DataHub, which can be and infrequent. You can report Dataset Profiles via the DataHub APIs for more frequent and reliable data."))),(0,n.yg)("p",null,"Volume Assertions also have an off switch: they can be started or stopped at any time with the click of button."),(0,n.yg)("h2",{id:"creating-a-volume-assertion"},"Creating a Volume Assertion"),(0,n.yg)("h3",{id:"prerequisites"},"Prerequisites"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Permissions"),": To create or delete Volume Assertions for a specific entity on DataHub, you'll need to be granted the\n",(0,n.yg)("inlineCode",{parentName:"p"},"Edit Assertions")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"Edit Monitors")," privileges for the entity. This will be granted to Entity owners as part of the ",(0,n.yg)("inlineCode",{parentName:"p"},"Asset Owners - Metadata Policy"),"\nby default.")),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"(Optional) ",(0,n.yg)("strong",{parentName:"p"},"Data Platform Connection"),": In order to create a Volume Assertion that queries the source data platform directly (instead of DataHub metadata), you'll need to have an ",(0,n.yg)("strong",{parentName:"p"},"Ingestion Source")," configured to your\nData Platform: Snowflake, BigQuery, or Redshift under the ",(0,n.yg)("strong",{parentName:"p"},"Integrations")," tab."))),(0,n.yg)("p",null,"Once these are in place, you're ready to create your Volume Assertions!"),(0,n.yg)("p",null,"You can also ",(0,n.yg)("strong",{parentName:"p"},"Bulk Create Smart Assertions")," via the ",(0,n.yg)("a",{parentName:"p",href:"/docs/managed-datahub/observe/data-health-dashboard#bulk-create-smart-assertions"},"Data Health Page")),(0,n.yg)("h3",{id:"steps"},"Steps"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Navigate to the Table that to monitor for volume"),(0,n.yg)("li",{parentName:"ol"},"Click the ",(0,n.yg)("strong",{parentName:"li"},"Quality")," tab")),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"80%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/freshness/profile-validation-tab.png"})),(0,n.yg)("ol",{start:3},(0,n.yg)("li",{parentName:"ol"},"Click ",(0,n.yg)("strong",{parentName:"li"},"+ Create Assertion"))),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"45%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/volume/assertion-builder-volume-choose-type.png"})),(0,n.yg)("ol",{start:4},(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Choose ",(0,n.yg)("strong",{parentName:"p"},"Volume"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Configure the evaluation ",(0,n.yg)("strong",{parentName:"p"},"schedule"),". This is the frequency at which the assertion will be evaluated to produce a pass or fail result, and the times\nwhen the table volume will be checked.")),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Configure the evaluation ",(0,n.yg)("strong",{parentName:"p"},"condition type"),". This determines the cases in which the new assertion will fail when it is evaluated."))),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"30%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/volume/assertion-builder-volume-condition-type.png"})),(0,n.yg)("ol",{start:7},(0,n.yg)("li",{parentName:"ol"},"(Optional) Click ",(0,n.yg)("strong",{parentName:"li"},"Advanced")," to customize the volume ",(0,n.yg)("strong",{parentName:"li"},"source"),". This is the mechanism that will be used to obtain the table\nrow count metric. Each Data Platform supports different options including Information Schema, Query, and DataHub Dataset Profile.")),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"30%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/volume/assertion-builder-volume-select-source-type.png"})),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Information Schema"),": Check the Data Platform system metadata tables to determine the table row count."),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Query"),": Issue a ",(0,n.yg)("inlineCode",{parentName:"li"},"COUNT(*)")," query to the table to determine the row count."),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"DataHub Dataset Profile"),": Use the DataHub Dataset Profile metadata to determine the row count.")),(0,n.yg)("ol",{start:8},(0,n.yg)("li",{parentName:"ol"},"Configure actions that should be taken when the Volume Assertion passes or fails")),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"40%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/shared/assertion-builder-actions.png"})),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Raise incident"),": Automatically raise a new DataHub ",(0,n.yg)("inlineCode",{parentName:"p"},"Volume")," Incident for the Table whenever the Volume Assertion is failing. This\nmay indicate that the Table is unfit for consumption. Configure Slack Notifications under ",(0,n.yg)("strong",{parentName:"p"},"Settings")," to be notified when\nan incident is created due to an Assertion failure.")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Resolve incident"),": Automatically resolved any incidents that were raised due to failures in this Volume Assertion. Note that\nany other incidents will not be impacted."))),(0,n.yg)("ol",{start:9},(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Click ",(0,n.yg)("strong",{parentName:"p"},"Next")," and provide a description.")),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"Click ",(0,n.yg)("strong",{parentName:"p"},"Save"),"."))),(0,n.yg)("p",null,"And that's it! DataHub will now begin to monitor your Volume Assertion for the table."),(0,n.yg)("p",null,"Once your assertion has run, you will begin to see Success or Failure status for the Table"),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"45%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/volume/profile-passing-volume-assertions-expanded.png"})),(0,n.yg)("h2",{id:"anomaly-detection-with-smart-assertions-"},"Anomaly Detection with Smart Assertions \u26a1"),(0,n.yg)("p",null,"As part of the ",(0,n.yg)("strong",{parentName:"p"},"DataHub Cloud Observe")," module, DataHub Cloud also provides ",(0,n.yg)("strong",{parentName:"p"},"Smart Assertions")," out of the box. These are\ndynamic, AI-powered Volume Assertions that you can use to monitor the volume of important warehouse Tables, without\nrequiring any manual setup."),(0,n.yg)("p",null,"You can create smart assertions by simply selecting the ",(0,n.yg)("inlineCode",{parentName:"p"},"Detect with AI")," option in the UI:"),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"90%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/volume/volume-smart-assertion.png"})),(0,n.yg)("h2",{id:"stopping-a-volume-assertion"},"Stopping a Volume Assertion"),(0,n.yg)("p",null,"In order to temporarily stop the evaluation of the assertion:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Navigate to the ",(0,n.yg)("strong",{parentName:"li"},"Quality")," tab of the Table with the assertion"),(0,n.yg)("li",{parentName:"ol"},"Click ",(0,n.yg)("strong",{parentName:"li"},"Volume")," to open the Volume Assertion assertions"),(0,n.yg)("li",{parentName:"ol"},'Click the "Stop" button for the assertion you wish to pause.')),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"25%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/shared/stop-assertion.png"})),(0,n.yg)("p",null,"To resume the assertion, simply click ",(0,n.yg)("strong",{parentName:"p"},"Start"),"."),(0,n.yg)("p",{align:"left"},(0,n.yg)("img",{width:"25%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/observe/shared/start-assertion.png"})),(0,n.yg)("h2",{id:"creating-volume-assertions-via-api"},"Creating Volume Assertions via API"),(0,n.yg)("p",null,"Under the hood, DataHub Cloud implements Volume Assertion Monitoring using two concepts:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Assertion"),': The specific expectation for volume, e.g. "The table was changed int the past 7 hours"\nor "The table is changed on a schedule of every day by 8am". This is the "what".')),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},(0,n.yg)("strong",{parentName:"p"},"Monitor"),': The process responsible for evaluating the Assertion on a given evaluation schedule and using specific\nmechanisms. This is the "how".'))),(0,n.yg)("p",null,"Note that to create or delete Assertions and Monitors for a specific entity on DataHub, you'll need the\n",(0,n.yg)("inlineCode",{parentName:"p"},"Edit Assertions")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"Edit Monitors")," privileges for it."),(0,n.yg)("h4",{id:"graphql"},"GraphQL"),(0,n.yg)("p",null,"In order to create or update a Volume Assertion, you can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"upsertDatasetVolumeAssertionMonitor")," mutation."),(0,n.yg)("h5",{id:"examples"},"Examples"),(0,n.yg)("p",null,"To create a Volume Assertion Entity that verifies that the row count for a table is between 10 and 20 rows, and runs every 8 hours:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetVolumeAssertionMonitor {\n  upsertDatasetVolumeAssertionMonitor(\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      type: ROW_COUNT_TOTAL\n      rowCountTotal: {\n        operator: BETWEEN\n        parameters: {\n          minValue: { value: "10", type: NUMBER }\n          maxValue: { value: "20", type: NUMBER }\n        }\n      }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */8 * * *"\n      }\n      evaluationParameters: { sourceType: INFORMATION_SCHEMA }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,n.yg)("p",null,"To create an AI Smart Freshness Assertion that runs every 8 hours:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetFreshnessAssertionMonitor {\n  upsertDatasetFreshnessAssertionMonitor(\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      inferWithAI: true\n      type: ROW_COUNT_TOTAL\n      # you can provide any value here as it will be overwritten continuously by the AI engine\n      rowCountTotal: {\n        operator: BETWEEN\n        parameters: {\n          minValue: { value: "0", type: NUMBER }\n          maxValue: { value: "0", type: NUMBER }\n        }\n      }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */8 * * *"\n      }\n      evaluationParameters: { sourceType: INFORMATION_SCHEMA }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,n.yg)("p",null,"The supported volume assertion types are ",(0,n.yg)("inlineCode",{parentName:"p"},"ROW_COUNT_TOTAL")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"ROW_COUNT_CHANGE"),". Other (e.g. incrementing segment) types are not yet supported.\nThe supported operator types are ",(0,n.yg)("inlineCode",{parentName:"p"},"GREATER_THAN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"GREATER_THAN_OR_EQUAL_TO"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"LESS_THAN"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"LESS_THAN_OR_EQUAL_TO"),", and ",(0,n.yg)("inlineCode",{parentName:"p"},"BETWEEN")," (requires minValue, maxValue).\nThe supported parameter types are ",(0,n.yg)("inlineCode",{parentName:"p"},"NUMBER"),"."),(0,n.yg)("p",null,"You can use same endpoint with assertion urn input to update an existing Volume Assertion and corresponding Monitor:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation upsertDatasetVolumeAssertionMonitor {\n  upsertDatasetVolumeAssertionMonitor(\n    assertionUrn: "<urn of assertion created in earlier query>"\n    input: {\n      entityUrn: "<urn of entity being monitored>"\n      type: ROW_COUNT_TOTAL\n      rowCountTotal: {\n        operator: BETWEEN\n        parameters: {\n          minValue: { value: "10", type: NUMBER }\n          maxValue: { value: "20", type: NUMBER }\n        }\n      }\n      evaluationSchedule: {\n        timezone: "America/Los_Angeles"\n        cron: "0 */6 * * *"\n      }\n      evaluationParameters: { sourceType: INFORMATION_SCHEMA }\n      mode: ACTIVE\n    }\n  ) {\n    urn\n  }\n}\n')),(0,n.yg)("p",null,"You can delete assertions along with their monitors using GraphQL mutations: ",(0,n.yg)("inlineCode",{parentName:"p"},"deleteAssertion")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"deleteMonitor"),"."),(0,n.yg)("h3",{id:"tips"},"Tips"),(0,n.yg)("admonition",{type:"info"},(0,n.yg)("p",{parentName:"admonition"},(0,n.yg)("strong",{parentName:"p"},"Authorization")),(0,n.yg)("p",{parentName:"admonition"},"Remember to always provide a DataHub Personal Access Token when calling the GraphQL API. To do so, just add the 'Authorization' header as follows:"),(0,n.yg)("pre",{parentName:"admonition"},(0,n.yg)("code",{parentName:"pre"},"Authorization: Bearer <personal-access-token>\n")),(0,n.yg)("p",{parentName:"admonition"},(0,n.yg)("strong",{parentName:"p"},"Exploring GraphQL API")),(0,n.yg)("p",{parentName:"admonition"},"Also, remember that you can play with an interactive version of the DataHub Cloud GraphQL API at ",(0,n.yg)("inlineCode",{parentName:"p"},"https://your-account-id.acryl.io/api/graphiql"))))}d.isMDXComponent=!0}}]);