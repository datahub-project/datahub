"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[15372],{15680:(e,a,t)=>{t.d(a,{xA:()=>p,yg:()=>y});var n=t(96540);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?l(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var o=n.createContext({}),g=function(e){var a=n.useContext(o),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},p=function(e){var a=g(e.components);return n.createElement(o.Provider,{value:a},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},u=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,l=e.originalType,o=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=g(t),u=r,y=d["".concat(o,".").concat(u)]||d[u]||m[u]||l;return t?n.createElement(y,i(i({ref:a},p),{},{components:t})):n.createElement(y,i({ref:a},p))}));function y(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var l=t.length,i=new Array(l);i[0]=u;var s={};for(var o in a)hasOwnProperty.call(a,o)&&(s[o]=a[o]);s.originalType=e,s[d]="string"==typeof e?e:r,i[1]=s;for(var g=2;g<l;g++)i[g]=t[g];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}u.displayName="MDXCreateElement"},16083:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>p,contentTitle:()=>o,default:()=>y,frontMatter:()=>s,metadata:()=>g,toc:()=>d});t(96540);var n=t(15680);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){return a=null!=a?a:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):function(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))})),e}function i(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}const s={title:"Dataset",sidebar_label:"Dataset",slug:"/metadata-ingestion/docs/transformer/dataset_transformer",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/docs/transformer/dataset_transformer.md"},o="Dataset Transformers",g={unversionedId:"metadata-ingestion/docs/transformer/dataset_transformer",id:"version-1.1.0/metadata-ingestion/docs/transformer/dataset_transformer",title:"Dataset",description:"The below table shows transformer which can transform aspects of entity Dataset.",source:"@site/versioned_docs/version-1.1.0/metadata-ingestion/docs/transformer/dataset_transformer.md",sourceDirName:"metadata-ingestion/docs/transformer",slug:"/metadata-ingestion/docs/transformer/dataset_transformer",permalink:"/docs/1.1.0/metadata-ingestion/docs/transformer/dataset_transformer",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/docs/transformer/dataset_transformer.md",tags:[],version:"1.1.0",frontMatter:{title:"Dataset",sidebar_label:"Dataset",slug:"/metadata-ingestion/docs/transformer/dataset_transformer",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/docs/transformer/dataset_transformer.md"},sidebar:"overviewSidebar",previous:{title:"Introduction",permalink:"/docs/1.1.0/metadata-ingestion/docs/transformer/intro"},next:{title:"CLI Ingestion",permalink:"/docs/1.1.0/metadata-ingestion/cli-ingestion"}},p={},d=[{value:"Extract Ownership from Tags",id:"extract-ownership-from-tags",level:2},{value:"Config Details",id:"config-details",level:3},{value:"Examples",id:"examples",level:3},{value:"Clean suffix prefix from Ownership",id:"clean-suffix-prefix-from-ownership",level:2},{value:"Config Details",id:"config-details-1",level:3},{value:"Mark Dataset Status",id:"mark-dataset-status",level:2},{value:"Config Details",id:"config-details-2",level:3},{value:"Simple Add Dataset ownership",id:"simple-add-dataset-ownership",level:2},{value:"Config Details",id:"config-details-3",level:3},{value:"Pattern Add Dataset ownership",id:"pattern-add-dataset-ownership",level:2},{value:"Config Details",id:"config-details-4",level:3},{value:"Simple Remove Dataset ownership",id:"simple-remove-dataset-ownership",level:2},{value:"Extract Dataset globalTags",id:"extract-dataset-globaltags",level:2},{value:"Config Details",id:"config-details-5",level:3},{value:"Simple Add Dataset globalTags",id:"simple-add-dataset-globaltags",level:2},{value:"Config Details",id:"config-details-6",level:3},{value:"Pattern Add Dataset globalTags",id:"pattern-add-dataset-globaltags",level:2},{value:"Config Details",id:"config-details-7",level:3},{value:"Add Dataset globalTags",id:"add-dataset-globaltags",level:2},{value:"Config Details",id:"config-details-8",level:3},{value:"Set Dataset browsePath",id:"set-dataset-browsepath",level:2},{value:"Config Details",id:"config-details-9",level:3},{value:"Simple Add Dataset glossaryTerms",id:"simple-add-dataset-glossaryterms",level:2},{value:"Config Details",id:"config-details-10",level:3},{value:"Pattern Add Dataset glossaryTerms",id:"pattern-add-dataset-glossaryterms",level:2},{value:"Config Details",id:"config-details-11",level:3},{value:"Tags to Term Mapping",id:"tags-to-term-mapping",level:2},{value:"Config Details",id:"config-details-12",level:3},{value:"Pattern Add Dataset Schema Field glossaryTerms",id:"pattern-add-dataset-schema-field-glossaryterms",level:2},{value:"Config Details",id:"config-details-13",level:3},{value:"Pattern Add Dataset Schema Field globalTags",id:"pattern-add-dataset-schema-field-globaltags",level:2},{value:"Config Details",id:"config-details-14",level:3},{value:"Simple Add Dataset datasetProperties",id:"simple-add-dataset-datasetproperties",level:2},{value:"Config Details",id:"config-details-15",level:3},{value:"Add Dataset datasetProperties",id:"add-dataset-datasetproperties",level:2},{value:"Config Details",id:"config-details-16",level:3},{value:"Replace ExternalUrl Dataset",id:"replace-externalurl-dataset",level:2},{value:"Config Details",id:"config-details-17",level:3},{value:"Replace ExternalUrl Container",id:"replace-externalurl-container",level:2},{value:"Config Details",id:"config-details-18",level:3},{value:"Clean User URN in DatasetUsageStatistics Aspect",id:"clean-user-urn-in-datasetusagestatistics-aspect",level:2},{value:"Config Details",id:"config-details-19",level:3},{value:"Simple Add Dataset domains",id:"simple-add-dataset-domains",level:2},{value:"Config Details",id:"config-details-20",level:3},{value:"Pattern Add Dataset domains",id:"pattern-add-dataset-domains",level:2},{value:"Config Details",id:"config-details-21",level:3},{value:"Domain Mapping Based on Tags",id:"domain-mapping-based-on-tags",level:2},{value:"Config Details",id:"config-details-22",level:3},{value:"Simple Add Dataset dataProduct",id:"simple-add-dataset-dataproduct",level:2},{value:"Config Details",id:"config-details-23",level:3},{value:"Pattern Add Dataset dataProduct",id:"pattern-add-dataset-dataproduct",level:2},{value:"Config Details",id:"config-details-24",level:3},{value:"Add Dataset dataProduct",id:"add-dataset-dataproduct",level:2},{value:"Config Details",id:"config-details-25",level:3},{value:"Relationship Between replace_existing and semantics",id:"relationship-between-replace_existing-and-semantics",level:2},{value:"Writing a custom transformer from scratch",id:"writing-a-custom-transformer-from-scratch",level:2},{value:"Defining a config",id:"defining-a-config",level:3},{value:"Defining the transformer",id:"defining-the-transformer",level:3},{value:"More Sophistication: Making calls to DataHub during Transformation",id:"more-sophistication-making-calls-to-datahub-during-transformation",level:3},{value:"Advanced Use-Case: Patching Owners",id:"advanced-use-case-patching-owners",level:4},{value:"Installing the package",id:"installing-the-package",level:3},{value:"Running the transform",id:"running-the-transform",level:3},{value:"Using this in the remote executor (DataHub Cloud only)",id:"using-this-in-the-remote-executor-datahub-cloud-only",level:3}],m={toc:d},u="wrapper";function y(e){var{components:a}=e,t=i(e,["components"]);return(0,n.yg)(u,l(function(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{},n=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),n.forEach((function(a){r(e,a,t[a])}))}return e}({},m,t),{components:a,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"dataset-transformers"},"Dataset Transformers"),(0,n.yg)("p",null,"The below table shows transformer which can transform aspects of entity ",(0,n.yg)("a",{parentName:"p",href:"/docs/1.1.0/generated/metamodel/entities/dataset"},"Dataset"),"."),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Dataset Aspect"),(0,n.yg)("th",{parentName:"tr",align:null},"Transformer"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"status")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#mark-dataset-status"},"Mark Dataset status"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"ownership")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#simple-add-dataset-ownership"},"Simple Add Dataset ownership"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-ownership"},"Pattern Add Dataset ownership"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#simple-remove-dataset-ownership"},"Simple Remove Dataset Ownership"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#extract-ownership-from-tags"},"Extract Ownership from Tags"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#clean-suffix-prefix-from-ownership"},"Clean suffix prefix from Ownership"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"globalTags")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#simple-add-dataset-globaltags"},"Simple Add Dataset globalTags "),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-globaltags"},"Pattern Add Dataset globalTags"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#add-dataset-globaltags"},"Add Dataset globalTags"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"browsePaths")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#set-dataset-browsepath"},"Set Dataset browsePath"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"glossaryTerms")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#simple-add-dataset-glossaryterms"},"Simple Add Dataset glossaryTerms "),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-glossaryterms"},"Pattern Add Dataset glossaryTerms"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#tags-to-term-mapping"},"Tags to Term Mapping"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"schemaMetadata")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-schema-field-glossaryterms"},"Pattern Add Dataset Schema Field glossaryTerms"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-schema-field-globaltags"},"Pattern Add Dataset Schema Field globalTags"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"datasetProperties")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#simple-add-dataset-datasetproperties"},"Simple Add Dataset datasetProperties"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#add-dataset-datasetproperties"},"Add Dataset datasetProperties"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"domains")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#simple-add-dataset-domains"},"Simple Add Dataset domains"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-domains"},"Pattern Add Dataset domains"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#domain-mapping-based-on-tags"},"Domain Mapping Based on Tags"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"dataProduct")),(0,n.yg)("td",{parentName:"tr",align:null},"- ",(0,n.yg)("a",{parentName:"td",href:"#simple-add-dataset-dataproduct"},"Simple Add Dataset dataProduct "),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#pattern-add-dataset-dataproduct"},"Pattern Add Dataset dataProduct"),(0,n.yg)("br",null)," - ",(0,n.yg)("a",{parentName:"td",href:"#add-dataset-dataproduct"},"Add Dataset dataProduct"))))),(0,n.yg)("h2",{id:"extract-ownership-from-tags"},"Extract Ownership from Tags"),(0,n.yg)("h3",{id:"config-details"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"tag_pattern")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"str"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Regex to use for tags to match against. Supports Regex to match a pattern which is used to remove content. Rest of string is considered owner ID for creating owner URN.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"is_user")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"bool"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"true")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether should be consider a user or not. If ",(0,n.yg)("inlineCode",{parentName:"td"},"false")," then considered a group.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"tag_character_mapping")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"dict","[str, str]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"A mapping of tag character to datahub owner character. If provided, ",(0,n.yg)("inlineCode",{parentName:"td"},"tag_pattern")," config should be matched against converted tag as per mapping")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"email_domain")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"str"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"If set then this is appended to create owner URN.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"extract_owner_type_from_tag_pattern")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"str"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to extract an owner type from provided tag pattern first group. If ",(0,n.yg)("inlineCode",{parentName:"td"},"true"),", no need to provide owner_type and owner_type_urn config. For example: if provided tag pattern is ",(0,n.yg)("inlineCode",{parentName:"td"},"(.*)_owner_email:")," and actual tag is ",(0,n.yg)("inlineCode",{parentName:"td"},"developer_owner_email"),", then extracted owner type will be ",(0,n.yg)("inlineCode",{parentName:"td"},"developer"),".")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"owner_type")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"str"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"TECHNICAL_OWNER")),(0,n.yg)("td",{parentName:"tr",align:null},"Ownership type.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"owner_type_urn")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"str"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"None")),(0,n.yg)("td",{parentName:"tr",align:null},"Set to a custom ownership type's URN if using custom ownership.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to add a dataset ownerships based on part of dataset tags. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"extract_ownership_from_tags")," transformer that\u2019s included in the ingestion framework."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "extract_ownership_from_tags"\n    config:\n      tag_pattern: "owner_email:"\n')),(0,n.yg)("p",null,"So if we have input dataset tag like"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:tag:owner_email:abc@email.com")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:tag:owner_email:xyz@email.com"))),(0,n.yg)("p",null,"The portion of the tag after the matched tag pattern will be converted into an owner. Hence users ",(0,n.yg)("inlineCode",{parentName:"p"},"abc@email.com")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"xyz@email.com")," will be added as owners."),(0,n.yg)("h3",{id:"examples"},"Examples"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add owners, however owner should be considered as group and also email domain not provided in tag string. For example: from tag urn ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:tag:owner:abc")," extracted owner urn should be ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:corpGroup:abc@email.com")," then config would look like this:",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "extract_ownership_from_tags"\n    config:\n      tag_pattern: "owner:"\n      is_user: false\n      email_domain: "email.com"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owners, however owner type and owner type urn wanted to provide externally. For example: from tag urn ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:tag:owner_email:abc@email.com")," owner type should be ",(0,n.yg)("inlineCode",{parentName:"li"},"CUSTOM")," and owner type urn as ",(0,n.yg)("inlineCode",{parentName:"li"},'"urn:li:ownershipType:data_product"')," then config would look like this:",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "extract_ownership_from_tags"\n    config:\n      tag_pattern: "owner_email:"\n      owner_type: "CUSTOM"\n      owner_type_urn: "urn:li:ownershipType:data_product"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owners, however some tag characters needs to replace with some other characters before extracting owner. For example: from tag urn ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:tag:owner__email:abc--xyz-email_com")," extracted owner urn should be ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:corpGroup:abc.xyz@email.com")," then config would look like this:",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "extract_ownership_from_tags"\n    config:\n      tag_pattern: "owner_email:"\n      tag_character_mapping:\n        "_": "."\n        "-": "@"\n        "--": "-"\n        "__": "_"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owners, however owner type also need to extracted from tag pattern. For example: from tag urn ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:tag:data_producer_owner_email:abc@email.com")," extracted owner type should be ",(0,n.yg)("inlineCode",{parentName:"li"},"data_producer")," then config would look like this:",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "extract_ownership_from_tags"\n    config:\n      tag_pattern: "(.*)_owner_email:"\n      extract_owner_type_from_tag_pattern: true\n')))),(0,n.yg)("h2",{id:"clean-suffix-prefix-from-ownership"},"Clean suffix prefix from Ownership"),(0,n.yg)("h3",{id:"config-details-1"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"pattern_for_cleanup")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list","[string]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of suffix/prefix to remove from the Owner URN(s)")))),(0,n.yg)("p",null,"Matches against a Onwer URN and remove the matching part from the Owner URN"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_cleanup_ownership"\n    config:\n      pattern_for_cleanup:\n        - "ABCDEF"\n        - (?<=_)(\\w+)\n')),(0,n.yg)("h2",{id:"mark-dataset-status"},"Mark Dataset Status"),(0,n.yg)("h3",{id:"config-details-2"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"removed")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Flag to control visbility of dataset on UI.")))),(0,n.yg)("p",null,"If you would like to stop a dataset from appearing in the UI, then you need to mark the status of the dataset as removed."),(0,n.yg)("p",null,"You can use this transformer in your source recipe to mark status as removed."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "mark_dataset_status"\n    config:\n      removed: true\n')),(0,n.yg)("h2",{id:"simple-add-dataset-ownership"},"Simple Add Dataset ownership"),(0,n.yg)("h3",{id:"config-details-3"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"owner_urns")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list","[string]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of owner urns.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"ownership_type")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null},'"DATAOWNER"'),(0,n.yg)("td",{parentName:"tr",align:null},"ownership type of the owners (either as enum or ownership type urn)")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove ownership from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"on_conflict")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"DO_UPDATE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to make changes if domains already exist. If set to DO_NOTHING, ",(0,n.yg)("inlineCode",{parentName:"td"},"semantics")," setting is irrelevant.")))),(0,n.yg)("p",null,"For transformer behaviour on ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics"),", please refer section ",(0,n.yg)("a",{parentName:"p",href:"#relationship-between-replace_existing-and-semantics"},"Relationship Between replace_existing And semantics"),"."),(0,n.yg)("br",null),"Let\u2019s suppose we\u2019d like to append a series of users who we know to own a dataset but aren't detected during normal ingestion. To do so, we can use the `simple_add_dataset_ownership` transformer that\u2019s included in the ingestion framework.",(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("p",null,"Below configuration will add listed owner_urns in ownership aspect"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_ownership"\n    config:\n      owner_urns:\n        - "urn:li:corpuser:username1"\n        - "urn:li:corpuser:username2"\n        - "urn:li:corpGroup:groupname"\n      ownership_type: "PRODUCER"\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_ownership")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add owners, however replace existing owners sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_ownership"\n    config:\n      replace_existing: true # false is default behaviour\n      owner_urns:\n        - "urn:li:corpuser:username1"\n        - "urn:li:corpuser:username2"\n        - "urn:li:corpGroup:groupname"\n      ownership_type: "urn:li:ownershipType:__system__producer"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owners, however overwrite the owners available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_ownership"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      owner_urns:\n        - "urn:li:corpuser:username1"\n        - "urn:li:corpuser:username2"\n        - "urn:li:corpGroup:groupname"\n      ownership_type: "urn:li:ownershipType:__system__producer"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owners, however keep the owners available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_ownership"\n    config:\n      semantics: PATCH\n      owner_urns:\n        - "urn:li:corpuser:username1"\n        - "urn:li:corpuser:username2"\n        - "urn:li:corpGroup:groupname"\n      ownership_type: "PRODUCER"\n')))),(0,n.yg)("h2",{id:"pattern-add-dataset-ownership"},"Pattern Add Dataset ownership"),(0,n.yg)("h3",{id:"config-details-4"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"owner_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map[regx, list","[urn]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"entity urn with regular expression and list of owners urn apply to matching entity urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"ownership_type")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null},'"DATAOWNER"'),(0,n.yg)("td",{parentName:"tr",align:null},"ownership type of the owners (either as enum or ownership type urn)")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove owners from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"is_container")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"bool"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to also consider a container or not. If true, then ownership will be attached to both the dataset and its container.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"on_conflict")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"DO_UPDATE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to make changes if domains already exist. If set to DO_NOTHING, ",(0,n.yg)("inlineCode",{parentName:"td"},"semantics")," setting is irrelevant.")))),(0,n.yg)("p",null,"let\u2019s suppose we\u2019d like to append a series of users who we know to own a different dataset from a data source but aren't detected during normal ingestion. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_ownership")," module that\u2019s included in the ingestion framework. This will match the pattern to ",(0,n.yg)("inlineCode",{parentName:"p"},"urn")," of the dataset and assign the respective owners."),(0,n.yg)("p",null,"If the is_container field is set to true, the module will not only attach the ownerships to the matching datasets but will also find and attach containers associated with those datasets. This means that both the datasets and their containers will be associated with the specified owners."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_ownership"\n    config:\n      owner_pattern:\n        rules:\n          ".*example1.*": ["urn:li:corpuser:username1"]\n          ".*example2.*": ["urn:li:corpuser:username2"]\n      ownership_type: "DEVELOPER"\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_ownership")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add owner, however replace existing owner sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_ownership"\n    config:\n      replace_existing: true # false is default behaviour\n      owner_pattern:\n        rules:\n          ".*example1.*": ["urn:li:corpuser:username1"]\n          ".*example2.*": ["urn:li:corpuser:username2"]\n      ownership_type: "urn:li:ownershipType:__system__producer"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owner, however overwrite the owners available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_ownership"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      owner_pattern:\n        rules:\n          ".*example1.*": ["urn:li:corpuser:username1"]\n          ".*example2.*": ["urn:li:corpuser:username2"]\n      ownership_type: "urn:li:ownershipType:__system__producer"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owner, however keep the owners available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_ownership"\n    config:\n      semantics: PATCH\n      owner_pattern:\n        rules:\n          ".*example1.*": ["urn:li:corpuser:username1"]\n          ".*example2.*": ["urn:li:corpuser:username2"]\n      ownership_type: "PRODUCER"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add owner to dataset and its containers",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_ownership"\n    config:\n      is_container: true\n      replace_existing: true # false is default behaviour\n      semantics: PATCH / OVERWRITE # Based on user\n      owner_pattern:\n        rules:\n          ".*example1.*": ["urn:li:corpuser:username1"]\n          ".*example2.*": ["urn:li:corpuser:username2"]\n      ownership_type: "PRODUCER"\n')),"\u26a0\ufe0f Warning:\nWhen working with two datasets in the same container but with different owners, all owners will be added for that dataset containers.")),(0,n.yg)("p",null,"For example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_ownership"\n    config:\n      is_container: true\n      owner_pattern:\n        rules:\n          ".*example1.*": ["urn:li:corpuser:username1"]\n          ".*example2.*": ["urn:li:corpuser:username2"]\n')),(0,n.yg)("p",null,"If example1 and example2 are in the same container, then both urns urn:li:corpuser:username1 and urn:li:corpuser:username2 will be added for respective dataset containers."),(0,n.yg)("h2",{id:"simple-remove-dataset-ownership"},"Simple Remove Dataset ownership"),(0,n.yg)("p",null,"If we wanted to clear existing owners sent by ingestion source we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_remove_dataset_ownership")," transformer which removes all owners sent by the ingestion source."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_remove_dataset_ownership"\n    config: {}\n')),(0,n.yg)("p",null,"The main use case of ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_remove_dataset_ownership")," is to remove incorrect owners present in the source. You can use it along with the ",(0,n.yg)("a",{parentName:"p",href:"#simple-add-dataset-ownership"},"Simple Add Dataset ownership")," to remove wrong owners and add the correct ones."),(0,n.yg)("p",null,"Note that whatever owners you send via ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_remove_dataset_ownership")," will overwrite the owners present in the UI."),(0,n.yg)("h2",{id:"extract-dataset-globaltags"},"Extract Dataset globalTags"),(0,n.yg)("h3",{id:"config-details-5"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"extract_tags_from")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"urn")),(0,n.yg)("td",{parentName:"tr",align:null},"Which field to extract tag from. Currently only ",(0,n.yg)("inlineCode",{parentName:"td"},"urn")," is supported.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"extract_tags_regex")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},".*")),(0,n.yg)("td",{parentName:"tr",align:null},"Regex to use to extract tag.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove globalTags from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to add a dataset tags based on part of urn. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"extract_dataset_tags")," transformer that\u2019s included in the ingestion framework."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "extract_dataset_tags"\n    config:\n      extract_tags_from: "urn"\n      extract_tags_regex: ".([^._]*)_"\n')),(0,n.yg)("p",null,"So if we have input URNs like"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:dataset:(urn:li:dataPlatform:kafka,clusterid.USA-ops-team_table1,PROD)")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:dataset:(urn:li:dataPlatform:kafka,clusterid.Canada-marketing_table1,PROD)"))),(0,n.yg)("p",null,"a tag called ",(0,n.yg)("inlineCode",{parentName:"p"},"USA-ops-team")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"Canada-marketing")," will be added to them respectively. This is helpful in case you are using prefixes in your datasets to segregate different things. Now you can turn that segregation into a tag on your dataset in DataHub for further use."),(0,n.yg)("h2",{id:"simple-add-dataset-globaltags"},"Simple Add Dataset globalTags"),(0,n.yg)("h3",{id:"config-details-6"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"tag_urns")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list","[string]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of globalTags urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove globalTags from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to add a set of dataset tags. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_tags")," transformer that\u2019s included in the ingestion framework."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_tags"\n    config:\n      tag_urns:\n        - "urn:li:tag:NeedsDocumentation"\n        - "urn:li:tag:Legacy"\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_tags")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add tags, however replace existing tags sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_tags"\n    config:\n      replace_existing: true # false is default behaviour\n      tag_urns:\n        - "urn:li:tag:NeedsDocumentation"\n        - "urn:li:tag:Legacy"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however overwrite the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_tags"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      tag_urns:\n        - "urn:li:tag:NeedsDocumentation"\n        - "urn:li:tag:Legacy"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however keep the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_tags"\n    config:\n      semantics: PATCH\n      tag_urns:\n        - "urn:li:tag:NeedsDocumentation"\n        - "urn:li:tag:Legacy"\n')))),(0,n.yg)("h2",{id:"pattern-add-dataset-globaltags"},"Pattern Add Dataset globalTags"),(0,n.yg)("h3",{id:"config-details-7"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"tag_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map[regx, list","[urn]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Entity urn with regular expression and list of tags urn apply to matching entity urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove globalTags from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to append a series of tags to specific datasets. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_tags")," module that\u2019s included in the ingestion framework. This will match the regex pattern to ",(0,n.yg)("inlineCode",{parentName:"p"},"urn")," of the dataset and assign the respective tags urns given in the array."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_tags"\n    config:\n      tag_pattern:\n        rules:\n          ".*example1.*": ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_tags")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add tags, however replace existing tags sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_tags"\n    config:\n      replace_existing: true # false is default behaviour\n      tag_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however overwrite the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_tags"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      tag_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however keep the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_tags"\n    config:\n      semantics: PATCH\n      tag_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n')))),(0,n.yg)("h2",{id:"add-dataset-globaltags"},"Add Dataset globalTags"),(0,n.yg)("h3",{id:"config-details-8"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"get_tags_to_add")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"callable[","[str]",", list","[TagAssociationClass]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"A function which takes entity urn as input and return TagAssociationClass.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove globalTags from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"If you'd like to add more complex logic for assigning tags, you can use the more generic add_dataset_tags transformer, which calls a user-provided function to determine the tags for each dataset."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_tags"\n    config:\n      get_tags_to_add: "<your_module>.<your_function>"\n')),(0,n.yg)("p",null,"Then define your function to return a list of TagAssociationClass tags, for example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'import logging\n\nimport datahub.emitter.mce_builder as builder\nfrom datahub.metadata.schema_classes import (\n    TagAssociationClass\n)\n\ndef custom_tags(entity_urn: str) -> List[TagAssociationClass]:\n    """Compute the tags to associate to a given dataset."""\n\n    tag_strings = []\n\n    ### Add custom logic here\n    tag_strings.append(\'custom1\')\n    tag_strings.append(\'custom2\')\n\n    tag_strings = [builder.make_tag_urn(tag=n) for n in tag_strings]\n    tags = [TagAssociationClass(tag=tag) for tag in tag_strings]\n\n    logging.info(f"Tagging dataset {entity_urn} with {tag_strings}.")\n    return tags\n')),(0,n.yg)("p",null,"Finally, you can install and use your custom transformer as ",(0,n.yg)("a",{parentName:"p",href:"#installing-the-package"},"shown here"),"."),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"add_dataset_tags")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add tags, however replace existing tags sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_tags"\n    config:\n      replace_existing: true # false is default behaviour\n      get_tags_to_add: "<your_module>.<your_function>"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however overwrite the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_tags"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      get_tags_to_add: "<your_module>.<your_function>"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however keep the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_tags"\n    config:\n      semantics: PATCH\n      get_tags_to_add: "<your_module>.<your_function>"\n')))),(0,n.yg)("h2",{id:"set-dataset-browsepath"},"Set Dataset browsePath"),(0,n.yg)("h3",{id:"config-details-9"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"path_templates")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list","[string]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of path templates.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove browsePath from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"If you would like to add to browse paths of dataset can use this transformer. There are 3 optional variables that you can use to get information from the dataset ",(0,n.yg)("inlineCode",{parentName:"p"},"urn"),":"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"ENV: env passed (default: prod)"),(0,n.yg)("li",{parentName:"ul"},"PLATFORM: ",(0,n.yg)("inlineCode",{parentName:"li"},"mysql"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"postgres")," or different platform supported by datahub"),(0,n.yg)("li",{parentName:"ul"},"DATASET_PARTS: slash separated parts of dataset name. e.g. ",(0,n.yg)("inlineCode",{parentName:"li"},"database_name/schema_name/[table_name]")," for postgres")),(0,n.yg)("p",null,"e.g. this can be used to create browse paths like ",(0,n.yg)("inlineCode",{parentName:"p"},"/prod/postgres/superset/public/logs")," for table ",(0,n.yg)("inlineCode",{parentName:"p"},"superset.public.logs")," in a ",(0,n.yg)("inlineCode",{parentName:"p"},"postgres")," database"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      path_templates:\n        - /ENV/PLATFORM/DATASET_PARTS\n')),(0,n.yg)("p",null,"If you don't want the environment but wanted to add something static in the browse path like the database instance name you can use this."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      path_templates:\n        - /PLATFORM/marketing_db/DATASET_PARTS\n')),(0,n.yg)("p",null,"It will create browse path like ",(0,n.yg)("inlineCode",{parentName:"p"},"/mysql/marketing_db/sales/orders")," for a table ",(0,n.yg)("inlineCode",{parentName:"p"},"sales.orders")," in ",(0,n.yg)("inlineCode",{parentName:"p"},"mysql")," database instance."),(0,n.yg)("p",null,"You can use this to add multiple browse paths. Different people might know the same data assets by different names."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      path_templates:\n        - /PLATFORM/marketing_db/DATASET_PARTS\n        - /data_warehouse/DATASET_PARTS\n')),(0,n.yg)("p",null,"This will add 2 browse paths like ",(0,n.yg)("inlineCode",{parentName:"p"},"/mysql/marketing_db/sales/orders")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"/data_warehouse/sales/orders")," for a table ",(0,n.yg)("inlineCode",{parentName:"p"},"sales.orders")," in ",(0,n.yg)("inlineCode",{parentName:"p"},"mysql")," database instance."),(0,n.yg)("p",null,"Default behaviour of the transform is to add new browse paths, you can optionally set ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing: True")," so\nthe transform becomes a ",(0,n.yg)("em",{parentName:"p"},"set")," operation instead of an ",(0,n.yg)("em",{parentName:"p"},"append"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      replace_existing: True\n      path_templates:\n        - /ENV/PLATFORM/DATASET_PARTS\n')),(0,n.yg)("p",null,"In this case, the resulting dataset will have only 1 browse path, the one from the transform."),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"set_dataset_browse_path")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add browsePath, however replace existing browsePath sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      replace_existing: true # false is default behaviour\n      path_templates:\n        - /PLATFORM/marketing_db/DATASET_PARTS\n'))),(0,n.yg)("li",{parentName:"ul"},"Add browsePath, however overwrite the browsePath available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      path_templates:\n        - /PLATFORM/marketing_db/DATASET_PARTS\n'))),(0,n.yg)("li",{parentName:"ul"},"Add browsePath, however keep the browsePath available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "set_dataset_browse_path"\n    config:\n      semantics: PATCH\n      path_templates:\n        - /PLATFORM/marketing_db/DATASET_PARTS\n')))),(0,n.yg)("h2",{id:"simple-add-dataset-glossaryterms"},"Simple Add Dataset glossaryTerms"),(0,n.yg)("h3",{id:"config-details-10"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"term_urns")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list","[string]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of glossaryTerms urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove glossaryTerms from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"We can use a similar convention to associate ",(0,n.yg)("a",{parentName:"p",href:"/docs/1.1.0/generated/ingestion/sources/business-glossary"},"Glossary Terms")," to datasets.\nWe can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_terms")," transformer that\u2019s included in the ingestion framework."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_terms"\n    config:\n      term_urns:\n        - "urn:li:glossaryTerm:Email"\n        - "urn:li:glossaryTerm:Address"\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_terms")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add terms, however replace existing terms sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_terms"\n    config:\n      replace_existing: true # false is default behaviour\n      term_urns:\n        - "urn:li:glossaryTerm:Email"\n        - "urn:li:glossaryTerm:Address"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add terms, however overwrite the terms available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_terms"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      term_urns:\n        - "urn:li:glossaryTerm:Email"\n        - "urn:li:glossaryTerm:Address"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add terms, however keep the terms available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_terms"\n    config:\n      semantics: PATCH\n      term_urns:\n        - "urn:li:glossaryTerm:Email"\n        - "urn:li:glossaryTerm:Address"\n')))),(0,n.yg)("h2",{id:"pattern-add-dataset-glossaryterms"},"Pattern Add Dataset glossaryTerms"),(0,n.yg)("h3",{id:"config-details-11"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"term_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map[regx, list","[urn]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"entity urn with regular expression and list of glossaryTerms urn apply to matching entity urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove glossaryTerms from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"We can add glossary terms to datasets based on a regex filter."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_terms"\n    config:\n      term_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:glossaryTerm:Email", "urn:li:glossaryTerm:Address"]\n          ".*example2.*": ["urn:li:glossaryTerm:PostalCode"]\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_terms")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add terms, however replace existing terms sent by ingestion source"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_terms"\n    config:\n      replace_existing: true # false is default behaviour\n      term_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:glossaryTerm:Email", "urn:li:glossaryTerm:Address"]\n          ".*example2.*": ["urn:li:glossaryTerm:PostalCode"]\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add terms, however overwrite the terms available for the dataset on DataHub GMS"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_terms"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      term_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:glossaryTerm:Email", "urn:li:glossaryTerm:Address"]\n          ".*example2.*": ["urn:li:glossaryTerm:PostalCode"]\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add terms, however keep the terms available for the dataset on DataHub GMS"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_terms"\n    config:\n      semantics: PATCH\n      term_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:glossaryTerm:Email", "urn:li:glossaryTerm:Address"]\n          ".*example2.*": ["urn:li:glossaryTerm:PostalCode"]\n')))),(0,n.yg)("h2",{id:"tags-to-term-mapping"},"Tags to Term Mapping"),(0,n.yg)("h3",{id:"config-details-12"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"tags")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"List","[str]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of tag names based on which terms will be created and associated with the dataset.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},'"OVERWRITE"'),(0,n.yg)("td",{parentName:"tr",align:null},"Determines whether to OVERWRITE or PATCH the terms associated with the dataset on DataHub GMS.")))),(0,n.yg)("br",null),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"tags_to_term")," transformer is designed to map specific tags to glossary terms within DataHub. It takes a configuration of tags that should be translated into corresponding glossary terms. This transformer can apply these mappings to any tags found either at the column level of a dataset or at the dataset top level."),(0,n.yg)("p",null,"When specifying tags in the configuration, use the tag's simple name rather than the full tag URN."),(0,n.yg)("p",null,"For example, instead of using the tag URN ",(0,n.yg)("inlineCode",{parentName:"p"},"urn:li:tag:snowflakedb.snowflakeschema.tag_name:tag_value"),", you should specify just the tag name ",(0,n.yg)("inlineCode",{parentName:"p"},"tag_name")," in the mapping configuration."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "tags_to_term"\n    config:\n      semantics: OVERWRITE # OVERWRITE is the default behavior\n      tags:\n        - "tag_name"\n')),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"tags_to_term")," transformer can be configured in the following ways:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add terms based on tags, however overwrite the terms available for the dataset on DataHub GMS")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "tags_to_term"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      tags:\n        - "example1"\n        - "example2"\n        - "example3"\n')),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add terms based on tags, however keep the terms available for the dataset on DataHub GMS")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "tags_to_term"\n    config:\n      semantics: PATCH\n      tags:\n        - "example1"\n        - "example2"\n        - "example3"\n')),(0,n.yg)("h2",{id:"pattern-add-dataset-schema-field-glossaryterms"},"Pattern Add Dataset Schema Field glossaryTerms"),(0,n.yg)("h3",{id:"config-details-13"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"term_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map[regx, list","[urn]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"entity urn with regular expression and list of glossaryTerms urn apply to matching entity urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove glossaryTerms from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"We can add glossary terms to schema fields based on a regex filter."),(0,n.yg)("p",null,"Note that only terms from the first matching pattern will be applied."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_terms"\n    config:\n      term_pattern:\n        rules:\n          ".*email.*": ["urn:li:glossaryTerm:Email"]\n          ".*name.*": ["urn:li:glossaryTerm:Name"]\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_schema_terms")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add terms, however replace existing terms sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_terms"\n    config:\n      replace_existing: true # false is default behaviour\n      term_pattern:\n        rules:\n          ".*email.*": ["urn:li:glossaryTerm:Email"]\n          ".*name.*": ["urn:li:glossaryTerm:Name"]\n'))),(0,n.yg)("li",{parentName:"ul"},"Add terms, however overwrite the terms available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_terms"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      term_pattern:\n        rules:\n          ".*email.*": ["urn:li:glossaryTerm:Email"]\n          ".*name.*": ["urn:li:glossaryTerm:Name"]\n'))),(0,n.yg)("li",{parentName:"ul"},"Add terms, however keep the terms available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_terms"\n    config:\n      semantics: PATCH\n      term_pattern:\n        rules:\n          ".*email.*": ["urn:li:glossaryTerm:Email"]\n          ".*name.*": ["urn:li:glossaryTerm:Name"]\n')))),(0,n.yg)("h2",{id:"pattern-add-dataset-schema-field-globaltags"},"Pattern Add Dataset Schema Field globalTags"),(0,n.yg)("h3",{id:"config-details-14"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"tag_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map[regx, list","[urn]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"entity urn with regular expression and list of tags urn apply to matching entity urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove globalTags from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"We can also append a series of tags to specific schema fields. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_schema_tags")," transformer. This will match the regex pattern to each schema field path and assign the respective tags urns given in the array."),(0,n.yg)("p",null,"Note that the tags from the first matching pattern will be applied, not all matching patterns."),(0,n.yg)("p",null,"The config would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_tags"\n    config:\n      tag_pattern:\n        rules:\n          ".*email.*": ["urn:li:tag:Email"]\n          ".*name.*": ["urn:li:tag:Name"]\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_schema_tags")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add tags, however replace existing tag sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_tags"\n    config:\n      replace_existing: true # false is default behaviour\n      tag_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however overwrite the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_tags"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      tag_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n'))),(0,n.yg)("li",{parentName:"ul"},"Add tags, however keep the tags available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_schema_tags"\n    config:\n      semantics: PATCH\n      tag_pattern:\n        rules:\n          ".*example1.*":\n            ["urn:li:tag:NeedsDocumentation", "urn:li:tag:Legacy"]\n          ".*example2.*": ["urn:li:tag:NeedsDocumentation"]\n')))),(0,n.yg)("h2",{id:"simple-add-dataset-datasetproperties"},"Simple Add Dataset datasetProperties"),(0,n.yg)("h3",{id:"config-details-15"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"properties")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"dict","[str, str]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Map of key value pair.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove datasetProperties from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_properties")," transformer assigns the properties to dataset entity from the configuration.\n",(0,n.yg)("inlineCode",{parentName:"p"},"properties")," field is a dictionary of string values. Note in case of any key collision, the value in the config will\noverwrite the previous value."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_properties"\n    config:\n      properties:\n        prop1: value1\n        prop2: value2\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_properties")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add dataset-properties, however replace existing dataset-properties sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_properties"\n    config:\n      replace_existing: true # false is default behaviour\n      properties:\n        prop1: value1\n        prop2: value2\n'))),(0,n.yg)("li",{parentName:"ul"},"Add dataset-properties, however overwrite the dataset-properties available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_properties"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      properties:\n        prop1: value1\n        prop2: value2\n'))),(0,n.yg)("li",{parentName:"ul"},"Add dataset-properties, however keep the dataset-properties available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_properties"\n    config:\n      semantics: PATCH\n      properties:\n        prop1: value1\n        prop2: value2\n')))),(0,n.yg)("h2",{id:"add-dataset-datasetproperties"},"Add Dataset datasetProperties"),(0,n.yg)("h3",{id:"config-details-16"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"add_properties_resolver_class")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Type","[AddDatasetPropertiesResolverBase]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"A class extends from ",(0,n.yg)("inlineCode",{parentName:"td"},"AddDatasetPropertiesResolverBase"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove datasetProperties from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"If you'd like to add more complex logic for assigning properties, you can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"add_dataset_properties")," transformer, which calls a user-provided class (that extends from ",(0,n.yg)("inlineCode",{parentName:"p"},"AddDatasetPropertiesResolverBase")," class) to determine the properties for each dataset."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_properties"\n    config:\n      add_properties_resolver_class: "<your_module>.<your_class>"\n')),(0,n.yg)("p",null,"Then define your class to return a list of custom properties, for example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"import logging\nfrom typing import Dict\nfrom datahub.ingestion.transformer.add_dataset_properties import AddDatasetPropertiesResolverBase\n\nclass MyPropertiesResolver(AddDatasetPropertiesResolverBase):\n    def get_properties_to_add(self, entity_urn: str) -> Dict[str, str]:\n        ### Add custom logic here\n        properties= {'my_custom_property': 'property value'}\n        logging.info(f\"Adding properties: {properties} to dataset: {entity_urn}.\")\n        return properties\n")),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"add_dataset_properties")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add dataset-properties, however replace existing dataset-properties sent by ingestion source"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_properties"\n    config:\n      replace_existing: true # false is default behaviour\n      add_properties_resolver_class: "<your_module>.<your_class>"\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add dataset-properties, however overwrite the dataset-properties available for the dataset on DataHub GMS"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_properties"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      add_properties_resolver_class: "<your_module>.<your_class>"\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add dataset-properties, however keep the dataset-properties available for the dataset on DataHub GMS"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_properties"\n    config:\n      semantics: PATCH\n      add_properties_resolver_class: "<your_module>.<your_class>"\n')))),(0,n.yg)("h2",{id:"replace-externalurl-dataset"},"Replace ExternalUrl Dataset"),(0,n.yg)("h3",{id:"config-details-17"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"input_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"String or pattern to replace")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replacement")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Replacement string")))),(0,n.yg)("p",null,"Matches the full/partial string in the externalUrl of the dataset properties and replace that with the replacement string"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "replace_external_url"\n    config:\n      input_pattern: \'\\b\\w*hub\\b\'\n      replacement: "sub"\n')),(0,n.yg)("h2",{id:"replace-externalurl-container"},"Replace ExternalUrl Container"),(0,n.yg)("h3",{id:"config-details-18"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"input_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"String or pattern to replace")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replacement")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"string"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Replacement string")))),(0,n.yg)("p",null,"Matches the full/partial string in the externalUrl of the container properties and replace that with the replacement string"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "replace_external_url_container"\n    config:\n      input_pattern: \'\\b\\w*hub\\b\'\n      replacement: "sub"\n')),(0,n.yg)("h2",{id:"clean-user-urn-in-datasetusagestatistics-aspect"},"Clean User URN in DatasetUsageStatistics Aspect"),(0,n.yg)("h3",{id:"config-details-19"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"pattern_for_cleanup")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list","[string]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of suffix/prefix to remove from the Owner URN(s)")))),(0,n.yg)("p",null,"Matches against a User URN in DatasetUsageStatistics aspect and remove the matching part from it"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_cleanup_dataset_usage_user"\n    config:\n      pattern_for_cleanup:\n        - "ABCDEF"\n        - (?<=_)(\\w+)\n')),(0,n.yg)("h2",{id:"simple-add-dataset-domains"},"Simple Add Dataset domains"),(0,n.yg)("h3",{id:"config-details-20"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"domains")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"list[union","[urn, str]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"List of simple domain name or domain urns.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove domains from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("p",null,"For transformer behaviour on ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics"),", please refer section ",(0,n.yg)("a",{parentName:"p",href:"#relationship-between-replace_existing-and-semantics"},"Relationship Between replace_existing And semantics"),"."),(0,n.yg)("br",null),(0,n.yg)("p",null,"let\u2019s suppose we\u2019d like to add a series of domain to dataset, in this case you can use ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_domain")," transformer."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("p",null,"Here we can set domains to either urn (i.e. urn:li:domain:engineering) or simple domain name (i.e. engineering) in both of the cases domain should be provisioned on DataHub GMS"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_domain"\n    config:\n      semantics: OVERWRITE\n      domains:\n        - urn:li:domain:engineering\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_domain")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add domains, however replace existing domains sent by ingestion source",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_domain"\n    config:\n      replace_existing: true # false is default behaviour\n      domains:\n        - "urn:li:domain:engineering"\n        - "urn:li:domain:hr"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add domains, however overwrite the domains available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_domain"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      domains:\n        - "urn:li:domain:engineering"\n        - "urn:li:domain:hr"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add domains, however keep the domains available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_domain"\n    config:\n      semantics: PATCH\n      domains:\n        - "urn:li:domain:engineering"\n        - "urn:li:domain:hr"\n')))),(0,n.yg)("h2",{id:"pattern-add-dataset-domains"},"Pattern Add Dataset domains"),(0,n.yg)("h3",{id:"config-details-21"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"domain_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map[regx, list[union","[urn, str]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"dataset urn with regular expression and list of simple domain name or domain urn need to be apply on matching dataset urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"replace_existing")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"boolean"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to remove domains from entity sent by ingestion source.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"OVERWRITE")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"is_container")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"bool"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to also consider a container or not. If true, then domains will be attached to both the dataset and its container.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to append a series of domain to specific datasets. To do so, we can use the pattern_add_dataset_domain transformer that\u2019s included in the ingestion framework.\nThis will match the regex pattern to urn of the dataset and assign the respective domain urns given in the array."),(0,n.yg)("p",null,"If the is_container field is set to true, the module will not only attach the domains to the matching datasets but will also find and attach containers associated with those datasets. This means that both the datasets and their containers will be associated with the specified owners."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:\nHere we can set domain list to either urn (i.e. urn:li:domain:hr) or simple domain name (i.e. hr)\nin both of the cases domain should be provisioned on DataHub GMS"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_domain"\n    config:\n      semantics: OVERWRITE\n      domain_pattern:\n        rules:\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.n.*\':\n            ["hr"]\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.t.*\':\n            ["urn:li:domain:finance"]\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"pattern_add_dataset_domain")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add domains, however replace existing domains sent by ingestion source"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_domain"\n    config:\n      replace_existing: true # false is default behaviour\n      domain_pattern:\n        rules:\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.n.*\':\n            ["hr"]\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.t.*\':\n            ["urn:li:domain:finance"]\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add domains, however overwrite the domains available for the dataset on DataHub GMS"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_domain"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      domain_pattern:\n        rules:\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.n.*\':\n            ["hr"]\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.t.*\':\n            ["urn:li:domain:finance"]\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add domains, however keep the domains available for the dataset on DataHub GMS"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_domain"\n    config:\n      semantics: PATCH\n      domain_pattern:\n        rules:\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.n.*\':\n            ["hr"]\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.t.*\':\n            ["urn:li:domain:finance"]\n'))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("p",{parentName:"li"},"Add domains to dataset and its containers"),(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_domain"\n    config:\n      is_container: true\n      semantics: PATCH / OVERWRITE # Based on user\n      domain_pattern:\n        rules:\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.n.*\':\n            ["hr"]\n          \'urn:li:dataset:\\(urn:li:dataPlatform:postgres,postgres\\.public\\.t.*\':\n            ["urn:li:domain:finance"]\n')),(0,n.yg)("p",{parentName:"li"},"\u26a0\ufe0f Warning:\nWhen working with two datasets in the same container but with different domains, all domains will be added for that dataset containers."))),(0,n.yg)("p",null,"For example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_domain"\n    config:\n      is_container: true\n      domain_pattern:\n        rules:\n          ".*example1.*": ["hr"]\n          ".*example2.*": ["urn:li:domain:finance"]\n')),(0,n.yg)("p",null,"If example1 and example2 are in the same container, then both domains hr and finance will be added for respective dataset containers."),(0,n.yg)("h2",{id:"domain-mapping-based-on-tags"},"Domain Mapping Based on Tags"),(0,n.yg)("h3",{id:"config-details-22"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"domain_mapping")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Dict","[str, str]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Dataset Entity tag as key and domain urn or name as value to map with dataset as asset.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"semantics")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"enum"),(0,n.yg)("td",{parentName:"tr",align:null},'"OVERWRITE"'),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to OVERWRITE or PATCH the entity present on DataHub GMS.")))),(0,n.yg)("br",null),(0,n.yg)("p",null,"let\u2019s suppose we\u2019d like to add domain to dataset based on tag, in this case you can use ",(0,n.yg)("inlineCode",{parentName:"p"},"domain_mapping_based_on_tags")," transformer."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("p",null,"Here we can set domains to either urn (i.e. urn:li:domain:engineering) or simple domain name (i.e. engineering) in both of the cases domain should be provisioned on DataHub GMS"),(0,n.yg)("p",null,"When specifying tags within the domain mapping, use the tag's simple name rather than the full tag URN."),(0,n.yg)("p",null,"For example, instead of using the tag URN urn:li:tag:NeedsDocumentation, you should specify just the simple tag name NeedsDocumentation in the domain mapping configuration"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "domain_mapping_based_on_tags"\n    config:\n      domain_mapping:\n        "NeedsDocumentation": "urn:li:domain:documentation"\n')),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"domain_mapping_based_on_tags")," can be configured in below different way"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add domains based on tags, however overwrite the domains available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "domain_mapping_based_on_tags"\n    config:\n      semantics: OVERWRITE # OVERWRITE is default behaviour\n      domain_mapping:\n        "example1": "urn:li:domain:engineering"\n        "example2": "urn:li:domain:hr"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add domains based on tags, however keep the domains available for the dataset on DataHub GMS",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "domain_mapping_based_on_tags"\n    config:\n      semantics: PATCH\n      domain_mapping:\n        "example1": "urn:li:domain:engineering"\n        "example2": "urn:li:domain:hr"\n')))),(0,n.yg)("h2",{id:"simple-add-dataset-dataproduct"},"Simple Add Dataset dataProduct"),(0,n.yg)("h3",{id:"config-details-23"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"dataset_to_data_product_urns")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Dict","[str, str]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Dataset Entity urn as key and dataproduct urn as value to create with dataset as asset.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to add a set of dataproduct with specific datasets as its assets. To do so, we can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_dataproduct")," transformer that\u2019s included in the ingestion framework."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "simple_add_dataset_dataproduct"\n    config:\n      dataset_to_data_product_urns:\n        "urn:li:dataset:(urn:li:dataPlatform:bigquery,example1,PROD)": "urn:li:dataProduct:first"\n        "urn:li:dataset:(urn:li:dataPlatform:bigquery,example2,PROD)": "urn:li:dataProduct:second"\n')),(0,n.yg)("h2",{id:"pattern-add-dataset-dataproduct"},"Pattern Add Dataset dataProduct"),(0,n.yg)("h3",{id:"config-details-24"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"dataset_to_data_product_urns_pattern")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"map","[regx, urn]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"Dataset Entity urn with regular expression and dataproduct urn apply to matching entity urn.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"is_container")),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"bool"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"false")),(0,n.yg)("td",{parentName:"tr",align:null},"Whether to also consider a container or not. If true, the data product will be attached to both the dataset and its container.")))),(0,n.yg)("p",null,"Let\u2019s suppose we\u2019d like to append a series of data products with specific datasets or their containers as assets. To do so, we can use the pattern_add_dataset_dataproduct module that\u2019s included in the ingestion framework. This module matches a regex pattern to the urn of the dataset and creates a data product entity with the given urn, associating the matched datasets as its assets."),(0,n.yg)("p",null,"If the is_container field is set to true, the module will not only attach the data product to the matching datasets but will also find and attach the containers associated with those datasets. This means that both the datasets and their containers will be associated with the specified data product."),(0,n.yg)("p",null,"The config, which we\u2019d append to our ingestion recipe YAML, would look like this:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Add Product to dataset",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_dataproduct"\n    config:\n      dataset_to_data_product_urns_pattern:\n        rules:\n          ".*example1.*": "urn:li:dataProduct:first"\n          ".*example2.*": "urn:li:dataProduct:second"\n'))),(0,n.yg)("li",{parentName:"ul"},"Add Product to dataset container",(0,n.yg)("pre",{parentName:"li"},(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_dataproduct"\n    config:\n      is_container: true\n      dataset_to_data_product_urns_pattern:\n        rules:\n          ".*example1.*": "urn:li:dataProduct:first"\n          ".*example2.*": "urn:li:dataProduct:second"\n')),"\u26a0\ufe0f Warning:\nWhen working with two datasets in the same container but with different data products, only one data product can be attached to the container.")),(0,n.yg)("p",null,"For example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "pattern_add_dataset_dataproduct"\n    config:\n      is_container: true\n      dataset_to_data_product_urns_pattern:\n        rules:\n          ".*example1.*": "urn:li:dataProduct:first"\n          ".*example2.*": "urn:li:dataProduct:second"\n')),(0,n.yg)("p",null,"If example1 and example2 are in the same container, only urn:li:dataProduct:first will be added. However, if they are in separate containers, the system works as expected and assigns the correct data product URNs."),(0,n.yg)("h2",{id:"add-dataset-dataproduct"},"Add Dataset dataProduct"),(0,n.yg)("h3",{id:"config-details-25"},"Config Details"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Field"),(0,n.yg)("th",{parentName:"tr",align:null},"Required"),(0,n.yg)("th",{parentName:"tr",align:null},"Type"),(0,n.yg)("th",{parentName:"tr",align:null},"Default"),(0,n.yg)("th",{parentName:"tr",align:null},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"get_data_product_to_add")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"callable[","[str]",", Optional","[str]","]"),(0,n.yg)("td",{parentName:"tr",align:null}),(0,n.yg)("td",{parentName:"tr",align:null},"A function which takes dataset entity urn as input and return dataproduct urn to create.")))),(0,n.yg)("p",null,"If you'd like to add more complex logic for creating dataproducts, you can use the more generic add_dataset_dataproduct transformer, which calls a user-provided function to determine the dataproduct to create with specified datasets as its asset."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "add_dataset_dataproduct"\n    config:\n      get_data_product_to_add: "<your_module>.<your_function>"\n')),(0,n.yg)("p",null,"Then define your function to return a dataproduct entity urn, for example:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'import datahub.emitter.mce_builder as builder\n\ndef custom_dataproducts(entity_urn: str) -> Optional[str]:\n    """Compute the dataproduct urn to a given dataset urn."""\n\n    dataset_to_data_product_map = {\n        builder.make_dataset_urn("bigquery", "example1"): "urn:li:dataProduct:first"\n    }\n    return dataset_to_data_product_map.get(dataset_urn)\n')),(0,n.yg)("p",null,"Finally, you can install and use your custom transformer as ",(0,n.yg)("a",{parentName:"p",href:"#installing-the-package"},"shown here"),"."),(0,n.yg)("h2",{id:"relationship-between-replace_existing-and-semantics"},"Relationship Between replace_existing and semantics"),(0,n.yg)("p",null,"The transformer behaviour mentioned here is in context of ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_ownership"),", however it is applicable for all dataset transformers which are supporting ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing"),"\nand ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics")," configuration attributes, for example ",(0,n.yg)("inlineCode",{parentName:"p"},"simple_add_dataset_tags")," will add or remove tags as per behaviour mentioned in this section."),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," controls whether to remove owners from currently executing ingestion pipeline."),(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"semantics")," controls whether to overwrite or patch owners present on DataHub GMS server. These owners might be added from DataHub Portal."),(0,n.yg)("p",null,"if ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"true")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"OVERWRITE")," then transformer takes below steps"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"As ",(0,n.yg)("inlineCode",{parentName:"li"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"true"),", remove the owners from input entity (i.e. dataset)"),(0,n.yg)("li",{parentName:"ol"},"Add owners mentioned in ingestion recipe to input entity"),(0,n.yg)("li",{parentName:"ol"},"As ",(0,n.yg)("inlineCode",{parentName:"li"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"OVERWRITE")," no need to fetch owners present on DataHub GMS server for the input entity"),(0,n.yg)("li",{parentName:"ol"},"Return input entity")),(0,n.yg)("p",null,"if ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"true")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"PATCH")," then transformer takes below steps"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("inlineCode",{parentName:"li"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"true"),", first remove the owners from input entity (i.e. dataset)"),(0,n.yg)("li",{parentName:"ol"},"Add owners mentioned in ingestion recipe to input entity"),(0,n.yg)("li",{parentName:"ol"},"As ",(0,n.yg)("inlineCode",{parentName:"li"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"PATCH")," fetch owners for the input entity from DataHub GMS Server"),(0,n.yg)("li",{parentName:"ol"},"Add owners fetched from DataHub GMS Server to input entity"),(0,n.yg)("li",{parentName:"ol"},"Return input entity")),(0,n.yg)("p",null,"if ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"false")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"OVERWRITE")," then transformer takes below steps"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"As ",(0,n.yg)("inlineCode",{parentName:"li"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"false"),", keep the owners present in input entity as is"),(0,n.yg)("li",{parentName:"ol"},"Add owners mentioned in ingestion recipe to input entity"),(0,n.yg)("li",{parentName:"ol"},"As ",(0,n.yg)("inlineCode",{parentName:"li"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"OVERWRITE")," no need to fetch owners from DataHub GMS Server for the input entity"),(0,n.yg)("li",{parentName:"ol"},"Return input entity")),(0,n.yg)("p",null,"if ",(0,n.yg)("inlineCode",{parentName:"p"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"false")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"p"},"PATCH")," then transformer takes below steps"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("inlineCode",{parentName:"li"},"replace_existing")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"false"),", keep the owners present in input entity as is"),(0,n.yg)("li",{parentName:"ol"},"Add owners mentioned in ingestion recipe to input entity"),(0,n.yg)("li",{parentName:"ol"},"As ",(0,n.yg)("inlineCode",{parentName:"li"},"semantics")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"PATCH")," fetch owners for the input entity from DataHub GMS Server"),(0,n.yg)("li",{parentName:"ol"},"Add owners fetched from DataHub GMS Server to input entity"),(0,n.yg)("li",{parentName:"ol"},"Return input entity")),(0,n.yg)("h2",{id:"writing-a-custom-transformer-from-scratch"},"Writing a custom transformer from scratch"),(0,n.yg)("p",null,"In the above couple of examples, we use classes that have already been implemented in the ingestion framework. However, it\u2019s common for more advanced cases to pop up where custom code is required, for instance if you'd like to utilize conditional logic or rewrite properties. In such cases, we can add our own modules and define the arguments it takes as a custom transformer."),(0,n.yg)("p",null,"As an example, suppose we want to append a set of ownership fields to our metadata that are dependent upon an external source \u2013 for instance, an API endpoint or file \u2013 rather than a preset list like above. In this case, we can set a JSON file as an argument to our custom config, and our transformer will read this file and append the included ownership elements to all metadata events."),(0,n.yg)("p",null,"Our JSON file might look like the following:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-json"},'[\n  "urn:li:corpuser:athos",\n  "urn:li:corpuser:porthos",\n  "urn:li:corpuser:aramis",\n  "urn:li:corpGroup:the_three_musketeers"\n]\n')),(0,n.yg)("h3",{id:"defining-a-config"},"Defining a config"),(0,n.yg)("p",null,"To get started, we\u2019ll initiate an ",(0,n.yg)("inlineCode",{parentName:"p"},"AddCustomOwnershipConfig")," class that inherits from ",(0,n.yg)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/configuration/common.py"},(0,n.yg)("inlineCode",{parentName:"a"},"datahub.configuration.common.ConfigModel")),". The sole parameter will be an ",(0,n.yg)("inlineCode",{parentName:"p"},"owners_json")," which expects a path to a JSON file containing a list of owner URNs. This will go in a file called ",(0,n.yg)("inlineCode",{parentName:"p"},"custom_transform_example.py"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"from datahub.configuration.common import ConfigModel\n\nclass AddCustomOwnershipConfig(ConfigModel):\n    owners_json: str\n")),(0,n.yg)("h3",{id:"defining-the-transformer"},"Defining the transformer"),(0,n.yg)("p",null,"Next, we\u2019ll define the transformer itself, which must inherit from ",(0,n.yg)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/api/transform.py"},(0,n.yg)("inlineCode",{parentName:"a"},"datahub.ingestion.api.transform.Transformer")),". The framework provides a helper class called ",(0,n.yg)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/transformer/base_transformer.py"},(0,n.yg)("inlineCode",{parentName:"a"},"datahub.ingestion.transformer.base_transformer.BaseTransformer"))," that makes it super-simple to write transformers.\nFirst, let's get all our imports in:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"# append these to the start of custom_transform_example.py\nimport json\nfrom typing import List, Optional\n\nfrom datahub.configuration.common import ConfigModel\nfrom datahub.ingestion.api.common import PipelineContext\nfrom datahub.ingestion.transformer.add_dataset_ownership import Semantics\nfrom datahub.ingestion.transformer.base_transformer import (\n    BaseTransformer,\n    SingleAspectTransformer,\n)\nfrom datahub.metadata.schema_classes import (\n    OwnerClass,\n    OwnershipClass,\n    OwnershipTypeClass,\n)\n\n")),(0,n.yg)("p",null,"Next, let's define the base scaffolding for the class:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# append this to the end of custom_transform_example.py\n\nclass AddCustomOwnership(BaseTransformer, SingleAspectTransformer):\n    """Transformer that adds owners to datasets according to a callback function."""\n\n    # context param to generate run metadata such as a run ID\n    ctx: PipelineContext\n    # as defined in the previous block\n    config: AddCustomOwnershipConfig\n\n    def __init__(self, config: AddCustomOwnershipConfig, ctx: PipelineContext):\n        super().__init__()\n        self.ctx = ctx\n        self.config = config\n\n        with open(self.config.owners_json, "r") as f:\n            raw_owner_urns = json.load(f)\n\n        self.owners = [\n            OwnerClass(owner=owner, type=OwnershipTypeClass.DATAOWNER)\n            for owner in raw_owner_urns\n        ]\n')),(0,n.yg)("p",null,"A transformer must have two functions: a ",(0,n.yg)("inlineCode",{parentName:"p"},"create()")," function for initialization and a ",(0,n.yg)("inlineCode",{parentName:"p"},"transform()")," function for executing the transformation. Transformers that extend ",(0,n.yg)("inlineCode",{parentName:"p"},"BaseTransformer")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"SingleAspectTransformer")," can avoid having to implement the more complex ",(0,n.yg)("inlineCode",{parentName:"p"},"transform")," function and just implement the ",(0,n.yg)("inlineCode",{parentName:"p"},"transform_aspect")," function."),(0,n.yg)("p",null,"Let's begin by adding a ",(0,n.yg)("inlineCode",{parentName:"p"},"create()")," method for parsing our configuration dictionary:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# add this as a function of AddCustomOwnership\n\n@classmethod\ndef create(cls, config_dict: dict, ctx: PipelineContext) -> "AddCustomOwnership":\n    config = AddCustomOwnershipConfig.parse_obj(config_dict)\n    return cls(config, ctx)\n')),(0,n.yg)("p",null,"Next we need to tell the helper classes which entity types and aspect we are interested in transforming. In this case, we want to only process ",(0,n.yg)("inlineCode",{parentName:"p"},"dataset")," entities and transform the ",(0,n.yg)("inlineCode",{parentName:"p"},"ownership")," aspect."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'def entity_types(self) -> List[str]:\n    return ["dataset"]\n\ndef aspect_name(self) -> str:\n    return "ownership"\n')),(0,n.yg)("p",null,"Finally we need to implement the ",(0,n.yg)("inlineCode",{parentName:"p"},"transform_aspect()")," method that does the work of adding our custom ownership classes. This method will be called be the framework with an optional aspect value filled out if the upstream source produced a value for this aspect. The framework takes care of pre-processing both MCE-s and MCP-s so that the ",(0,n.yg)("inlineCode",{parentName:"p"},"transform_aspect()")," function is only called one per entity. Our job is merely to inspect the incoming aspect (or absence) and produce a transformed value for this aspect. Returning ",(0,n.yg)("inlineCode",{parentName:"p"},"None")," from this method will effectively suppress this aspect from being emitted."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"# add this as a function of AddCustomOwnership\n\ndef transform_aspect(  # type: ignore\n    self, entity_urn: str, aspect_name: str, aspect: Optional[OwnershipClass]\n) -> Optional[OwnershipClass]:\n\n    owners_to_add = self.owners\n    assert aspect is None or isinstance(aspect, OwnershipClass)\n\n    if owners_to_add:\n        ownership = (\n            aspect\n            if aspect\n            else OwnershipClass(\n                owners=[],\n            )\n        )\n        ownership.owners.extend(owners_to_add)\n\n    return ownership\n")),(0,n.yg)("h3",{id:"more-sophistication-making-calls-to-datahub-during-transformation"},"More Sophistication: Making calls to DataHub during Transformation"),(0,n.yg)("p",null,"In some advanced cases, you might want to check with DataHub before performing a transformation. A good example for this might be retrieving the current set of owners of a dataset before providing the new set of owners during an ingestion process. To allow transformers to always be able to query the graph, the framework provides them access to the graph through the context object ",(0,n.yg)("inlineCode",{parentName:"p"},"ctx"),". Connectivity to the graph is automatically instantiated anytime the pipeline uses a REST sink. In case you are using the Kafka sink, you can additionally provide access to the graph by configuring it in your pipeline."),(0,n.yg)("p",null,"Here is an example of a recipe that uses Kafka as the sink, but provides access to the graph by explicitly configuring the ",(0,n.yg)("inlineCode",{parentName:"p"},"datahub_api"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: mysql\n  config:\n     # ..source configs\n\nsink:\n  type: datahub-kafka\n  config:\n     connection:\n        bootstrap: localhost:9092\n    schema_registry_url: "http://localhost:8081"\n\ndatahub_api:\n  server: http://localhost:8080\n  # standard configs accepted by datahub rest client ...\n')),(0,n.yg)("h4",{id:"advanced-use-case-patching-owners"},"Advanced Use-Case: Patching Owners"),(0,n.yg)("p",null,"With the above capability, we can now build more powerful transformers that can check with the server-side state before issuing changes in metadata.\ne.g. Here is how the AddDatasetOwnership transformer can now support PATCH semantics by ensuring that it never deletes any owners that are stored on the server."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"def transform_one(self, mce: MetadataChangeEventClass) -> MetadataChangeEventClass:\n    if not isinstance(mce.proposedSnapshot, DatasetSnapshotClass):\n        return mce\n    owners_to_add = self.config.get_owners_to_add(mce.proposedSnapshot)\n    if owners_to_add:\n        ownership = builder.get_or_add_aspect(\n            mce,\n            OwnershipClass(\n                owners=[],\n            ),\n        )\n        ownership.owners.extend(owners_to_add)\n\n        if self.config.semantics == Semantics.PATCH:\n            assert self.ctx.graph\n            patch_ownership = AddDatasetOwnership.get_ownership_to_set(\n                self.ctx.graph, mce.proposedSnapshot.urn, ownership\n            )\n            builder.set_aspect(\n                mce, aspect=patch_ownership, aspect_type=OwnershipClass\n            )\n    return mce\n")),(0,n.yg)("h3",{id:"installing-the-package"},"Installing the package"),(0,n.yg)("p",null,"Now that we've defined the transformer, we need to make it visible to DataHub. The easiest way to do this is to just place it in the same directory as your recipe, in which case the module name is the same as the file \u2013 in this case, ",(0,n.yg)("inlineCode",{parentName:"p"},"custom_transform_example"),"."),(0,n.yg)("details",null,(0,n.yg)("summary",null,"Advanced: Installing as a package and enable discoverability"),"Alternatively, create a `setup.py` in the same directory as our transform script to make it visible globally. After installing this package (e.g. with `python setup.py` or `pip install -e .`), our module will be installed and importable as `custom_transform_example`.",(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'from setuptools import find_packages, setup\n\nsetup(\n    name="custom_transform_example",\n    version="1.0",\n    packages=find_packages(),\n    # if you don\'t already have DataHub installed, add it under install_requires\n    # install_requires=["acryl-datahub"],\n    entry_points={\n        "datahub.ingestion.transformer.plugins": [\n            "custom_transform_example_alias = custom_transform_example:AddCustomOwnership",\n        ],\n    },\n)\n')),(0,n.yg)("p",null,"Additionally, declare the transformer under the ",(0,n.yg)("inlineCode",{parentName:"p"},"entry_points")," variable of the setup script. This enables the transformer to be\nlisted when running ",(0,n.yg)("inlineCode",{parentName:"p"},"datahub check plugins"),", and sets up the transformer's shortened alias for use in recipes.")),(0,n.yg)("h3",{id:"running-the-transform"},"Running the transform"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'transformers:\n  - type: "custom_transform_example_alias"\n    config:\n      owners_json: "<path_to_owners_json>" # the JSON file mentioned at the start\n')),(0,n.yg)("p",null,"After running ",(0,n.yg)("inlineCode",{parentName:"p"},"datahub ingest -c <path_to_recipe>"),", our MCEs will now have the following owners appended:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-json"},'"owners": [\n    {\n        "owner": "urn:li:corpuser:athos",\n        "type": "DATAOWNER",\n        "source": null\n    },\n    {\n        "owner": "urn:li:corpuser:porthos",\n        "type": "DATAOWNER",\n        "source": null\n    },\n    {\n        "owner": "urn:li:corpuser:aramis",\n        "type": "DATAOWNER",\n        "source": null\n    },\n    {\n        "owner": "urn:li:corpGroup:the_three_musketeers",\n        "type": "DATAOWNER",\n        "source": null\n    },\n    // ...and any additional owners\n],\n')),(0,n.yg)("h3",{id:"using-this-in-the-remote-executor-datahub-cloud-only"},"Using this in the remote executor (DataHub Cloud only)"),(0,n.yg)("p",null,"Build the image with your transformer"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"docker build -t acryldata:customtransform1 -f metadata-ingestion/examples/transforms/example.Dockerfile metadata-ingestion/examples/transforms\n")),(0,n.yg)("p",null,"Test it works"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"docker run -it --rm acryldata:customtransform1 bash\n")),(0,n.yg)("p",null,"Inside the docker container"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"source venv/bin/activate\ndatahub ingest -c ./custom_transformer/recipe.dhub.yaml\n")),(0,n.yg)("p",null,"If you use this image for remote executor then you can set ",(0,n.yg)("inlineCode",{parentName:"p"},"file:///datahub-executor/custom_transformer")," as an extra pip dependency to install the transformer in your ingestion."),(0,n.yg)("p",null,"All the files for this tutorial may be found ",(0,n.yg)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/examples/transforms/"},"here"),"."))}y.isMDXComponent=!0}}]);