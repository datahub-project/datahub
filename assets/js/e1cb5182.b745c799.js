"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[86018],{15680:(e,n,a)=>{a.d(n,{xA:()=>s,yg:()=>y});var t=a(96540);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=t.createContext({}),g=function(e){var n=t.useContext(p),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},s=function(e){var n=g(e.components);return t.createElement(p.Provider,{value:n},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},m=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),u=g(a),m=r,y=u["".concat(p,".").concat(m)]||u[m]||d[m]||i;return a?t.createElement(y,l(l({ref:n},s),{},{components:a})):t.createElement(y,l({ref:n},s))}));function y(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=m;var o={};for(var p in n)hasOwnProperty.call(n,p)&&(o[p]=n[p]);o.originalType=e,o[u]="string"==typeof e?e:r,l[1]=o;for(var g=2;g<i;g++)l[g]=a[g];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}m.displayName="MDXCreateElement"},50349:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>p,default:()=>y,frontMatter:()=>o,metadata:()=>g,toc:()=>u});a(96540);var t=a(15680);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))})),e}function l(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}const o={title:"OpenLineage",slug:"/lineage/openlineage",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/lineage/openlineage.md"},p="OpenLineage",g={unversionedId:"docs/lineage/openlineage",id:"docs/lineage/openlineage",title:"OpenLineage",description:"DataHub, now supports OpenLineage integration. With this support, DataHub can ingest and display lineage information from various data processing frameworks, providing users with a comprehensive understanding of their data pipelines.",source:"@site/genDocs/docs/lineage/openlineage.md",sourceDirName:"docs/lineage",slug:"/lineage/openlineage",permalink:"/docs/lineage/openlineage",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/lineage/openlineage.md",tags:[],version:"current",frontMatter:{title:"OpenLineage",slug:"/lineage/openlineage",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/lineage/openlineage.md"},sidebar:"overviewSidebar",previous:{title:"Managing Data Lineage via UI",permalink:"/docs/features/feature-guides/ui-lineage"},next:{title:"Logical Models",permalink:"/docs/features/feature-guides/logical-models/overview"}},s={},u=[{value:"Features",id:"features",level:2},{value:"OpenLineage Support with DataHub",id:"openlineage-support-with-datahub",level:2},{value:"1. REST Endpoint Support",id:"1-rest-endpoint-support",level:3},{value:"How to Use",id:"how-to-use",level:4},{value:"How to set up Airflow",id:"how-to-set-up-airflow",level:5},{value:"How to modify configurations",id:"how-to-modify-configurations",level:4},{value:"DataHub OpenLineage Configuration",id:"datahub-openlineage-configuration",level:5},{value:"Configuration Overview",id:"configuration-overview",level:5},{value:"Environment Variables",id:"environment-variables",level:5},{value:"Usage Examples",id:"usage-examples",level:5},{value:"Known Limitations",id:"known-limitations",level:4},{value:"2. Spark Event Listener Plugin",id:"2-spark-event-listener-plugin",level:3},{value:"How to Use",id:"how-to-use-1",level:4},{value:"References",id:"references",level:2}],d={toc:u},m="wrapper";function y(e){var{components:n}=e,a=l(e,["components"]);return(0,t.yg)(m,i(function(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{},t=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(t=t.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),t.forEach((function(n){r(e,n,a[n])}))}return e}({},d,a),{components:n,mdxType:"MDXLayout"}),(0,t.yg)("h1",{id:"openlineage"},"OpenLineage"),(0,t.yg)("p",null,"DataHub, now supports ",(0,t.yg)("a",{parentName:"p",href:"https://openlineage.io/"},"OpenLineage")," integration. With this support, DataHub can ingest and display lineage information from various data processing frameworks, providing users with a comprehensive understanding of their data pipelines."),(0,t.yg)("h2",{id:"features"},"Features"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},"REST Endpoint Support"),": DataHub now includes a REST endpoint that can understand OpenLineage events. This allows users to send lineage information directly to DataHub, enabling easy integration with various data processing frameworks.")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},(0,t.yg)("strong",{parentName:"p"},(0,t.yg)("a",{parentName:"strong",href:"/docs/metadata-integration/java/acryl-spark-lineage"},"Spark Event Listener Plugin")),": DataHub provides a Spark Event Listener plugin that seamlessly integrates OpenLineage's Spark plugin. This plugin enhances DataHub's OpenLineage support by offering additional features such as PathSpec support, column-level lineage, patch support and more."))),(0,t.yg)("h2",{id:"openlineage-support-with-datahub"},"OpenLineage Support with DataHub"),(0,t.yg)("h3",{id:"1-rest-endpoint-support"},"1. REST Endpoint Support"),(0,t.yg)("p",null,"DataHub's REST endpoint allows users to send OpenLineage events directly to DataHub. This enables easy integration with various data processing frameworks, providing users with a centralized location for viewing and managing data lineage information."),(0,t.yg)("p",null,"With Spark and Airflow we recommend using the Spark Lineage or DataHub's Airflow plugin for tighter integration with DataHub."),(0,t.yg)("h4",{id:"how-to-use"},"How to Use"),(0,t.yg)("p",null,"To send OpenLineage messages to DataHub using the REST endpoint, simply make a POST request to the following endpoint:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre"},"POST GMS_SERVER_HOST:GMS_PORT/openapi/openlineage/api/v1/lineage\n")),(0,t.yg)("p",null,"Include the OpenLineage message in the request body in JSON format."),(0,t.yg)("p",null,"Example:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "eventType": "START",\n  "eventTime": "2020-12-28T19:52:00.001+10:00",\n  "run": {\n    "runId": "d46e465b-d358-4d32-83d4-df660ff614dd"\n  },\n  "job": {\n    "namespace": "workshop",\n    "name": "process_taxes"\n  },\n  "inputs": [\n    {\n      "namespace": "postgres://workshop-db:None",\n      "name": "workshop.public.taxes",\n      "facets": {\n        "dataSource": {\n          "_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.10.0/integration/airflow",\n          "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/DataSourceDatasetFacet",\n          "name": "postgres://workshop-db:None",\n          "uri": "workshop-db"\n        }\n      }\n    }\n  ],\n  "producer": "https://github.com/OpenLineage/OpenLineage/blob/v1-0-0/client"\n}\n')),(0,t.yg)("h5",{id:"how-to-set-up-airflow"},"How to set up Airflow"),(0,t.yg)("p",null,"Follow the Airflow guide to setup the Airflow DAGs to send lineage information to DataHub. The guide can be found ",(0,t.yg)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/guides/user.html"},"here"),".\nThe transport should look like this:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "type": "http",\n  "url": "https://GMS_SERVER_HOST:GMS_PORT/openapi/openlineage/",\n  "endpoint": "api/v1/lineage",\n  "auth": {\n    "type": "api_key",\n    "api_key": "your-datahub-api-key"\n  }\n}\n')),(0,t.yg)("h4",{id:"how-to-modify-configurations"},"How to modify configurations"),(0,t.yg)("p",null,"To modify the configurations for the OpenLineage REST endpoint, you can change it using environment variables. The following configurations are available:"),(0,t.yg)("h5",{id:"datahub-openlineage-configuration"},"DataHub OpenLineage Configuration"),(0,t.yg)("p",null,"This document describes all available configuration options for the DataHub OpenLineage integration, including environment variables, application properties, and their usage."),(0,t.yg)("h5",{id:"configuration-overview"},"Configuration Overview"),(0,t.yg)("p",null,"The DataHub OpenLineage integration can be configured using environment variables, application properties files (",(0,t.yg)("inlineCode",{parentName:"p"},"application.yml")," or ",(0,t.yg)("inlineCode",{parentName:"p"},"application.properties"),"), or JVM system properties. All configuration options are prefixed with ",(0,t.yg)("inlineCode",{parentName:"p"},"datahub.openlineage"),"."),(0,t.yg)("h5",{id:"environment-variables"},"Environment Variables"),(0,t.yg)("table",null,(0,t.yg)("thead",{parentName:"table"},(0,t.yg)("tr",{parentName:"thead"},(0,t.yg)("th",{parentName:"tr",align:null},"Environment Variable"),(0,t.yg)("th",{parentName:"tr",align:null},"Property"),(0,t.yg)("th",{parentName:"tr",align:null},"Type"),(0,t.yg)("th",{parentName:"tr",align:null},"Default"),(0,t.yg)("th",{parentName:"tr",align:null},"Description"))),(0,t.yg)("tbody",{parentName:"table"},(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_ENV")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.env")),(0,t.yg)("td",{parentName:"tr",align:null},"String"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"PROD")),(0,t.yg)("td",{parentName:"tr",align:null},"Environment for DataFlow cluster and Dataset fabricType (see valid values below)")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_ORCHESTRATOR")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.orchestrator")),(0,t.yg)("td",{parentName:"tr",align:null},"String"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"null")),(0,t.yg)("td",{parentName:"tr",align:null},"Orchestrator name for DataFlow entities. When set, takes precedence over processing_engine facet and producer URL")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_PLATFORM_INSTANCE")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.platform-instance")),(0,t.yg)("td",{parentName:"tr",align:null},"String"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"null")),(0,t.yg)("td",{parentName:"tr",align:null},"Override DataFlow cluster (defaults to env if not specified)")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_COMMON_DATASET_ENV")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.common-dataset-env")),(0,t.yg)("td",{parentName:"tr",align:null},"String"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"null")),(0,t.yg)("td",{parentName:"tr",align:null},"Override Dataset environment independently from DataFlow cluster")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_COMMON_DATASET_PLATFORM_INSTANCE")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.common-dataset-platform-instance")),(0,t.yg)("td",{parentName:"tr",align:null},"String"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"null")),(0,t.yg)("td",{parentName:"tr",align:null},"Common platform instance for dataset entities")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_MATERIALIZE_DATASET")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.materialize-dataset")),(0,t.yg)("td",{parentName:"tr",align:null},"Boolean"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"true")),(0,t.yg)("td",{parentName:"tr",align:null},"Whether to materialize dataset entities")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_INCLUDE_SCHEMA_METADATA")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.include-schema-metadata")),(0,t.yg)("td",{parentName:"tr",align:null},"Boolean"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"true")),(0,t.yg)("td",{parentName:"tr",align:null},"Whether to include schema metadata in lineage")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_CAPTURE_COLUMN_LEVEL_LINEAGE")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.capture-column-level-lineage")),(0,t.yg)("td",{parentName:"tr",align:null},"Boolean"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"true")),(0,t.yg)("td",{parentName:"tr",align:null},"Whether to capture column-level lineage information")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_USE_PATCH")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.use-patch")),(0,t.yg)("td",{parentName:"tr",align:null},"Boolean"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"false")),(0,t.yg)("td",{parentName:"tr",align:null},"Whether to use patch operations for lineage/incremental lineage")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"DATAHUB_OPENLINEAGE_FILE_PARTITION_REGEXP_PATTERN")),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"datahub.openlineage.file-partition-regexp-pattern")),(0,t.yg)("td",{parentName:"tr",align:null},"String"),(0,t.yg)("td",{parentName:"tr",align:null},(0,t.yg)("inlineCode",{parentName:"td"},"null")),(0,t.yg)("td",{parentName:"tr",align:null},"Regular expression pattern for file partition detection")))),(0,t.yg)("blockquote",null,(0,t.yg)("p",{parentName:"blockquote"},(0,t.yg)("strong",{parentName:"p"},"Valid ",(0,t.yg)("inlineCode",{parentName:"strong"},"env")," values"),": ",(0,t.yg)("inlineCode",{parentName:"p"},"PROD"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"DEV"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"TEST"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"QA"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"UAT"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"EI"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"PRE"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"STG"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"NON_PROD"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"CORP"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"RVW"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"PRD"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"TST"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"SIT"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"SBX"),", ",(0,t.yg)("inlineCode",{parentName:"p"},"SANDBOX")),(0,t.yg)("p",{parentName:"blockquote"},(0,t.yg)("strong",{parentName:"p"},"How ",(0,t.yg)("inlineCode",{parentName:"strong"},"env")," works"),":"),(0,t.yg)("ul",{parentName:"blockquote"},(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"By default"),", ",(0,t.yg)("inlineCode",{parentName:"li"},"env")," sets both the DataFlow cluster and Dataset fabricType for simplicity"),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},"For advanced scenarios"),", use ",(0,t.yg)("inlineCode",{parentName:"li"},"platform-instance")," to override the DataFlow cluster or ",(0,t.yg)("inlineCode",{parentName:"li"},"common-dataset-env")," to override the Dataset environment independently")),(0,t.yg)("p",{parentName:"blockquote"},(0,t.yg)("strong",{parentName:"p"},"Note"),": The ",(0,t.yg)("inlineCode",{parentName:"p"},"env")," property naming matches DataHub SDK conventions where ",(0,t.yg)("inlineCode",{parentName:"p"},"env")," is the user-facing parameter that internally maps to the URN ",(0,t.yg)("inlineCode",{parentName:"p"},"cluster")," field.")),(0,t.yg)("h5",{id:"usage-examples"},"Usage Examples"),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"Setting Environment and Orchestrator")),(0,t.yg)("p",null,(0,t.yg)("em",{parentName:"p"},"Simple Configuration (Recommended):")),(0,t.yg)("p",null,"For most use cases, set ",(0,t.yg)("inlineCode",{parentName:"p"},"env")," to configure both DataFlow and Datasets:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-bash"},'# Development environment - sets DataFlow cluster to "dev" and Dataset fabricType to DEV\nDATAHUB_OPENLINEAGE_ENV=DEV\nDATAHUB_OPENLINEAGE_ORCHESTRATOR=my-orchestrator\n\n# Production environment - sets DataFlow cluster to "prod" and Dataset fabricType to PROD\nDATAHUB_OPENLINEAGE_ENV=PROD\nDATAHUB_OPENLINEAGE_ORCHESTRATOR=dagster\n\n# Staging environment\nDATAHUB_OPENLINEAGE_ENV=STG\nDATAHUB_OPENLINEAGE_ORCHESTRATOR=custom-pipeline\n')),(0,t.yg)("p",null,(0,t.yg)("em",{parentName:"p"},"Advanced Configuration (Multi-Region/Complex Deployments):")),(0,t.yg)("p",null,"Override DataFlow cluster or Dataset environment independently:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-bash"},"# DataFlow in specific regional cluster, but datasets marked as generic PROD\nDATAHUB_OPENLINEAGE_ENV=PROD\nDATAHUB_OPENLINEAGE_PLATFORM_INSTANCE=prod-us-west-2  # DataFlow cluster override\n\n# Test pipeline against DEV data (cross-environment testing)\nDATAHUB_OPENLINEAGE_ENV=PROD                    # DataFlow cluster: prod\nDATAHUB_OPENLINEAGE_COMMON_DATASET_ENV=DEV      # Dataset fabricType: DEV\n\n# Blue-green deployment\nDATAHUB_OPENLINEAGE_ENV=PROD\nDATAHUB_OPENLINEAGE_PLATFORM_INSTANCE=prod-blue  # or prod-green\n")),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"Using Application Properties")),(0,t.yg)("p",null,"Alternatively, configure via ",(0,t.yg)("inlineCode",{parentName:"p"},"application.yml"),":"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-yaml"},"datahub:\n  openlineage:\n    env: PROD\n    orchestrator: my-custom-orchestrator\n    platform-instance: us-west-2\n    capture-column-level-lineage: true\n")),(0,t.yg)("p",null,(0,t.yg)("strong",{parentName:"p"},"Priority Order for Orchestrator Determination")),(0,t.yg)("p",null,"The orchestrator name is determined in the following priority order:"),(0,t.yg)("ol",null,(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("inlineCode",{parentName:"li"},"DATAHUB_OPENLINEAGE_ORCHESTRATOR")," environment variable (highest priority)"),(0,t.yg)("li",{parentName:"ol"},(0,t.yg)("inlineCode",{parentName:"li"},"processing_engine")," facet in the OpenLineage event"),(0,t.yg)("li",{parentName:"ol"},"Parsing the ",(0,t.yg)("inlineCode",{parentName:"li"},"producer")," URL field with known patterns (Airflow, etc.)")),(0,t.yg)("h4",{id:"known-limitations"},"Known Limitations"),(0,t.yg)("p",null,"With Spark and Airflow we recommend using the Spark Lineage or DataHub's Airflow plugin for tighter integration with DataHub."),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("strong",{parentName:"li"},(0,t.yg)("a",{parentName:"strong",href:"/docs/metadata-integration/java/acryl-spark-lineage/#configuring-hdfs-based-dataset-urns"},"PathSpec")," Support"),": While the REST endpoint supports OpenLineage messages, full ",(0,t.yg)("a",{parentName:"li",href:"/docs/metadata-integration/java/acryl-spark-lineage/#configuring-hdfs-based-dataset-urns"},"PathSpec"),") support is not yet available in the OpenLineage endpoint but it is available in the DataHub Cloud Spark Plugin.")),(0,t.yg)("p",null,"etc..."),(0,t.yg)("h3",{id:"2-spark-event-listener-plugin"},"2. Spark Event Listener Plugin"),(0,t.yg)("p",null,"DataHub's Spark Event Listener plugin enhances OpenLineage support by providing additional features such as PathSpec support, column-level lineage, and more."),(0,t.yg)("h4",{id:"how-to-use-1"},"How to Use"),(0,t.yg)("p",null,"Follow the guides of the Spark Lineage plugin page for more information on how to set up the Spark Lineage plugin. The guide can be found ",(0,t.yg)("a",{parentName:"p",href:"/docs/metadata-integration/java/acryl-spark-lineage"},"here")),(0,t.yg)("h2",{id:"references"},"References"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("a",{parentName:"li",href:"https://openlineage.io/"},"OpenLineage")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("a",{parentName:"li",href:"/docs/api/openapi/openapi-usage-guide"},"DataHub OpenAPI Guide")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("a",{parentName:"li",href:"/docs/metadata-integration/java/acryl-spark-lineage"},"DataHub Spark Lineage Plugin"))))}y.isMDXComponent=!0}}]);