"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[42179],{7756:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>m,contentTitle:()=>d,default:()=>f,frontMatter:()=>p,metadata:()=>g,toc:()=>c});t(96540);var n=t(15680),l=t(53720),i=t(5400);function s(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){return a=null!=a?a:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):function(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))})),e}function o(e,a){if(null==e)return{};var t,n,l=function(e,a){if(null==e)return{};var t,n,l={},i=Object.keys(e);for(n=0;n<i.length;n++)t=i[n],a.indexOf(t)>=0||(l[t]=e[t]);return l}(e,a);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)t=i[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(l[t]=e[t])}return l}const p={sidebar_position:13,title:"Databricks",slug:"/generated/ingestion/sources/databricks",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/databricks.md"},d="Databricks",g={unversionedId:"docs/generated/ingestion/sources/databricks",id:"docs/generated/ingestion/sources/databricks",title:"Databricks",description:"DataHub supports integration with Databricks ecosystem using a multitude of connectors, depending on your exact setup.",source:"@site/genDocs/docs/generated/ingestion/sources/databricks.md",sourceDirName:"docs/generated/ingestion/sources",slug:"/generated/ingestion/sources/databricks",permalink:"/docs/generated/ingestion/sources/databricks",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/databricks.md",tags:[],version:"current",sidebarPosition:13,frontMatter:{sidebar_position:13,title:"Databricks",slug:"/generated/ingestion/sources/databricks",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/databricks.md"},sidebar:"overviewSidebar",previous:{title:"CSV Enricher",permalink:"/docs/generated/ingestion/sources/csv-enricher"},next:{title:"DataHub",permalink:"/docs/generated/ingestion/sources/datahub"}},m={},c=[{value:"Databricks Unity Catalog (new)",id:"databricks-unity-catalog-new",level:2},{value:"Databricks Hive (old)",id:"databricks-hive-old",level:2},{value:"Databricks Spark",id:"databricks-spark",level:2},{value:"Watch the DataHub Talk at the Data and AI Summit 2022",id:"watch-the-datahub-talk-at-the-data-and-ai-summit-2022",level:2},{value:"Important Capabilities",id:"important-capabilities",level:3},{value:"Prerequisities",id:"prerequisities",level:3},{value:"Authentication Options",id:"authentication-options",level:4},{value:"Provision your service account:",id:"provision-your-service-account",level:4},{value:"CLI based Ingestion",id:"cli-based-ingestion",level:3},{value:"Starter Recipe",id:"starter-recipe",level:3},{value:"Config Details",id:"config-details",level:3},{value:"Advanced",id:"advanced",level:3},{value:"Multiple Databricks Workspaces",id:"multiple-databricks-workspaces",level:4},{value:"Troubleshooting",id:"troubleshooting",level:3},{value:"No data lineage captured or missing lineage",id:"no-data-lineage-captured-or-missing-lineage",level:4},{value:"Lineage extraction is too slow",id:"lineage-extraction-is-too-slow",level:4},{value:"Code Coordinates",id:"code-coordinates",level:3}],y={toc:c},u="wrapper";function f(e){var{components:a}=e,t=o(e,["components"]);return(0,n.yg)(u,r(function(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{},n=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),n.forEach((function(a){s(e,a,t[a])}))}return e}({},y,t),{components:a,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"databricks"},"Databricks"),(0,n.yg)("p",null,"DataHub supports integration with Databricks ecosystem using a multitude of connectors, depending on your exact setup."),(0,n.yg)("h2",{id:"databricks-unity-catalog-new"},"Databricks Unity Catalog (new)"),(0,n.yg)("p",null,"The recently introduced ",(0,n.yg)("a",{parentName:"p",href:"https://www.databricks.com/product/unity-catalog"},"Unity Catalog")," provides a new way to govern your assets within the Databricks lakehouse. If you have Unity Catalog Enabled Workspace, you can use the ",(0,n.yg)("inlineCode",{parentName:"p"},"databricks")," source (aka ",(0,n.yg)("inlineCode",{parentName:"p"},"unity-catalog")," source, see below for details) to integrate your metadata into DataHub as an alternate to the Hive pathway. This also ingests hive metastore catalog in Databricks and is recommended approach to ingest Databricks ecosystem in DataHub."),(0,n.yg)("h2",{id:"databricks-hive-old"},"Databricks Hive (old)"),(0,n.yg)("p",null,"The alternative way to integrate is via the Hive connector. The ",(0,n.yg)("a",{parentName:"p",href:"http://datahubproject.io/docs/generated/ingestion/sources/hive#starter-recipe"},"Hive starter recipe")," has a section describing how to connect to your Databricks workspace."),(0,n.yg)("h2",{id:"databricks-spark"},"Databricks Spark"),(0,n.yg)("p",null,"To complete the picture, we recommend adding push-based ingestion from your Spark jobs to see real-time activity and lineage between your Databricks tables and your Spark jobs. Use the Spark agent to push metadata to DataHub using the instructions ",(0,n.yg)("a",{parentName:"p",href:"/docs/metadata-integration/java/acryl-spark-lineage#configuration-instructions-databricks"},"here"),"."),(0,n.yg)("h2",{id:"watch-the-datahub-talk-at-the-data-and-ai-summit-2022"},"Watch the DataHub Talk at the Data and AI Summit 2022"),(0,n.yg)("p",null,"For a deeper look at how to think about DataHub within and across your Databricks ecosystem, watch the recording of our talk at the Data and AI Summit 2022."),(0,n.yg)("p",{align:"center"},(0,n.yg)("a",{href:"https://www.youtube.com/watch?v=SCP0PR3t7dc"},(0,n.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/metadata-ingestion/databricks/data_and_ai_summit_2022.png"}))),"![Certified](https://img.shields.io/badge/support%20status-certified-brightgreen)",(0,n.yg)("h3",{id:"important-capabilities"},"Important Capabilities"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Capability"),(0,n.yg)("th",{parentName:"tr",align:null},"Status"),(0,n.yg)("th",{parentName:"tr",align:null},"Notes"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Asset Containers"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default. Supported for types - Catalog, Schema.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Column-level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/sql_profiles"},"Data Profiling")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Supported via the ",(0,n.yg)("inlineCode",{parentName:"td"},"profiling.enabled")," config.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Dataset Usage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Descriptions"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/stateful#stale-entity-removal"},"Detect Deleted Entities")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default via stateful ingestion.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/domains"},"Domains")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Supported via the ",(0,n.yg)("inlineCode",{parentName:"td"},"domain")," config field.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Extract Ownership"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Supported via the ",(0,n.yg)("inlineCode",{parentName:"td"},"include_ownership")," config.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/platform-instances"},"Platform Instance")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Schema Metadata"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Table-Level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Test Connection"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")))),(0,n.yg)("p",null,"This plugin extracts the following metadata from Databricks Unity Catalog:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"metastores"),(0,n.yg)("li",{parentName:"ul"},"schemas"),(0,n.yg)("li",{parentName:"ul"},"tables and column lineage"),(0,n.yg)("li",{parentName:"ul"},"model and model versions")),(0,n.yg)("h3",{id:"prerequisities"},"Prerequisities"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Get your Databricks instance's ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/workspace/workspace-details.html#workspace-instance-names-urls-and-ids"},"workspace url")),(0,n.yg)("li",{parentName:"ul"},"Create a ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/administration-guide/users-groups/service-principals.html#what-is-a-service-principal"},"Databricks Service Principal"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"You can skip this step and use your own account to get things running quickly,\nbut we strongly recommend creating a dedicated service principal for production use.")))),(0,n.yg)("h4",{id:"authentication-options"},"Authentication Options"),(0,n.yg)("p",null,"You can authenticate with Databricks using OAuth, Azure authentication, a Personal Access Token (legacy), or Databricks unified authentication:"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Option 1: OAuth")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Generate a Databricks OAuth secret using the following guide:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/aws/en/dev-tools/auth/oauth-m2m#oauth-m2m-manual"},"Authorize service principal access to Databricks with OAuth"))))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Option 2: Azure Authentication (for Azure Databricks)")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Create an Azure Active Directory application:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"Follow the ",(0,n.yg)("a",{parentName:"li",href:"https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app"},"Azure AD app registration guide")),(0,n.yg)("li",{parentName:"ul"},"Note down the ",(0,n.yg)("inlineCode",{parentName:"li"},"client_id")," (Application ID), ",(0,n.yg)("inlineCode",{parentName:"li"},"tenant_id")," (Directory ID), and create a ",(0,n.yg)("inlineCode",{parentName:"li"},"client_secret")))),(0,n.yg)("li",{parentName:"ul"},"Grant the Azure AD application access to your Databricks workspace:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"Add the service principal to your Databricks workspace following ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/administration-guide/users-groups/service-principals.html#add-a-service-principal-to-your-azure-databricks-account-using-the-account-console"},"this guide"))))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Option 3: Personal Access Token (PAT) (legacy)")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Generate a Databricks Personal Access token following the following guides:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/administration-guide/users-groups/service-principals.html#personal-access-tokens"},"Service Principals")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/dev-tools/auth.html#databricks-personal-access-tokens"},"Personal Access Tokens"))))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Option 4: Unified authentication")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Set authentication configuration via environment variables or Databricks configuration profiles, as specified in the ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/aws/en/dev-tools/auth/unified-auth"},"Databricks unified authentication guide"),".")),(0,n.yg)("h4",{id:"provision-your-service-account"},"Provision your service account:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"To ingest your workspace's metadata and lineage, your service principal must have all of the following:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"One of: metastore admin role, ownership of, or ",(0,n.yg)("inlineCode",{parentName:"li"},"USE CATALOG")," privilege on any catalogs you want to ingest"),(0,n.yg)("li",{parentName:"ul"},"One of: metastore admin role, ownership of, or ",(0,n.yg)("inlineCode",{parentName:"li"},"USE SCHEMA")," privilege on any schemas you want to ingest"),(0,n.yg)("li",{parentName:"ul"},"Ownership of or ",(0,n.yg)("inlineCode",{parentName:"li"},"SELECT")," privilege on any tables and views you want to ingest"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/data-governance/unity-catalog/manage-privileges/ownership.html"},"Ownership documentation")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/data-governance/unity-catalog/manage-privileges/privileges.html"},"Privileges documentation")))),(0,n.yg)("li",{parentName:"ul"},"To ingest legacy hive_metastore catalog (",(0,n.yg)("inlineCode",{parentName:"li"},"include_hive_metastore")," - enabled by default), your service principal must have all of the following:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"READ_METADATA")," and ",(0,n.yg)("inlineCode",{parentName:"li"},"USAGE")," privilege on ",(0,n.yg)("inlineCode",{parentName:"li"},"hive_metastore")," catalog"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"READ_METADATA")," and ",(0,n.yg)("inlineCode",{parentName:"li"},"USAGE")," privilege on schemas you want to ingest"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"READ_METADATA")," and ",(0,n.yg)("inlineCode",{parentName:"li"},"USAGE")," privilege on tables and views you want to ingest"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/en/sql/language-manual/sql-ref-privileges-hms.html"},"Hive Metastore Privileges documentation")))),(0,n.yg)("li",{parentName:"ul"},"To ingest your workspace's notebooks and respective lineage, your service principal must have ",(0,n.yg)("inlineCode",{parentName:"li"},"CAN_READ")," privileges on the folders containing the notebooks you want to ingest: ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/en/security/auth-authz/access-control/workspace-acl.html#folder-permissions"},"guide"),"."),(0,n.yg)("li",{parentName:"ul"},"To ",(0,n.yg)("inlineCode",{parentName:"li"},"include_usage_statistics")," (enabled by default), your service principal must have one of the following:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"CAN_MANAGE")," permissions on any SQL Warehouses you want to ingest: ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/security/auth-authz/access-control/sql-endpoint-acl.html"},"guide"),"."),(0,n.yg)("li",{parentName:"ul"},"When ",(0,n.yg)("inlineCode",{parentName:"li"},"usage_data_source")," is set to ",(0,n.yg)("inlineCode",{parentName:"li"},"SYSTEM_TABLES")," or ",(0,n.yg)("inlineCode",{parentName:"li"},"AUTO")," (default) with ",(0,n.yg)("inlineCode",{parentName:"li"},"warehouse_id")," configured: ",(0,n.yg)("inlineCode",{parentName:"li"},"SELECT")," privilege on ",(0,n.yg)("inlineCode",{parentName:"li"},"system.query.history")," table for improved performance with large query volumes and multi-workspace setups."))),(0,n.yg)("li",{parentName:"ul"},"To ingest ",(0,n.yg)("inlineCode",{parentName:"li"},"profiling")," information with ",(0,n.yg)("inlineCode",{parentName:"li"},"method: ge"),", you need ",(0,n.yg)("inlineCode",{parentName:"li"},"SELECT")," privileges on all profiled tables."),(0,n.yg)("li",{parentName:"ul"},"To ingest ",(0,n.yg)("inlineCode",{parentName:"li"},"profiling")," information with ",(0,n.yg)("inlineCode",{parentName:"li"},"method: analyze")," and ",(0,n.yg)("inlineCode",{parentName:"li"},"call_analyze: true")," (enabled by default), your service principal must have ownership or ",(0,n.yg)("inlineCode",{parentName:"li"},"MODIFY")," privilege on any tables you want to profile.",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"Alternatively, you can run ",(0,n.yg)("a",{parentName:"li",href:"https://docs.databricks.com/sql/language-manual/sql-ref-syntax-aux-analyze-table.html"},"ANALYZE TABLE")," yourself on any tables you want to profile, then set ",(0,n.yg)("inlineCode",{parentName:"li"},"call_analyze")," to ",(0,n.yg)("inlineCode",{parentName:"li"},"false"),".\nYou will still need ",(0,n.yg)("inlineCode",{parentName:"li"},"SELECT")," privilege on those tables to fetch the results."))),(0,n.yg)("li",{parentName:"ul"},"Check the starter recipe below and replace ",(0,n.yg)("inlineCode",{parentName:"li"},"workspace_url")," and either ",(0,n.yg)("inlineCode",{parentName:"li"},"token")," (for PAT authentication) or ",(0,n.yg)("inlineCode",{parentName:"li"},"azure_auth")," credentials (for Azure authentication) with your information from the previous steps.")),(0,n.yg)("h3",{id:"cli-based-ingestion"},"CLI based Ingestion"),(0,n.yg)("h3",{id:"starter-recipe"},"Starter Recipe"),(0,n.yg)("p",null,"Check out the following recipe to get started with ingestion! See ",(0,n.yg)("a",{parentName:"p",href:"#config-details"},"below")," for full configuration options."),(0,n.yg)("p",null,"For general pointers on writing and running a recipe, see our ",(0,n.yg)("a",{parentName:"p",href:"/docs/metadata-ingestion#recipes"},"main recipe guide"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: databricks\n  config:\n    workspace_url: https://my-workspace.cloud.databricks.com\n    \n    # Authentication Option 1: OAuth\n    client_id: "<client_id>"\n    client_secret: "<client_secret>"\n    \n    # Authentication Option 2: Azure Authentication (for Azure Databricks)\n    # Uncomment the following section and comment out the token above to use Azure auth\n    # azure_auth:\n    #   client_id: "<azure_client_id>"\n    #   tenant_id: "<azure_tenant_id>" \n    #   client_secret: "<azure_client_secret>"\n\n    # Authentication Option 3: Personal Access Token\n    # Uncomment the following section and comment out client_id/client_secret above\n    # token: "<token>"\n\n    # Authentication Option 4: Databricks unified auth\n    # Comment out client_id/client_secret above to use Databricks unified auth (reads environment variables\n    # and local Databricks configuration profiles)\n\n    include_metastore: false\n    include_ownership: true\n    include_ml_model_aliases: false\n    ml_model_max_results: 1000\n    profiling:\n      method: "ge"\n      enabled: true\n      warehouse_id: "<warehouse_id>"\n      profile_table_level_only: false\n      max_wait_secs: 60\n      pattern:\n        deny:\n          - ".*\\\\.unwanted_schema"\n\n#    emit_siblings: true\n#    delta_lake_options:\n#      platform_instance_name: null\n#      env: \'PROD\'\n\n#    profiling:\n#      method: "analyze"\n#      enabled: true\n#      warehouse_id: "<warehouse_id>"\n#      profile_table_level_only: true\n#      call_analyze: true\n\n#    catalogs: ["my_catalog"]\n#    schema_pattern:\n#      deny:\n#        - information_schema\n#    table_pattern:\n#      allow:\n#        - my_catalog.my_schema.my_table\n#     First you have to create domains on Datahub by following this guide -> https://docs.datahub.com/docs/domains/#domains-setup-prerequisites-and-permissions\n#    domain:\n#      urn:li:domain:1111-222-333-444-555:\n#        allow:\n#          - main.*\n\n    stateful_ingestion:\n      enabled: true\n\npipeline_name: acme-corp-unity\n\n\n# sink configs if needed\n\n')),(0,n.yg)("h3",{id:"config-details"},"Config Details"),(0,n.yg)(l.A,{mdxType:"Tabs"},(0,n.yg)(i.A,{value:"options",label:"Options",default:!0,mdxType:"TabItem"},(0,n.yg)("p",null,"Note that a ",(0,n.yg)("inlineCode",{parentName:"p"},".")," is used to denote nested fields in the YAML recipe."),(0,n.yg)("div",{className:"config-table"},(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:"left"},"Field"),(0,n.yg)("th",{parentName:"tr",align:"left"},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"workspace_url"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Databricks workspace url. e.g. ",(0,n.yg)("a",{parentName:"td",href:"https://my-workspace.cloud.databricks.com"},"https://my-workspace.cloud.databricks.com"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"bucket_duration"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "DAY", "HOUR"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"client_id"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Databricks service principal client ID ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"client_secret"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string(password), null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Databricks service principal client secret ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"column_lineage_column_limit"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Limit the number of columns to get column level lineage.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"300")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"convert_urns_to_lowercase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to convert dataset urns to lowercase. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"databricks_api_page_size"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Page size for Databricks API calls when listing resources (catalogs, schemas, tables, etc.). When set to 0 (default), uses server-side configured page length (recommended). When set to a positive value, the page length is the minimum of this value and the server configured value. Must be a non-negative integer. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"0")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"emit_siblings"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to emit siblings relation with corresponding delta-lake platform's table. If enabled, this will also ingest the corresponding delta-lake table. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_stateful_profiling"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Enable stateful profiling. This will store profiling timestamps per dataset after successful profiling. and will not run profiling again in subsequent run if table has not been updated.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"end_time"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string(date-time)"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Latest date of lineage/usage to consider. Default: Current time in UTC")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"extra_client_options"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Additional options to pass to Databricks SQLAlchemy client. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"format_sql_queries"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to format sql queries ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"ignore_start_time_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to ignore the start_time and retrieve all available lineage. When enabled, the start_time filter will be set to zero to extract all lineage events regardless of the configured time window. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_column_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to enable/disable lineage generation. Currently we have to call a rest call per column to get column level lineage due to the Databrick api which can slow down ingestion.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_external_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to enable/disable lineage generation for external tables. Only external S3 tables are supported at the moment. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_hive_metastore"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ingest legacy ",(0,n.yg)("inlineCode",{parentName:"td"},"hive_metastore")," catalog. This requires executing queries on SQL warehouse. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_metastore"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ingest the workspace's metastore as a container and include it in all urns. Changing this will affect the urns of all entities in the workspace. This config is deprecated and will be removed in the future, so it is recommended to not set this to ",(0,n.yg)("inlineCode",{parentName:"td"},"True")," for new ingestions. If you have an existing unity catalog ingestion, you'll want to avoid duplicates by soft deleting existing data. If stateful ingestion is enabled, running with ",(0,n.yg)("inlineCode",{parentName:"td"},"include_metastore: false")," should be sufficient. Otherwise, we recommend deleting via the cli: ",(0,n.yg)("inlineCode",{parentName:"td"},"datahub delete --platform databricks")," and re-ingesting with ",(0,n.yg)("inlineCode",{parentName:"td"},"include_metastore: false"),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_ml_model_aliases"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to include ML model aliases in the ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_notebooks"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Ingest notebooks, represented as DataHub datasets. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_operational_stats"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to display operational stats. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_ownership"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to enable/disable ownership generation for metastores, catalogs, schemas, and tables. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_read_operational_stats"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to report read operational stats. Experimental. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_table_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to enable/disable lineage generation. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_table_location_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"If the source supports it, include table lineage to the underlying storage location. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_tables"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether tables should be ingested. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_tags"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to enable/disable column/table tag extraction. Requires warehouse_id to be set since tag extraction needs to query system.information_schema.tags. If warehouse_id is not provided, this will be automatically disabled to allow ingestion to continue. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_top_n_queries"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ingest the top_n_queries. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_usage_statistics"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Generate usage statistics. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_view_column_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Populates column-level lineage for  view->view and table->view lineage using DataHub's sql parser. Requires ",(0,n.yg)("inlineCode",{parentName:"td"},"include_view_lineage")," to be enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_view_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Populates view->view and table->view lineage using DataHub's sql parser. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_views"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether views should be ingested. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"incremental_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, emits lineage as incremental to existing lineage already in DataHub. When disabled, re-states lineage on each run. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"ingest_data_platform_instance_aspect"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Option to enable/disable ingestion of the data platform instance aspect. The default data platform instance id for a dataset is workspace_name ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"lineage_data_source"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "AUTO", "SYSTEM_TABLES", "API"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"ml_model_max_results"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Maximum number of ML models to ingest. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"1000")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"options"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Any options specified here will be passed to ",(0,n.yg)("a",{parentName:"td",href:"https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine"},"SQLAlchemy.create_engine")," as kwargs.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"platform_instance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.datahub.com/docs/platform-instances/"},"https://docs.datahub.com/docs/platform-instances/")," for more details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"scheme"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"default-line "},"Default: ",(0,n.yg)("span",{className:"default-value"},"databricks")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"start_time"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string(date-time)"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Earliest date of lineage/usage to consider. Default: Last full day in UTC (or hour, depending on ",(0,n.yg)("inlineCode",{parentName:"td"},"bucket_duration"),"). You can also specify relative time with respect to end_time such as '-7 days' Or '-7d'. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"token"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string(password), null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Databricks personal access token ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"top_n_queries"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number of top queries to save to each table. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"10")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"usage_data_source"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "AUTO", "SYSTEM_TABLES", "API"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"use_file_backed_cache"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to use a file backed cache for the view definitions. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"warehouse_id"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"SQL Warehouse id, for running queries. Must be explicitly provided to enable SQL-based features. Required for the following features that need SQL access: 1) Tag extraction (include_tags=True) - queries system.information_schema.tags 2) Hive Metastore catalog (include_hive_metastore=True) - queries legacy hive_metastore catalog 3) System table lineage (lineage_data_source=SYSTEM_TABLES) - queries system.access.table_lineage/column_lineage 4) Data profiling (profiling.enabled=True) - runs SELECT/ANALYZE queries on tables. When warehouse_id is missing, these features will be automatically disabled (with warnings) to allow ingestion to continue. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"workspace_name"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Name of the workspace. Default to deployment name present in workspace_url ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"env"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The environment that all assets produced by this connector belong to ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PROD")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"azure_auth"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of AzureAuthConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Azure configuration ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"azure_auth."),(0,n.yg)("span",{className:"path-main"},"client_id"),"\xa0",(0,n.yg)("abbr",{title:"Required if azure_auth is set"},"\u2753"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Azure application (client) ID. This is the unique identifier for the registered Azure AD application.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"azure_auth."),(0,n.yg)("span",{className:"path-main"},"client_secret"),"\xa0",(0,n.yg)("abbr",{title:"Required if azure_auth is set"},"\u2753"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string(password)"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Azure application client secret used for authentication. This is a confidential credential that should be kept secure.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"azure_auth."),(0,n.yg)("span",{className:"path-main"},"tenant_id"),"\xa0",(0,n.yg)("abbr",{title:"Required if azure_auth is set"},"\u2753"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Azure tenant (directory) ID. This identifies the Azure AD tenant where the application is registered.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"catalog_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"catalog_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"catalogs"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of array, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Fixed list of catalogs to ingest. If not specified, catalogs will be ingested based on ",(0,n.yg)("inlineCode",{parentName:"td"},"catalog_pattern"),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"catalogs."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"delta_lake_options"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"DeltaLakeDetails"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"delta_lake_options."),(0,n.yg)("span",{className:"path-main"},"platform_instance_name"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Delta-lake paltform instance name ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"delta_lake_options."),(0,n.yg)("span",{className:"path-main"},"env"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Delta-lake environment ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PROD")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"domain"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"map(str,AllowDenyPattern)"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),"."),(0,n.yg)("span",{className:"path-main"},"allow"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"List of regex patterns to include in ingestion ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","'",".","*","'","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),".allow."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),"."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),"."),(0,n.yg)("span",{className:"path-main"},"deny"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"List of regex patterns to exclude from ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"domain.",(0,n.yg)("inlineCode",{parentName:"td"},"key"),".deny."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"notebook_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"notebook_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"profile_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profile_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"schema_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"schema_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"table_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"table_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"user_email_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"user_email_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"view_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"view_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"classification"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"ClassificationConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether classification should be used to auto-detect glossary terms ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"info_type_to_term"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"map(str,string)"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"max_workers"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number of worker processes to use for classification. Set to 1 to disable. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"4")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"sample_size"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number of sample values used for classification. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"100")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"classifiers"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Classifiers to use to auto-detect glossary terms. If more than one classifier, infotype predictions from the classifier defined later in sequence take precedance. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","{","'","type","'",": ","'","datahub","'",", ","'","config","'",": None","}","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification.classifiers."),(0,n.yg)("span",{className:"path-main"},"DynamicTypedClassifierConfig"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"DynamicTypedClassifierConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification.classifiers.DynamicTypedClassifierConfig."),(0,n.yg)("span",{className:"path-main"},"type"),"\xa0",(0,n.yg)("abbr",{title:"Required if DynamicTypedClassifierConfig is set"},"\u2753"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The type of the classifier to use. For DataHub,  use ",(0,n.yg)("inlineCode",{parentName:"td"},"datahub"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification.classifiers.DynamicTypedClassifierConfig."),(0,n.yg)("span",{className:"path-main"},"config"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of object, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The configuration required for initializing the classifier. If not specified, uses defaults for classifer type. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"column_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification.column_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification."),(0,n.yg)("span",{className:"path-main"},"table_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"classification.table_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"profiling"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of UnityCatalogGEProfilerConfig, UnityCatalogAnalyzeProfilerConfig, UnityCatalogSQLAlchemyProfilerConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Data profiling configuration ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","'","method","'",": ","'","ge","'",", ","'","enabled","'",": False, ","'","operation","_","conf...")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"call_analyze"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to call ANALYZE TABLE as part of profile ingestion.If false, will ingest the results of the most recent ANALYZE TABLE call, if any. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"catch_exceptions"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"default-line "},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether profiling should be done. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"field_sample_values_limit"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Upper limit for number of sample values to collect for all columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"20")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_distinct_count"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the number of distinct values for each column. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_distinct_value_frequencies"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for distinct value frequencies. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_histogram"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the histogram for numeric fields. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_max_value"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the max value of numeric columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_mean_value"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the mean value of numeric columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_median_value"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the median value of numeric columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_min_value"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the min value of numeric columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_null_count"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the number of nulls for each column. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_quantiles"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the quantiles of numeric columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_sample_values"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the sample values for all columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"include_field_stddev_value"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile for the standard deviation of numeric columns. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"limit"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Max number of documents to profile. By default, profiles all documents. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"max_number_of_fields_to_profile"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A positive integer that specifies the maximum number of columns to profile for any table. ",(0,n.yg)("inlineCode",{parentName:"td"},"None")," implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"max_wait_secs"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, integer, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Maximum time to wait for a table to be profiled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"max_workers"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number of worker threads to use for profiling. Set to 1 to disable. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"20")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"method"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Const value: ge ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"ge")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"offset"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Offset in documents to profile. By default, uses no offset. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"partition_datetime"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string(date-time), null, union(anyOf), string(date-time), null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"If specified, profile only the partition which matches this datetime. If not specified, profile the latest partition. Only Bigquery supports this. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"partition_profiling_enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile partitioned tables. Only BigQuery and Aws Athena supports this. If enabled, latest partition data is used for profiling. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_external_tables"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile external tables. Only Snowflake and Redshift supports this. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_if_updated_since_days"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of number, null, union(anyOf), number, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Profile table only if it has been updated since these many number of days. If set to ",(0,n.yg)("inlineCode",{parentName:"td"},"null"),", no constraint of last modified time for tables to profile. Supported only in ",(0,n.yg)("inlineCode",{parentName:"td"},"snowflake")," and ",(0,n.yg)("inlineCode",{parentName:"td"},"BigQuery"),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_nested_fields"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile complex types like structs, arrays and maps.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_table_level_only"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to perform profiling at table-level only, or include column-level profiling as well. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_table_row_count_estimate_only"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Use an approximate query for row count. This will be much faster but slightly less accurate. Only supported for Postgres and MySQL.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_table_row_limit"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Profile tables only if their row count is less than specified count. If set to ",(0,n.yg)("inlineCode",{parentName:"td"},"null"),", no limit on the row count of tables to profile. Supported only in ",(0,n.yg)("inlineCode",{parentName:"td"},"Snowflake"),", ",(0,n.yg)("inlineCode",{parentName:"td"},"BigQuery"),". Supported for ",(0,n.yg)("inlineCode",{parentName:"td"},"Oracle")," based on gathered stats. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"5000000")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"profile_table_size_limit"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Profile tables only if their size is less than specified GBs. If set to ",(0,n.yg)("inlineCode",{parentName:"td"},"null"),", no limit on the size of tables to profile. Supported only in ",(0,n.yg)("inlineCode",{parentName:"td"},"Snowflake"),", ",(0,n.yg)("inlineCode",{parentName:"td"},"BigQuery")," and ",(0,n.yg)("inlineCode",{parentName:"td"},"Databricks"),". Supported for ",(0,n.yg)("inlineCode",{parentName:"td"},"Oracle")," based on calculated size from gathered stats. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"5")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"query_combiner_enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("em",{parentName:"td"},"This feature is still experimental and can be disabled if it causes issues.")," Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"report_dropped_profiles"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to report datasets or dataset columns which were not profiled. Set to ",(0,n.yg)("inlineCode",{parentName:"td"},"True")," for debugging purposes. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"sample_size"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number of rows to be sampled from table for column level profiling.Applicable only if ",(0,n.yg)("inlineCode",{parentName:"td"},"use_sampling")," is set to True. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"10000")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"turn_off_expensive_profiling_metrics"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"use_sampling"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to profile column level stats on sample of table. Only BigQuery and Snowflake support this. If enabled, profiling is done on rows sampled from table. Sampling is not done for smaller tables.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"warehouse_id"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null, union(anyOf), string, null, union(anyOf), string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"SQL Warehouse id, for running profiling queries. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"operation_config"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of OperationConfig, OperationConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling.operation_config."),(0,n.yg)("span",{className:"path-main"},"lower_freq_profile_enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to do profiling at lower freq or not. This does not do any scheduling just adds additional checks to when not to run profiling. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling.operation_config."),(0,n.yg)("span",{className:"path-main"},"profile_date_of_month"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number between 1 to 31 for date of month (both inclusive). If not specified, defaults to Nothing and this field does not take affect. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling.operation_config."),(0,n.yg)("span",{className:"path-main"},"profile_day_of_week"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null, union(anyOf), integer, null, union(anyOf), integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number between 0 to 6 for day of week (both inclusive). 0 is Monday and 6 is Sunday. If not specified, defaults to Nothing and this field does not take affect. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of AllowDenyPattern, AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling.pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null, union(anyOf), boolean, null, union(anyOf), boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling."),(0,n.yg)("span",{className:"path-main"},"tags_to_ignore_sampling"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of array, null, union(anyOf), array, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Fixed list of tags to ignore sampling. If not specified, tables will be sampled based on ",(0,n.yg)("inlineCode",{parentName:"td"},"use_sampling"),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"profiling.tags_to_ignore_sampling."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"stateful_ingestion"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of StatefulStaleMetadataRemovalConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Unity Catalog Stateful Ingestion Config. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or ",(0,n.yg)("inlineCode",{parentName:"td"},"datahub_api")," is specified, otherwise False ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"fail_safe_threshold"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"number"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the 'fail_safe_threshold'. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"75.0")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"remove_stale_metadata"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))))))),(0,n.yg)(i.A,{value:"schema",label:"Schema",mdxType:"TabItem"},(0,n.yg)("p",null,"The ",(0,n.yg)("a",{parentName:"p",href:"https://json-schema.org/"},"JSONSchema")," for this configuration is inlined below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "$defs": {\n    "AllowDenyPattern": {\n      "additionalProperties": false,\n      "description": "A class to store allow deny regexes",\n      "properties": {\n        "allow": {\n          "default": [\n            ".*"\n          ],\n          "description": "List of regex patterns to include in ingestion",\n          "items": {\n            "type": "string"\n          },\n          "title": "Allow",\n          "type": "array"\n        },\n        "deny": {\n          "default": [],\n          "description": "List of regex patterns to exclude from ingestion.",\n          "items": {\n            "type": "string"\n          },\n          "title": "Deny",\n          "type": "array"\n        },\n        "ignoreCase": {\n          "anyOf": [\n            {\n              "type": "boolean"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": true,\n          "description": "Whether to ignore case sensitivity during pattern matching.",\n          "title": "Ignorecase"\n        }\n      },\n      "title": "AllowDenyPattern",\n      "type": "object"\n    },\n    "AzureAuthConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "client_secret": {\n          "description": "Azure application client secret used for authentication. This is a confidential credential that should be kept secure.",\n          "format": "password",\n          "title": "Client Secret",\n          "type": "string",\n          "writeOnly": true\n        },\n        "client_id": {\n          "description": "Azure application (client) ID. This is the unique identifier for the registered Azure AD application.",\n          "title": "Client Id",\n          "type": "string"\n        },\n        "tenant_id": {\n          "description": "Azure tenant (directory) ID. This identifies the Azure AD tenant where the application is registered.",\n          "title": "Tenant Id",\n          "type": "string"\n        }\n      },\n      "required": [\n        "client_secret",\n        "client_id",\n        "tenant_id"\n      ],\n      "title": "AzureAuthConfig",\n      "type": "object"\n    },\n    "BucketDuration": {\n      "enum": [\n        "DAY",\n        "HOUR"\n      ],\n      "title": "BucketDuration",\n      "type": "string"\n    },\n    "ClassificationConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "enabled": {\n          "default": false,\n          "description": "Whether classification should be used to auto-detect glossary terms",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "sample_size": {\n          "default": 100,\n          "description": "Number of sample values used for classification.",\n          "title": "Sample Size",\n          "type": "integer"\n        },\n        "max_workers": {\n          "default": 4,\n          "description": "Number of worker processes to use for classification. Set to 1 to disable.",\n          "title": "Max Workers",\n          "type": "integer"\n        },\n        "table_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns to filter tables for classification. This is used in combination with other patterns in parent config. Specify regex to match the entire table name in `database.schema.table` format. e.g. to match all tables starting with customer in Customer database and public schema, use the regex \'Customer.public.customer.*\'"\n        },\n        "column_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns to filter columns for classification. This is used in combination with other patterns in parent config. Specify regex to match the column name in `database.schema.table.column` format."\n        },\n        "info_type_to_term": {\n          "additionalProperties": {\n            "type": "string"\n          },\n          "default": {},\n          "description": "Optional mapping to provide glossary term identifier for info type",\n          "title": "Info Type To Term",\n          "type": "object"\n        },\n        "classifiers": {\n          "default": [\n            {\n              "type": "datahub",\n              "config": null\n            }\n          ],\n          "description": "Classifiers to use to auto-detect glossary terms. If more than one classifier, infotype predictions from the classifier defined later in sequence take precedance.",\n          "items": {\n            "$ref": "#/$defs/DynamicTypedClassifierConfig"\n          },\n          "title": "Classifiers",\n          "type": "array"\n        }\n      },\n      "title": "ClassificationConfig",\n      "type": "object"\n    },\n    "DeltaLakeDetails": {\n      "additionalProperties": false,\n      "properties": {\n        "platform_instance_name": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Delta-lake paltform instance name",\n          "title": "Platform Instance Name"\n        },\n        "env": {\n          "default": "PROD",\n          "description": "Delta-lake environment",\n          "title": "Env",\n          "type": "string"\n        }\n      },\n      "title": "DeltaLakeDetails",\n      "type": "object"\n    },\n    "DynamicTypedClassifierConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "type": {\n          "description": "The type of the classifier to use. For DataHub,  use `datahub`",\n          "title": "Type",\n          "type": "string"\n        },\n        "config": {\n          "anyOf": [\n            {},\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "The configuration required for initializing the classifier. If not specified, uses defaults for classifer type.",\n          "title": "Config"\n        }\n      },\n      "required": [\n        "type"\n      ],\n      "title": "DynamicTypedClassifierConfig",\n      "type": "object"\n    },\n    "LineageDataSource": {\n      "enum": [\n        "AUTO",\n        "SYSTEM_TABLES",\n        "API"\n      ],\n      "title": "LineageDataSource",\n      "type": "string"\n    },\n    "OperationConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "lower_freq_profile_enabled": {\n          "default": false,\n          "description": "Whether to do profiling at lower freq or not. This does not do any scheduling just adds additional checks to when not to run profiling.",\n          "title": "Lower Freq Profile Enabled",\n          "type": "boolean"\n        },\n        "profile_day_of_week": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Number between 0 to 6 for day of week (both inclusive). 0 is Monday and 6 is Sunday. If not specified, defaults to Nothing and this field does not take affect.",\n          "title": "Profile Day Of Week"\n        },\n        "profile_date_of_month": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Number between 1 to 31 for date of month (both inclusive). If not specified, defaults to Nothing and this field does not take affect.",\n          "title": "Profile Date Of Month"\n        }\n      },\n      "title": "OperationConfig",\n      "type": "object"\n    },\n    "StatefulStaleMetadataRemovalConfig": {\n      "additionalProperties": false,\n      "description": "Base specialized config for Stateful Ingestion with stale metadata removal capability.",\n      "properties": {\n        "enabled": {\n          "default": false,\n          "description": "Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or `datahub_api` is specified, otherwise False",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "remove_stale_metadata": {\n          "default": true,\n          "description": "Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled.",\n          "title": "Remove Stale Metadata",\n          "type": "boolean"\n        },\n        "fail_safe_threshold": {\n          "default": 75.0,\n          "description": "Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the \'fail_safe_threshold\'.",\n          "maximum": 100.0,\n          "minimum": 0.0,\n          "title": "Fail Safe Threshold",\n          "type": "number"\n        }\n      },\n      "title": "StatefulStaleMetadataRemovalConfig",\n      "type": "object"\n    },\n    "UnityCatalogAnalyzeProfilerConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "method": {\n          "const": "analyze",\n          "default": "analyze",\n          "title": "Method",\n          "type": "string"\n        },\n        "warehouse_id": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "SQL Warehouse id, for running profiling queries.",\n          "title": "Warehouse Id"\n        },\n        "pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns to filter tables for profiling during ingestion. Specify regex to match the `catalog.schema.table` format. Note that only tables allowed by the `table_pattern` will be considered."\n        },\n        "enabled": {\n          "default": false,\n          "description": "Whether profiling should be done.",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "operation_config": {\n          "$ref": "#/$defs/OperationConfig",\n          "description": "Experimental feature. To specify operation configs."\n        },\n        "profile_table_level_only": {\n          "default": false,\n          "description": "Whether to perform profiling at table-level only or include column-level profiling as well.",\n          "title": "Profile Table Level Only",\n          "type": "boolean"\n        },\n        "call_analyze": {\n          "default": true,\n          "description": "Whether to call ANALYZE TABLE as part of profile ingestion.If false, will ingest the results of the most recent ANALYZE TABLE call, if any.",\n          "title": "Call Analyze",\n          "type": "boolean"\n        },\n        "max_wait_secs": {\n          "default": 3600,\n          "description": "Maximum time to wait for an ANALYZE TABLE query to complete.",\n          "title": "Max Wait Secs",\n          "type": "integer"\n        },\n        "max_workers": {\n          "default": 20,\n          "description": "Number of worker threads to use for profiling. Set to 1 to disable.",\n          "title": "Max Workers",\n          "type": "integer"\n        }\n      },\n      "title": "UnityCatalogAnalyzeProfilerConfig",\n      "type": "object"\n    },\n    "UnityCatalogGEProfilerConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "method": {\n          "const": "ge",\n          "default": "ge",\n          "title": "Method",\n          "type": "string"\n        },\n        "enabled": {\n          "default": false,\n          "description": "Whether profiling should be done.",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "operation_config": {\n          "$ref": "#/$defs/OperationConfig",\n          "description": "Experimental feature. To specify operation configs."\n        },\n        "limit": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Max number of documents to profile. By default, profiles all documents.",\n          "title": "Limit"\n        },\n        "offset": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Offset in documents to profile. By default, uses no offset.",\n          "title": "Offset"\n        },\n        "profile_table_level_only": {\n          "default": false,\n          "description": "Whether to perform profiling at table-level only, or include column-level profiling as well.",\n          "title": "Profile Table Level Only",\n          "type": "boolean"\n        },\n        "include_field_null_count": {\n          "default": true,\n          "description": "Whether to profile for the number of nulls for each column.",\n          "title": "Include Field Null Count",\n          "type": "boolean"\n        },\n        "include_field_distinct_count": {\n          "default": true,\n          "description": "Whether to profile for the number of distinct values for each column.",\n          "title": "Include Field Distinct Count",\n          "type": "boolean"\n        },\n        "include_field_min_value": {\n          "default": true,\n          "description": "Whether to profile for the min value of numeric columns.",\n          "title": "Include Field Min Value",\n          "type": "boolean"\n        },\n        "include_field_max_value": {\n          "default": true,\n          "description": "Whether to profile for the max value of numeric columns.",\n          "title": "Include Field Max Value",\n          "type": "boolean"\n        },\n        "include_field_mean_value": {\n          "default": true,\n          "description": "Whether to profile for the mean value of numeric columns.",\n          "title": "Include Field Mean Value",\n          "type": "boolean"\n        },\n        "include_field_median_value": {\n          "default": true,\n          "description": "Whether to profile for the median value of numeric columns.",\n          "title": "Include Field Median Value",\n          "type": "boolean"\n        },\n        "include_field_stddev_value": {\n          "default": true,\n          "description": "Whether to profile for the standard deviation of numeric columns.",\n          "title": "Include Field Stddev Value",\n          "type": "boolean"\n        },\n        "include_field_quantiles": {\n          "default": false,\n          "description": "Whether to profile for the quantiles of numeric columns.",\n          "title": "Include Field Quantiles",\n          "type": "boolean"\n        },\n        "include_field_distinct_value_frequencies": {\n          "default": false,\n          "description": "Whether to profile for distinct value frequencies.",\n          "title": "Include Field Distinct Value Frequencies",\n          "type": "boolean"\n        },\n        "include_field_histogram": {\n          "default": false,\n          "description": "Whether to profile for the histogram for numeric fields.",\n          "title": "Include Field Histogram",\n          "type": "boolean"\n        },\n        "include_field_sample_values": {\n          "default": true,\n          "description": "Whether to profile for the sample values for all columns.",\n          "title": "Include Field Sample Values",\n          "type": "boolean"\n        },\n        "max_workers": {\n          "default": 20,\n          "description": "Number of worker threads to use for profiling. Set to 1 to disable.",\n          "title": "Max Workers",\n          "type": "integer"\n        },\n        "report_dropped_profiles": {\n          "default": false,\n          "description": "Whether to report datasets or dataset columns which were not profiled. Set to `True` for debugging purposes.",\n          "title": "Report Dropped Profiles",\n          "type": "boolean"\n        },\n        "turn_off_expensive_profiling_metrics": {\n          "default": false,\n          "description": "Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10.",\n          "title": "Turn Off Expensive Profiling Metrics",\n          "type": "boolean"\n        },\n        "field_sample_values_limit": {\n          "default": 20,\n          "description": "Upper limit for number of sample values to collect for all columns.",\n          "title": "Field Sample Values Limit",\n          "type": "integer"\n        },\n        "max_number_of_fields_to_profile": {\n          "anyOf": [\n            {\n              "exclusiveMinimum": 0,\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "A positive integer that specifies the maximum number of columns to profile for any table. `None` implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up.",\n          "title": "Max Number Of Fields To Profile"\n        },\n        "profile_if_updated_since_days": {\n          "anyOf": [\n            {\n              "exclusiveMinimum": 0,\n              "type": "number"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Profile table only if it has been updated since these many number of days. If set to `null`, no constraint of last modified time for tables to profile. Supported only in `snowflake` and `BigQuery`.",\n          "schema_extra": {\n            "supported_sources": [\n              "snowflake",\n              "bigquery"\n            ]\n          },\n          "title": "Profile If Updated Since Days"\n        },\n        "profile_table_size_limit": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": 5,\n          "description": "Profile tables only if their size is less than specified GBs. If set to `null`, no limit on the size of tables to profile. Supported only in `Snowflake`, `BigQuery` and `Databricks`. Supported for `Oracle` based on calculated size from gathered stats.",\n          "schema_extra": {\n            "supported_sources": [\n              "snowflake",\n              "bigquery",\n              "unity-catalog",\n              "oracle"\n            ]\n          },\n          "title": "Profile Table Size Limit"\n        },\n        "profile_table_row_limit": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": 5000000,\n          "description": "Profile tables only if their row count is less than specified count. If set to `null`, no limit on the row count of tables to profile. Supported only in `Snowflake`, `BigQuery`. Supported for `Oracle` based on gathered stats.",\n          "schema_extra": {\n            "supported_sources": [\n              "snowflake",\n              "bigquery",\n              "oracle"\n            ]\n          },\n          "title": "Profile Table Row Limit"\n        },\n        "profile_table_row_count_estimate_only": {\n          "default": false,\n          "description": "Use an approximate query for row count. This will be much faster but slightly less accurate. Only supported for Postgres and MySQL. ",\n          "schema_extra": {\n            "supported_sources": [\n              "postgres",\n              "mysql"\n            ]\n          },\n          "title": "Profile Table Row Count Estimate Only",\n          "type": "boolean"\n        },\n        "query_combiner_enabled": {\n          "default": true,\n          "description": "*This feature is still experimental and can be disabled if it causes issues.* Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible.",\n          "title": "Query Combiner Enabled",\n          "type": "boolean"\n        },\n        "catch_exceptions": {\n          "default": true,\n          "description": "",\n          "title": "Catch Exceptions",\n          "type": "boolean"\n        },\n        "partition_profiling_enabled": {\n          "default": true,\n          "description": "Whether to profile partitioned tables. Only BigQuery and Aws Athena supports this. If enabled, latest partition data is used for profiling.",\n          "schema_extra": {\n            "supported_sources": [\n              "athena",\n              "bigquery"\n            ]\n          },\n          "title": "Partition Profiling Enabled",\n          "type": "boolean"\n        },\n        "partition_datetime": {\n          "anyOf": [\n            {\n              "format": "date-time",\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "If specified, profile only the partition which matches this datetime. If not specified, profile the latest partition. Only Bigquery supports this.",\n          "schema_extra": {\n            "supported_sources": [\n              "bigquery"\n            ]\n          },\n          "title": "Partition Datetime"\n        },\n        "use_sampling": {\n          "default": true,\n          "description": "Whether to profile column level stats on sample of table. Only BigQuery and Snowflake support this. If enabled, profiling is done on rows sampled from table. Sampling is not done for smaller tables. ",\n          "schema_extra": {\n            "supported_sources": [\n              "bigquery",\n              "snowflake"\n            ]\n          },\n          "title": "Use Sampling",\n          "type": "boolean"\n        },\n        "sample_size": {\n          "default": 10000,\n          "description": "Number of rows to be sampled from table for column level profiling.Applicable only if `use_sampling` is set to True.",\n          "schema_extra": {\n            "supported_sources": [\n              "bigquery",\n              "snowflake"\n            ]\n          },\n          "title": "Sample Size",\n          "type": "integer"\n        },\n        "profile_external_tables": {\n          "default": false,\n          "description": "Whether to profile external tables. Only Snowflake and Redshift supports this.",\n          "schema_extra": {\n            "supported_sources": [\n              "redshift",\n              "snowflake"\n            ]\n          },\n          "title": "Profile External Tables",\n          "type": "boolean"\n        },\n        "tags_to_ignore_sampling": {\n          "anyOf": [\n            {\n              "items": {\n                "type": "string"\n              },\n              "type": "array"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Fixed list of tags to ignore sampling. If not specified, tables will be sampled based on `use_sampling`.",\n          "title": "Tags To Ignore Sampling"\n        },\n        "profile_nested_fields": {\n          "default": false,\n          "description": "Whether to profile complex types like structs, arrays and maps. ",\n          "title": "Profile Nested Fields",\n          "type": "boolean"\n        },\n        "warehouse_id": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "SQL Warehouse id, for running profiling queries.",\n          "title": "Warehouse Id"\n        },\n        "pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns to filter tables for profiling during ingestion. Specify regex to match the `catalog.schema.table` format. Note that only tables allowed by the `table_pattern` will be considered."\n        },\n        "max_wait_secs": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Maximum time to wait for a table to be profiled.",\n          "title": "Max Wait Secs"\n        }\n      },\n      "title": "UnityCatalogGEProfilerConfig",\n      "type": "object"\n    },\n    "UnityCatalogSQLAlchemyProfilerConfig": {\n      "additionalProperties": false,\n      "properties": {\n        "method": {\n          "const": "sqlalchemy",\n          "default": "sqlalchemy",\n          "title": "Method",\n          "type": "string"\n        },\n        "enabled": {\n          "default": false,\n          "description": "Whether profiling should be done.",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "operation_config": {\n          "$ref": "#/$defs/OperationConfig",\n          "description": "Experimental feature. To specify operation configs."\n        },\n        "limit": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Max number of documents to profile. By default, profiles all documents.",\n          "title": "Limit"\n        },\n        "offset": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Offset in documents to profile. By default, uses no offset.",\n          "title": "Offset"\n        },\n        "profile_table_level_only": {\n          "default": false,\n          "description": "Whether to perform profiling at table-level only, or include column-level profiling as well.",\n          "title": "Profile Table Level Only",\n          "type": "boolean"\n        },\n        "include_field_null_count": {\n          "default": true,\n          "description": "Whether to profile for the number of nulls for each column.",\n          "title": "Include Field Null Count",\n          "type": "boolean"\n        },\n        "include_field_distinct_count": {\n          "default": true,\n          "description": "Whether to profile for the number of distinct values for each column.",\n          "title": "Include Field Distinct Count",\n          "type": "boolean"\n        },\n        "include_field_min_value": {\n          "default": true,\n          "description": "Whether to profile for the min value of numeric columns.",\n          "title": "Include Field Min Value",\n          "type": "boolean"\n        },\n        "include_field_max_value": {\n          "default": true,\n          "description": "Whether to profile for the max value of numeric columns.",\n          "title": "Include Field Max Value",\n          "type": "boolean"\n        },\n        "include_field_mean_value": {\n          "default": true,\n          "description": "Whether to profile for the mean value of numeric columns.",\n          "title": "Include Field Mean Value",\n          "type": "boolean"\n        },\n        "include_field_median_value": {\n          "default": true,\n          "description": "Whether to profile for the median value of numeric columns.",\n          "title": "Include Field Median Value",\n          "type": "boolean"\n        },\n        "include_field_stddev_value": {\n          "default": true,\n          "description": "Whether to profile for the standard deviation of numeric columns.",\n          "title": "Include Field Stddev Value",\n          "type": "boolean"\n        },\n        "include_field_quantiles": {\n          "default": false,\n          "description": "Whether to profile for the quantiles of numeric columns.",\n          "title": "Include Field Quantiles",\n          "type": "boolean"\n        },\n        "include_field_distinct_value_frequencies": {\n          "default": false,\n          "description": "Whether to profile for distinct value frequencies.",\n          "title": "Include Field Distinct Value Frequencies",\n          "type": "boolean"\n        },\n        "include_field_histogram": {\n          "default": false,\n          "description": "Whether to profile for the histogram for numeric fields.",\n          "title": "Include Field Histogram",\n          "type": "boolean"\n        },\n        "include_field_sample_values": {\n          "default": true,\n          "description": "Whether to profile for the sample values for all columns.",\n          "title": "Include Field Sample Values",\n          "type": "boolean"\n        },\n        "max_workers": {\n          "default": 20,\n          "description": "Number of worker threads to use for profiling. Set to 1 to disable.",\n          "title": "Max Workers",\n          "type": "integer"\n        },\n        "report_dropped_profiles": {\n          "default": false,\n          "description": "Whether to report datasets or dataset columns which were not profiled. Set to `True` for debugging purposes.",\n          "title": "Report Dropped Profiles",\n          "type": "boolean"\n        },\n        "turn_off_expensive_profiling_metrics": {\n          "default": false,\n          "description": "Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10.",\n          "title": "Turn Off Expensive Profiling Metrics",\n          "type": "boolean"\n        },\n        "field_sample_values_limit": {\n          "default": 20,\n          "description": "Upper limit for number of sample values to collect for all columns.",\n          "title": "Field Sample Values Limit",\n          "type": "integer"\n        },\n        "max_number_of_fields_to_profile": {\n          "anyOf": [\n            {\n              "exclusiveMinimum": 0,\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "A positive integer that specifies the maximum number of columns to profile for any table. `None` implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up.",\n          "title": "Max Number Of Fields To Profile"\n        },\n        "profile_if_updated_since_days": {\n          "anyOf": [\n            {\n              "exclusiveMinimum": 0,\n              "type": "number"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Profile table only if it has been updated since these many number of days. If set to `null`, no constraint of last modified time for tables to profile. Supported only in `snowflake` and `BigQuery`.",\n          "schema_extra": {\n            "supported_sources": [\n              "snowflake",\n              "bigquery"\n            ]\n          },\n          "title": "Profile If Updated Since Days"\n        },\n        "profile_table_size_limit": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": 5,\n          "description": "Profile tables only if their size is less than specified GBs. If set to `null`, no limit on the size of tables to profile. Supported only in `Snowflake`, `BigQuery` and `Databricks`. Supported for `Oracle` based on calculated size from gathered stats.",\n          "schema_extra": {\n            "supported_sources": [\n              "snowflake",\n              "bigquery",\n              "unity-catalog",\n              "oracle"\n            ]\n          },\n          "title": "Profile Table Size Limit"\n        },\n        "profile_table_row_limit": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": 5000000,\n          "description": "Profile tables only if their row count is less than specified count. If set to `null`, no limit on the row count of tables to profile. Supported only in `Snowflake`, `BigQuery`. Supported for `Oracle` based on gathered stats.",\n          "schema_extra": {\n            "supported_sources": [\n              "snowflake",\n              "bigquery",\n              "oracle"\n            ]\n          },\n          "title": "Profile Table Row Limit"\n        },\n        "profile_table_row_count_estimate_only": {\n          "default": false,\n          "description": "Use an approximate query for row count. This will be much faster but slightly less accurate. Only supported for Postgres and MySQL. ",\n          "schema_extra": {\n            "supported_sources": [\n              "postgres",\n              "mysql"\n            ]\n          },\n          "title": "Profile Table Row Count Estimate Only",\n          "type": "boolean"\n        },\n        "query_combiner_enabled": {\n          "default": true,\n          "description": "*This feature is still experimental and can be disabled if it causes issues.* Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible.",\n          "title": "Query Combiner Enabled",\n          "type": "boolean"\n        },\n        "catch_exceptions": {\n          "default": true,\n          "description": "",\n          "title": "Catch Exceptions",\n          "type": "boolean"\n        },\n        "partition_profiling_enabled": {\n          "default": true,\n          "description": "Whether to profile partitioned tables. Only BigQuery and Aws Athena supports this. If enabled, latest partition data is used for profiling.",\n          "schema_extra": {\n            "supported_sources": [\n              "athena",\n              "bigquery"\n            ]\n          },\n          "title": "Partition Profiling Enabled",\n          "type": "boolean"\n        },\n        "partition_datetime": {\n          "anyOf": [\n            {\n              "format": "date-time",\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "If specified, profile only the partition which matches this datetime. If not specified, profile the latest partition. Only Bigquery supports this.",\n          "schema_extra": {\n            "supported_sources": [\n              "bigquery"\n            ]\n          },\n          "title": "Partition Datetime"\n        },\n        "use_sampling": {\n          "default": true,\n          "description": "Whether to profile column level stats on sample of table. Only BigQuery and Snowflake support this. If enabled, profiling is done on rows sampled from table. Sampling is not done for smaller tables. ",\n          "schema_extra": {\n            "supported_sources": [\n              "bigquery",\n              "snowflake"\n            ]\n          },\n          "title": "Use Sampling",\n          "type": "boolean"\n        },\n        "sample_size": {\n          "default": 10000,\n          "description": "Number of rows to be sampled from table for column level profiling.Applicable only if `use_sampling` is set to True.",\n          "schema_extra": {\n            "supported_sources": [\n              "bigquery",\n              "snowflake"\n            ]\n          },\n          "title": "Sample Size",\n          "type": "integer"\n        },\n        "profile_external_tables": {\n          "default": false,\n          "description": "Whether to profile external tables. Only Snowflake and Redshift supports this.",\n          "schema_extra": {\n            "supported_sources": [\n              "redshift",\n              "snowflake"\n            ]\n          },\n          "title": "Profile External Tables",\n          "type": "boolean"\n        },\n        "tags_to_ignore_sampling": {\n          "anyOf": [\n            {\n              "items": {\n                "type": "string"\n              },\n              "type": "array"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Fixed list of tags to ignore sampling. If not specified, tables will be sampled based on `use_sampling`.",\n          "title": "Tags To Ignore Sampling"\n        },\n        "profile_nested_fields": {\n          "default": false,\n          "description": "Whether to profile complex types like structs, arrays and maps. ",\n          "title": "Profile Nested Fields",\n          "type": "boolean"\n        },\n        "warehouse_id": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "SQL Warehouse id, for running profiling queries.",\n          "title": "Warehouse Id"\n        },\n        "pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns to filter tables for profiling during ingestion. Specify regex to match the `catalog.schema.table` format. Note that only tables allowed by the `table_pattern` will be considered."\n        },\n        "max_wait_secs": {\n          "anyOf": [\n            {\n              "type": "integer"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Maximum time to wait for a table to be profiled.",\n          "title": "Max Wait Secs"\n        }\n      },\n      "title": "UnityCatalogSQLAlchemyProfilerConfig",\n      "type": "object"\n    },\n    "UsageDataSource": {\n      "enum": [\n        "AUTO",\n        "SYSTEM_TABLES",\n        "API"\n      ],\n      "title": "UsageDataSource",\n      "type": "string"\n    }\n  },\n  "additionalProperties": false,\n  "properties": {\n    "schema_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "Regex patterns for schemas to filter in ingestion. Specify regex to the full `metastore.catalog.schema` name. e.g. to match all tables in schema analytics, use the regex `^mymetastore\\\\.mycatalog\\\\.analytics$`."\n    },\n    "table_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "Regex patterns for tables to filter in ingestion. Specify regex to match the entire table name in `catalog.schema.table` format. e.g. to match all tables starting with customer in Customer catalog and public schema, use the regex `Customer\\\\.public\\\\.customer.*`."\n    },\n    "view_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "Regex patterns for views to filter in ingestion. Note: Defaults to table_pattern if not specified. Specify regex to match the entire view name in database.schema.view format. e.g. to match all views starting with customer in Customer database and public schema, use the regex \'Customer.public.customer.*\'"\n    },\n    "classification": {\n      "$ref": "#/$defs/ClassificationConfig",\n      "default": {\n        "enabled": false,\n        "sample_size": 100,\n        "max_workers": 4,\n        "table_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "column_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "info_type_to_term": {},\n        "classifiers": [\n          {\n            "config": null,\n            "type": "datahub"\n          }\n        ]\n      },\n      "description": "For details, refer to [Classification](../../../../metadata-ingestion/docs/dev_guides/classification.md)."\n    },\n    "incremental_lineage": {\n      "default": false,\n      "description": "When enabled, emits lineage as incremental to existing lineage already in DataHub. When disabled, re-states lineage on each run.",\n      "title": "Incremental Lineage",\n      "type": "boolean"\n    },\n    "convert_urns_to_lowercase": {\n      "default": false,\n      "description": "Whether to convert dataset urns to lowercase.",\n      "title": "Convert Urns To Lowercase",\n      "type": "boolean"\n    },\n    "enable_stateful_profiling": {\n      "default": true,\n      "description": "Enable stateful profiling. This will store profiling timestamps per dataset after successful profiling. and will not run profiling again in subsequent run if table has not been updated. ",\n      "title": "Enable Stateful Profiling",\n      "type": "boolean"\n    },\n    "env": {\n      "default": "PROD",\n      "description": "The environment that all assets produced by this connector belong to",\n      "title": "Env",\n      "type": "string"\n    },\n    "platform_instance": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See https://docs.datahub.com/docs/platform-instances/ for more details.",\n      "title": "Platform Instance"\n    },\n    "bucket_duration": {\n      "$ref": "#/$defs/BucketDuration",\n      "default": "DAY",\n      "description": "Size of the time window to aggregate usage stats."\n    },\n    "end_time": {\n      "description": "Latest date of lineage/usage to consider. Default: Current time in UTC",\n      "format": "date-time",\n      "title": "End Time",\n      "type": "string"\n    },\n    "start_time": {\n      "default": null,\n      "description": "Earliest date of lineage/usage to consider. Default: Last full day in UTC (or hour, depending on `bucket_duration`). You can also specify relative time with respect to end_time such as \'-7 days\' Or \'-7d\'.",\n      "format": "date-time",\n      "title": "Start Time",\n      "type": "string"\n    },\n    "top_n_queries": {\n      "default": 10,\n      "description": "Number of top queries to save to each table.",\n      "exclusiveMinimum": 0,\n      "title": "Top N Queries",\n      "type": "integer"\n    },\n    "user_email_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "regex patterns for user emails to filter in usage."\n    },\n    "include_operational_stats": {\n      "default": true,\n      "description": "Whether to display operational stats.",\n      "title": "Include Operational Stats",\n      "type": "boolean"\n    },\n    "include_read_operational_stats": {\n      "default": false,\n      "description": "Whether to report read operational stats. Experimental.",\n      "title": "Include Read Operational Stats",\n      "type": "boolean"\n    },\n    "format_sql_queries": {\n      "default": false,\n      "description": "Whether to format sql queries",\n      "title": "Format Sql Queries",\n      "type": "boolean"\n    },\n    "include_top_n_queries": {\n      "default": true,\n      "description": "Whether to ingest the top_n_queries.",\n      "title": "Include Top N Queries",\n      "type": "boolean"\n    },\n    "stateful_ingestion": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/StatefulStaleMetadataRemovalConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Unity Catalog Stateful Ingestion Config."\n    },\n    "options": {\n      "additionalProperties": true,\n      "description": "Any options specified here will be passed to [SQLAlchemy.create_engine](https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine) as kwargs.",\n      "title": "Options",\n      "type": "object"\n    },\n    "profile_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "Regex patterns to filter tables (or specific columns) for profiling during ingestion. Note that only tables allowed by the `table_pattern` will be considered."\n    },\n    "domain": {\n      "additionalProperties": {\n        "$ref": "#/$defs/AllowDenyPattern"\n      },\n      "default": {},\n      "description": "Attach domains to catalogs, schemas or tables during ingestion using regex patterns. Domain key can be a guid like *urn:li:domain:ec428203-ce86-4db3-985d-5a8ee6df32ba* or a string like \\"Marketing\\".) If you provide strings, then datahub will attempt to resolve this name to a guid, and will error out if this fails. There can be multiple domain keys specified.",\n      "title": "Domain",\n      "type": "object"\n    },\n    "include_views": {\n      "default": true,\n      "description": "Whether views should be ingested.",\n      "title": "Include Views",\n      "type": "boolean"\n    },\n    "include_tables": {\n      "default": true,\n      "description": "Whether tables should be ingested.",\n      "title": "Include Tables",\n      "type": "boolean"\n    },\n    "include_table_location_lineage": {\n      "default": true,\n      "description": "If the source supports it, include table lineage to the underlying storage location.",\n      "title": "Include Table Location Lineage",\n      "type": "boolean"\n    },\n    "include_view_lineage": {\n      "default": true,\n      "description": "Populates view->view and table->view lineage using DataHub\'s sql parser.",\n      "title": "Include View Lineage",\n      "type": "boolean"\n    },\n    "include_view_column_lineage": {\n      "default": true,\n      "description": "Populates column-level lineage for  view->view and table->view lineage using DataHub\'s sql parser. Requires `include_view_lineage` to be enabled.",\n      "title": "Include View Column Lineage",\n      "type": "boolean"\n    },\n    "use_file_backed_cache": {\n      "default": true,\n      "description": "Whether to use a file backed cache for the view definitions.",\n      "title": "Use File Backed Cache",\n      "type": "boolean"\n    },\n    "profiling": {\n      "default": {\n        "method": "ge",\n        "enabled": false,\n        "operation_config": {\n          "lower_freq_profile_enabled": false,\n          "profile_date_of_month": null,\n          "profile_day_of_week": null\n        },\n        "limit": null,\n        "offset": null,\n        "profile_table_level_only": false,\n        "include_field_null_count": true,\n        "include_field_distinct_count": true,\n        "include_field_min_value": true,\n        "include_field_max_value": true,\n        "include_field_mean_value": true,\n        "include_field_median_value": true,\n        "include_field_stddev_value": true,\n        "include_field_quantiles": false,\n        "include_field_distinct_value_frequencies": false,\n        "include_field_histogram": false,\n        "include_field_sample_values": true,\n        "max_workers": 20,\n        "report_dropped_profiles": false,\n        "turn_off_expensive_profiling_metrics": false,\n        "field_sample_values_limit": 20,\n        "max_number_of_fields_to_profile": null,\n        "profile_if_updated_since_days": null,\n        "profile_table_size_limit": 5,\n        "profile_table_row_limit": 5000000,\n        "profile_table_row_count_estimate_only": false,\n        "query_combiner_enabled": true,\n        "catch_exceptions": true,\n        "partition_profiling_enabled": true,\n        "partition_datetime": null,\n        "use_sampling": true,\n        "sample_size": 10000,\n        "profile_external_tables": false,\n        "tags_to_ignore_sampling": null,\n        "profile_nested_fields": false,\n        "warehouse_id": null,\n        "pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "max_wait_secs": null\n      },\n      "description": "Data profiling configuration",\n      "discriminator": {\n        "mapping": {\n          "analyze": "#/$defs/UnityCatalogAnalyzeProfilerConfig",\n          "ge": "#/$defs/UnityCatalogGEProfilerConfig",\n          "sqlalchemy": "#/$defs/UnityCatalogSQLAlchemyProfilerConfig"\n        },\n        "propertyName": "method"\n      },\n      "oneOf": [\n        {\n          "$ref": "#/$defs/UnityCatalogGEProfilerConfig"\n        },\n        {\n          "$ref": "#/$defs/UnityCatalogAnalyzeProfilerConfig"\n        },\n        {\n          "$ref": "#/$defs/UnityCatalogSQLAlchemyProfilerConfig"\n        }\n      ],\n      "title": "Profiling"\n    },\n    "scheme": {\n      "default": "databricks",\n      "title": "Scheme",\n      "type": "string"\n    },\n    "token": {\n      "anyOf": [\n        {\n          "format": "password",\n          "type": "string",\n          "writeOnly": true\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Databricks personal access token",\n      "title": "Token"\n    },\n    "azure_auth": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/AzureAuthConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Azure configuration"\n    },\n    "client_id": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Databricks service principal client ID",\n      "title": "Client Id"\n    },\n    "client_secret": {\n      "anyOf": [\n        {\n          "format": "password",\n          "type": "string",\n          "writeOnly": true\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Databricks service principal client secret",\n      "title": "Client Secret"\n    },\n    "workspace_url": {\n      "description": "Databricks workspace url. e.g. https://my-workspace.cloud.databricks.com",\n      "title": "Workspace Url",\n      "type": "string"\n    },\n    "warehouse_id": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "SQL Warehouse id, for running queries. Must be explicitly provided to enable SQL-based features. Required for the following features that need SQL access: 1) Tag extraction (include_tags=True) - queries system.information_schema.tags 2) Hive Metastore catalog (include_hive_metastore=True) - queries legacy hive_metastore catalog 3) System table lineage (lineage_data_source=SYSTEM_TABLES) - queries system.access.table_lineage/column_lineage 4) Data profiling (profiling.enabled=True) - runs SELECT/ANALYZE queries on tables. When warehouse_id is missing, these features will be automatically disabled (with warnings) to allow ingestion to continue.",\n      "title": "Warehouse Id"\n    },\n    "extra_client_options": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "Additional options to pass to Databricks SQLAlchemy client.",\n      "title": "Extra Client Options",\n      "type": "object"\n    },\n    "include_metastore": {\n      "default": false,\n      "description": "Whether to ingest the workspace\'s metastore as a container and include it in all urns. Changing this will affect the urns of all entities in the workspace. This config is deprecated and will be removed in the future, so it is recommended to not set this to `True` for new ingestions. If you have an existing unity catalog ingestion, you\'ll want to avoid duplicates by soft deleting existing data. If stateful ingestion is enabled, running with `include_metastore: false` should be sufficient. Otherwise, we recommend deleting via the cli: `datahub delete --platform databricks` and re-ingesting with `include_metastore: false`.",\n      "title": "Include Metastore",\n      "type": "boolean"\n    },\n    "ingest_data_platform_instance_aspect": {\n      "anyOf": [\n        {\n          "type": "boolean"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": false,\n      "description": "Option to enable/disable ingestion of the data platform instance aspect. The default data platform instance id for a dataset is workspace_name",\n      "title": "Ingest Data Platform Instance Aspect"\n    },\n    "catalogs": {\n      "anyOf": [\n        {\n          "items": {\n            "type": "string"\n          },\n          "type": "array"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Fixed list of catalogs to ingest. If not specified, catalogs will be ingested based on `catalog_pattern`.",\n      "title": "Catalogs"\n    },\n    "catalog_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "Regex patterns for catalogs to filter in ingestion. Specify regex to match the full `metastore.catalog` name."\n    },\n    "notebook_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "Regex patterns for notebooks to filter in ingestion, based on notebook *path*. Specify regex to match the entire notebook path in `/<dir>/.../<name>` format. e.g. to match all notebooks in the root Shared directory, use the regex `/Shared/.*`."\n    },\n    "include_table_lineage": {\n      "default": true,\n      "description": "Option to enable/disable lineage generation.",\n      "title": "Include Table Lineage",\n      "type": "boolean"\n    },\n    "include_external_lineage": {\n      "default": true,\n      "description": "Option to enable/disable lineage generation for external tables. Only external S3 tables are supported at the moment.",\n      "title": "Include External Lineage",\n      "type": "boolean"\n    },\n    "include_notebooks": {\n      "default": false,\n      "description": "Ingest notebooks, represented as DataHub datasets.",\n      "title": "Include Notebooks",\n      "type": "boolean"\n    },\n    "include_ownership": {\n      "default": false,\n      "description": "Option to enable/disable ownership generation for metastores, catalogs, schemas, and tables.",\n      "title": "Include Ownership",\n      "type": "boolean"\n    },\n    "include_tags": {\n      "default": true,\n      "description": "Option to enable/disable column/table tag extraction. Requires warehouse_id to be set since tag extraction needs to query system.information_schema.tags. If warehouse_id is not provided, this will be automatically disabled to allow ingestion to continue.",\n      "title": "Include Tags",\n      "type": "boolean"\n    },\n    "include_column_lineage": {\n      "default": true,\n      "description": "Option to enable/disable lineage generation. Currently we have to call a rest call per column to get column level lineage due to the Databrick api which can slow down ingestion. ",\n      "title": "Include Column Lineage",\n      "type": "boolean"\n    },\n    "lineage_data_source": {\n      "$ref": "#/$defs/LineageDataSource",\n      "default": "AUTO",\n      "description": "Source for lineage data extraction. Options: \'AUTO\' - Use system tables when SQL warehouse is available, fallback to API; \'SYSTEM_TABLES\' - Force use of system.access.table_lineage and system.access.column_lineage tables (requires SQL warehouse); \'API\' - Force use of REST API endpoints for lineage data"\n    },\n    "ignore_start_time_lineage": {\n      "default": false,\n      "description": "Option to ignore the start_time and retrieve all available lineage. When enabled, the start_time filter will be set to zero to extract all lineage events regardless of the configured time window.",\n      "title": "Ignore Start Time Lineage",\n      "type": "boolean"\n    },\n    "column_lineage_column_limit": {\n      "default": 300,\n      "description": "Limit the number of columns to get column level lineage. ",\n      "title": "Column Lineage Column Limit",\n      "type": "integer"\n    },\n    "databricks_api_page_size": {\n      "default": 0,\n      "description": "Page size for Databricks API calls when listing resources (catalogs, schemas, tables, etc.). When set to 0 (default), uses server-side configured page length (recommended). When set to a positive value, the page length is the minimum of this value and the server configured value. Must be a non-negative integer.",\n      "minimum": 0,\n      "title": "Databricks Api Page Size",\n      "type": "integer"\n    },\n    "include_usage_statistics": {\n      "default": true,\n      "description": "Generate usage statistics.",\n      "title": "Include Usage Statistics",\n      "type": "boolean"\n    },\n    "usage_data_source": {\n      "$ref": "#/$defs/UsageDataSource",\n      "default": "AUTO",\n      "description": "Source for usage/query history data extraction. Options: \'AUTO\' (default) - Automatically use system.query.history table when SQL warehouse is configured, otherwise fall back to REST API. This provides better performance for multi-workspace setups and large query volumes when warehouse_id is set. \'SYSTEM_TABLES\' - Force use of system.query.history table (requires SQL warehouse and SELECT permission on system.query.history). \'API\' - Force use of REST API endpoints for query history (legacy method, may have limitations with multiple workspaces)."\n    },\n    "emit_siblings": {\n      "default": true,\n      "description": "Whether to emit siblings relation with corresponding delta-lake platform\'s table. If enabled, this will also ingest the corresponding delta-lake table.",\n      "title": "Emit Siblings",\n      "type": "boolean"\n    },\n    "delta_lake_options": {\n      "$ref": "#/$defs/DeltaLakeDetails",\n      "default": {\n        "platform_instance_name": null,\n        "env": "PROD"\n      },\n      "description": "Details about the delta lake, incase to emit siblings"\n    },\n    "include_ml_model_aliases": {\n      "default": false,\n      "description": "Whether to include ML model aliases in the ingestion.",\n      "title": "Include Ml Model Aliases",\n      "type": "boolean"\n    },\n    "ml_model_max_results": {\n      "default": 1000,\n      "description": "Maximum number of ML models to ingest.",\n      "minimum": 0,\n      "title": "Ml Model Max Results",\n      "type": "integer"\n    },\n    "include_hive_metastore": {\n      "default": true,\n      "description": "Whether to ingest legacy `hive_metastore` catalog. This requires executing queries on SQL warehouse.",\n      "title": "Include Hive Metastore",\n      "type": "boolean"\n    },\n    "workspace_name": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Name of the workspace. Default to deployment name present in workspace_url",\n      "title": "Workspace Name"\n    }\n  },\n  "required": [\n    "workspace_url"\n  ],\n  "title": "UnityCatalogSourceConfig",\n  "type": "object"\n}\n')))),(0,n.yg)("h3",{id:"advanced"},"Advanced"),(0,n.yg)("h4",{id:"multiple-databricks-workspaces"},"Multiple Databricks Workspaces"),(0,n.yg)("p",null,"If you have multiple databricks workspaces ",(0,n.yg)("strong",{parentName:"p"},"that point to the same Unity Catalog metastore"),", our suggestion is to use separate recipes for ingesting the workspace-specific Hive Metastore catalog and Unity Catalog metastore's information schema."),(0,n.yg)("p",null,"To ingest Hive metastore information schema"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Setup one ingestion recipe per workspace"),(0,n.yg)("li",{parentName:"ul"},"Use platform instance equivalent to workspace name"),(0,n.yg)("li",{parentName:"ul"},"Ingest only hive_metastore catalog in the recipe using config ",(0,n.yg)("inlineCode",{parentName:"li"},'catalogs: ["hive_metastore"]'))),(0,n.yg)("p",null,"To ingest Unity Catalog information schema"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Disable hive metastore catalog ingestion in the recipe using config ",(0,n.yg)("inlineCode",{parentName:"li"},"include_hive_metastore: False")),(0,n.yg)("li",{parentName:"ul"},"Ideally, just ingest from one workspace"),(0,n.yg)("li",{parentName:"ul"},"To ingest from both workspaces (e.g. if each workspace has different permissions and therefore restricted view of the UC metastore):",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"Use same platform instance for all workspaces using same UC metastore"),(0,n.yg)("li",{parentName:"ul"},"Ingest usage from only one workspace (you lose usage from other workspace)"),(0,n.yg)("li",{parentName:"ul"},"Use filters to only ingest each catalog once, but shouldn\u2019t be necessary")))),(0,n.yg)("h3",{id:"troubleshooting"},"Troubleshooting"),(0,n.yg)("h4",{id:"no-data-lineage-captured-or-missing-lineage"},"No data lineage captured or missing lineage"),(0,n.yg)("p",null,"Check that you meet the ",(0,n.yg)("a",{parentName:"p",href:"https://docs.databricks.com/data-governance/unity-catalog/data-lineage.html#requirements"},"Unity Catalog lineage requirements"),"."),(0,n.yg)("p",null,"Also check the ",(0,n.yg)("a",{parentName:"p",href:"https://docs.databricks.com/data-governance/unity-catalog/data-lineage.html#limitations"},"Unity Catalog limitations")," to make sure that lineage would be expected to exist in this case."),(0,n.yg)("h4",{id:"lineage-extraction-is-too-slow"},"Lineage extraction is too slow"),(0,n.yg)("p",null,"Currently, there is no way to get table or column lineage in bulk from the Databricks Unity Catalog REST api. Table lineage calls require one API call per table, and column lineage calls require one API call per column. If you find metadata extraction taking too long, you can turn off column level lineage extraction via the ",(0,n.yg)("inlineCode",{parentName:"p"},"include_column_lineage")," config flag."),(0,n.yg)("h3",{id:"code-coordinates"},"Code Coordinates"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Class Name: ",(0,n.yg)("inlineCode",{parentName:"li"},"datahub.ingestion.source.unity.source.UnityCatalogSource")),(0,n.yg)("li",{parentName:"ul"},"Browse on ",(0,n.yg)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/unity/source.py"},"GitHub"))),(0,n.yg)("h2",null,"Questions"),(0,n.yg)("p",null,"If you've got any questions on configuring ingestion for Databricks, feel free to ping us on ",(0,n.yg)("a",{parentName:"p",href:"https://datahub.com/slack"},"our Slack"),"."))}f.isMDXComponent=!0}}]);