"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[71453],{51479:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"1.1.0","label":"1.1.0","banner":"unmaintained","badge":true,"noIndex":false,"className":"docs-version-1.1.0","isLast":false,"docsSidebars":{"overviewSidebar":[{"type":"html","value":"<div>Getting Started</div>","defaultStyle":true},{"label":"What Is DataHub?","type":"category","collapsed":true,"items":[{"type":"link","label":"Quickstart Guide","href":"/docs/1.1.0/quickstart","docId":"docs/quickstart"},{"type":"link","label":"Demo","href":"https://demo.datahub.com/"},{"type":"link","label":"Adoption Stories","href":"https://datahub.com/adoption-stories/"}],"collapsible":true,"href":"/docs/1.1.0/features"},{"type":"category","label":"Features","items":[{"label":"Assertions","type":"category","items":[{"type":"link","label":"Column Assertions","href":"/docs/1.1.0/managed-datahub/observe/column-assertions","className":"saasOnly","docId":"docs/managed-datahub/observe/column-assertions"},{"type":"link","label":"Custom SQL Assertions","href":"/docs/1.1.0/managed-datahub/observe/custom-sql-assertions","className":"saasOnly","docId":"docs/managed-datahub/observe/custom-sql-assertions"},{"type":"link","label":"Freshness Assertions","href":"/docs/1.1.0/managed-datahub/observe/freshness-assertions","className":"saasOnly","docId":"docs/managed-datahub/observe/freshness-assertions"},{"type":"link","label":"Schema Assertions","href":"/docs/1.1.0/managed-datahub/observe/schema-assertions","className":"saasOnly","docId":"docs/managed-datahub/observe/schema-assertions"},{"type":"link","label":"Volume Assertions","href":"/docs/1.1.0/managed-datahub/observe/volume-assertions","className":"saasOnly","docId":"docs/managed-datahub/observe/volume-assertions"},{"label":"Open Assertions Specification","type":"category","items":[{"type":"link","label":"Snowflake","href":"/docs/1.1.0/assertions/snowflake/snowflake_dmfs","docId":"docs/assertions/snowflake/snowflake_dmfs"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/assertions/open-assertions-spec"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/managed-datahub/observe/assertions"},{"type":"link","label":"Access Management","href":"/docs/1.1.0/features/feature-guides/access-management","docId":"docs/features/feature-guides/access-management"},{"label":"Automations","type":"category","collapsed":true,"items":[{"type":"link","label":"Documentation Propagation","href":"/docs/1.1.0/automations/docs-propagation","docId":"docs/automations/docs-propagation"},{"type":"link","label":"Glossary Term Propagation","href":"/docs/1.1.0/automations/glossary-term-propagation","docId":"docs/automations/glossary-term-propagation"},{"type":"link","label":"BigQuery Metadata Sync","href":"/docs/1.1.0/automations/bigquery-metadata-sync","className":"saasOnly","docId":"docs/automations/bigquery-metadata-sync"},{"type":"link","label":"Snowflake Tag Sync","href":"/docs/1.1.0/automations/snowflake-tag-propagation","className":"saasOnly","docId":"docs/automations/snowflake-tag-propagation"},{"type":"link","label":"AI Classification","href":"/docs/1.1.0/automations/ai-term-suggestion","className":"saasOnly","docId":"docs/automations/ai-term-suggestion"},{"type":"link","label":"AI Documentation","href":"/docs/1.1.0/automations/ai-docs","className":"saasOnly","docId":"docs/automations/ai-docs"}],"collapsible":true},{"type":"link","label":"Business Attributes","href":"/docs/1.1.0/businessattributes","docId":"docs/businessattributes"},{"type":"link","label":"Business Glossary","href":"/docs/1.1.0/glossary/business-glossary","docId":"docs/glossary/business-glossary"},{"label":"Compliance Forms","type":"category","collapsed":true,"items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/features/feature-guides/compliance-forms/overview","docId":"docs/features/feature-guides/compliance-forms/overview"},{"type":"link","label":"Create a Form","href":"/docs/1.1.0/features/feature-guides/compliance-forms/create-a-form","docId":"docs/features/feature-guides/compliance-forms/create-a-form"},{"type":"link","label":"Complete a Form","href":"/docs/1.1.0/features/feature-guides/compliance-forms/complete-a-form","docId":"docs/features/feature-guides/compliance-forms/complete-a-form"},{"type":"link","label":"Form Analytics","href":"/docs/1.1.0/features/feature-guides/compliance-forms/analytics","className":"saasOnly","docId":"docs/features/feature-guides/compliance-forms/analytics"}],"collapsible":true},{"type":"link","label":"Data Contract","href":"/docs/1.1.0/managed-datahub/observe/data-contract","docId":"docs/managed-datahub/observe/data-contract"},{"type":"link","label":"Data Products","href":"/docs/1.1.0/dataproducts","docId":"docs/dataproducts"},{"type":"link","label":"Dataset Usage and Query History","href":"/docs/1.1.0/features/dataset-usage-and-query-history","docId":"docs/features/dataset-usage-and-query-history"},{"type":"link","label":"Domains","href":"/docs/1.1.0/domains","docId":"docs/domains"},{"type":"link","label":"Incidents","href":"/docs/1.1.0/incidents/incidents","docId":"docs/incidents/incidents"},{"type":"link","label":"Ingestion","href":"/docs/1.1.0/ui-ingestion","docId":"docs/ui-ingestion"},{"label":"Lineage","type":"category","items":[{"type":"link","label":"Lineage Impact analysis","href":"/docs/1.1.0/act-on-metadata/impact-analysis","docId":"docs/act-on-metadata/impact-analysis"},{"type":"link","label":"Managing Lineage via UI","href":"/docs/1.1.0/features/feature-guides/ui-lineage","docId":"docs/features/feature-guides/ui-lineage"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/generated/lineage/lineage-feature-guide"},{"type":"link","label":"Metadata Tests","href":"/docs/1.1.0/tests/metadata-tests","className":"saasOnly","docId":"docs/tests/metadata-tests"},{"type":"link","label":"Ownership","href":"/docs/1.1.0/ownership/ownership-types","docId":"docs/ownership/ownership-types"},{"type":"link","label":"Policies","href":"/docs/1.1.0/authorization/access-policies-guide","docId":"docs/authorization/access-policies-guide"},{"type":"link","label":"Posts","href":"/docs/1.1.0/posts","docId":"docs/posts"},{"label":"Properties","type":"category","collapsed":true,"items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/features/feature-guides/properties/overview","docId":"docs/features/feature-guides/properties/overview"},{"type":"link","label":"Create and Add a Structured Property","href":"/docs/1.1.0/features/feature-guides/properties/create-a-property","docId":"docs/features/feature-guides/properties/create-a-property"}],"collapsible":true},{"type":"link","label":"Schema history","href":"/docs/1.1.0/schema-history","docId":"docs/schema-history"},{"type":"link","label":"Search","href":"/docs/1.1.0/how/search","docId":"docs/how/search"},{"type":"link","label":"Sync Status","href":"/docs/1.1.0/sync-status","docId":"docs/sync-status"},{"type":"link","label":"Tags","href":"/docs/1.1.0/tags","docId":"docs/tags"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/category/features"},{"label":"DataHub Cloud","type":"category","collapsed":true,"items":[{"type":"link","label":"Getting Started with DataHub Cloud","href":"/docs/1.1.0/managed-datahub/welcome-acryl","docId":"docs/managed-datahub/welcome-acryl"},{"type":"category","label":"Configure Single Sign-On","items":[{"type":"link","label":"Prerequisites for OIDC Authentication","href":"/docs/1.1.0/authentication/guides/sso/initialize-oidc","className":"saasOnly","docId":"docs/authentication/guides/sso/initialize-oidc"},{"type":"link","label":"Enable OIDC SSO","href":"/docs/1.1.0/managed-datahub/integrations/oidc-sso-integration","className":"saasOnly","docId":"docs/managed-datahub/integrations/oidc-sso-integration"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Remote Executor","items":[{"type":"link","label":"About Remote Executor","href":"/docs/1.1.0/managed-datahub/remote-executor/about","className":"saasOnly","docId":"docs/managed-datahub/remote-executor/about"},{"type":"link","label":"Configuring Remote Executor","href":"/docs/1.1.0/managed-datahub/operator-guide/setting-up-remote-ingestion-executor","className":"saasOnly","docId":"docs/managed-datahub/operator-guide/setting-up-remote-ingestion-executor"},{"type":"link","label":"Monitoring Remote Executor","href":"/docs/1.1.0/managed-datahub/remote-executor/monitoring","className":"saasOnly","docId":"docs/managed-datahub/remote-executor/monitoring"}],"collapsed":true,"collapsible":true},{"type":"category","label":"DataHub API","items":[{"type":"link","label":"Entity Events API","href":"/docs/1.1.0/managed-datahub/datahub-api/entity-events-api","className":"saasOnly","docId":"docs/managed-datahub/datahub-api/entity-events-api"},{"type":"category","label":"GraphQL API","items":[{"type":"link","label":"Getting Started","href":"/docs/1.1.0/managed-datahub/datahub-api/graphql-api/getting-started","docId":"docs/managed-datahub/datahub-api/graphql-api/getting-started"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Slack","items":[{"type":"link","label":"Configure Slack For Notifications","href":"/docs/1.1.0/managed-datahub/slack/saas-slack-setup","className":"saasOnly","docId":"docs/managed-datahub/slack/saas-slack-setup"},{"type":"link","label":"Slack App Features","href":"/docs/1.1.0/managed-datahub/slack/saas-slack-app","className":"saasOnly","docId":"docs/managed-datahub/slack/saas-slack-app"},{"type":"link","label":"Troubleshoot Slack Issues","href":"/docs/1.1.0/managed-datahub/slack/saas-slack-troubleshoot","className":"saasOnly","docId":"docs/managed-datahub/slack/saas-slack-troubleshoot"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Operator Guides","items":[{"type":"link","label":"Setting up Events API on AWS EventBridge","href":"/docs/1.1.0/managed-datahub/operator-guide/setting-up-events-api-on-aws-eventbridge","className":"saasOnly","docId":"docs/managed-datahub/operator-guide/setting-up-events-api-on-aws-eventbridge"},{"type":"link","label":"AWS PrivateLink","href":"/docs/1.1.0/managed-datahub/integrations/aws-privatelink","className":"saasOnly","docId":"docs/managed-datahub/integrations/aws-privatelink"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Approval Workflows","href":"/docs/1.1.0/managed-datahub/approval-workflows","className":"saasOnly","docId":"docs/managed-datahub/approval-workflows"},{"type":"link","label":"Cloud Chrome Extension","href":"/docs/1.1.0/managed-datahub/chrome-extension","docId":"docs/managed-datahub/chrome-extension"},{"type":"link","label":"Subscriptions & Notifications","href":"/docs/1.1.0/managed-datahub/subscription-and-notification","className":"saasOnly","docId":"docs/managed-datahub/subscription-and-notification"},{"type":"category","label":"DataHub Cloud Release History","items":[{"type":"link","label":"v0.3.10","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_10","docId":"docs/managed-datahub/release-notes/v_0_3_10"},{"type":"link","label":"v0.3.9","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_9","docId":"docs/managed-datahub/release-notes/v_0_3_9"},{"type":"link","label":"v0.3.8","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_8","docId":"docs/managed-datahub/release-notes/v_0_3_8"},{"type":"link","label":"v0.3.7","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_7","docId":"docs/managed-datahub/release-notes/v_0_3_7"},{"type":"link","label":"v0.3.6","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_6","docId":"docs/managed-datahub/release-notes/v_0_3_6"},{"type":"link","label":"v0.3.5","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_5","docId":"docs/managed-datahub/release-notes/v_0_3_5"},{"type":"link","label":"v0.3.4","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_4","docId":"docs/managed-datahub/release-notes/v_0_3_4"},{"type":"link","label":"v0.3.3","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_3","docId":"docs/managed-datahub/release-notes/v_0_3_3"},{"type":"link","label":"v0.3.2","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_2","docId":"docs/managed-datahub/release-notes/v_0_3_2"},{"type":"link","label":"v0.3.1","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_3_1","docId":"docs/managed-datahub/release-notes/v_0_3_1"},{"type":"link","label":"v0.2.16","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_16","docId":"docs/managed-datahub/release-notes/v_0_2_16"},{"type":"link","label":"v0.2.15.1","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_15","docId":"docs/managed-datahub/release-notes/v_0_2_15"},{"type":"link","label":"v0.2.14.1","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_14","docId":"docs/managed-datahub/release-notes/v_0_2_14"},{"type":"link","label":"v0.2.13","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_13","docId":"docs/managed-datahub/release-notes/v_0_2_13"},{"type":"link","label":"v0.2.12","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_12","docId":"docs/managed-datahub/release-notes/v_0_2_12"},{"type":"link","label":"v0.2.11","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_11","docId":"docs/managed-datahub/release-notes/v_0_2_11"},{"type":"link","label":"v0.2.10","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_10","docId":"docs/managed-datahub/release-notes/v_0_2_10"},{"type":"link","label":"v0.2.9","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_9","docId":"docs/managed-datahub/release-notes/v_0_2_9"},{"type":"link","label":"v0.2.8","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_8","docId":"docs/managed-datahub/release-notes/v_0_2_8"},{"type":"link","label":"v0.2.7","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_7","docId":"docs/managed-datahub/release-notes/v_0_2_7"},{"type":"link","label":"v0.2.6","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_6","docId":"docs/managed-datahub/release-notes/v_0_2_6"},{"type":"link","label":"v0.2.5","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_5","docId":"docs/managed-datahub/release-notes/v_0_2_5"},{"type":"link","label":"v0.2.4","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_4","docId":"docs/managed-datahub/release-notes/v_0_2_4"},{"type":"link","label":"v0.2.3","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_3","docId":"docs/managed-datahub/release-notes/v_0_2_3"},{"type":"link","label":"v0.2.2","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_2","docId":"docs/managed-datahub/release-notes/v_0_2_2"},{"type":"link","label":"v0.2.1","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_1","docId":"docs/managed-datahub/release-notes/v_0_2_1"},{"type":"link","label":"v0.2.0","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_2_0","docId":"docs/managed-datahub/release-notes/v_0_2_0"},{"type":"link","label":"v0.1.73","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_1_73","docId":"docs/managed-datahub/release-notes/v_0_1_73"},{"type":"link","label":"v0.1.72","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_1_72","docId":"docs/managed-datahub/release-notes/v_0_1_72"},{"type":"link","label":"v0.1.70","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_1_70","docId":"docs/managed-datahub/release-notes/v_0_1_70"},{"type":"link","label":"v0.1.69","href":"/docs/1.1.0/managed-datahub/release-notes/v_0_1_69","docId":"docs/managed-datahub/release-notes/v_0_1_69"}],"collapsed":true,"collapsible":true}],"collapsible":true,"href":"/docs/1.1.0/managed-datahub/managed-datahub-overview"},{"type":"html","value":"<div>Integrations</div>","defaultStyle":true},{"type":"category","label":"Overview","items":[{"type":"link","label":"Recipe","href":"/docs/1.1.0/metadata-ingestion/recipe_overview","docId":"metadata-ingestion/recipe_overview"},{"type":"category","label":"Sinks","items":[{"type":"link","label":"Console","href":"/docs/1.1.0/metadata-ingestion/sink_docs/console","docId":"metadata-ingestion/sink_docs/console"},{"type":"link","label":"DataHub","href":"/docs/1.1.0/metadata-ingestion/sink_docs/datahub","docId":"metadata-ingestion/sink_docs/datahub"},{"type":"link","label":"Metadata File","href":"/docs/1.1.0/metadata-ingestion/sink_docs/metadata-file","docId":"metadata-ingestion/sink_docs/metadata-file"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/metadata-ingestion/sink_overview"},{"type":"category","label":"Transformers","items":[{"type":"link","label":"Dataset","href":"/docs/1.1.0/metadata-ingestion/docs/transformer/dataset_transformer","docId":"metadata-ingestion/docs/transformer/dataset_transformer"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/metadata-ingestion/docs/transformer/intro"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/metadata-ingestion"},{"type":"category","label":"Quickstart Guides","items":[{"type":"link","label":"CLI Ingestion","href":"/docs/1.1.0/metadata-ingestion/cli-ingestion","docId":"metadata-ingestion/cli-ingestion"},{"type":"category","label":"BigQuery","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/quick-ingestion-guides/bigquery/overview","docId":"docs/quick-ingestion-guides/bigquery/overview"},{"type":"link","label":"Setup","href":"/docs/1.1.0/quick-ingestion-guides/bigquery/setup","docId":"docs/quick-ingestion-guides/bigquery/setup"},{"type":"link","label":"Configuration","href":"/docs/1.1.0/quick-ingestion-guides/bigquery/configuration","docId":"docs/quick-ingestion-guides/bigquery/configuration"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Redshift","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/quick-ingestion-guides/redshift/overview","docId":"docs/quick-ingestion-guides/redshift/overview"},{"type":"link","label":"Setup","href":"/docs/1.1.0/quick-ingestion-guides/redshift/setup","docId":"docs/quick-ingestion-guides/redshift/setup"},{"type":"link","label":"Configuration","href":"/docs/1.1.0/quick-ingestion-guides/redshift/configuration","docId":"docs/quick-ingestion-guides/redshift/configuration"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Snowflake","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/quick-ingestion-guides/snowflake/overview","docId":"docs/quick-ingestion-guides/snowflake/overview"},{"type":"link","label":"Setup","href":"/docs/1.1.0/quick-ingestion-guides/snowflake/setup","docId":"docs/quick-ingestion-guides/snowflake/setup"},{"type":"link","label":"Configuration","href":"/docs/1.1.0/quick-ingestion-guides/snowflake/configuration","docId":"docs/quick-ingestion-guides/snowflake/configuration"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Tableau","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/quick-ingestion-guides/tableau/overview","docId":"docs/quick-ingestion-guides/tableau/overview"},{"type":"link","label":"Setup","href":"/docs/1.1.0/quick-ingestion-guides/tableau/setup","docId":"docs/quick-ingestion-guides/tableau/setup"},{"type":"link","label":"Configuration","href":"/docs/1.1.0/quick-ingestion-guides/tableau/configuration","docId":"docs/quick-ingestion-guides/tableau/configuration"}],"collapsed":true,"collapsible":true},{"type":"category","label":"PowerBI","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/quick-ingestion-guides/powerbi/overview","docId":"docs/quick-ingestion-guides/powerbi/overview"},{"type":"link","label":"Setup","href":"/docs/1.1.0/quick-ingestion-guides/powerbi/setup","docId":"docs/quick-ingestion-guides/powerbi/setup"},{"type":"link","label":"Configuration","href":"/docs/1.1.0/quick-ingestion-guides/powerbi/configuration","docId":"docs/quick-ingestion-guides/powerbi/configuration"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Looker","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/quick-ingestion-guides/looker/overview","docId":"docs/quick-ingestion-guides/looker/overview"},{"type":"link","label":"Setup","href":"/docs/1.1.0/quick-ingestion-guides/looker/setup","docId":"docs/quick-ingestion-guides/looker/setup"},{"type":"link","label":"Configuration","href":"/docs/1.1.0/quick-ingestion-guides/looker/configuration","docId":"docs/quick-ingestion-guides/looker/configuration"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Sources","items":[{"type":"link","label":"Airflow","href":"/docs/1.1.0/lineage/airflow","docId":"docs/lineage/airflow"},{"type":"link","label":"Dagster","href":"/docs/1.1.0/lineage/dagster","docId":"docs/lineage/dagster"},{"type":"link","label":"Prefect","href":"/docs/1.1.0/lineage/prefect","docId":"docs/lineage/prefect"},{"type":"link","label":"Spark","href":"/docs/1.1.0/metadata-integration/java/acryl-spark-lineage","docId":"metadata-integration/java/acryl-spark-lineage/README"},{"type":"link","label":"Great Expectations","href":"/docs/1.1.0/metadata-ingestion/integration_docs/great-expectations","docId":"metadata-ingestion/integration_docs/great-expectations"},{"type":"link","label":"Protobuf Schemas","href":"/docs/1.1.0/metadata-integration/java/datahub-protobuf","docId":"metadata-integration/java/datahub-protobuf/README"},{"type":"link","label":"ABS Data Lake","href":"/docs/1.1.0/generated/ingestion/sources/abs","docId":"docs/generated/ingestion/sources/abs"},{"type":"link","label":"Athena","href":"/docs/1.1.0/generated/ingestion/sources/athena","docId":"docs/generated/ingestion/sources/athena"},{"type":"link","label":"Azure AD","href":"/docs/1.1.0/generated/ingestion/sources/azure-ad","docId":"docs/generated/ingestion/sources/azure-ad"},{"type":"link","label":"BigQuery","href":"/docs/1.1.0/generated/ingestion/sources/bigquery","docId":"docs/generated/ingestion/sources/bigquery"},{"type":"link","label":"Business Glossary","href":"/docs/1.1.0/generated/ingestion/sources/business-glossary","docId":"docs/generated/ingestion/sources/business-glossary"},{"type":"link","label":"Cassandra","href":"/docs/1.1.0/generated/ingestion/sources/cassandra","docId":"docs/generated/ingestion/sources/cassandra"},{"type":"link","label":"ClickHouse","href":"/docs/1.1.0/generated/ingestion/sources/clickhouse","docId":"docs/generated/ingestion/sources/clickhouse"},{"type":"link","label":"CockroachDB","href":"/docs/1.1.0/generated/ingestion/sources/cockroachdb","docId":"docs/generated/ingestion/sources/cockroachdb"},{"type":"link","label":"CSV Enricher","href":"/docs/1.1.0/generated/ingestion/sources/csv-enricher","docId":"docs/generated/ingestion/sources/csv-enricher"},{"type":"link","label":"Databricks","href":"/docs/1.1.0/generated/ingestion/sources/databricks","docId":"docs/generated/ingestion/sources/databricks"},{"type":"link","label":"DataHub","href":"/docs/1.1.0/generated/ingestion/sources/datahub","docId":"docs/generated/ingestion/sources/datahub"},{"type":"link","label":"DataHubApply","href":"/docs/1.1.0/generated/ingestion/sources/datahubapply","docId":"docs/generated/ingestion/sources/datahubapply"},{"type":"link","label":"DataHubGc","href":"/docs/1.1.0/generated/ingestion/sources/datahubgc","docId":"docs/generated/ingestion/sources/datahubgc"},{"type":"link","label":"dbt","href":"/docs/1.1.0/generated/ingestion/sources/dbt","docId":"docs/generated/ingestion/sources/dbt"},{"type":"link","label":"Delta Lake","href":"/docs/1.1.0/generated/ingestion/sources/delta-lake","docId":"docs/generated/ingestion/sources/delta-lake"},{"type":"link","label":"Demo Data","href":"/docs/1.1.0/generated/ingestion/sources/demo-data","docId":"docs/generated/ingestion/sources/demo-data"},{"type":"link","label":"Dremio","href":"/docs/1.1.0/generated/ingestion/sources/dremio","docId":"docs/generated/ingestion/sources/dremio"},{"type":"link","label":"Druid","href":"/docs/1.1.0/generated/ingestion/sources/druid","docId":"docs/generated/ingestion/sources/druid"},{"type":"link","label":"DynamoDB","href":"/docs/1.1.0/generated/ingestion/sources/dynamodb","docId":"docs/generated/ingestion/sources/dynamodb"},{"type":"link","label":"Elasticsearch","href":"/docs/1.1.0/generated/ingestion/sources/elasticsearch","docId":"docs/generated/ingestion/sources/elasticsearch"},{"type":"link","label":"Feast","href":"/docs/1.1.0/generated/ingestion/sources/feast","docId":"docs/generated/ingestion/sources/feast"},{"type":"link","label":"File Based Lineage","href":"/docs/1.1.0/generated/ingestion/sources/file-based-lineage","docId":"docs/generated/ingestion/sources/file-based-lineage"},{"type":"link","label":"Fivetran","href":"/docs/1.1.0/generated/ingestion/sources/fivetran","docId":"docs/generated/ingestion/sources/fivetran"},{"type":"link","label":"Glue","href":"/docs/1.1.0/generated/ingestion/sources/glue","docId":"docs/generated/ingestion/sources/glue"},{"type":"link","label":"Google Cloud Storage","href":"/docs/1.1.0/generated/ingestion/sources/gcs","docId":"docs/generated/ingestion/sources/gcs"},{"type":"link","label":"Grafana","href":"/docs/1.1.0/generated/ingestion/sources/grafana","docId":"docs/generated/ingestion/sources/grafana"},{"type":"link","label":"Hex","href":"/docs/1.1.0/generated/ingestion/sources/hex","docId":"docs/generated/ingestion/sources/hex"},{"type":"link","label":"Hive","href":"/docs/1.1.0/generated/ingestion/sources/hive","docId":"docs/generated/ingestion/sources/hive"},{"type":"link","label":"Hive Metastore","href":"/docs/1.1.0/generated/ingestion/sources/hive-metastore","docId":"docs/generated/ingestion/sources/hive-metastore"},{"type":"link","label":"Iceberg","href":"/docs/1.1.0/generated/ingestion/sources/iceberg","docId":"docs/generated/ingestion/sources/iceberg"},{"type":"link","label":"JSON Schemas","href":"/docs/1.1.0/generated/ingestion/sources/json-schema","docId":"docs/generated/ingestion/sources/json-schema"},{"type":"link","label":"Kafka","href":"/docs/1.1.0/generated/ingestion/sources/kafka","docId":"docs/generated/ingestion/sources/kafka"},{"type":"link","label":"Kafka Connect","href":"/docs/1.1.0/generated/ingestion/sources/kafka-connect","docId":"docs/generated/ingestion/sources/kafka-connect"},{"type":"link","label":"LDAP","href":"/docs/1.1.0/generated/ingestion/sources/ldap","docId":"docs/generated/ingestion/sources/ldap"},{"type":"link","label":"Looker","href":"/docs/1.1.0/generated/ingestion/sources/looker","docId":"docs/generated/ingestion/sources/looker"},{"type":"link","label":"MariaDB","href":"/docs/1.1.0/generated/ingestion/sources/mariadb","docId":"docs/generated/ingestion/sources/mariadb"},{"type":"link","label":"Metabase","href":"/docs/1.1.0/generated/ingestion/sources/metabase","docId":"docs/generated/ingestion/sources/metabase"},{"type":"link","label":"Metadata File","href":"/docs/1.1.0/generated/ingestion/sources/metadata-file","docId":"docs/generated/ingestion/sources/metadata-file"},{"type":"link","label":"Microsoft SQL Server","href":"/docs/1.1.0/generated/ingestion/sources/mssql","docId":"docs/generated/ingestion/sources/mssql"},{"type":"link","label":"MLflow","href":"/docs/1.1.0/generated/ingestion/sources/mlflow","docId":"docs/generated/ingestion/sources/mlflow"},{"type":"link","label":"Mode","href":"/docs/1.1.0/generated/ingestion/sources/mode","docId":"docs/generated/ingestion/sources/mode"},{"type":"link","label":"MongoDB","href":"/docs/1.1.0/generated/ingestion/sources/mongodb","docId":"docs/generated/ingestion/sources/mongodb"},{"type":"link","label":"MySQL","href":"/docs/1.1.0/generated/ingestion/sources/mysql","docId":"docs/generated/ingestion/sources/mysql"},{"type":"link","label":"Neo4j","href":"/docs/1.1.0/generated/ingestion/sources/neo4j","docId":"docs/generated/ingestion/sources/neo4j"},{"type":"link","label":"NiFi","href":"/docs/1.1.0/generated/ingestion/sources/nifi","docId":"docs/generated/ingestion/sources/nifi"},{"type":"link","label":"Okta","href":"/docs/1.1.0/generated/ingestion/sources/okta","docId":"docs/generated/ingestion/sources/okta"},{"type":"link","label":"OpenAPI","href":"/docs/1.1.0/generated/ingestion/sources/openapi","docId":"docs/generated/ingestion/sources/openapi"},{"type":"link","label":"Oracle","href":"/docs/1.1.0/generated/ingestion/sources/oracle","docId":"docs/generated/ingestion/sources/oracle"},{"type":"link","label":"Postgres","href":"/docs/1.1.0/generated/ingestion/sources/postgres","docId":"docs/generated/ingestion/sources/postgres"},{"type":"link","label":"PowerBI","href":"/docs/1.1.0/generated/ingestion/sources/powerbi","docId":"docs/generated/ingestion/sources/powerbi"},{"type":"link","label":"PowerBI Report Server","href":"/docs/1.1.0/generated/ingestion/sources/powerbi-report-server","docId":"docs/generated/ingestion/sources/powerbi-report-server"},{"type":"link","label":"Preset","href":"/docs/1.1.0/generated/ingestion/sources/preset","docId":"docs/generated/ingestion/sources/preset"},{"type":"link","label":"Presto","href":"/docs/1.1.0/generated/ingestion/sources/presto","docId":"docs/generated/ingestion/sources/presto"},{"type":"link","label":"Pulsar","href":"/docs/1.1.0/generated/ingestion/sources/pulsar","docId":"docs/generated/ingestion/sources/pulsar"},{"type":"link","label":"Qlik Sense","href":"/docs/1.1.0/generated/ingestion/sources/qlik-sense","docId":"docs/generated/ingestion/sources/qlik-sense"},{"type":"link","label":"Redash","href":"/docs/1.1.0/generated/ingestion/sources/redash","docId":"docs/generated/ingestion/sources/redash"},{"type":"link","label":"Redshift","href":"/docs/1.1.0/generated/ingestion/sources/redshift","docId":"docs/generated/ingestion/sources/redshift"},{"type":"link","label":"S3 / Local Files","href":"/docs/1.1.0/generated/ingestion/sources/s3","docId":"docs/generated/ingestion/sources/s3"},{"type":"link","label":"SageMaker","href":"/docs/1.1.0/generated/ingestion/sources/sagemaker","docId":"docs/generated/ingestion/sources/sagemaker"},{"type":"link","label":"Salesforce","href":"/docs/1.1.0/generated/ingestion/sources/salesforce","docId":"docs/generated/ingestion/sources/salesforce"},{"type":"link","label":"SAP Analytics Cloud","href":"/docs/1.1.0/generated/ingestion/sources/sac","docId":"docs/generated/ingestion/sources/sac"},{"type":"link","label":"SAP HANA","href":"/docs/1.1.0/generated/ingestion/sources/hana","docId":"docs/generated/ingestion/sources/hana"},{"type":"link","label":"Sigma","href":"/docs/1.1.0/generated/ingestion/sources/sigma","docId":"docs/generated/ingestion/sources/sigma"},{"type":"link","label":"Slack","href":"/docs/1.1.0/generated/ingestion/sources/slack","docId":"docs/generated/ingestion/sources/slack"},{"type":"link","label":"Snowflake","href":"/docs/1.1.0/generated/ingestion/sources/snowflake","docId":"docs/generated/ingestion/sources/snowflake"},{"type":"link","label":"SQL Queries","href":"/docs/1.1.0/generated/ingestion/sources/sql-queries","docId":"docs/generated/ingestion/sources/sql-queries"},{"type":"link","label":"SQLAlchemy","href":"/docs/1.1.0/generated/ingestion/sources/sqlalchemy","docId":"docs/generated/ingestion/sources/sqlalchemy"},{"type":"link","label":"Superset","href":"/docs/1.1.0/generated/ingestion/sources/superset","docId":"docs/generated/ingestion/sources/superset"},{"type":"link","label":"Tableau","href":"/docs/1.1.0/generated/ingestion/sources/tableau","docId":"docs/generated/ingestion/sources/tableau"},{"type":"link","label":"Teradata","href":"/docs/1.1.0/generated/ingestion/sources/teradata","docId":"docs/generated/ingestion/sources/teradata"},{"type":"link","label":"Trino","href":"/docs/1.1.0/generated/ingestion/sources/trino","docId":"docs/generated/ingestion/sources/trino"},{"type":"link","label":"Vertex AI","href":"/docs/1.1.0/generated/ingestion/sources/vertexai","docId":"docs/generated/ingestion/sources/vertexai"},{"type":"link","label":"Vertica","href":"/docs/1.1.0/generated/ingestion/sources/vertica","docId":"docs/generated/ingestion/sources/vertica"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/metadata-ingestion/source_overview"},{"type":"category","label":"Advanced Guides","items":[{"type":"category","label":"Scheduling Ingestion","items":[{"type":"link","label":"Introduction to Scheduling Metadata Ingestion","href":"/docs/1.1.0/metadata-ingestion/schedule_docs/intro","docId":"metadata-ingestion/schedule_docs/intro"},{"type":"link","label":"Using Cron","href":"/docs/1.1.0/metadata-ingestion/schedule_docs/cron","docId":"metadata-ingestion/schedule_docs/cron"},{"type":"link","label":"Using Airflow","href":"/docs/1.1.0/metadata-ingestion/schedule_docs/airflow","docId":"metadata-ingestion/schedule_docs/airflow"},{"type":"link","label":"Using Kubernetes","href":"/docs/1.1.0/metadata-ingestion/schedule_docs/kubernetes","docId":"metadata-ingestion/schedule_docs/kubernetes"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Working With Platform Instances","href":"/docs/1.1.0/platform-instances","docId":"docs/platform-instances"},{"type":"link","label":"SQL Parsing","href":"/docs/1.1.0/lineage/sql_parsing","docId":"docs/lineage/sql_parsing"},{"type":"link","label":"Stateful Ingestion","href":"/docs/1.1.0/metadata-ingestion/docs/dev_guides/stateful","docId":"metadata-ingestion/docs/dev_guides/stateful"},{"type":"link","label":"Classification","href":"/docs/1.1.0/metadata-ingestion/docs/dev_guides/classification","docId":"metadata-ingestion/docs/dev_guides/classification"},{"type":"link","label":"Adding Stateful Ingestion to a Source","href":"/docs/1.1.0/metadata-ingestion/docs/dev_guides/add_stateful_ingestion_to_source","docId":"metadata-ingestion/docs/dev_guides/add_stateful_ingestion_to_source"},{"type":"link","label":"SQL Profiling","href":"/docs/1.1.0/metadata-ingestion/docs/dev_guides/sql_profiles","docId":"metadata-ingestion/docs/dev_guides/sql_profiles"},{"type":"link","label":"Profiling ingestions","href":"/docs/1.1.0/metadata-ingestion/docs/dev_guides/profiling_ingestions","docId":"metadata-ingestion/docs/dev_guides/profiling_ingestions"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<div>API & SDKs</div>","defaultStyle":true},{"type":"category","label":"DataHub\'s Open Metadata Standard","items":[{"type":"link","label":"The Metadata Model","href":"/docs/1.1.0/metadata-modeling/metadata-model","docId":"docs/modeling/metadata-model"},{"type":"link","label":"Metadata Events","href":"/docs/1.1.0/what/mxe","docId":"docs/what/mxe"},{"type":"category","label":"Entities","items":[{"type":"link","label":"Data Platform","href":"/docs/1.1.0/generated/metamodel/entities/dataplatform","docId":"docs/generated/metamodel/entities/dataPlatform"},{"type":"link","label":"Role","href":"/docs/1.1.0/generated/metamodel/entities/role","docId":"docs/generated/metamodel/entities/role"},{"type":"link","label":"Dataset","href":"/docs/1.1.0/generated/metamodel/entities/dataset","docId":"docs/generated/metamodel/entities/dataset"},{"type":"link","label":"DataJob","href":"/docs/1.1.0/generated/metamodel/entities/datajob","docId":"docs/generated/metamodel/entities/dataJob"},{"type":"link","label":"DataFlow","href":"/docs/1.1.0/generated/metamodel/entities/dataflow","docId":"docs/generated/metamodel/entities/dataFlow"},{"type":"link","label":"DataProcess","href":"/docs/1.1.0/generated/metamodel/entities/dataprocess","docId":"docs/generated/metamodel/entities/dataProcess"},{"type":"link","label":"DataProcessInstance","href":"/docs/1.1.0/generated/metamodel/entities/dataprocessinstance","docId":"docs/generated/metamodel/entities/dataProcessInstance"},{"type":"link","label":"Chart","href":"/docs/1.1.0/generated/metamodel/entities/chart","docId":"docs/generated/metamodel/entities/chart"},{"type":"link","label":"Dashboard","href":"/docs/1.1.0/generated/metamodel/entities/dashboard","docId":"docs/generated/metamodel/entities/dashboard"},{"type":"link","label":"Notebook","href":"/docs/1.1.0/generated/metamodel/entities/notebook","docId":"docs/generated/metamodel/entities/notebook"},{"type":"link","label":"Corpuser","href":"/docs/1.1.0/generated/metamodel/entities/corpuser","docId":"docs/generated/metamodel/entities/corpuser"},{"type":"link","label":"CorpGroup","href":"/docs/1.1.0/generated/metamodel/entities/corpgroup","docId":"docs/generated/metamodel/entities/corpGroup"},{"type":"link","label":"Domain","href":"/docs/1.1.0/generated/metamodel/entities/domain","docId":"docs/generated/metamodel/entities/domain"},{"type":"link","label":"Container","href":"/docs/1.1.0/generated/metamodel/entities/container","docId":"docs/generated/metamodel/entities/container"},{"type":"link","label":"Tag","href":"/docs/1.1.0/generated/metamodel/entities/tag","docId":"docs/generated/metamodel/entities/tag"},{"type":"link","label":"GlossaryTerm","href":"/docs/1.1.0/generated/metamodel/entities/glossaryterm","docId":"docs/generated/metamodel/entities/glossaryTerm"},{"type":"link","label":"GlossaryNode","href":"/docs/1.1.0/generated/metamodel/entities/glossarynode","docId":"docs/generated/metamodel/entities/glossaryNode"},{"type":"link","label":"Assertion","href":"/docs/1.1.0/generated/metamodel/entities/assertion","docId":"docs/generated/metamodel/entities/assertion"},{"type":"link","label":"MlModel","href":"/docs/1.1.0/generated/metamodel/entities/mlmodel","docId":"docs/generated/metamodel/entities/mlModel"},{"type":"link","label":"MlModelGroup","href":"/docs/1.1.0/generated/metamodel/entities/mlmodelgroup","docId":"docs/generated/metamodel/entities/mlModelGroup"},{"type":"link","label":"MlModelDeployment","href":"/docs/1.1.0/generated/metamodel/entities/mlmodeldeployment","docId":"docs/generated/metamodel/entities/mlModelDeployment"},{"type":"link","label":"MlFeatureTable","href":"/docs/1.1.0/generated/metamodel/entities/mlfeaturetable","docId":"docs/generated/metamodel/entities/mlFeatureTable"},{"type":"link","label":"MlFeature","href":"/docs/1.1.0/generated/metamodel/entities/mlfeature","docId":"docs/generated/metamodel/entities/mlFeature"},{"type":"link","label":"MlPrimaryKey","href":"/docs/1.1.0/generated/metamodel/entities/mlprimarykey","docId":"docs/generated/metamodel/entities/mlPrimaryKey"},{"type":"link","label":"Test","href":"/docs/1.1.0/generated/metamodel/entities/test","docId":"docs/generated/metamodel/entities/test"},{"type":"link","label":"SchemaField","href":"/docs/1.1.0/generated/metamodel/entities/schemafield","docId":"docs/generated/metamodel/entities/schemaField"},{"type":"link","label":"VersionSet","href":"/docs/1.1.0/generated/metamodel/entities/versionset","docId":"docs/generated/metamodel/entities/versionSet"},{"type":"link","label":"Incident","href":"/docs/1.1.0/generated/metamodel/entities/incident","docId":"docs/generated/metamodel/entities/incident"},{"type":"link","label":"DataHubRole","href":"/docs/1.1.0/generated/metamodel/entities/datahubrole","docId":"docs/generated/metamodel/entities/dataHubRole"},{"type":"link","label":"Post","href":"/docs/1.1.0/generated/metamodel/entities/post","docId":"docs/generated/metamodel/entities/post"},{"type":"link","label":"DataHubView","href":"/docs/1.1.0/generated/metamodel/entities/datahubview","docId":"docs/generated/metamodel/entities/dataHubView"},{"type":"link","label":"ErModelRelationship","href":"/docs/1.1.0/generated/metamodel/entities/ermodelrelationship","docId":"docs/generated/metamodel/entities/erModelRelationship"},{"type":"link","label":"Query","href":"/docs/1.1.0/generated/metamodel/entities/query","docId":"docs/generated/metamodel/entities/query"},{"type":"link","label":"DataProduct","href":"/docs/1.1.0/generated/metamodel/entities/dataproduct","docId":"docs/generated/metamodel/entities/dataProduct"},{"type":"link","label":"OwnershipType","href":"/docs/1.1.0/generated/metamodel/entities/ownershiptype","docId":"docs/generated/metamodel/entities/ownershipType"},{"type":"link","label":"BusinessAttribute","href":"/docs/1.1.0/generated/metamodel/entities/businessattribute","docId":"docs/generated/metamodel/entities/businessAttribute"},{"type":"link","label":"DataContract","href":"/docs/1.1.0/generated/metamodel/entities/datacontract","docId":"docs/generated/metamodel/entities/dataContract"},{"type":"link","label":"EntityType","href":"/docs/1.1.0/generated/metamodel/entities/entitytype","docId":"docs/generated/metamodel/entities/entityType"},{"type":"link","label":"DataType","href":"/docs/1.1.0/generated/metamodel/entities/datatype","docId":"docs/generated/metamodel/entities/dataType"},{"type":"link","label":"StructuredProperty","href":"/docs/1.1.0/generated/metamodel/entities/structuredproperty","docId":"docs/generated/metamodel/entities/structuredProperty"},{"type":"link","label":"Form","href":"/docs/1.1.0/generated/metamodel/entities/form","docId":"docs/generated/metamodel/entities/form"},{"type":"link","label":"PlatformResource","href":"/docs/1.1.0/generated/metamodel/entities/platformresource","docId":"docs/generated/metamodel/entities/platformResource"},{"type":"link","label":"DataHubPolicy","href":"/docs/1.1.0/generated/metamodel/entities/datahubpolicy","docId":"docs/generated/metamodel/entities/dataHubPolicy"},{"type":"link","label":"DataHubIngestionSource","href":"/docs/1.1.0/generated/metamodel/entities/datahubingestionsource","docId":"docs/generated/metamodel/entities/dataHubIngestionSource"},{"type":"link","label":"DataHubSecret","href":"/docs/1.1.0/generated/metamodel/entities/datahubsecret","docId":"docs/generated/metamodel/entities/dataHubSecret"},{"type":"link","label":"DataHubExecutionRequest","href":"/docs/1.1.0/generated/metamodel/entities/datahubexecutionrequest","docId":"docs/generated/metamodel/entities/dataHubExecutionRequest"},{"type":"link","label":"DataHubRetention","href":"/docs/1.1.0/generated/metamodel/entities/datahubretention","docId":"docs/generated/metamodel/entities/dataHubRetention"},{"type":"link","label":"DataPlatformInstance","href":"/docs/1.1.0/generated/metamodel/entities/dataplatforminstance","docId":"docs/generated/metamodel/entities/dataPlatformInstance"},{"type":"link","label":"Telemetry","href":"/docs/1.1.0/generated/metamodel/entities/telemetry","docId":"docs/generated/metamodel/entities/telemetry"},{"type":"link","label":"DataHubAccessToken","href":"/docs/1.1.0/generated/metamodel/entities/datahubaccesstoken","docId":"docs/generated/metamodel/entities/dataHubAccessToken"},{"type":"link","label":"DataHubUpgrade","href":"/docs/1.1.0/generated/metamodel/entities/datahubupgrade","docId":"docs/generated/metamodel/entities/dataHubUpgrade"},{"type":"link","label":"InviteToken","href":"/docs/1.1.0/generated/metamodel/entities/invitetoken","docId":"docs/generated/metamodel/entities/inviteToken"},{"type":"link","label":"GlobalSettings","href":"/docs/1.1.0/generated/metamodel/entities/globalsettings","docId":"docs/generated/metamodel/entities/globalSettings"},{"type":"link","label":"DataHubStepState","href":"/docs/1.1.0/generated/metamodel/entities/datahubstepstate","docId":"docs/generated/metamodel/entities/dataHubStepState"},{"type":"link","label":"DataHubPersona","href":"/docs/1.1.0/generated/metamodel/entities/datahubpersona","docId":"docs/generated/metamodel/entities/dataHubPersona"},{"type":"link","label":"DataHubConnection","href":"/docs/1.1.0/generated/metamodel/entities/datahubconnection","docId":"docs/generated/metamodel/entities/dataHubConnection"},{"type":"link","label":"DataHubOpenAPISchema","href":"/docs/1.1.0/generated/metamodel/entities/datahubopenapischema","docId":"docs/generated/metamodel/entities/dataHubOpenAPISchema"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Concepts","href":"/docs/1.1.0/what-is-datahub/datahub-concepts","docId":"docs/what-is-datahub/datahub-concepts"},{"type":"category","label":"Metadata Standards","items":[{"type":"link","label":"Iceberg Catalog","href":"/docs/1.1.0/iceberg-catalog","docId":"docs/iceberg-catalog"},{"type":"link","label":"OpenLineage","href":"/docs/1.1.0/lineage/openlineage","docId":"docs/lineage/openlineage"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/metadata-standards"},{"type":"link","label":"APIs","href":"/docs/1.1.0/api/datahub-apis","docId":"docs/api/datahub-apis"},{"type":"category","label":"API","items":[{"type":"category","label":"GraphQL API","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/api/graphql/overview","docId":"docs/api/graphql/overview"},{"type":"category","label":"Reference","items":[{"type":"link","label":"Queries","href":"/docs/1.1.0/graphql/queries","docId":"graphql/queries"},{"type":"link","label":"Mutations","href":"/docs/1.1.0/graphql/mutations","docId":"graphql/mutations"},{"type":"link","label":"Objects","href":"/docs/1.1.0/graphql/objects","docId":"graphql/objects"},{"type":"link","label":"Inputs","href":"/docs/1.1.0/graphql/inputObjects","docId":"graphql/inputObjects"},{"type":"link","label":"Interfaces","href":"/docs/1.1.0/graphql/interfaces","docId":"graphql/interfaces"},{"type":"link","label":"Unions","href":"/docs/1.1.0/graphql/unions","docId":"graphql/unions"},{"type":"link","label":"Enums","href":"/docs/1.1.0/graphql/enums","docId":"graphql/enums"},{"type":"link","label":"Scalars","href":"/docs/1.1.0/graphql/scalars","docId":"graphql/scalars"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Guides","items":[{"type":"link","label":"How To Set Up GraphQL","href":"/docs/1.1.0/api/graphql/how-to-set-up-graphql","docId":"docs/api/graphql/how-to-set-up-graphql"},{"type":"link","label":"Getting Started With GraphQL","href":"/docs/1.1.0/api/graphql/getting-started","docId":"docs/api/graphql/getting-started"},{"type":"link","label":"GraphQL Best Practices","href":"/docs/1.1.0/api/graphql/graphql-best-practices","docId":"docs/api/graphql/graphql-best-practices"},{"type":"link","label":"Access Token Management","href":"/docs/1.1.0/api/graphql/token-management","docId":"docs/api/graphql/token-management"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"OpenAPI","items":[{"type":"link","label":"OpenAPI Guide","href":"/docs/1.1.0/api/openapi/openapi-usage-guide","docId":"docs/api/openapi/openapi-usage-guide"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Timeline API","href":"/docs/1.1.0/dev-guides/timeline","docId":"docs/dev-guides/timeline"},{"type":"category","label":"Rest.li API","items":[{"type":"link","label":"Rest.li API Guide","href":"/docs/1.1.0/api/restli/restli-overview","docId":"docs/api/restli/restli-overview"},{"type":"link","label":"Restore Indices","href":"/docs/1.1.0/api/restli/restore-indices","docId":"docs/api/restli/restore-indices"},{"type":"link","label":"Get Index Sizes","href":"/docs/1.1.0/api/restli/get-index-sizes","docId":"docs/api/restli/get-index-sizes"},{"type":"link","label":"Truncate Timeseries Aspect","href":"/docs/1.1.0/api/restli/truncate-time-series-aspect","docId":"docs/api/restli/truncate-time-series-aspect"},{"type":"link","label":"Get ElasticSearch Task Status Endpoint","href":"/docs/1.1.0/api/restli/get-elastic-task-status","docId":"docs/api/restli/get-elastic-task-status"},{"type":"link","label":"Evaluate Tests","href":"/docs/1.1.0/api/restli/evaluate-tests","docId":"docs/api/restli/evaluate-tests"},{"type":"link","label":"Aspect Versioning and Rest.li Modeling","href":"/docs/1.1.0/advanced/aspect-versioning","docId":"docs/advanced/aspect-versioning"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Python SDK","items":[{"type":"link","label":"Python Emitter","href":"/docs/1.1.0/metadata-ingestion/as-a-library","docId":"metadata-ingestion/as-a-library"},{"type":"category","label":"Python SDK Reference","items":[{"type":"link","label":"Builder","href":"/docs/1.1.0/python-sdk/builder","docId":"python-sdk/builder"},{"type":"link","label":"Client","href":"/docs/1.1.0/python-sdk/clients","docId":"python-sdk/clients"},{"type":"link","label":"Models","href":"/docs/1.1.0/python-sdk/models","docId":"python-sdk/models"},{"type":"link","label":"URNs","href":"/docs/1.1.0/python-sdk/urns","docId":"python-sdk/urns"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Java SDK","href":"/docs/1.1.0/metadata-integration/java/as-a-library","docId":"metadata-integration/java/as-a-library"},{"type":"category","label":"DataHub CLI","items":[{"type":"link","label":"Dataset Command","href":"/docs/1.1.0/cli-commands/dataset","docId":"docs/cli-commands/dataset"},{"type":"link","label":"Lite (Experimental)","href":"/docs/1.1.0/datahub_lite","docId":"docs/datahub_lite"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/cli"},{"type":"category","label":"DataHub Actions","items":[{"type":"link","label":"Introduction","href":"/docs/1.1.0/actions","docId":"docs/actions/README"},{"type":"link","label":"Quickstart","href":"/docs/1.1.0/actions/quickstart","docId":"docs/actions/quickstart"},{"type":"link","label":"Concepts","href":"/docs/1.1.0/actions/concepts","docId":"docs/actions/concepts"},{"type":"category","label":"Sources","items":[{"type":"link","label":"Cloud Event Source","href":"/docs/1.1.0/actions/sources/datahub-cloud-event-source","docId":"docs/actions/sources/datahub-cloud-event-source"},{"type":"link","label":"Kafka Event Source","href":"/docs/1.1.0/actions/sources/kafka-event-source","docId":"docs/actions/sources/kafka-event-source"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Events","items":[{"type":"link","label":"Audit Events Search API V1","href":"/docs/1.1.0/actions/events/audit-events-search-guide","docId":"docs/actions/events/audit-events-search-guide"},{"type":"link","label":"Entity Change Event V1","href":"/docs/1.1.0/actions/events/entity-change-event","docId":"docs/actions/events/entity-change-event"},{"type":"link","label":"Metadata Change Log Event V1","href":"/docs/1.1.0/actions/events/metadata-change-log-event","docId":"docs/actions/events/metadata-change-log-event"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Actions","items":[{"type":"link","label":"Ingestion Executor","href":"/docs/1.1.0/actions/actions/executor","docId":"docs/actions/actions/executor"},{"type":"link","label":"Hello World","href":"/docs/1.1.0/actions/actions/hello_world","docId":"docs/actions/actions/hello_world"},{"type":"link","label":"Slack","href":"/docs/1.1.0/actions/actions/slack","docId":"docs/actions/actions/slack"},{"type":"link","label":"Microsoft Teams","href":"/docs/1.1.0/actions/actions/teams","docId":"docs/actions/actions/teams"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Guides","items":[{"type":"link","label":"Developing a Transformer","href":"/docs/1.1.0/actions/guides/developing-a-transformer","docId":"docs/actions/guides/developing-a-transformer"},{"type":"link","label":"Developing an Action","href":"/docs/1.1.0/actions/guides/developing-an-action","docId":"docs/actions/guides/developing-an-action"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/act-on-metadata"},{"type":"category","label":"API & SDK Guides","items":[{"type":"link","label":"Dataset","href":"/docs/1.1.0/api/tutorials/datasets","docId":"docs/api/tutorials/datasets"},{"type":"link","label":"Deprecation","href":"/docs/1.1.0/api/tutorials/deprecation","docId":"docs/api/tutorials/deprecation"},{"type":"link","label":"Description","href":"/docs/1.1.0/api/tutorials/descriptions","docId":"docs/api/tutorials/descriptions"},{"type":"link","label":"Custom Properties","href":"/docs/1.1.0/api/tutorials/custom-properties","docId":"docs/api/tutorials/custom-properties"},{"type":"link","label":"Assertions","href":"/docs/1.1.0/api/tutorials/assertions","docId":"docs/api/tutorials/assertions"},{"type":"link","label":"Custom Assertions","href":"/docs/1.1.0/api/tutorials/custom-assertions","docId":"docs/api/tutorials/custom-assertions"},{"type":"link","label":"Incidents","href":"/docs/1.1.0/api/tutorials/incidents","docId":"docs/api/tutorials/incidents"},{"type":"link","label":"Operations","href":"/docs/1.1.0/api/tutorials/operations","docId":"docs/api/tutorials/operations"},{"type":"link","label":"Data Contracts","href":"/docs/1.1.0/api/tutorials/data-contracts","docId":"docs/api/tutorials/data-contracts"},{"type":"link","label":"Domains","href":"/docs/1.1.0/api/tutorials/domains","docId":"docs/api/tutorials/domains"},{"type":"link","label":"Compliance Forms","href":"/docs/1.1.0/api/tutorials/forms","docId":"docs/api/tutorials/forms"},{"type":"link","label":"Data Lineage","href":"/docs/1.1.0/api/tutorials/lineage","docId":"docs/api/tutorials/lineage"},{"type":"link","label":"AI/ML Integration","href":"/docs/1.1.0/api/tutorials/ml","docId":"docs/api/tutorials/ml"},{"type":"link","label":"Feature Store","href":"/docs/1.1.0/api/tutorials/ml_feature_store","docId":"docs/api/tutorials/ml_feature_store"},{"type":"link","label":"Ownership","href":"/docs/1.1.0/api/tutorials/owners","docId":"docs/api/tutorials/owners"},{"type":"link","label":"Structured Properties","href":"/docs/1.1.0/api/tutorials/structured-properties","docId":"docs/api/tutorials/structured-properties"},{"type":"link","label":"Tags","href":"/docs/1.1.0/api/tutorials/tags","docId":"docs/api/tutorials/tags"},{"type":"link","label":"Terms","href":"/docs/1.1.0/api/tutorials/terms","docId":"docs/api/tutorials/terms"},{"type":"link","label":"Patch","href":"/docs/1.1.0/advanced/patch","docId":"docs/advanced/patch"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<div>Admin</div>","defaultStyle":true},{"type":"category","label":"Authentication","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/authentication","docId":"docs/authentication/README"},{"type":"link","label":"Concepts & Key Components","href":"/docs/1.1.0/authentication/concepts","docId":"docs/authentication/concepts"},{"type":"link","label":"Changing the default user credentials","href":"/docs/1.1.0/authentication/changing-default-credentials","docId":"docs/authentication/changing-default-credentials"},{"type":"link","label":"Onboarding Users to DataHub","href":"/docs/1.1.0/authentication/guides/add-users","docId":"docs/authentication/guides/add-users"},{"type":"category","label":"Frontend Authentication","items":[{"type":"link","label":"JaaS Authentication","href":"/docs/1.1.0/authentication/guides/jaas","docId":"docs/authentication/guides/jaas"},{"type":"link","label":"Prerequisites for OIDC Authentication","href":"/docs/1.1.0/authentication/guides/sso/initialize-oidc","docId":"docs/authentication/guides/sso/initialize-oidc"},{"type":"link","label":"Configuring OIDC Authentication","href":"/docs/1.1.0/authentication/guides/sso/configure-oidc-react","docId":"docs/authentication/guides/sso/configure-oidc-react"},{"type":"link","label":"OIDC Proxy Configuration","href":"/docs/1.1.0/authentication/guides/sso/configure-oidc-behind-proxy","docId":"docs/authentication/guides/sso/configure-oidc-behind-proxy"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Metadata Service Authentication","href":"/docs/1.1.0/authentication/introducing-metadata-service-authentication","docId":"docs/authentication/introducing-metadata-service-authentication"},{"type":"link","label":"Personal Access Tokens","href":"/docs/1.1.0/authentication/personal-access-tokens","docId":"docs/authentication/personal-access-tokens"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Authorization","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/authorization","docId":"docs/authorization/README"},{"type":"link","label":"Roles","href":"/docs/1.1.0/authorization/roles","docId":"docs/authorization/roles"},{"type":"link","label":"Policies Guide","href":"/docs/1.1.0/authorization/policies","docId":"docs/authorization/policies"},{"type":"link","label":"Authorization using Groups","href":"/docs/1.1.0/authorization/groups","docId":"docs/authorization/groups"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Advanced Guides","items":[{"type":"link","label":"Removing Metadata from DataHub","href":"/docs/1.1.0/how/delete-metadata","docId":"docs/how/delete-metadata"},{"type":"link","label":"Configuring Authorization with Apache Ranger","href":"/docs/1.1.0/how/configuring-authorization-with-apache-ranger","docId":"docs/how/configuring-authorization-with-apache-ranger"},{"type":"category","label":"SCIM Provisioning","items":[{"type":"link","label":"SCIM Integration: MS Entra and DataHub","href":"/docs/1.1.0/managed-datahub/configuring-identity-provisioning-with-ms-entra","docId":"docs/managed-datahub/configuring-identity-provisioning-with-ms-entra"},{"type":"link","label":"SCIM Integration: Okta and DataHub","href":"/docs/1.1.0/managed-datahub/configuring-identity-provisioning-with-okta","docId":"docs/managed-datahub/configuring-identity-provisioning-with-okta"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Taking backup of DataHub","href":"/docs/1.1.0/how/backup-datahub","docId":"docs/how/backup-datahub"},{"type":"link","label":"Restoring Search and Graph Indices from Local Database","href":"/docs/1.1.0/how/restore-indices","docId":"docs/how/restore-indices"},{"type":"link","label":"Configuring Database Retention","href":"/docs/1.1.0/advanced/db-retention","docId":"docs/advanced/db-retention"},{"type":"link","label":"Monitoring DataHub","href":"/docs/1.1.0/advanced/monitoring","docId":"docs/advanced/monitoring"},{"type":"link","label":"Telemetry","href":"/docs/1.1.0/deploy/telemetry","docId":"docs/deploy/telemetry"},{"type":"link","label":"Configuring Kafka","href":"/docs/1.1.0/how/kafka-config","docId":"docs/how/kafka-config"},{"type":"link","label":"Debugging by Jattach","href":"/docs/1.1.0/how/jattach-guide","docId":"docs/how/jattach-guide"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<div>Deployment</div>","defaultStyle":true},{"type":"category","label":"Deployment Guides","items":[{"type":"link","label":"Deploying to AWS","href":"/docs/1.1.0/deploy/aws","docId":"docs/deploy/aws"},{"type":"link","label":"Deploying to GCP","href":"/docs/1.1.0/deploy/gcp","docId":"docs/deploy/gcp"},{"type":"link","label":"Deploying to Azure","href":"/docs/1.1.0/deploy/azure","docId":"docs/deploy/azure"},{"type":"link","label":"Deploying with Docker","href":"/docs/1.1.0/docker","docId":"docker/README"},{"type":"link","label":"Deploying with Kubernetes","href":"/docs/1.1.0/deploy/kubernetes","docId":"docs/deploy/kubernetes"}],"collapsed":true,"collapsible":true,"href":"/docs/1.1.0/category/deployment-guides"},{"type":"category","label":"Advanced Guides","items":[{"type":"link","label":"Integrating with Confluent Cloud","href":"/docs/1.1.0/deploy/confluent-cloud","docId":"docs/deploy/confluent-cloud"},{"type":"link","label":"Deployment Environment Variables","href":"/docs/1.1.0/deploy/environment-vars","docId":"docs/deploy/environment-vars"},{"type":"link","label":"How to Extract Logs from DataHub Containers","href":"/docs/1.1.0/how/extract-container-logs","docId":"docs/how/extract-container-logs"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<div>Developers</div>","defaultStyle":true},{"type":"category","label":"Architecture","items":[{"type":"link","label":"Overview","href":"/docs/1.1.0/architecture/architecture","docId":"docs/architecture/architecture"},{"type":"link","label":"Components","href":"/docs/1.1.0/components","docId":"docs/components"},{"type":"link","label":"Ingestion Framework","href":"/docs/1.1.0/architecture/metadata-ingestion","docId":"docs/architecture/metadata-ingestion"},{"type":"link","label":"Serving Tier","href":"/docs/1.1.0/architecture/metadata-serving","docId":"docs/architecture/metadata-serving"},{"type":"link","label":"Docker Container Architecture","href":"/docs/1.1.0/architecture/docker-containers","docId":"docs/architecture/docker-containers"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Developing on DataHub","items":[{"type":"link","label":"Local Development","href":"/docs/1.1.0/developers","docId":"docs/developers"},{"type":"link","label":"Using Docker Images During Development","href":"/docs/1.1.0/docker/development","docId":"docs/docker/development"},{"type":"link","label":"Developing on Metadata Ingestion","href":"/docs/1.1.0/metadata-ingestion/developing","docId":"metadata-ingestion/developing"},{"type":"link","label":"Creating a New GraphQL Endpoint in GMS","href":"/docs/1.1.0/api/graphql/graphql-endpoint-development","docId":"docs/api/graphql/graphql-endpoint-development"},{"type":"category","label":"Modules","items":[{"type":"link","label":"datahub-web-react","href":"/docs/1.1.0/datahub-web-react","docId":"datahub-web-react/README"},{"type":"link","label":"datahub-frontend","href":"/docs/1.1.0/datahub-frontend","docId":"datahub-frontend/README"},{"type":"link","label":"datahub-graphql-core","href":"/docs/1.1.0/datahub-graphql-core","docId":"datahub-graphql-core/README"},{"type":"link","label":"metadata-service","href":"/docs/1.1.0/metadata-service","docId":"metadata-service/README"},{"type":"link","label":"metadata-jobs:mae-consumer-job","href":"/docs/1.1.0/metadata-jobs/mae-consumer-job","docId":"metadata-jobs/mae-consumer-job/README"},{"type":"link","label":"metadata-jobs:mce-consumer-job","href":"/docs/1.1.0/metadata-jobs/mce-consumer-job","docId":"metadata-jobs/mce-consumer-job/README"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Troubleshooting","items":[{"type":"link","label":"Quickstart Debugging Guide","href":"/docs/1.1.0/troubleshooting/quickstart","docId":"docs/troubleshooting/quickstart"},{"type":"link","label":"Build Debugging Guide","href":"/docs/1.1.0/troubleshooting/build","docId":"docs/troubleshooting/build"},{"type":"link","label":"General Debugging Guide","href":"/docs/1.1.0/troubleshooting/general","docId":"docs/troubleshooting/general"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Advanced Guides","items":[{"type":"link","label":"MetadataChangeProposal & MetadataChangeLog Events","href":"/docs/1.1.0/advanced/mcp-mcl","docId":"docs/advanced/mcp-mcl"},{"type":"link","label":"Saving MCPs to a File","href":"/docs/1.1.0/advanced/writing-mcps","docId":"docs/advanced/writing-mcps"},{"type":"link","label":"Extending the Metadata Model","href":"/docs/1.1.0/metadata-modeling/extending-the-metadata-model","docId":"docs/modeling/extending-the-metadata-model"},{"type":"link","label":"API Tracing","href":"/docs/1.1.0/advanced/api-tracing","docId":"docs/advanced/api-tracing"},{"type":"link","label":"React Analytics","href":"/docs/1.1.0/datahub-web-react/src/app/analytics","docId":"datahub-web-react/src/app/analytics/README"},{"type":"link","label":"Upgrade Docker Image","href":"/docs/1.1.0/docker/datahub-upgrade","docId":"docker/datahub-upgrade/README"},{"type":"link","label":"Adding a Metadata Ingestion Source","href":"/docs/1.1.0/metadata-ingestion/adding-source","docId":"metadata-ingestion/adding-source"},{"type":"link","label":"Using a Custom Ingestion Source","href":"/docs/1.1.0/how/add-custom-ingestion-source","docId":"docs/how/add-custom-ingestion-source"},{"type":"link","label":"Adding a custom Dataset Data Platform","href":"/docs/1.1.0/how/add-custom-data-platform","docId":"docs/how/add-custom-data-platform"},{"type":"link","label":"Migrate Graph Service Implementation to Elasticsearch","href":"/docs/1.1.0/how/migrating-graph-service-implementation","docId":"docs/how/migrating-graph-service-implementation"},{"type":"link","label":"SchemaFieldPath Specification (Version 2)","href":"/docs/1.1.0/advanced/field-path-spec-v2","docId":"docs/advanced/field-path-spec-v2"},{"type":"link","label":"Browse Paths Upgrade (August 2022)","href":"/docs/1.1.0/advanced/browse-paths-upgrade","docId":"docs/advanced/browse-paths-upgrade"},{"type":"link","label":"Generating Browse Paths (V2)","href":"/docs/1.1.0/browsev2/browse-paths-v2","docId":"docs/browseV2/browse-paths-v2"},{"type":"link","label":"Datahub\'s Reporting Framework for Ingestion Job Telemetry","href":"/docs/1.1.0/metadata-ingestion/docs/dev_guides/reporting_telemetry","docId":"metadata-ingestion/docs/dev_guides/reporting_telemetry"},{"type":"link","label":"Plugins Guide","href":"/docs/1.1.0/plugins","docId":"docs/plugins"},{"type":"link","label":"Bootstrap MetadataChangeProposals (MCPs)","href":"/docs/1.1.0/advanced/bootstrap-mcps","docId":"docs/advanced/bootstrap-mcps"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<div>Community</div>","defaultStyle":true},{"label":"Community","type":"category","collapsed":true,"items":[{"type":"link","label":"Slack","href":"/docs/1.1.0/slack","docId":"docs/slack"},{"type":"link","label":"Town Halls","href":"/docs/1.1.0/townhalls","docId":"docs/townhalls"},{"type":"link","label":"Code of Conduct","href":"/docs/1.1.0/code_of_conduct","docId":"docs/CODE_OF_CONDUCT"},{"type":"link","label":"Contributing","href":"/docs/1.1.0/contributing","docId":"docs/CONTRIBUTING"},{"type":"link","label":"Articles & Talks","href":"/docs/1.1.0/links","docId":"docs/links"},{"type":"link","label":"RFC Process","href":"/docs/1.1.0/rfc","docId":"docs/rfc"},{"type":"link","label":"Reporting Security Issues","href":"/docs/1.1.0/security","docId":"SECURITY"}],"collapsible":true,"href":"/docs/1.1.0/category/community"},{"type":"category","label":"Release History","items":[{"type":"link","label":"Releases","href":"/docs/1.1.0/releases","docId":"releases"},{"type":"link","label":"Updating DataHub","href":"/docs/1.1.0/how/updating-datahub","docId":"docs/how/updating-datahub"}],"collapsed":true,"collapsible":true}]},"docs":{"datahub-actions/README":{"id":"datahub-actions/README","title":"\u26a1 DataHub Actions Framework","description":"Welcome to DataHub Actions! The Actions framework makes responding to realtime changes in your Metadata Graph easy, enabling you to seamlessly integrate DataHub into a broader events-based architecture."},"datahub-actions/src/datahub_actions/plugin/action/tag/README":{"id":"datahub-actions/src/datahub_actions/plugin/action/tag/README","title":"Tag Sync Action","description":"The Tag Sync (or Tag Propagation) Action allows you to propagate tags from your assets into downstream entities. e.g. You can apply a tag (like critical) on a dataset and have it propagate down to all the downstream datasets."},"datahub-actions/src/datahub_actions/plugin/action/term/README":{"id":"datahub-actions/src/datahub_actions/plugin/action/term/README","title":"Glossary Term Propagation Action","description":"The Glossary Term Propagation Action allows you to propagate glossary terms from your assets into downstream entities."},"datahub-frontend/README":{"id":"datahub-frontend/README","title":"datahub-frontend","description":"DataHub frontend is a Play service written in Java. It is served as a mid-tier","sidebar":"overviewSidebar"},"datahub-graphql-core/README":{"id":"datahub-graphql-core/README","title":"datahub-graphql-core","description":"DataHub GraphQL API is a shared lib module containing a GraphQL API on top of the GMS service layer. It exposes a graph-based representation","sidebar":"overviewSidebar"},"datahub-web-react/README":{"id":"datahub-web-react/README","title":"datahub-web-react","description":"About","sidebar":"overviewSidebar"},"datahub-web-react/src/app/analytics/README":{"id":"datahub-web-react/src/app/analytics/README","title":"DataHub React Analytics","description":"About","sidebar":"overviewSidebar"},"docker/airflow/local_airflow":{"id":"docker/airflow/local_airflow","title":"Running Airflow locally with DataHub","description":"This guide is currently unmaintained. As of 0.10.0 the container described is not published alongside the DataHub CLI. If you\'d like to use it, please reach out to us on the community slack."},"docker/datahub-upgrade/README":{"id":"docker/datahub-upgrade/README","title":"DataHub Upgrade Docker Image","description":"This container is used to automatically apply upgrades from one version of DataHub to another.","sidebar":"overviewSidebar"},"docker/README":{"id":"docker/README","title":"Deploying with Docker","description":"Prerequisites","sidebar":"overviewSidebar"},"docs/act-on-metadata":{"id":"docs/act-on-metadata","title":"Act on Metadata Overview","description":"DataHub\'s metadata infrastructure is stream-oriented, meaning that all changes in metadata are communicated and reflected within the platform within seconds.","sidebar":"overviewSidebar"},"docs/act-on-metadata/impact-analysis":{"id":"docs/act-on-metadata/impact-analysis","title":"Lineage Impact Analysis","description":"Lineage Impact Analysis is a powerful workflow for understanding the complete set of upstream and downstream dependencies of a Dataset, Dashboard, Chart, and many other DataHub Entities.","sidebar":"overviewSidebar"},"docs/actions/actions/executor":{"id":"docs/actions/actions/executor","title":"Ingestion Executor","description":"Certified","sidebar":"overviewSidebar"},"docs/actions/actions/hello_world":{"id":"docs/actions/actions/hello_world","title":"Hello World","description":"Certified","sidebar":"overviewSidebar"},"docs/actions/actions/slack":{"id":"docs/actions/actions/slack","title":"Slack","description":"|                  |                                                                                               |","sidebar":"overviewSidebar"},"docs/actions/actions/teams":{"id":"docs/actions/actions/teams","title":"Microsoft Teams","description":"|                  |                                                                                               |","sidebar":"overviewSidebar"},"docs/actions/concepts":{"id":"docs/actions/concepts","title":"Concepts","description":"The Actions framework includes pluggable components for filtering, transforming, and reacting to important DataHub, such as","sidebar":"overviewSidebar"},"docs/actions/events/audit-events-search-guide":{"id":"docs/actions/events/audit-events-search-guide","title":"Audit Events Search API V1","description":"Endpoint","sidebar":"overviewSidebar"},"docs/actions/events/entity-change-event":{"id":"docs/actions/events/entity-change-event","title":"Entity Change Event V1","description":"Event Type","sidebar":"overviewSidebar"},"docs/actions/events/metadata-change-log-event":{"id":"docs/actions/events/metadata-change-log-event","title":"Metadata Change Log Event V1","description":"Event Type","sidebar":"overviewSidebar"},"docs/actions/guides/developing-a-transformer":{"id":"docs/actions/guides/developing-a-transformer","title":"Developing a Transformer","description":"In this guide, we will outline each step to developing a custom Transformer for the DataHub Actions Framework.","sidebar":"overviewSidebar"},"docs/actions/guides/developing-an-action":{"id":"docs/actions/guides/developing-an-action","title":"Developing an Action","description":"In this guide, we will outline each step to developing a Action for the DataHub Actions Framework.","sidebar":"overviewSidebar"},"docs/actions/quickstart":{"id":"docs/actions/quickstart","title":"Quickstart","description":"Prerequisites","sidebar":"overviewSidebar"},"docs/actions/README":{"id":"docs/actions/README","title":"Introduction","description":"Welcome to DataHub Actions! The Actions framework makes responding to realtime changes in your Metadata Graph easy, enabling you to seamlessly integrate DataHub into a broader events-based architecture.","sidebar":"overviewSidebar"},"docs/actions/sources/datahub-cloud-event-source":{"id":"docs/actions/sources/datahub-cloud-event-source","title":"DataHub Cloud Event Source","description":"Prerequisites","sidebar":"overviewSidebar"},"docs/actions/sources/kafka-event-source":{"id":"docs/actions/sources/kafka-event-source","title":"Kafka Event Source","description":"Overview","sidebar":"overviewSidebar"},"docs/advanced/api-tracing":{"id":"docs/advanced/api-tracing","title":"API Tracing","description":"Introduction","sidebar":"overviewSidebar"},"docs/advanced/aspect-versioning":{"id":"docs/advanced/aspect-versioning","title":"Aspect Versioning","description":"As each version of metadata aspect is immutable, any update to an existing aspect results in the creation of a new version. Typically one would expect the version number increases sequentially with the largest version number being the latest version, i.e. v1 (oldest), v2 (second oldest), ..., vN (latest). However, this approach results in major challenges in both rest.li modeling & transaction isolation and therefore requires a rethinking.","sidebar":"overviewSidebar"},"docs/advanced/backfilling":{"id":"docs/advanced/backfilling","title":"Backfilling Search Index & Graph DB","description":"WIP"},"docs/advanced/bootstrap-mcps":{"id":"docs/advanced/bootstrap-mcps","title":"Bootstrap MetadataChangeProposals (MCPs)","description":"Bootstrap MCPs are templated MCPs which are loaded when the system-update job runs. This allows adding","sidebar":"overviewSidebar"},"docs/advanced/browse-paths-upgrade":{"id":"docs/advanced/browse-paths-upgrade","title":"Browse Paths Upgrade (August 2022)","description":"Background","sidebar":"overviewSidebar"},"docs/advanced/db-retention":{"id":"docs/advanced/db-retention","title":"Configuring Database Retention","description":"Goal","sidebar":"overviewSidebar"},"docs/advanced/derived-aspects":{"id":"docs/advanced/derived-aspects","title":"Derived Aspects","description":"WIP"},"docs/advanced/entity-hierarchy":{"id":"docs/advanced/entity-hierarchy","title":"Entity Hierarchy","description":"WIP"},"docs/advanced/field-path-spec-v2":{"id":"docs/advanced/field-path-spec-v2","title":"SchemaFieldPath Specification (Version 2)","description":"This document outlines the formal specification for the fieldPath member of","sidebar":"overviewSidebar"},"docs/advanced/high-cardinality":{"id":"docs/advanced/high-cardinality","title":"High Cardinality Relationships","description":"As explained in What is a Relationship, the raw metadata for forming relationships is captured directly inside of a Metadata Aspect. The most natural way to model this is using an array, e.g. a group membership aspect contains an array of user URNs. However, this poses some challenges when the cardinality of the relationship is expected to be large (say, greater than 10,000). The aspect becomes large in size, which leads to slow update and retrieval. It may even exceed the underlying limit of the document store, which is often in the range of a few MBs. Furthermore, sending large messages (> 1MB) over Kafka requires special tuning and is generally discouraged."},"docs/advanced/mcp-mcl":{"id":"docs/advanced/mcp-mcl","title":"MetadataChangeProposal & MetadataChangeLog Events","description":"Overview & Vision","sidebar":"overviewSidebar"},"docs/advanced/monitoring":{"id":"docs/advanced/monitoring","title":"Monitoring DataHub","description":"Monitoring DataHub\'s system components is critical for operating and improving DataHub. This doc explains how to add","sidebar":"overviewSidebar"},"docs/advanced/partial-update":{"id":"docs/advanced/partial-update","title":"Supporting Partial Aspect Update","description":"WIP"},"docs/advanced/patch":{"id":"docs/advanced/patch","title":"Emitting Patch Updates to DataHub","description":"Why Would You Use Patch","sidebar":"overviewSidebar"},"docs/advanced/pdl-best-practices":{"id":"docs/advanced/pdl-best-practices","title":"PDL Best Practices","description":"WIP"},"docs/advanced/writing-mcps":{"id":"docs/advanced/writing-mcps","title":"Saving MCPs to a File","description":"What is an MCP?","sidebar":"overviewSidebar"},"docs/api/datahub-apis":{"id":"docs/api/datahub-apis","title":"DataHub APIs","description":"DataHub has several APIs to manipulate metadata on the platform. Here\'s the list of APIs and their pros and cons to help you choose the right one for your use case.","sidebar":"overviewSidebar"},"docs/api/graphql/getting-started":{"id":"docs/api/graphql/getting-started","title":"Getting Started With GraphQL","description":"Reading an Entity: Queries","sidebar":"overviewSidebar"},"docs/api/graphql/graphql-best-practices":{"id":"docs/api/graphql/graphql-best-practices","title":"GraphQL Best Practices","description":"Introduction:","sidebar":"overviewSidebar"},"docs/api/graphql/graphql-endpoint-development":{"id":"docs/api/graphql/graphql-endpoint-development","title":"Creating a New GraphQL Endpoint in GMS","description":"This guide will walk you through how to add a new GraphQL endpoint in GMS.","sidebar":"overviewSidebar"},"docs/api/graphql/how-to-set-up-graphql":{"id":"docs/api/graphql/how-to-set-up-graphql","title":"How To Set Up GraphQL","description":"Preparing Local Datahub Deployment","sidebar":"overviewSidebar"},"docs/api/graphql/overview":{"id":"docs/api/graphql/overview","title":"DataHub GraphQL API","description":"DataHub provides a rich graphql API for programmatically interacting with the Entities & Relationships comprising your organization\'s Metadata Graph.","sidebar":"overviewSidebar"},"docs/api/graphql/token-management":{"id":"docs/api/graphql/token-management","title":"Access Token Management","description":"DataHub provides the following graphql endpoints for managing Access Tokens. In this page you will see examples as well","sidebar":"overviewSidebar"},"docs/api/openapi/openapi-usage-guide":{"id":"docs/api/openapi/openapi-usage-guide","title":"DataHub OpenAPI Guide","description":"Why OpenAPI","sidebar":"overviewSidebar"},"docs/api/restli/evaluate-tests":{"id":"docs/api/restli/evaluate-tests","title":"Evaluate Tests Endpoint","description":"You can do a HTTP POST request to /gms/test?action=evaluate endpoint with the urn as part of JSON Payload to run metadata tests for the particular URN.","sidebar":"overviewSidebar"},"docs/api/restli/get-elastic-task-status":{"id":"docs/api/restli/get-elastic-task-status","title":"Get ElasticSearch Task Status Endpoint","description":"You can do a HTTP POST request to /gms/operations?action=getEsTaskStatus endpoint to see the status of the input task running in ElasticSearch. For example, the task ID given by the truncateTimeseriesAspect endpoint. The task ID can be passed in as a string with node name and task ID separated by a colon (as is output by the previous API), or the node name and task ID parameters separately.","sidebar":"overviewSidebar"},"docs/api/restli/get-index-sizes":{"id":"docs/api/restli/get-index-sizes","title":"Get Index Sizes Endpoint","description":"You can do a HTTP POST request to /gms/operations?action=getIndexSizes endpoint with no parameters to see the size of indices in ElasticSearch. For now, only timeseries indices are supported, as they can grow indefinitely, and the truncateTimeseriesAspect endpoint is provided to clean up old entries. This endpoint can be used in conjunction with the cleanup endpoint to see which indices are the largest before truncation.","sidebar":"overviewSidebar"},"docs/api/restli/restli-overview":{"id":"docs/api/restli/restli-overview","title":"Rest.li API","description":"You can access basic documentation on the API endpoints by opening the /restli/docs endpoint in the browser.","sidebar":"overviewSidebar"},"docs/api/restli/restore-indices":{"id":"docs/api/restli/restore-indices","title":"Restore Indices Endpoint","description":"You can do a HTTP POST request to /gms/operations?action=restoreIndices endpoint with the urn as part of JSON Payload to restore indices for the particular URN, or with the urnLike regex to restore for batchSize URNs matching the pattern starting from start.","sidebar":"overviewSidebar"},"docs/api/restli/truncate-time-series-aspect":{"id":"docs/api/restli/truncate-time-series-aspect","title":"Truncate Timeseries Index Endpoint","description":"You can do a HTTP POST request to /gms/operations?action=truncateTimeseriesAspect endpoint to manage the size of a time series index by removing entries older than a certain timestamp, thereby truncating the table to only the entries needed, to save space. The getIndexSizes endpoint can be used to identify the largest indices. The output includes the index parameters needed for this function.","sidebar":"overviewSidebar"},"docs/api/tutorials/assertions":{"id":"docs/api/tutorials/assertions","title":"Assertions","description":"This guide specifically covers how to use the Assertion APIs for DataHub Cloud native assertions, including:","sidebar":"overviewSidebar"},"docs/api/tutorials/custom-assertions":{"id":"docs/api/tutorials/custom-assertions","title":"Custom Assertions","description":"This guide specifically covers how to create and report results for custom assertions in DataHub.","sidebar":"overviewSidebar"},"docs/api/tutorials/custom-properties":{"id":"docs/api/tutorials/custom-properties","title":"Custom Properties","description":"Why Would You Use Custom Properties on Datasets?","sidebar":"overviewSidebar"},"docs/api/tutorials/data-contracts":{"id":"docs/api/tutorials/data-contracts","title":"Data Contracts","description":"This guide specifically covers how to use the Data Contract APIs with DataHub Cloud.","sidebar":"overviewSidebar"},"docs/api/tutorials/datasets":{"id":"docs/api/tutorials/datasets","title":"Dataset","description":"Why Would You Use Datasets?","sidebar":"overviewSidebar"},"docs/api/tutorials/deprecation":{"id":"docs/api/tutorials/deprecation","title":"Deprecation","description":"Why Would You Deprecate Datasets?","sidebar":"overviewSidebar"},"docs/api/tutorials/descriptions":{"id":"docs/api/tutorials/descriptions","title":"Description","description":"Why Would You Use Description on Dataset?","sidebar":"overviewSidebar"},"docs/api/tutorials/domains":{"id":"docs/api/tutorials/domains","title":"Domains","description":"Why Would You Use Domains?","sidebar":"overviewSidebar"},"docs/api/tutorials/forms":{"id":"docs/api/tutorials/forms","title":"Compliance Forms","description":"Why Would You Use Compliance Forms?","sidebar":"overviewSidebar"},"docs/api/tutorials/incidents":{"id":"docs/api/tutorials/incidents","title":"Incidents","description":"Why Would You Use Incidents APIs?","sidebar":"overviewSidebar"},"docs/api/tutorials/lineage":{"id":"docs/api/tutorials/lineage","title":"Data Lineage","description":"Why Would You Use Lineage?","sidebar":"overviewSidebar"},"docs/api/tutorials/ml":{"id":"docs/api/tutorials/ml","title":"AI/ML Framework Integration with DataHub","description":"Why Integrate Your AI/ML System with DataHub?","sidebar":"overviewSidebar"},"docs/api/tutorials/ml_feature_store":{"id":"docs/api/tutorials/ml_feature_store","title":"Feature Store Integration With DataHub","description":"Why Would You Integrate Feature Store with DataHub?","sidebar":"overviewSidebar"},"docs/api/tutorials/operations":{"id":"docs/api/tutorials/operations","title":"Operations","description":"Why Would You Use Operations APIs?","sidebar":"overviewSidebar"},"docs/api/tutorials/owners":{"id":"docs/api/tutorials/owners","title":"Ownership","description":"Why Would You Use Users and Groups?","sidebar":"overviewSidebar"},"docs/api/tutorials/structured-properties":{"id":"docs/api/tutorials/structured-properties","title":"Structured Properties","description":"Why Would You Use Structured Properties?","sidebar":"overviewSidebar"},"docs/api/tutorials/tags":{"id":"docs/api/tutorials/tags","title":"Tags","description":"Why Would You Use Tags on Datasets?","sidebar":"overviewSidebar"},"docs/api/tutorials/terms":{"id":"docs/api/tutorials/terms","title":"Terms","description":"Why Would You Use Terms on Datasets?","sidebar":"overviewSidebar"},"docs/architecture/architecture":{"id":"docs/architecture/architecture","title":"Overview","description":"DataHub is a 3rd generation data catalog that enables Data Discovery, Collaboration, Governance, and end-to-end Observability","sidebar":"overviewSidebar"},"docs/architecture/docker-containers":{"id":"docs/architecture/docker-containers","title":"Docker Container Architecture","description":"When running DataHub via docker-compose. or helm, the following is a diagram of the containers involved","sidebar":"overviewSidebar"},"docs/architecture/metadata-ingestion":{"id":"docs/architecture/metadata-ingestion","title":"Ingestion Framework","description":"DataHub supports an extremely flexible ingestion architecture that can support push, pull, asynchronous and synchronous models.","sidebar":"overviewSidebar"},"docs/architecture/metadata-serving":{"id":"docs/architecture/metadata-serving","title":"Serving Tier","description":"The figure below shows the high-level system diagram for DataHub\'s Serving Tier.","sidebar":"overviewSidebar"},"docs/assertions/open-assertions-spec":{"id":"docs/assertions/open-assertions-spec","title":"DataHub Open Data Quality Assertions Specification","description":"DataHub is developing an open-source Data Quality Assertions Specification & Compiler that will allow you to declare data quality checks / expectations / assertions using a simple, universal","sidebar":"overviewSidebar"},"docs/assertions/snowflake/snowflake_dmfs":{"id":"docs/assertions/snowflake/snowflake_dmfs","title":"Snowflake DMF Assertions [BETA]","description":"The DataHub Open Assertion Compiler allows you to define your Data Quality assertions in a simple YAML format, and then compile them to be executed by Snowflake Data Metric Functions.","sidebar":"overviewSidebar"},"docs/authentication/changing-default-credentials":{"id":"docs/authentication/changing-default-credentials","title":"Changing the default user credentials","description":"Default User Credential","sidebar":"overviewSidebar"},"docs/authentication/concepts":{"id":"docs/authentication/concepts","title":"Concepts & Key Components","description":"We introduced a few important concepts to the Metadata Service to make authentication work:","sidebar":"overviewSidebar"},"docs/authentication/guides/add-users":{"id":"docs/authentication/guides/add-users","title":"Onboarding Users to DataHub","description":"New user accounts can be provisioned on DataHub in 3 ways:","sidebar":"overviewSidebar"},"docs/authentication/guides/jaas":{"id":"docs/authentication/guides/jaas","title":"JaaS Authentication","description":"Overview","sidebar":"overviewSidebar"},"docs/authentication/guides/sso/configure-oidc-behind-proxy":{"id":"docs/authentication/guides/sso/configure-oidc-behind-proxy","title":"OIDC Proxy Configuration","description":"Authored on 22/08/2023","sidebar":"overviewSidebar"},"docs/authentication/guides/sso/configure-oidc-react":{"id":"docs/authentication/guides/sso/configure-oidc-react","title":"Configuring OIDC Authentication","description":"The DataHub React application supports OIDC authentication built on top of the Pac4j Play library.","sidebar":"overviewSidebar"},"docs/authentication/guides/sso/initialize-oidc":{"id":"docs/authentication/guides/sso/initialize-oidc","title":"Prerequisites for OIDC Authentication","description":"This guide will walk you through the following steps with your identity provider:","sidebar":"overviewSidebar"},"docs/authentication/introducing-metadata-service-authentication":{"id":"docs/authentication/introducing-metadata-service-authentication","title":"Metadata Service Authentication","description":"Introduction","sidebar":"overviewSidebar"},"docs/authentication/personal-access-tokens":{"id":"docs/authentication/personal-access-tokens","title":"Personal Access Tokens","description":"Personal Access Tokens, or PATs for short, allow users to represent themselves in code and programmatically use DataHub\'s APIs in deployments where security is a concern.","sidebar":"overviewSidebar"},"docs/authentication/README":{"id":"docs/authentication/README","title":"Overview","description":"Authentication is the process of verifying the identity of a user or service. There are two","sidebar":"overviewSidebar"},"docs/authorization/access-policies-guide":{"id":"docs/authorization/access-policies-guide","title":"Access Policies","description":"Access Policies define who can do what to which resources. In conjunction with Roles, Access Policies determine what users are allowed to do on DataHub.","sidebar":"overviewSidebar"},"docs/authorization/groups":{"id":"docs/authorization/groups","title":"Authorization using Groups","description":"Introduction","sidebar":"overviewSidebar"},"docs/authorization/policies":{"id":"docs/authorization/policies","title":"Policies Guide","description":"Introduction","sidebar":"overviewSidebar"},"docs/authorization/README":{"id":"docs/authorization/README","title":"Overview","description":"Authorization specifies what accesses an authenticated user has within a system.","sidebar":"overviewSidebar"},"docs/authorization/roles":{"id":"docs/authorization/roles","title":"Roles","description":"DataHub provides the ability to use Roles to manage permissions.","sidebar":"overviewSidebar"},"docs/automations/ai-docs":{"id":"docs/automations/ai-docs","title":"AI Documentation","description":"This feature is currently in closed beta. Reach out to your DataHub Cloud representative to get access.","sidebar":"overviewSidebar"},"docs/automations/ai-term-suggestion":{"id":"docs/automations/ai-term-suggestion","title":"AI Glossary Term Suggestions","description":"This feature is currently in closed beta. Reach out to your DataHub Cloud representative to get access.","sidebar":"overviewSidebar"},"docs/automations/bigquery-metadata-sync":{"id":"docs/automations/bigquery-metadata-sync","title":"BigQuery Metadata Sync Automation","description":"This feature is currently in open beta in DataHub Cloud. Reach out to your DataHub Cloud representative to get access.","sidebar":"overviewSidebar"},"docs/automations/docs-propagation":{"id":"docs/automations/docs-propagation","title":"Documentation Propagation Automation","description":"This feature is currently in open beta in DataHub Cloud. Reach out to your DataHub Cloud representative to get access.","sidebar":"overviewSidebar"},"docs/automations/glossary-term-propagation":{"id":"docs/automations/glossary-term-propagation","title":"Glossary Term Propagation Automation","description":"This feature is currently in open beta in DataHub Cloud. Reach out to your DataHub Cloud representative to get access.","sidebar":"overviewSidebar"},"docs/automations/snowflake-tag-propagation":{"id":"docs/automations/snowflake-tag-propagation","title":"Snowflake Tag Propagation Automation","description":"This feature is currently in open beta in DataHub Cloud. Reach out to your DataHub Cloud representative to get access.","sidebar":"overviewSidebar"},"docs/browseV2/browse-paths-v2":{"id":"docs/browseV2/browse-paths-v2","title":"Generating Browse Paths (V2)","description":"Introduction","sidebar":"overviewSidebar"},"docs/businessattributes":{"id":"docs/businessattributes","title":"Business Attributes","description":"Note: This is BETA feature","sidebar":"overviewSidebar"},"docs/cli":{"id":"docs/cli","title":"DataHub CLI","description":"DataHub comes with a friendly cli called datahub that allows you to perform a lot of common operations using just the command line. DataHub maintains the pypi package for datahub.","sidebar":"overviewSidebar"},"docs/cli-commands/dataset":{"id":"docs/cli-commands/dataset","title":"DataHub Dataset Command","description":"The dataset command allows you to interact with Dataset entities in DataHub. This includes creating, updating, retrieving, validating, and synchronizing Dataset metadata.","sidebar":"overviewSidebar"},"docs/CODE_OF_CONDUCT":{"id":"docs/CODE_OF_CONDUCT","title":"Code of Conduct","description":"Our Pledge","sidebar":"overviewSidebar"},"docs/components":{"id":"docs/components","title":"Components","description":"The DataHub platform consists of the components shown in the following diagram.","sidebar":"overviewSidebar"},"docs/CONTRIBUTING":{"id":"docs/CONTRIBUTING","title":"Contributing","description":"We always welcome contributions to help make DataHub better. Take a moment to read this document if you would like to contribute.","sidebar":"overviewSidebar"},"docs/datahub_lite":{"id":"docs/datahub_lite","title":"DataHub Lite (Experimental)","description":"What is it?","sidebar":"overviewSidebar"},"docs/dataproducts":{"id":"docs/dataproducts","title":"Data Products","description":"\ud83e\udd1d Version compatibility","sidebar":"overviewSidebar"},"docs/deploy/aws":{"id":"docs/deploy/aws","title":"Deploying to AWS","description":"The following is a set of instructions to quickstart DataHub on AWS Elastic Kubernetes Service (EKS). Note, the guide","sidebar":"overviewSidebar"},"docs/deploy/azure":{"id":"docs/deploy/azure","title":"Deploying to Azure","description":"The following is a set of instructions to quickstart DataHub on Azure Kubernetes Service (AKS). Note, the guide","sidebar":"overviewSidebar"},"docs/deploy/confluent-cloud":{"id":"docs/deploy/confluent-cloud","title":"Integrating with Confluent Cloud","description":"DataHub provides the ability to easily leverage Confluent Cloud as your Kafka provider. To do so, you\'ll need to configure DataHub to talk to a broker and schema registry hosted by Confluent.","sidebar":"overviewSidebar"},"docs/deploy/environment-vars":{"id":"docs/deploy/environment-vars","title":"Deployment Environment Variables","description":"The following is a summary of a few important environment variables which expose various levers which control how","sidebar":"overviewSidebar"},"docs/deploy/gcp":{"id":"docs/deploy/gcp","title":"Deploying to GCP","description":"The following is a set of instructions to quickstart DataHub on GCP Google Kubernetes Engine (GKE). Note, the guide","sidebar":"overviewSidebar"},"docs/deploy/kubernetes":{"id":"docs/deploy/kubernetes","title":"Deploying with Kubernetes","description":"Introduction","sidebar":"overviewSidebar"},"docs/deploy/telemetry":{"id":"docs/deploy/telemetry","title":"DataHub Telemetry","description":"Overview of DataHub Telemetry","sidebar":"overviewSidebar"},"docs/dev-guides/timeline":{"id":"docs/dev-guides/timeline","title":"Timeline API","description":"The Timeline API supports viewing version history of schemas, documentation, tags, glossary terms, and other updates","sidebar":"overviewSidebar"},"docs/developers":{"id":"docs/developers","title":"Local Development","description":"Requirements","sidebar":"overviewSidebar"},"docs/docker/development":{"id":"docs/docker/development","title":"Using Docker Images During Development","description":"We\'ve created a special docker-compose.dev.yml override file that should configure docker images to be easier to use","sidebar":"overviewSidebar"},"docs/domains":{"id":"docs/domains","title":"Domains","description":"Starting in version 0.8.25, DataHub supports grouping data assets into logical collections called Domains. Domains are curated, top-level folders or categories where related assets can be explicitly grouped. Management of Domains can be centralized, or distributed out to Domain owners Currently, an asset can belong to only one Domain at a time.","sidebar":"overviewSidebar"},"docs/features":{"id":"docs/features","title":"What is DataHub?","description":"DataHub is a modern data catalog designed to streamline metadata management, data discovery, and data governance. It enables users to efficiently explore and understand their data, track data lineage, profile datasets, and establish data contracts.","sidebar":"overviewSidebar"},"docs/features/dataset-usage-and-query-history":{"id":"docs/features/dataset-usage-and-query-history","title":"Dataset Usage & Query History","description":"Dataset Usage & Query History can give dataset-level information about the top queries which referenced a dataset.","sidebar":"overviewSidebar"},"docs/features/feature-guides/access-management":{"id":"docs/features/feature-guides/access-management","title":"Access Management","description":"Introduction","sidebar":"overviewSidebar"},"docs/features/feature-guides/compliance-forms/analytics":{"id":"docs/features/feature-guides/compliance-forms/analytics","title":"Form Analytics","description":"DataHub Cloud provides out-of-the-box analytics to help you monitor and track the success of your Compliance Form initiatives. This guide will walk you through the available reporting views and how to leverage them effectively.","sidebar":"overviewSidebar"},"docs/features/feature-guides/compliance-forms/complete-a-form":{"id":"docs/features/feature-guides/compliance-forms/complete-a-form","title":"Complete a Form","description":"Once a Compliance Form has been published (see Create a Compliance Form), Assignees will receive notifications in their Task Center prompting them to complete the Form for each Asset they are responsible for.","sidebar":"overviewSidebar"},"docs/features/feature-guides/compliance-forms/create-a-form":{"id":"docs/features/feature-guides/compliance-forms/create-a-form","title":"Create a Form","description":"This guide will walk you through creating and assigning Compliance Forms, including:","sidebar":"overviewSidebar"},"docs/features/feature-guides/compliance-forms/overview":{"id":"docs/features/feature-guides/compliance-forms/overview","title":"Overview","description":"DataHub Compliance Forms streamline the process of documenting, annotating, and classifying your most critical Data Assets through a collaborative, crowdsourced approach.","sidebar":"overviewSidebar"},"docs/features/feature-guides/properties/create-a-property":{"id":"docs/features/feature-guides/properties/create-a-property","title":"Create and Add a Structured Property","description":"This guide walks you through creating a Structured Property via the DataHub UI, including:","sidebar":"overviewSidebar"},"docs/features/feature-guides/properties/overview":{"id":"docs/features/feature-guides/properties/overview","title":"Overview","description":"DataHub Structured Properties allow you to add custom, validated properties to any Entity type in DataHub. Using Structured Properties, you can enable data discovery and governance based on attributes unique to your organization.","sidebar":"overviewSidebar"},"docs/features/feature-guides/ui-lineage":{"id":"docs/features/feature-guides/ui-lineage","title":"Managing Data Lineage via UI","description":"Viewing Data Lineage","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/abs":{"id":"docs/generated/ingestion/sources/abs","title":"ABS Data Lake","description":"This connector ingests Azure Blob Storage (abbreviated to abs) datasets into DataHub. It allows mapping an individual","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/athena":{"id":"docs/generated/ingestion/sources/athena","title":"Athena","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/azure-ad":{"id":"docs/generated/ingestion/sources/azure-ad","title":"Azure AD","description":"Extracting DataHub Users","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/bigquery":{"id":"docs/generated/ingestion/sources/bigquery","title":"BigQuery","description":"Ingesting metadata from BigQuery requires using the bigquery module.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/business-glossary":{"id":"docs/generated/ingestion/sources/business-glossary","title":"Business Glossary","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/cassandra":{"id":"docs/generated/ingestion/sources/cassandra","title":"Cassandra","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/clickhouse":{"id":"docs/generated/ingestion/sources/clickhouse","title":"ClickHouse","description":"There are 2 sources that provide integration with ClickHouse","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/cockroachdb":{"id":"docs/generated/ingestion/sources/cockroachdb","title":"CockroachDB","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/csv-enricher":{"id":"docs/generated/ingestion/sources/csv-enricher","title":"CSV Enricher","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/databricks":{"id":"docs/generated/ingestion/sources/databricks","title":"Databricks","description":"DataHub supports integration with Databricks ecosystem using a multitude of connectors, depending on your exact setup.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/datahub":{"id":"docs/generated/ingestion/sources/datahub","title":"DataHub","description":"Migrate data from one DataHub instance to another.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/datahubapply":{"id":"docs/generated/ingestion/sources/datahubapply","title":"DataHubApply","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/datahubgc":{"id":"docs/generated/ingestion/sources/datahubgc","title":"DataHubGc","description":"Overview","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/dbt":{"id":"docs/generated/ingestion/sources/dbt","title":"dbt","description":"There are 2 sources that provide integration with dbt","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/delta-lake":{"id":"docs/generated/ingestion/sources/delta-lake","title":"Delta Lake","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/demo-data":{"id":"docs/generated/ingestion/sources/demo-data","title":"Demo Data","description":"This source loads sample data into DataHub. It is intended for demo and testing purposes only.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/dremio":{"id":"docs/generated/ingestion/sources/dremio","title":"Dremio","description":"Concept Mapping","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/druid":{"id":"docs/generated/ingestion/sources/druid","title":"Druid","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/dynamodb":{"id":"docs/generated/ingestion/sources/dynamodb","title":"DynamoDB","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/elasticsearch":{"id":"docs/generated/ingestion/sources/elasticsearch","title":"Elasticsearch","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/feast":{"id":"docs/generated/ingestion/sources/feast","title":"Feast","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/file-based-lineage":{"id":"docs/generated/ingestion/sources/file-based-lineage","title":"File Based Lineage","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/fivetran":{"id":"docs/generated/ingestion/sources/fivetran","title":"Fivetran","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/gcs":{"id":"docs/generated/ingestion/sources/gcs","title":"Google Cloud Storage","description":"This connector ingests Google Cloud Storage datasets into DataHub. It allows mapping an individual file or a folder of files to a dataset in DataHub.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/glue":{"id":"docs/generated/ingestion/sources/glue","title":"Glue","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/grafana":{"id":"docs/generated/ingestion/sources/grafana","title":"Grafana","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/hana":{"id":"docs/generated/ingestion/sources/hana","title":"SAP HANA","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/hex":{"id":"docs/generated/ingestion/sources/hex","title":"Hex","description":"This connector ingests Hex assets into DataHub.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/hive":{"id":"docs/generated/ingestion/sources/hive","title":"Hive","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/hive-metastore":{"id":"docs/generated/ingestion/sources/hive-metastore","title":"Hive Metastore","description":"There are 2 sources that provide integration with Hive Metastore","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/iceberg":{"id":"docs/generated/ingestion/sources/iceberg","title":"Iceberg","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/json-schema":{"id":"docs/generated/ingestion/sources/json-schema","title":"JSON Schemas","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/kafka":{"id":"docs/generated/ingestion/sources/kafka","title":"Kafka","description":"Extract Topics & Schemas from Apache Kafka or Confluent Cloud.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/kafka-connect":{"id":"docs/generated/ingestion/sources/kafka-connect","title":"Kafka Connect","description":"Integration Details","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/ldap":{"id":"docs/generated/ingestion/sources/ldap","title":"LDAP","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/looker":{"id":"docs/generated/ingestion/sources/looker","title":"Looker","description":"There are 2 sources that provide integration with Looker","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/mariadb":{"id":"docs/generated/ingestion/sources/mariadb","title":"MariaDB","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/metabase":{"id":"docs/generated/ingestion/sources/metabase","title":"Metabase","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/metadata-file":{"id":"docs/generated/ingestion/sources/metadata-file","title":"Metadata File","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/mlflow":{"id":"docs/generated/ingestion/sources/mlflow","title":"MLflow","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/mode":{"id":"docs/generated/ingestion/sources/mode","title":"Mode","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/mongodb":{"id":"docs/generated/ingestion/sources/mongodb","title":"MongoDB","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/mssql":{"id":"docs/generated/ingestion/sources/mssql","title":"Microsoft SQL Server","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/mysql":{"id":"docs/generated/ingestion/sources/mysql","title":"MySQL","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/neo4j":{"id":"docs/generated/ingestion/sources/neo4j","title":"Neo4j","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/nifi":{"id":"docs/generated/ingestion/sources/nifi","title":"NiFi","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/okta":{"id":"docs/generated/ingestion/sources/okta","title":"Okta","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/openapi":{"id":"docs/generated/ingestion/sources/openapi","title":"OpenAPI","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/oracle":{"id":"docs/generated/ingestion/sources/oracle","title":"Oracle","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/postgres":{"id":"docs/generated/ingestion/sources/postgres","title":"Postgres","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/powerbi":{"id":"docs/generated/ingestion/sources/powerbi","title":"PowerBI","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/powerbi-report-server":{"id":"docs/generated/ingestion/sources/powerbi-report-server","title":"PowerBI Report Server","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/preset":{"id":"docs/generated/ingestion/sources/preset","title":"Preset","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/presto":{"id":"docs/generated/ingestion/sources/presto","title":"Presto","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/pulsar":{"id":"docs/generated/ingestion/sources/pulsar","title":"Pulsar","description":"Integration Details","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/qlik-sense":{"id":"docs/generated/ingestion/sources/qlik-sense","title":"Qlik Sense","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/redash":{"id":"docs/generated/ingestion/sources/redash","title":"Redash","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/redshift":{"id":"docs/generated/ingestion/sources/redshift","title":"Redshift","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/s3":{"id":"docs/generated/ingestion/sources/s3","title":"S3 / Local Files","description":"This connector ingests AWS S3 datasets into DataHub. It allows mapping an individual file or a folder of files to a dataset in DataHub.","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/sac":{"id":"docs/generated/ingestion/sources/sac","title":"SAP Analytics Cloud","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/sagemaker":{"id":"docs/generated/ingestion/sources/sagemaker","title":"SageMaker","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/salesforce":{"id":"docs/generated/ingestion/sources/salesforce","title":"Salesforce","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/sigma":{"id":"docs/generated/ingestion/sources/sigma","title":"Sigma","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/slack":{"id":"docs/generated/ingestion/sources/slack","title":"Slack","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/snowflake":{"id":"docs/generated/ingestion/sources/snowflake","title":"Snowflake","description":"Snowflake Ingestion through the UI","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/sql-queries":{"id":"docs/generated/ingestion/sources/sql-queries","title":"SQL Queries","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/sqlalchemy":{"id":"docs/generated/ingestion/sources/sqlalchemy","title":"SQLAlchemy","description":"Incubating","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/superset":{"id":"docs/generated/ingestion/sources/superset","title":"Superset","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/tableau":{"id":"docs/generated/ingestion/sources/tableau","title":"Tableau","description":"Certified","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/teradata":{"id":"docs/generated/ingestion/sources/teradata","title":"Teradata","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/trino":{"id":"docs/generated/ingestion/sources/trino","title":"Trino","description":"There are 2 sources that provide integration with Trino","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/vertexai":{"id":"docs/generated/ingestion/sources/vertexai","title":"Vertex AI","description":"Testing","sidebar":"overviewSidebar"},"docs/generated/ingestion/sources/vertica":{"id":"docs/generated/ingestion/sources/vertica","title":"Vertica","description":"Integration Details","sidebar":"overviewSidebar"},"docs/generated/lineage/lineage-feature-guide":{"id":"docs/generated/lineage/lineage-feature-guide","title":"About DataHub Lineage","description":"Data lineage is a map that shows how data flows through your organization. It details where your data originates, how it travels, and where it ultimately ends up.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/assertion":{"id":"docs/generated/metamodel/entities/assertion","title":"Assertion","description":"Assertion entity represents a data quality rule applied on dataset.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/businessAttribute":{"id":"docs/generated/metamodel/entities/businessAttribute","title":"BusinessAttribute","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/chart":{"id":"docs/generated/metamodel/entities/chart","title":"Chart","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/container":{"id":"docs/generated/metamodel/entities/container","title":"Container","description":"A container of related data assets.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/corpGroup":{"id":"docs/generated/metamodel/entities/corpGroup","title":"CorpGroup","description":"CorpGroup represents an identity of a group of users in the enterprise.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/corpuser":{"id":"docs/generated/metamodel/entities/corpuser","title":"Corpuser","description":"CorpUser represents an identity of a person (or an account) in the enterprise.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dashboard":{"id":"docs/generated/metamodel/entities/dashboard","title":"Dashboard","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataContract":{"id":"docs/generated/metamodel/entities/dataContract","title":"DataContract","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataFlow":{"id":"docs/generated/metamodel/entities/dataFlow","title":"DataFlow","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubAccessToken":{"id":"docs/generated/metamodel/entities/dataHubAccessToken","title":"DataHubAccessToken","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubConnection":{"id":"docs/generated/metamodel/entities/dataHubConnection","title":"DataHubConnection","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubExecutionRequest":{"id":"docs/generated/metamodel/entities/dataHubExecutionRequest","title":"DataHubExecutionRequest","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubIngestionSource":{"id":"docs/generated/metamodel/entities/dataHubIngestionSource","title":"DataHubIngestionSource","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubOpenAPISchema":{"id":"docs/generated/metamodel/entities/dataHubOpenAPISchema","title":"DataHubOpenAPISchema","description":"Contains aspects which are used in OpenAPI requests/responses which are not otherwise present in the data model.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubPersona":{"id":"docs/generated/metamodel/entities/dataHubPersona","title":"DataHubPersona","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubPolicy":{"id":"docs/generated/metamodel/entities/dataHubPolicy","title":"DataHubPolicy","description":"DataHub Policies represent access policies granted to users or groups on metadata operations like edit, view etc.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubRetention":{"id":"docs/generated/metamodel/entities/dataHubRetention","title":"DataHubRetention","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubRole":{"id":"docs/generated/metamodel/entities/dataHubRole","title":"DataHubRole","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubSecret":{"id":"docs/generated/metamodel/entities/dataHubSecret","title":"DataHubSecret","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubStepState":{"id":"docs/generated/metamodel/entities/dataHubStepState","title":"DataHubStepState","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubUpgrade":{"id":"docs/generated/metamodel/entities/dataHubUpgrade","title":"DataHubUpgrade","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataHubView":{"id":"docs/generated/metamodel/entities/dataHubView","title":"DataHubView","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataJob":{"id":"docs/generated/metamodel/entities/dataJob","title":"DataJob","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataPlatform":{"id":"docs/generated/metamodel/entities/dataPlatform","title":"Data Platform","description":"Data Platforms are systems or tools that contain Datasets, Dashboards, Charts, and all other kinds of data assets modeled in the metadata graph.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataPlatformInstance":{"id":"docs/generated/metamodel/entities/dataPlatformInstance","title":"DataPlatformInstance","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataProcess":{"id":"docs/generated/metamodel/entities/dataProcess","title":"DataProcess","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataProcessInstance":{"id":"docs/generated/metamodel/entities/dataProcessInstance","title":"DataProcessInstance","description":"DataProcessInstance represents an instance of a datajob/jobflow run","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataProduct":{"id":"docs/generated/metamodel/entities/dataProduct","title":"DataProduct","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataset":{"id":"docs/generated/metamodel/entities/dataset","title":"Dataset","description":"The dataset entity is one the most important entities in the metadata model. They represent collections of data that are typically represented as Tables or Views in a database (e.g. BigQuery, Snowflake, Redshift etc.), Streams in a stream-processing environment (Kafka, Pulsar etc.), bundles of data found as Files or Folders in data lake systems (S3, ADLS, etc.).","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/dataType":{"id":"docs/generated/metamodel/entities/dataType","title":"DataType","description":"A type of data element stored within DataHub.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/domain":{"id":"docs/generated/metamodel/entities/domain","title":"Domain","description":"A data domain within an organization.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/entityType":{"id":"docs/generated/metamodel/entities/entityType","title":"EntityType","description":"A type of entity in the DataHub Metadata Model.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/erModelRelationship":{"id":"docs/generated/metamodel/entities/erModelRelationship","title":"ErModelRelationship","description":"ER Model Relationship of  Dataset Fields","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/form":{"id":"docs/generated/metamodel/entities/form","title":"Form","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/globalSettings":{"id":"docs/generated/metamodel/entities/globalSettings","title":"GlobalSettings","description":"Global settings for an the platform","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/glossaryNode":{"id":"docs/generated/metamodel/entities/glossaryNode","title":"GlossaryNode","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/glossaryTerm":{"id":"docs/generated/metamodel/entities/glossaryTerm","title":"GlossaryTerm","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/incident":{"id":"docs/generated/metamodel/entities/incident","title":"Incident","description":"An incident for an asset.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/inviteToken":{"id":"docs/generated/metamodel/entities/inviteToken","title":"InviteToken","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/mlFeature":{"id":"docs/generated/metamodel/entities/mlFeature","title":"MlFeature","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/mlFeatureTable":{"id":"docs/generated/metamodel/entities/mlFeatureTable","title":"MlFeatureTable","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/mlModel":{"id":"docs/generated/metamodel/entities/mlModel","title":"MlModel","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/mlModelDeployment":{"id":"docs/generated/metamodel/entities/mlModelDeployment","title":"MlModelDeployment","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/mlModelGroup":{"id":"docs/generated/metamodel/entities/mlModelGroup","title":"MlModelGroup","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/mlPrimaryKey":{"id":"docs/generated/metamodel/entities/mlPrimaryKey","title":"MlPrimaryKey","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/notebook":{"id":"docs/generated/metamodel/entities/notebook","title":"Notebook","description":"\u26a0\ufe0f Notice: The Notebook entity is under active community development and IS NOT YET fully supported on the DataHub web application.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/ownershipType":{"id":"docs/generated/metamodel/entities/ownershipType","title":"OwnershipType","description":"Ownership Type represents a user-created ownership category for a person or group who is responsible for an asset.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/platformResource":{"id":"docs/generated/metamodel/entities/platformResource","title":"PlatformResource","description":"Platform Resources are assets that are unmodeled and stored outside of the core data model. They are stored in DataHub primarily to help with application-specific use-cases that are not sufficiently generalized to move into the core data model.","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/post":{"id":"docs/generated/metamodel/entities/post","title":"Post","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/query":{"id":"docs/generated/metamodel/entities/query","title":"Query","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/role":{"id":"docs/generated/metamodel/entities/role","title":"Role","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/schemaField":{"id":"docs/generated/metamodel/entities/schemaField","title":"SchemaField","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/structuredProperty":{"id":"docs/generated/metamodel/entities/structuredProperty","title":"StructuredProperty","description":"Structured Property represents a property meant for extending the core model of a logical entity","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/tag":{"id":"docs/generated/metamodel/entities/tag","title":"Tag","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/telemetry":{"id":"docs/generated/metamodel/entities/telemetry","title":"Telemetry","description":"Aspects","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/test":{"id":"docs/generated/metamodel/entities/test","title":"Test","description":"A DataHub test","sidebar":"overviewSidebar"},"docs/generated/metamodel/entities/versionSet":{"id":"docs/generated/metamodel/entities/versionSet","title":"VersionSet","description":"Aspects","sidebar":"overviewSidebar"},"docs/glossary/business-glossary":{"id":"docs/glossary/business-glossary","title":"Business Glossary","description":"Introduction","sidebar":"overviewSidebar"},"docs/how/add-custom-data-platform":{"id":"docs/how/add-custom-data-platform","title":"Adding a custom Dataset Data Platform","description":"A Data Platform represents a 3rd party system from which Metadata Entities are ingested from. Each Dataset that is ingested is associated with a single platform, for example MySQL, Snowflake, Redshift, or BigQuery.","sidebar":"overviewSidebar"},"docs/how/add-custom-ingestion-source":{"id":"docs/how/add-custom-ingestion-source","title":"Using a Custom Ingestion Source","description":"Adding a custom ingestion source is the easiest way to extend Datahubs ingestion framework to support source systems","sidebar":"overviewSidebar"},"docs/how/add-new-aspect":{"id":"docs/how/add-new-aspect","title":"How to add a new metadata aspect?","description":"Adding a new metadata aspect is one of the most common ways to extend an existing entity."},"docs/how/add-user-data":{"id":"docs/how/add-user-data","title":"Adding user metadata in DataHub","description":"This guide shares how you can add user metadata in DataHub. Usually you would want to use one of our sources for ingesting user metadata. But if there is no connector for your use case then you would want to use this guide."},"docs/how/backup-datahub":{"id":"docs/how/backup-datahub","title":"Taking backup of DataHub","description":"Production","sidebar":"overviewSidebar"},"docs/how/configuring-authorization-with-apache-ranger":{"id":"docs/how/configuring-authorization-with-apache-ranger","title":"Configuring Authorization with Apache Ranger","description":"DataHub integration with Apache Ranger allows DataHub Authorization policies to be controlled inside Apache Ranger.","sidebar":"overviewSidebar"},"docs/how/delete-metadata":{"id":"docs/how/delete-metadata","title":"Removing Metadata from DataHub","description":"To follow this guide, you\'ll need the DataHub CLI.","sidebar":"overviewSidebar"},"docs/how/extract-container-logs":{"id":"docs/how/extract-container-logs","title":"How to Extract Logs from DataHub Containers","description":"DataHub containers, datahub GMS (backend server) and datahub frontend (UI server), write log files to the local container filesystem. To extract these logs, you\'ll need to get them from inside the container where the services are running.","sidebar":"overviewSidebar"},"docs/how/jattach-guide":{"id":"docs/how/jattach-guide","title":"Debugging by Jattach","description":"We have installed jattach in Docker image of datahub-gms, datahub-mae-consumer, datahub-mce-consumer","sidebar":"overviewSidebar"},"docs/how/kafka-config":{"id":"docs/how/kafka-config","title":"Configuring Kafka","description":"DataHub requires Kafka to operate. Kafka is used as a durable log that can be used to store inbound","sidebar":"overviewSidebar"},"docs/how/migrating-graph-service-implementation":{"id":"docs/how/migrating-graph-service-implementation","title":"Migrate Graph Service Implementation to Elasticsearch","description":"We currently support either Elasticsearch or Neo4j as backend implementations for the graph service. We recommend","sidebar":"overviewSidebar"},"docs/how/restore-indices":{"id":"docs/how/restore-indices","title":"Restoring Search and Graph Indices from Local Database","description":"If search infrastructure (Elasticsearch/Opensearch) or graph services (Elasticsearch/Opensearch/Neo4j) become inconsistent,","sidebar":"overviewSidebar"},"docs/how/search":{"id":"docs/how/search","title":"Search","description":"The search bar is an important mechanism for discovering data assets in DataHub. From the search bar, you can find Datasets, Columns, Dashboards, Charts, Data Pipelines, and more. Simply type in a term and press \'enter\'.","sidebar":"overviewSidebar"},"docs/how/ui-tabs-guide":{"id":"docs/how/ui-tabs-guide","title":"UI Tabs Guide","description":"Some of the tabs in the UI might not be enabled by default. This guide is supposed to tell Admins of DataHub how to enable those UI tabs."},"docs/how/updating-datahub":{"id":"docs/how/updating-datahub","title":"Updating DataHub","description":"\x3c!--","sidebar":"overviewSidebar"},"docs/iceberg-catalog":{"id":"docs/iceberg-catalog","title":"DataHub Iceberg Catalog","description":"Note that this feature is currently in open Beta. With any questions or issues, please reach out to your DataHub","sidebar":"overviewSidebar"},"docs/incidents/incidents":{"id":"docs/incidents/incidents","title":"Incidents","description":"This page provides an overview of working with the DataHub Incidents API.","sidebar":"overviewSidebar"},"docs/lineage/airflow":{"id":"docs/lineage/airflow","title":"Airflow Integration","description":"If you\'re looking to schedule DataHub ingestion using Airflow, see the guide on scheduling ingestion with Airflow.","sidebar":"overviewSidebar"},"docs/lineage/dagster":{"id":"docs/lineage/dagster","title":"Dagster Integration","description":"This connector supports extracting:","sidebar":"overviewSidebar"},"docs/lineage/openlineage":{"id":"docs/lineage/openlineage","title":"OpenLineage","description":"DataHub, now supports OpenLineage integration. With this support, DataHub can ingest and display lineage information from various data processing frameworks, providing users with a comprehensive understanding of their data pipelines.","sidebar":"overviewSidebar"},"docs/lineage/prefect":{"id":"docs/lineage/prefect","title":"Prefect Integration with DataHub","description":"Overview","sidebar":"overviewSidebar"},"docs/lineage/sql_parsing":{"id":"docs/lineage/sql_parsing","title":"SQL Parsing","description":"Many data platforms are built on top of SQL, which means deeply understanding SQL queries is critical for understanding column-level lineage, usage, and more.","sidebar":"overviewSidebar"},"docs/links":{"id":"docs/links","title":"Articles & Talks","description":"Overviews","sidebar":"overviewSidebar"},"docs/managed-datahub/approval-workflows":{"id":"docs/managed-datahub/approval-workflows","title":"Approval Workflows","description":"Overview","sidebar":"overviewSidebar"},"docs/managed-datahub/chrome-extension":{"id":"docs/managed-datahub/chrome-extension","title":"DataHub Cloud Chrome Extension","description":"Learn how to upload and use the DataHub Cloud Chrome extension (beta) locally before it\'s available on the Chrome store.","sidebar":"overviewSidebar"},"docs/managed-datahub/configuring-identity-provisioning-with-ms-entra":{"id":"docs/managed-datahub/configuring-identity-provisioning-with-ms-entra","title":"SCIM Integration: MS Entra and DataHub","description":"SCIM Integration: MS Entra and DataHub","sidebar":"overviewSidebar"},"docs/managed-datahub/configuring-identity-provisioning-with-okta":{"id":"docs/managed-datahub/configuring-identity-provisioning-with-okta","title":"SCIM Integration: Okta and DataHub","description":"SCIM Integration: Okta and DataHub","sidebar":"overviewSidebar"},"docs/managed-datahub/datahub-api/entity-events-api":{"id":"docs/managed-datahub/datahub-api/entity-events-api","title":"Entity Events API","description":"This guide details the Entity Events API, which allows you to take action when things change on DataHub.","sidebar":"overviewSidebar"},"docs/managed-datahub/datahub-api/graphql-api/getting-started":{"id":"docs/managed-datahub/datahub-api/graphql-api/getting-started","title":"Getting Started","description":"Getting started with the DataHub GraphQL API.","sidebar":"overviewSidebar"},"docs/managed-datahub/integrations/aws-privatelink":{"id":"docs/managed-datahub/integrations/aws-privatelink","title":"AWS PrivateLink","description":"If you require a private connection between the provisioned DataHub instance and your own existing AWS account, DataHub Cloud supports using AWS PrivateLink in order to complete this private connection.","sidebar":"overviewSidebar"},"docs/managed-datahub/integrations/oidc-sso-integration":{"id":"docs/managed-datahub/integrations/oidc-sso-integration","title":"Enable OIDC SSO","description":"This page will help you set up OIDC SSO with your identity provider to log into DataHub","sidebar":"overviewSidebar"},"docs/managed-datahub/managed-datahub-overview":{"id":"docs/managed-datahub/managed-datahub-overview","title":"How DataHub Cloud compares to DataHub","description":"DataHub Cloud: AI & Data Context Platform","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/assertions":{"id":"docs/managed-datahub/observe/assertions","title":"Assertions","description":"Currently we support Snowflake, Redshift, BigQuery, and Databricks for out-of-the-box contract monitoring as part of DataHub Cloud Observe.","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/column-assertions":{"id":"docs/managed-datahub/observe/column-assertions","title":"Column Assertions","description":"This page provides an overview of working with DataHub Column Assertions","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/custom-sql-assertions":{"id":"docs/managed-datahub/observe/custom-sql-assertions","title":"Custom SQL Assertions","description":"This page provides an overview of working with DataHub SQL Assertions","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/data-contract":{"id":"docs/managed-datahub/observe/data-contract","title":"Data Contracts","description":"What Is a Data Contract","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/freshness-assertions":{"id":"docs/managed-datahub/observe/freshness-assertions","title":"Freshness Assertions","description":"This page provides an overview of working with DataHub Freshness Assertions","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/schema-assertions":{"id":"docs/managed-datahub/observe/schema-assertions","title":"Schema Assertions","description":"This page provides an overview of working with DataHub Schema Assertions","sidebar":"overviewSidebar"},"docs/managed-datahub/observe/volume-assertions":{"id":"docs/managed-datahub/observe/volume-assertions","title":"Volume Assertions","description":"This page provides an overview of working with DataHub Volume Assertions","sidebar":"overviewSidebar"},"docs/managed-datahub/operator-guide/setting-up-events-api-on-aws-eventbridge":{"id":"docs/managed-datahub/operator-guide/setting-up-events-api-on-aws-eventbridge","title":"Setting up Events API on AWS EventBridge","description":"This guide will walk through the configuration required to start receiving DataHub Cloud events via AWS EventBridge.","sidebar":"overviewSidebar"},"docs/managed-datahub/operator-guide/setting-up-remote-ingestion-executor":{"id":"docs/managed-datahub/operator-guide/setting-up-remote-ingestion-executor","title":"Configuring Remote Executor","description":"Learn how to set up, deploy, and configure Remote Executors in your environment","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_1_69":{"id":"docs/managed-datahub/release-notes/v_0_1_69","title":"v0.1.69","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_1_70":{"id":"docs/managed-datahub/release-notes/v_0_1_70","title":"v0.1.70","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_1_72":{"id":"docs/managed-datahub/release-notes/v_0_1_72","title":"v0.1.72","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_1_73":{"id":"docs/managed-datahub/release-notes/v_0_1_73","title":"v0.1.73","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_0":{"id":"docs/managed-datahub/release-notes/v_0_2_0","title":"v0.2.0","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_1":{"id":"docs/managed-datahub/release-notes/v_0_2_1","title":"v0.2.1","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_10":{"id":"docs/managed-datahub/release-notes/v_0_2_10","title":"v0.2.10","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_11":{"id":"docs/managed-datahub/release-notes/v_0_2_11","title":"v0.2.11","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_12":{"id":"docs/managed-datahub/release-notes/v_0_2_12","title":"v0.2.12","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_13":{"id":"docs/managed-datahub/release-notes/v_0_2_13","title":"v0.2.13","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_14":{"id":"docs/managed-datahub/release-notes/v_0_2_14","title":"v0.2.14.1","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_15":{"id":"docs/managed-datahub/release-notes/v_0_2_15","title":"v0.2.15.1","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_16":{"id":"docs/managed-datahub/release-notes/v_0_2_16","title":"v0.2.16","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_2":{"id":"docs/managed-datahub/release-notes/v_0_2_2","title":"v0.2.2","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_3":{"id":"docs/managed-datahub/release-notes/v_0_2_3","title":"v0.2.3","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_4":{"id":"docs/managed-datahub/release-notes/v_0_2_4","title":"v0.2.4","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_5":{"id":"docs/managed-datahub/release-notes/v_0_2_5","title":"v0.2.5","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_6":{"id":"docs/managed-datahub/release-notes/v_0_2_6","title":"v0.2.6","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_7":{"id":"docs/managed-datahub/release-notes/v_0_2_7","title":"v0.2.7","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_8":{"id":"docs/managed-datahub/release-notes/v_0_2_8","title":"v0.2.8","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_2_9":{"id":"docs/managed-datahub/release-notes/v_0_2_9","title":"v0.2.9","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_1":{"id":"docs/managed-datahub/release-notes/v_0_3_1","title":"v0.3.1","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_10":{"id":"docs/managed-datahub/release-notes/v_0_3_10","title":"v0.3.10","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_2":{"id":"docs/managed-datahub/release-notes/v_0_3_2","title":"v0.3.2","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_3":{"id":"docs/managed-datahub/release-notes/v_0_3_3","title":"v0.3.3","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_4":{"id":"docs/managed-datahub/release-notes/v_0_3_4","title":"v0.3.4","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_5":{"id":"docs/managed-datahub/release-notes/v_0_3_5","title":"v0.3.5","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_6":{"id":"docs/managed-datahub/release-notes/v_0_3_6","title":"v0.3.6","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_7":{"id":"docs/managed-datahub/release-notes/v_0_3_7","title":"v0.3.7","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_8":{"id":"docs/managed-datahub/release-notes/v_0_3_8","title":"v0.3.8","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/release-notes/v_0_3_9":{"id":"docs/managed-datahub/release-notes/v_0_3_9","title":"v0.3.9","description":"---","sidebar":"overviewSidebar"},"docs/managed-datahub/remote-executor/about":{"id":"docs/managed-datahub/remote-executor/about","title":"About Remote Executor","description":"Learn about DataHub\'s Remote Executor feature for secure metadata ingestion from private sources","sidebar":"overviewSidebar"},"docs/managed-datahub/remote-executor/monitoring":{"id":"docs/managed-datahub/remote-executor/monitoring","title":"Monitoring Remote Executor","description":"Learn how to monitor and observe Remote Executor health and performance","sidebar":"overviewSidebar"},"docs/managed-datahub/slack/saas-slack-app":{"id":"docs/managed-datahub/slack/saas-slack-app","title":"Slack App Features","description":"Overview","sidebar":"overviewSidebar"},"docs/managed-datahub/slack/saas-slack-setup":{"id":"docs/managed-datahub/slack/saas-slack-setup","title":"Configure Slack For Notifications","description":"Install the DataHub Slack App into your Slack workspace","sidebar":"overviewSidebar"},"docs/managed-datahub/slack/saas-slack-troubleshoot":{"id":"docs/managed-datahub/slack/saas-slack-troubleshoot","title":"Troubleshoot Slack Issues","description":"This document provides troubleshooting guidance for the Slack integration. For more details on setting up the Slack integration, click here.","sidebar":"overviewSidebar"},"docs/managed-datahub/subscription-and-notification":{"id":"docs/managed-datahub/subscription-and-notification","title":"Subscriptions & Notifications","description":"DataHub\'s Subscriptions and Notifications feature gives you real-time change alerts on data assets of your choice.","sidebar":"overviewSidebar"},"docs/managed-datahub/welcome-acryl":{"id":"docs/managed-datahub/welcome-acryl","title":"Getting Started with DataHub Cloud","description":"Welcome to the DataHub Cloud! We at DataHub are on a mission to make data reliable by bringing clarity to the who, what, when, & how of your data ecosystem. We\'re thrilled to be on this journey with you; and cannot wait to see what we build together!","sidebar":"overviewSidebar"},"docs/metadata-standards":{"id":"docs/metadata-standards","title":"Metadata Standards","description":"The data and AI tooling and infrastructure stack is constantly evolving and adding new concepts (from datasets to dashboards, to models and training runs). DataHub\u2019s goal is to harmonize this complexity and make it understandable for humans and machines, while not sacrificing fidelity. As a result, over 10 years of iteration, the DataHub project has evolved into a comprehensive living metadata model that serves as a de-facto standard for metadata in the data and AI stack.","sidebar":"overviewSidebar"},"docs/modeling/extending-the-metadata-model":{"id":"docs/modeling/extending-the-metadata-model","title":"Extending the Metadata Model","description":"You can extend the metadata model by either creating a new Entity or extending an existing one. Unsure if you need to","sidebar":"overviewSidebar"},"docs/modeling/metadata-model":{"id":"docs/modeling/metadata-model","title":"The Metadata Model","description":"DataHub takes a schema-first approach to modeling metadata. We use the open-source Pegasus schema language (PDL) extended with a custom set of annotations to model metadata. The DataHub storage, serving, indexing and ingestion layer operates directly on top of the metadata model and supports strong types all the way from the client to the storage layer.","sidebar":"overviewSidebar"},"docs/ownership/ownership-types":{"id":"docs/ownership/ownership-types","title":"Custom Ownership Types","description":"\ud83e\udd1d Version compatibility","sidebar":"overviewSidebar"},"docs/platform-instances":{"id":"docs/platform-instances","title":"Working With Platform Instances","description":"DataHub\'s metadata model for Datasets supports a three-part key currently:","sidebar":"overviewSidebar"},"docs/plugins":{"id":"docs/plugins","title":"Plugins Guide","description":"Plugins are way to enhance the basic DataHub functionality in a custom manner.","sidebar":"overviewSidebar"},"docs/posts":{"id":"docs/posts","title":"Posts","description":"DataHub allows users to make Posts that can be displayed on the app. Currently, Posts are only supported on the Home Page, but may be extended to other surfaces of the app in the future. Posts can be used to accomplish the following:","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/bigquery/configuration":{"id":"docs/quick-ingestion-guides/bigquery/configuration","title":"Configuration","description":"Now that you have created a Service Account and Service Account Key in BigQuery in the prior step, it\'s now time to set up a connection via the DataHub UI.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/bigquery/overview":{"id":"docs/quick-ingestion-guides/bigquery/overview","title":"Overview","description":"What You Will Get Out of This Guide","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/bigquery/setup":{"id":"docs/quick-ingestion-guides/bigquery/setup","title":"Setup","description":"To configure ingestion from BigQuery, you\'ll need a Service Account configured with the proper permission sets and an associated Service Account Key.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/looker/configuration":{"id":"docs/quick-ingestion-guides/looker/configuration","title":"Configuration","description":"Now that you have created a DataHub-specific API key with the relevant access in the prior step, it\'s time to set up a connection via the DataHub UI.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/looker/overview":{"id":"docs/quick-ingestion-guides/looker/overview","title":"Overview","description":"What You Will Get Out of This Guide","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/looker/setup":{"id":"docs/quick-ingestion-guides/looker/setup","title":"Setup","description":"Looker Prerequisites","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/powerbi/configuration":{"id":"docs/quick-ingestion-guides/powerbi/configuration","title":"Configuration","description":"Now that you have created a DataHub specific Azure AD app with the relevant access in the prior step, it\'s now time to set up a connection via the DataHub UI.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/powerbi/overview":{"id":"docs/quick-ingestion-guides/powerbi/overview","title":"Overview","description":"What You Will Get Out of This Guide","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/powerbi/setup":{"id":"docs/quick-ingestion-guides/powerbi/setup","title":"Setup","description":"In order to configure ingestion from PowerBI, you\'ll first have to ensure you have an Azure AD app with permission to access the PowerBI resources.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/redshift/configuration":{"id":"docs/quick-ingestion-guides/redshift/configuration","title":"Configuration","description":"Now that you have created a DataHub user in Redshift in the prior step, it\'s time to set up a connection via the DataHub UI.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/redshift/overview":{"id":"docs/quick-ingestion-guides/redshift/overview","title":"Overview","description":"What You Will Get Out of This Guide","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/redshift/setup":{"id":"docs/quick-ingestion-guides/redshift/setup","title":"Setup","description":"To configure ingestion from Redshift, you\'ll need a User configured with the proper permission sets, and an associated.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/snowflake/configuration":{"id":"docs/quick-ingestion-guides/snowflake/configuration","title":"Configuration","description":"Now that you have created a DataHub-specific user with the relevant roles in Snowflake in the prior step, it\'s now time to set up a connection via the DataHub UI.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/snowflake/overview":{"id":"docs/quick-ingestion-guides/snowflake/overview","title":"Overview","description":"What You Will Get Out of This Guide","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/snowflake/setup":{"id":"docs/quick-ingestion-guides/snowflake/setup","title":"Setup","description":"In order to configure ingestion from Snowflake, you\'ll first have to ensure you have a Snowflake user with the ACCOUNTADMIN role or MANAGE GRANTS privilege.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/tableau/configuration":{"id":"docs/quick-ingestion-guides/tableau/configuration","title":"Configuration","description":"Now that you have created a DataHub-specific user with the relevant access in Tableau in the prior step, it\'s now time to set up a connection via the DataHub UI.","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/tableau/overview":{"id":"docs/quick-ingestion-guides/tableau/overview","title":"Overview","description":"What You Will Get Out of This Guide","sidebar":"overviewSidebar"},"docs/quick-ingestion-guides/tableau/setup":{"id":"docs/quick-ingestion-guides/tableau/setup","title":"Setup","description":"In order to configure ingestion from Tableau, you\'ll first have to enable Tableau Metadata API and you should have a user with Site Administrator Explorer permissions.","sidebar":"overviewSidebar"},"docs/quickstart":{"id":"docs/quickstart","title":"DataHub Quickstart Guide","description":"This guide provides instructions on deploying the open source DataHub locally.","sidebar":"overviewSidebar"},"docs/rfc":{"id":"docs/rfc","title":"DataHub RFC Process","description":"What is an RFC?","sidebar":"overviewSidebar"},"docs/roadmap":{"id":"docs/roadmap","title":"DataHub Roadmap","description":"The DataHub Roadmap has a new home!"},"docs/schema-history":{"id":"docs/schema-history","title":"Schema History","description":"Schema History is a valuable tool for understanding how a Dataset changes over time and gives insight into the following cases,","sidebar":"overviewSidebar"},"docs/SECURITY_STANCE":{"id":"docs/SECURITY_STANCE","title":"DataHub\'s Commitment to Security","description":"Introduction"},"docs/slack":{"id":"docs/slack","title":"Slack","description":"The DataHub Slack is a thriving and rapidly growing community - we can\'t wait for you to join us!","sidebar":"overviewSidebar"},"docs/sync-status":{"id":"docs/sync-status","title":"Sync Status","description":"When looking at metadata in DataHub, it\'s useful to know if the information you\'re looking at is relevant.","sidebar":"overviewSidebar"},"docs/tags":{"id":"docs/tags","title":"Tags","description":"Tags are informal, loosely controlled labels that help in search & discovery. They can be added to datasets, dataset schemas, or containers, for an easy way to label or categorize entities \u2013 without having to associate them to a broader business glossary or vocabulary.","sidebar":"overviewSidebar"},"docs/tests/metadata-tests":{"id":"docs/tests/metadata-tests","title":"Metadata Tests","description":"DataHub includes a highly configurable, no-code framework that allows you to configure broad-spanning monitors & continuous actions","sidebar":"overviewSidebar"},"docs/townhall-history":{"id":"docs/townhall-history","title":"Town Hall History","description":"For the Town Hall meetings after June 2023, please refer to our LinkedIn Live event history."},"docs/townhalls":{"id":"docs/townhalls","title":"DataHub Town Halls","description":"We hold virtual Town Hall meetings with the DataHub Community on the last Thursday of every month (with some exceptions due to holidays).","sidebar":"overviewSidebar"},"docs/troubleshooting/build":{"id":"docs/troubleshooting/build","title":"Build Debugging Guide","description":"For when Local Development did not work out smoothly.","sidebar":"overviewSidebar"},"docs/troubleshooting/general":{"id":"docs/troubleshooting/general","title":"General Debugging Guide","description":"Logo for my platform is not appearing on the Home Page or search results","sidebar":"overviewSidebar"},"docs/troubleshooting/quickstart":{"id":"docs/troubleshooting/quickstart","title":"Quickstart Debugging Guide","description":"For when Quickstart did not work out smoothly.","sidebar":"overviewSidebar"},"docs/ui-ingestion":{"id":"docs/ui-ingestion","title":"UI Based Ingestion / Managed Ingestion","description":"Introduction","sidebar":"overviewSidebar"},"docs/what-is-datahub/datahub-concepts":{"id":"docs/what-is-datahub/datahub-concepts","title":"DataHub Concepts","description":"Explore key concepts of DataHub to take full advantage of its capabilities in managing your data.","sidebar":"overviewSidebar"},"docs/what/aspect":{"id":"docs/what/aspect","title":"What is a metadata aspect?","description":"A metadata aspect is a structured document, or more precisely a record in PDL,"},"docs/what/delta":{"id":"docs/what/delta","title":"What is a metadata delta?","description":"Rest.li supports partial update natively without needing explicitly defined models."},"docs/what/entity":{"id":"docs/what/entity","title":"Entities","description":"This page has been moved. Please refer to The Metadata Model for details on"},"docs/what/gma":{"id":"docs/what/gma","title":"What is Generalized Metadata Architecture (GMA)?","description":"GMA is the backend infrastructure for DataHub. Unlike existing architectures, GMA leverages multiple storage technologies to efficiently service the four most commonly used query patterns"},"docs/what/gms":{"id":"docs/what/gms","title":"What is Generalized Metadata Service (GMS)?","description":"Metadata for entities onboarded to GMA is served through microservices known as Generalized Metadata Service (GMS). GMS typically provides a Rest.li API and must access the metadata using GMA DAOs."},"docs/what/graph":{"id":"docs/what/graph","title":"What is GMA graph?","description":"All the entities and relationships are stored in a graph database, Neo4j."},"docs/what/mxe":{"id":"docs/what/mxe","title":"Metadata Events","description":"DataHub makes use a few important Kafka events for operation. The most notable of these include","sidebar":"overviewSidebar"},"docs/what/relationship":{"id":"docs/what/relationship","title":"What is a relationship?","description":"A relationship is a named associate between exactly two entities, a source and a destination."},"docs/what/search-document":{"id":"docs/what/search-document","title":"What is a search document?","description":"Search documents are also modeled using PDL explicitly."},"docs/what/search-index":{"id":"docs/what/search-index","title":"What is GMA search index?","description":"Each search document type (or entity type) will be mapped to an independent search index in Elasticsearch."},"docs/what/snapshot":{"id":"docs/what/snapshot","title":"What is a snapshot?","description":"A metadata snapshot models the current state of one or multiple metadata aspects associated with a particular entity."},"docs/what/urn":{"id":"docs/what/urn","title":"What is URN?","description":"URN (Uniform Resource Name) is the chosen scheme of URI to uniquely define any resource in DataHub. It has the following form"},"graphql/enums":{"id":"graphql/enums","title":"Enums","description":"AccessLevel","sidebar":"overviewSidebar"},"graphql/inputObjects":{"id":"graphql/inputObjects","title":"Input objects","description":"AcceptRoleInput","sidebar":"overviewSidebar"},"graphql/interfaces":{"id":"graphql/interfaces","title":"Interfaces","description":"Aspect","sidebar":"overviewSidebar"},"graphql/mutations":{"id":"graphql/mutations","title":"Mutations","description":"acceptRole","sidebar":"overviewSidebar"},"graphql/objects":{"id":"graphql/objects","title":"Objects","description":"Access","sidebar":"overviewSidebar"},"graphql/queries":{"id":"graphql/queries","title":"Queries","description":"aggregateAcrossEntities","sidebar":"overviewSidebar"},"graphql/scalars":{"id":"graphql/scalars","title":"Scalars","description":"Boolean","sidebar":"overviewSidebar"},"graphql/unions":{"id":"graphql/unions","title":"Unions","description":"AnalyticsChart","sidebar":"overviewSidebar"},"metadata-ingestion-modules/airflow-plugin/README":{"id":"metadata-ingestion-modules/airflow-plugin/README","title":"Datahub Airflow Plugin","description":"See the DataHub Airflow docs for details."},"metadata-ingestion-modules/dagster-plugin/README":{"id":"metadata-ingestion-modules/dagster-plugin/README","title":"Datahub Dagster Plugin","description":"See the DataHub Dagster docs for details."},"metadata-ingestion-modules/gx-plugin/README":{"id":"metadata-ingestion-modules/gx-plugin/README","title":"Datahub GX Plugin","description":"See the DataHub GX docs for details."},"metadata-ingestion-modules/prefect-plugin/README":{"id":"metadata-ingestion-modules/prefect-plugin/README","title":"prefect-datahub","description":"Emit flows & tasks metadata to DataHub REST API with prefect-datahub"},"metadata-ingestion/adding-source":{"id":"metadata-ingestion/adding-source","title":"Adding a Metadata Ingestion Source","description":"There are two ways of adding a metadata ingestion source.","sidebar":"overviewSidebar"},"metadata-ingestion/as-a-library":{"id":"metadata-ingestion/as-a-library","title":"Python Emitter","description":"In some cases, you might want to construct Metadata events directly and use programmatic ways to emit that metadata to DataHub. Use-cases are typically push-based and include emitting metadata events from CI/CD pipelines, custom orchestrators etc.","sidebar":"overviewSidebar"},"metadata-ingestion/cli-ingestion":{"id":"metadata-ingestion/cli-ingestion","title":"CLI Ingestion","description":"Batch ingestion involves extracting metadata from a source system in bulk. Typically, this happens on a predefined schedule using the Metadata Ingestion framework.","sidebar":"overviewSidebar"},"metadata-ingestion/developing":{"id":"metadata-ingestion/developing","title":"Developing on Metadata Ingestion","description":"If you just want to use metadata ingestion, check the user-centric guide.","sidebar":"overviewSidebar"},"metadata-ingestion/docs/dev_guides/add_stateful_ingestion_to_source":{"id":"metadata-ingestion/docs/dev_guides/add_stateful_ingestion_to_source","title":"Adding Stateful Ingestion to a Source","description":"Currently, datahub supports the Stale Metadata Removal and","sidebar":"overviewSidebar"},"metadata-ingestion/docs/dev_guides/classification":{"id":"metadata-ingestion/docs/dev_guides/classification","title":"Classification","description":"The classification feature enables sources to be configured to automatically predict info types for columns and use them as glossary terms. This is an explicit opt-in feature and is not enabled by default.","sidebar":"overviewSidebar"},"metadata-ingestion/docs/dev_guides/profiling_ingestions":{"id":"metadata-ingestion/docs/dev_guides/profiling_ingestions","title":"Profiling ingestions","description":"\ud83e\udd1d Version compatibility","sidebar":"overviewSidebar"},"metadata-ingestion/docs/dev_guides/reporting_telemetry":{"id":"metadata-ingestion/docs/dev_guides/reporting_telemetry","title":"Datahub\'s Reporting Framework for Ingestion Job Telemetry","description":"The Datahub\'s reporting framework allows for configuring reporting providers with the ingestion pipelines to send","sidebar":"overviewSidebar"},"metadata-ingestion/docs/dev_guides/sql_profiles":{"id":"metadata-ingestion/docs/dev_guides/sql_profiles","title":"SQL Profiling","description":"SQL Profiling collects table level and column level statistics.","sidebar":"overviewSidebar"},"metadata-ingestion/docs/dev_guides/stateful":{"id":"metadata-ingestion/docs/dev_guides/stateful","title":"Stateful Ingestion","description":"The stateful ingestion feature enables sources to be configured to save custom checkpoint states from their","sidebar":"overviewSidebar"},"metadata-ingestion/docs/transformer/dataset_transformer":{"id":"metadata-ingestion/docs/transformer/dataset_transformer","title":"Dataset","description":"The below table shows transformer which can transform aspects of entity Dataset.","sidebar":"overviewSidebar"},"metadata-ingestion/docs/transformer/intro":{"id":"metadata-ingestion/docs/transformer/intro","title":"Introduction","description":"What\u2019s a transformer?","sidebar":"overviewSidebar"},"metadata-ingestion/examples/structured_properties/README":{"id":"metadata-ingestion/examples/structured_properties/README","title":"Extended Properties","description":"Expected Capabilities"},"metadata-ingestion/examples/transforms/README":{"id":"metadata-ingestion/examples/transforms/README","title":"Custom transformer script","description":"This script sets up a transformer that reads in a list of owner URNs from a JSON file specified via owners_json and appends these owners to every MCE."},"metadata-ingestion/integration_docs/great-expectations":{"id":"metadata-ingestion/integration_docs/great-expectations","title":"Great Expectations","description":"This guide helps to setup and configure DataHubValidationAction in Great Expectations to send assertions(expectations) and their results to DataHub using DataHub\'s Python Rest emitter.","sidebar":"overviewSidebar"},"metadata-ingestion/README":{"id":"metadata-ingestion/README","title":"Introduction to Metadata Ingestion","description":"Please see our Integrations page to browse our ingestion sources and filter on their features.","sidebar":"overviewSidebar"},"metadata-ingestion/recipe_overview":{"id":"metadata-ingestion/recipe_overview","title":"Recipes","description":"A recipe is the main configuration file for metadata ingestion. It tells our ingestion scripts where to pull data from (source) and where to put it (sink).","sidebar":"overviewSidebar"},"metadata-ingestion/schedule_docs/airflow":{"id":"metadata-ingestion/schedule_docs/airflow","title":"Using Airflow","description":"If you are using Apache Airflow for your scheduling then you might want to also use it for scheduling your ingestion recipes. For any Airflow specific questions you can go through Airflow docs for more details.","sidebar":"overviewSidebar"},"metadata-ingestion/schedule_docs/cron":{"id":"metadata-ingestion/schedule_docs/cron","title":"Using Cron","description":"Assume you have a recipe file /home/ubuntu/datahubingest/mysqlto_datahub.yml on your machine","sidebar":"overviewSidebar"},"metadata-ingestion/schedule_docs/datahub":{"id":"metadata-ingestion/schedule_docs/datahub","title":"Using DataHub","description":"UI Ingestion can be used to schedule metadata ingestion through DataHub."},"metadata-ingestion/schedule_docs/intro":{"id":"metadata-ingestion/schedule_docs/intro","title":"Introduction to Scheduling Metadata Ingestion","description":"Given a recipe file /home/ubuntu/datahubingest/mysqlto_datahub.yml.","sidebar":"overviewSidebar"},"metadata-ingestion/schedule_docs/kubernetes":{"id":"metadata-ingestion/schedule_docs/kubernetes","title":"Using Kubernetes","description":"If you have deployed DataHub using our official helm charts you can use the","sidebar":"overviewSidebar"},"metadata-ingestion/sink_docs/console":{"id":"metadata-ingestion/sink_docs/console","title":"Console","description":"For context on getting started with ingestion, check out our metadata ingestion guide.","sidebar":"overviewSidebar"},"metadata-ingestion/sink_docs/datahub":{"id":"metadata-ingestion/sink_docs/datahub","title":"DataHub","description":"DataHub Rest","sidebar":"overviewSidebar"},"metadata-ingestion/sink_docs/metadata-file":{"id":"metadata-ingestion/sink_docs/metadata-file","title":"Metadata File","description":"For context on getting started with ingestion, check out our metadata ingestion guide.","sidebar":"overviewSidebar"},"metadata-ingestion/sink_overview":{"id":"metadata-ingestion/sink_overview","title":"Sinks","description":"Sinks are destinations for metadata.","sidebar":"overviewSidebar"},"metadata-ingestion/source_overview":{"id":"metadata-ingestion/source_overview","title":"Sources","description":"Sources are the data systems that we are extracting metadata from.","sidebar":"overviewSidebar"},"metadata-ingestion/source-docs-template":{"id":"metadata-ingestion/source-docs-template","title":"Source Name","description":"Certified"},"metadata-integration/java/acryl-spark-lineage/README":{"id":"metadata-integration/java/acryl-spark-lineage/README","title":"Spark","description":"To integrate Spark with DataHub, we provide a lightweight Java agent that listens for Spark application and job events","sidebar":"overviewSidebar"},"metadata-integration/java/as-a-library":{"id":"metadata-integration/java/as-a-library","title":"Java Emitter","description":"In some cases, you might want to construct Metadata events directly and use programmatic ways to emit that metadata to DataHub. Use-cases are typically push-based and include emitting metadata events from CI/CD pipelines, custom orchestrators etc.","sidebar":"overviewSidebar"},"metadata-integration/java/datahub-protobuf/README":{"id":"metadata-integration/java/datahub-protobuf/README","title":"Protobuf Schemas","description":"The datahub-protobuf module is designed to be used with the Java Emitter, the input is a compiled protobuf binary .protoc files and optionally the corresponding .proto source code. You can supply a file with multiple nested messages to be processed. If you have a file with multiple non-nested messages, you will need to separate them out into different files or supply the root message, as otherwise we will only process the first one.","sidebar":"overviewSidebar"},"metadata-integration/java/datahub-schematron/README":{"id":"metadata-integration/java/datahub-schematron/README","title":"SchemaTron (Incubating)","description":"\u26a0\ufe0f This is an incubating project in draft status. APIs and functionality may change significantly between releases."},"metadata-integration/java/openlineage-converter/README":{"id":"metadata-integration/java/openlineage-converter/README","title":"Openlineage Converter","description":"Overview"},"metadata-integration/java/spark-lineage-legacy/README":{"id":"metadata-integration/java/spark-lineage-legacy/README","title":"Spark (Legacy)","description":"This is our legacy Spark Integration which is replaced by DataHub Cloud Spark Lineage"},"metadata-jobs/mae-consumer-job/README":{"id":"metadata-jobs/mae-consumer-job/README","title":"metadata-jobs:mae-consumer-job","description":"The Metadata Audit Event Consumer is a Spring job which can be deployed by itself, or as part of the Metadata Service.","sidebar":"overviewSidebar"},"metadata-jobs/mce-consumer-job/README":{"id":"metadata-jobs/mce-consumer-job/README","title":"metadata-jobs:mce-consumer-job","description":"The Metadata Change Event Consumer is a Spring job which can be deployed by itself, or as part of the Metadata Service.","sidebar":"overviewSidebar"},"metadata-jobs/README":{"id":"metadata-jobs/README","title":"MXE Processing Jobs","description":"DataHub uses Kafka as the pub-sub message queue in the backend. There are 2 Kafka topics used by DataHub which are"},"metadata-models-custom/README":{"id":"metadata-models-custom/README","title":"A Custom Metadata Model","description":"This module hosts a gradle project where you can store your custom metadata model. It contains an example extension for you to follow."},"metadata-service/README":{"id":"metadata-service/README","title":"metadata-service","description":"DataHub Metadata Service is a service written in Java consisting of multiple servlets:","sidebar":"overviewSidebar"},"metadata-service/services/README":{"id":"metadata-service/services/README","title":"Service Layer","description":"Module to abstract away business logic from implementation specific libraries to make them lighter weight from a"},"perf-test/README":{"id":"perf-test/README","title":"Load testing with Locust","description":"Locust is an open-source, python-based, easy-to-use load testing tool. It provides an interface to"},"python-sdk/builder":{"id":"python-sdk/builder","title":"Builder","description":"\\\\n\\\\n\\\\nThese classes and methods make it easier to construct MetadataChangeProposals and MetadataChangeEvents.\\\\n\\\\n\\\\nclass datahub.emitter.mcp.MetadataChangeProposalWrapper(entityType=\'ENTITYTYPEUNSET\', changeType=\'UPSERT\', entityUrn=None, entityKeyAspect=None, auditHeader=None, aspectName=None, aspect=None, systemMetadata=None, headers=None)\\\\nBases\\\\n\\\\nentityType (str)\\\\nchangeType (Unionstr, ChangeTypeClass])\\\\nentityUrn (Optional[str])\\\\nentityKeyAspect (Optional[Aspect])\\\\nauditHeader (Optional[KafkaAuditHeaderClass])\\\\naspectName (Optional[str])\\\\naspect (Optional[Aspect])\\\\nsystemMetadata (Optional[SystemMetadataClass])\\\\nheaders (Optional[Dict[str, str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nentityType Union[str, ChangeTypeClass] = \'UPSERT\'\\\\n\\\\n\\\\n\\\\nentityUrn Optional[Aspect] = None\\\\n\\\\n\\\\n\\\\nauditHeader Optional[str] = None\\\\n\\\\n\\\\n\\\\naspect Optional[SystemMetadataClass] = None\\\\n\\\\n\\\\n\\\\nheaders\\\\n\\\\nentityUrn (str)\\\\naspects (Sequence[Optional[Aspect]])\\\\n\\\\n\\\\nReturn type\\\\nMetadataChangeProposalClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nvalidate()\\\\n\\\\nReturn type\\\\n\\\\ntuples (bool)\\\\nsimplifiedstructure (bool)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nobj (dict)\\\\ntuples (bool)\\\\n\\\\n\\\\nReturn type\\\\nException if the generic aspect is invalid, e.g. contains invalid json.\\\\n\\\\nParameters\\\\nOptional[MetadataChangeProposalWrapper]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod tryfrommcl(mcl)\\\\n\\\\nParameters\\\\nUnion[MetadataChangeProposalWrapper, MetadataChangeProposalClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromobjrequirewrapper(obj, tuples=False)\\\\n\\\\nParameters\\\\nMetadataChangeProposalWrapper\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nasworkunit(*, treaterrorsaswarnings=False, isprimarysource=True)\\\\n\\\\nParameters\\\\nMetadataWorkUnit\\\\n\\\\n\\\\n\\\\n\\\\nConvenience functions for creating MCEs\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.setdataseturntolower(value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcebuilder.OwnerType(value)\\\\nBases\\\\nint\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.maketsmillis(ts)\\\\n\\\\nParameters\\\\nOptional[int]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.parsetsmillis(ts)\\\\n\\\\nParameters\\\\nOptional[datetime]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedataplatformurn(platform)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedataseturn(platform, name, env=\'PROD\')\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedataplatforminstanceurn(platform, instance)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedataseturnwithplatforminstance(platform, name, platforminstance, env=\'PROD\')\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makeschemafieldurn(parenturn, fieldpath)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.schemafieldurntokey(schemafieldurn)\\\\n\\\\nParameters\\\\nOptional[SchemaFieldKeyClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.dataseturntokey(dataseturn)\\\\n\\\\nParameters\\\\nOptional[DatasetKeyClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.datasetkeytourn(key)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makecontainerurn(guid)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.containerurntokey(guid)\\\\n\\\\nParameters\\\\nOptional[ContainerKeyClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.datahubguid(obj)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makeassertionurn(assertionid)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.assertionurntokey(assertionurn)\\\\n\\\\nParameters\\\\nOptional[AssertionKeyClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makeuserurn(username)\\\\nMakes a user urn if the input is not a user or group urn already\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makegroupurn(groupname)\\\\nMakes a group urn if the input is not a user or group urn already\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.maketagurn(tag)\\\\nMakes a tag urn if the input is not a tag urn already\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makeownerurn(owner, ownertype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makeownershiptypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.maketermurn(term)\\\\nMakes a term urn if the input is not a term urn already\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedataflowurn(orchestrator, flowid, cluster=\'prod\', platforminstance=None)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedatajoburnwithflow(flowurn, jobid)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedataprocessinstanceurn(dataProcessInstanceId)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedatajoburn(orchestrator, flowid, jobid, cluster=\'prod\', platforminstance=None)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedashboardurn(platform, name, platforminstance=None)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.dashboardurntokey(dashboardurn)\\\\n\\\\nParameters\\\\nOptional[DashboardKeyClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makecharturn(platform, name, platforminstance=None)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.charturntokey(charturn)\\\\n\\\\nParameters\\\\nOptional[ChartKeyClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makedomainurn(domain)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makemlprimarykeyurn(featuretablename, primarykeyname)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makemlfeatureurn(featuretablename, featurename)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makemlfeaturetableurn(platform, featuretablename)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makemlmodelurn(platform, modelname, env)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makemlmodeldeploymenturn(platform, deploymentname, env)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makemlmodelgroupurn(platform, groupname, env)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.validateownershiptype(ownershiptype)\\\\n\\\\nParameters\\\\nTuple[str, Optional[str]]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcebuilder.makelineagemce(upstreamurns, downstreamurn, lineagetype=\'TRANSFORMED\')\\\\nNote\\\\n\\\\nupstreamurns (List[str])\\\\ndownstreamurn (str)\\\\nlineagetype (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nSnapshotType (Type[DictWrapper])\\\\nAspectType (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\nAspectType (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\nAspectType (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\nAspectType (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\naspecttype (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\ndefault (TypeVar(Aspect, bound= Aspect))\\\\n\\\\n\\\\nReturn type\\\\ntags (List[str])\\\\n\\\\nReturn type\\\\n\\\\nownerurns (List[str])\\\\nsourcetype (Union[str, OwnershipSourceTypeClass, None])\\\\nownertype (Union[str, OwnershipTypeClass])\\\\n\\\\n\\\\nReturn type\\\\ntermurns (List[str])\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\naspect (Optional[TypeVar(Aspect, bound= Aspect)])\\\\naspecttype (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type BaseModel\\\\n\\\\nParameters\\\\nDict[str, str]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nguid()\\\\n\\\\nReturn type ClassVar[ConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcp_builder.ContainerKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nplatform Optionalstr]\\\\n\\\\n\\\\n\\\\nenv bool\\\\n\\\\n\\\\n\\\\nguiddict()\\\\n\\\\nReturn type\\\\nDict[str, str]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nasurntyped()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nparentkey()\\\\n\\\\nReturn type ClassVar[ConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.mcpbuilder.PlatformKey\\\\nalias of ContainerKey\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.NamespaceKey(**data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\nnamespace (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamespace ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.DatabaseKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompat_env_as_instance (bool)\\\\ndatabase (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatabase ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcp_builder.SchemaKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\ndatabase (str)\\\\nschema (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndbschema ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.ProjectIdKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompat_env_as_instance (bool)\\\\nproject_id (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproject_id ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcp_builder.ExperimentKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nid ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.MetastoreKey(**data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\nmetastore (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nmetastore ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.CatalogKeyWithMetastore(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompat_env_as_instance (bool)\\\\nmetastore (str)\\\\ncatalog (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ncatalog ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcp_builder.UnitySchemaKeyWithMetastore(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\nmetastore (str)\\\\ncatalog (str)\\\\nunityschema (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nunityschema ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.CatalogKey(**data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\ncatalog (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ncatalog ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.UnitySchemaKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompat_env_as_instance (bool)\\\\ncatalog (str)\\\\nunity_schema (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nunity_schema ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcp_builder.BigQueryDatasetKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\nprojectid (str)\\\\ndatasetid (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatasetid ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.FolderKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompat_env_as_instance (bool)\\\\nfolder_abs_path (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nfolder_abs_path ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcp_builder.BucketKey(data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nplatform (str)\\\\ninstance (str | None)\\\\nenv (str | None)\\\\nbackcompatenvasinstance (bool)\\\\nbucketname (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nbucketname ClassVarConfigDict] = {}\\\\nConfiguration for the model, should be a dictionary conforming to [ConfigDict.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.mcpbuilder.NotebookKey(**data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nnotebookid (int)\\\\nplatform (str)\\\\ninstance (str | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnotebookid str\\\\n\\\\n\\\\n\\\\ninstance\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nmodelconfig\\\\n\\\\nentityurn (str)\\\\ndomainurn (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentitytype (str)\\\\nentityurn (str)\\\\nownerurn (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentitytype (str)\\\\nentityurn (str)\\\\ntags (List[str])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentityurn (str)\\\\nstructuredproperties (Dict[StructuredPropertyUrn, str])\\\\n\\\\n\\\\nReturn type\\\\n\\\\ncontainerkey (TypeVar(KeyType, bound= ContainerKey))\\\\nname (str)\\\\nsubtypes (List[str])\\\\nparentcontainerkey (Optional[ContainerKey])\\\\nextraproperties (Optional[Dict[str, str]])\\\\nstructuredproperties (Optional[Dict[StructuredPropertyUrn, str]])\\\\ndomainurn (Optional[str])\\\\ndescription (Optional[str])\\\\nownerurn (Optional[str])\\\\nexternalurl (Optional[str])\\\\ntags (Optional[List[str]])\\\\nqualifiedname (Optional[str])\\\\ncreated (Optional[int])\\\\nlastmodified (Optional[int])\\\\n\\\\n\\\\nReturn type\\\\n\\\\ncontainerkey (TypeVar(KeyType, bound= ContainerKey))\\\\ndataseturn (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\ncontainerkey (TypeVar(KeyType, bound= ContainerKey))\\\\nentitytype (str)\\\\nentityurn (str)\\\\n\\\\n\\\\nReturn type\\\\nmce (MetadataChangeEventClass)\\\\n\\\\nReturn type\\\\n\\\\nurn (str)\\\\nembedurl (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentitytype (str)\\\\naspecttype (Type[TypeVar(Aspect, bound= Aspect)])\\\\n\\\\n\\\\nReturn type:\\\\nbool\\\\n\\\\n\\\\n\\\\n\\\\n\\"}}>","sidebar":"overviewSidebar"},"python-sdk/clients":{"id":"python-sdk/clients","title":"Client","description":"\\\\n\\\\n\\\\nThe Kafka emitter or Rest emitter can be used to push metadata to DataHub.\\\\nThe DataHub graph client extends the Rest emitter with additional functionality.\\\\n\\\\n\\\\nclass datahub.emitter.restemitter.EmitMode(value)\\\\nBases ConfigEnum\\\\nAn enumeration.\\\\n\\\\n\\\\nRESTLI = \'RESTLI\'\\\\n\\\\n\\\\n\\\\nOPENAPI = \'OPENAPI\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.restemitter.RequestsSessionConfig(**data)\\\\nBases\\\\n\\\\ndata (Any)\\\\ntimeout (float | Tuplefloat, float] | None)\\\\nretrystatuscodes (List[int])\\\\nretrymethods (List[str])\\\\nretrymaxtimes (int)\\\\nextraheaders (Dict[str, str])\\\\ncacertificatepath (str | None)\\\\nclientcertificatepath (str | None)\\\\ndisablesslverification (bool)\\\\nclientmode (ClientMode | None)\\\\ndatahubcomponent (str | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntimeout List[int]\\\\n\\\\n\\\\n\\\\nretrymethods int\\\\n\\\\n\\\\n\\\\nextraheaders Optional[str]\\\\n\\\\n\\\\n\\\\nclientcertificatepath bool\\\\n\\\\n\\\\n\\\\nclientmode Optional[str]\\\\n\\\\n\\\\n\\\\nbuildsession()\\\\n\\\\nReturn type\\\\nsession (Session) \\\\u2013 The requests.Session object to check\\\\n\\\\nReturn type\\\\nThe corresponding ClientMode enum value if found, None otherwise\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nmodelconfig &lt;function ConfigModel.Config.schemaextra&gt;, \'extra\' (&lt;class \'cachedproperty.cachedproperty\'&gt;,), \'jsonschemaextra\' Closeable, Emitter\\\\n\\\\nParameters RestServiceConfig\\\\n\\\\n\\\\n\\\\nfetchserverconfig()\\\\nFetch configuration from the server if not already loaded.\\\\n\\\\nReturn type\\\\nThe configuration dictionary\\\\n\\\\nRaises\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetserverconfig()\\\\n\\\\nReturn type\\\\nDataHubGraph\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemit(item, callback=None, emitmode=EmitMode.SYNCPRIMARY)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemitmce(mce)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemitmcp(mcp, asyncflag=None, emitmode=EmitMode.SYNCPRIMARY, waittimeout=datetime.timedelta(seconds=3600))\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemitmcps(mcps, emitmode=EmitMode.SYNCPRIMARY, waittimeout=datetime.timedelta(seconds=3600))\\\\n\\\\nParameters\\\\nint\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemitusage(usageStats)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nflush()\\\\n\\\\nReturn type\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.emitter.restemitter.DatahubRestEmitter\\\\nalias of DataHubRestEmitter\\\\n\\\\n\\\\n\\\\nclass datahub.emitter.kafkaemitter.KafkaEmitterConfig(**data)\\\\nBases\\\\n\\\\ndata (Any)\\\\nconnection (KafkaProducerConnectionConfig)\\\\ntopicroutes (Dict[str, str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nconnection Dict[str, str]\\\\n\\\\n\\\\n\\\\nclassmethod validatetopicroutes(v)\\\\n\\\\nParameters\\\\nDict[str, str]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nmodelconfig &lt;function ConfigModel.Config.schemaextra&gt;, \'extra\' (&lt;class \'cachedproperty.cachedproperty\'&gt;,), \'jsonschemaextra\' Closeable, Emitter\\\\n\\\\nParameters\\\\n\\\\nitem (Union[MetadataChangeEventClass, MetadataChangeProposalClass, MetadataChangeProposalWrapper])\\\\ncallback (Optional[Callable[[Exception, str], None]])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmce (MetadataChangeEventClass)\\\\ncallback (Callable[[Exception, str], None])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nmcp (Union[MetadataChangeProposalClass, MetadataChangeProposalWrapper])\\\\ncallback (Callable[[Exception, str], None])\\\\n\\\\n\\\\nReturn type\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclose()\\\\n\\\\nReturn type object\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nrelationshiptype Optional[str] = None\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.ingestion.graph.client.entitytypetographql(entitytype)\\\\nConvert the entity types into GraphQL \\\\u201cEntityType\\\\u201d enum values.\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.ingestion.graph.client.flexibleentitytypetographql(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.ingestion.graph.client.DataHubGraph(config)\\\\nBases\\\\nconfig (DatahubClientConfig)\\\\n\\\\n\\\\n\\\\n\\\\ntestconnection()\\\\n\\\\nReturn type str\\\\nGet the public-facing base url of the frontend\\\\nThis url can be used to construct links to the frontend. The url will not include a trailing slash.\\\\nNote Only supported with DataHub Cloud.\\\\n\\\\nParameters\\\\nstr\\\\n\\\\nReturns\\\\nemitter (DataHubRestEmitter)\\\\n\\\\nReturn type\\\\n\\\\nrun_id (str)\\\\nextra_sink_config (Optional[Dict])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nitems (Iterable[Union[MetadataChangeEventClass, MetadataChangeProposalClass, MetadataChangeProposalWrapper]])\\\\nrunid (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentityurn (str) \\\\u2013 The urn of the entity\\\\naspecttype (Type[TypeVar(Aspect, bound= Aspect)]) \\\\u2013 The type class of the aspect being requested (e.g. datahub.metadata.schemaclasses.DatasetProperties)\\\\nversion (int) \\\\u2013 The version of the aspect to retrieve. The default of 0 means latest. Versions &gt; 0 go from oldest to newest, so 1 is the oldest.\\\\n\\\\n\\\\nReturn type\\\\nthe Aspect as a dictionary if present, None if no aspect was found (HTTP status 404)\\\\n\\\\nRaises\\\\n\\\\nentityurn (str)\\\\naspecttype (Type[TypeVar(Aspect, bound= Aspect)])\\\\naspect (str)\\\\naspecttypename (Optional[str])\\\\nversion (int)\\\\n\\\\n\\\\nReturn type\\\\nDict[str, Any]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetownership(entityurn)\\\\n\\\\nParameters\\\\nOptional[OwnershipClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetschemametadata(entityurn)\\\\n\\\\nParameters\\\\nOptional[SchemaMetadataClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetdomainproperties(entityurn)\\\\n\\\\nParameters\\\\nOptional[DomainPropertiesClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetdatasetproperties(entityurn)\\\\n\\\\nParameters\\\\nOptional[DatasetPropertiesClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngettags(entityurn)\\\\n\\\\nParameters\\\\nOptional[GlobalTagsClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetglossaryterms(entityurn)\\\\n\\\\nParameters\\\\nOptional[GlossaryTermsClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetdomain(entityurn)\\\\n\\\\nParameters\\\\nOptional[DomainsClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetbrowsepath(entityurn)\\\\n\\\\nParameters\\\\nOptional[BrowsePathsClass]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetusageaspectsfromurn(entityurn, starttimestamp, endtimestamp)\\\\n\\\\nParameters\\\\nOptional[List[DatasetUsageStatisticsClass]]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nlistallentityurns(entitytype, start, count)\\\\n\\\\nParameters\\\\nOptional[List[str]]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetlatesttimeseriesvalue(entityurn, aspecttype, filtercriteriamap)\\\\n\\\\nParameters\\\\nOptional[TypeVar(Aspect, bound= Aspect)]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngettimeseriesvalues(entityurn, aspecttype, filter, limit=10)\\\\n\\\\nParameters\\\\nList[TypeVar(Aspect, bound= Aspect)]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetentityraw(entityurn, aspects=None)\\\\n\\\\nParameters\\\\nDict\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetaspectsforentity(entityurn, aspects, aspecttypes)\\\\nGet multiple aspects for an entity.\\\\nDeprecated in favor of getaspect (single aspect) or getentitysemityped (full\\\\nentity without manually specifying a list of aspects).\\\\nWarning\\\\n\\\\nentityurn (str) \\\\u2013 The urn of the entity\\\\naspects (List[str]) \\\\u2013 List of aspect names being requested (e.g. [schemaMetadata, datasetProperties])\\\\naspecttypes (List[Type[TypeVar(Aspect, bound= Aspect)]]) \\\\u2013 List of aspect type classes being requested (e.g. [datahub.metadata.schemaclasses.DatasetProperties])\\\\nentityurn\\\\n\\\\n\\\\nReturn type\\\\nOptionally, a map of aspectname to aspectvalue as a dictionary if present, aspectvalue will be set to None if that aspect was not found. Returns None on HTTP status 404.\\\\n\\\\nRaises Do not use this method to determine if an entity exists! This method will always return\\\\nsomething, even if the entity doesn\\\\u2019t actually exist in DataHub.\\\\n\\\\nParameters\\\\nList[MetadataChangeProposalWrapper]\\\\n\\\\nReturns Do not use this method to determine if an entity exists! This method will always return\\\\nsomething, even if the entity doesn\\\\u2019t actually exist in DataHub.\\\\n\\\\nParameters\\\\nAspectBag\\\\n\\\\nReturns\\\\ndomainname (str)\\\\n\\\\nReturn type\\\\nurn (str) \\\\u2013 The urn of the connection.\\\\n\\\\nReturn type\\\\nThe connection config as a dictionary, or None if the connection was not found.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nsetconnectionjson(urn, *, platformurn, config, name=None)\\\\nSet a connection config.\\\\nThis is only supported with DataHub Cloud.\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetcontainerurnsbyfilter(env=None, searchquery=\'\')\\\\nReturn container urns that match based on query\\\\n\\\\nParameters\\\\nIterable[str]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nget_urns_by_filter(, entitytypes=None, platform=None, platforminstance=None, env=None, query=None, container=None, status=RemovedStatusFilter.NOTSOFTDELETED, batchsize=10000, extraFilters=None, extraorfilters=None)\\\\nFetch all urns that match all of the given filters.\\\\nFilters are combined conjunctively. If multiple filters are specified, the results will match all of them.\\\\nNote that specifying a platform filter will automatically exclude all entity types that do not have a platform.\\\\nThe same goes for the env filter.\\\\n\\\\nParameters\\\\nIterable[str]\\\\n\\\\nReturns Only supported with DataHub Cloud.\\\\nFilters are combined conjunctively. If multiple filters are specified, the results will match all of them.\\\\nNote that specifying a platform filter will automatically exclude all entity types that do not have a platform.\\\\nThe same goes for the env filter.\\\\n\\\\nParameters\\\\nIterable[dict]\\\\n\\\\nReturns\\\\n\\\\npipelinename (str)\\\\nplatform (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nstart (int)\\\\ncount (int)\\\\nentity (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\naspect (str)\\\\nurnlike (Optional[str])\\\\n\\\\n\\\\nReturn type\\\\n\\\\nquery (str)\\\\nvariables (Optional[Dict])\\\\noperationname (Optional[str])\\\\nformatexception (bool)\\\\n\\\\n\\\\nReturn type StrEnum\\\\nAn enumeration.\\\\n\\\\n\\\\nINCOMING = \'INCOMING\'\\\\n\\\\n\\\\n\\\\nOUTGOING = \'OUTGOING\'\\\\n\\\\n\\\\n\\\\n\\\\ngetrelatedentities(entityurn, relationshiptypes, direction)\\\\n\\\\nParameters\\\\nIterable[RelatedEntity]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nexists(entityurn)\\\\n\\\\nParameters\\\\nbool\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nsoftdeleteentity(urn, runid=\'datahub-graph-client\', deletion_timestamp=None)\\\\nSoft-delete an entity by urn.\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nset_soft_delete_status(urn, delete, run_id=\'datahub-graph-client\', deletiontimestamp=None)\\\\nChange status of soft-delete an entity by urn.\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nharddeleteentity(urn)\\\\nHard delete an entity by urn.\\\\n\\\\nParameters\\\\nTuple[int, int]\\\\n\\\\nReturns\\\\n\\\\nurn (str) \\\\u2013 The urn of the entity to delete.\\\\nhard (bool) \\\\u2013 Whether to hard delete the entity. If False (default), the entity will be soft deleted.\\\\n\\\\n\\\\nReturn type\\\\n\\\\nurn (str) \\\\u2013 The urn of the entity.\\\\naspectname (str) \\\\u2013 The name of the timeseries aspect to delete.\\\\nstarttime (Optional[datetime]) \\\\u2013 The start time of the timeseries data to delete. If not specified, defaults to the beginning of time.\\\\nendtime (Optional[datetime]) \\\\u2013 The end time of the timeseries data to delete. If not specified, defaults to the end of time.\\\\n\\\\n\\\\nReturn type\\\\nThe number of timeseries rows affected.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndeletereferencestourn(urn, dryrun=False)\\\\nDelete references to a given entity.\\\\nThis is useful for cleaning up references to an entity that is about to be deleted.\\\\nFor example, when deleting a tag, you might use this to remove that tag from all other\\\\nentities that reference it.\\\\nThis does not delete the entity itself.\\\\n\\\\nParameters\\\\nTuple[int, List[Dict]]\\\\n\\\\nReturns\\\\n\\\\nplatform (str)\\\\nplatforminstance (Optional[str])\\\\nenv (str)\\\\nbatchsize (int)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nsql (str)\\\\nplatform (str)\\\\nplatforminstance (Optional[str])\\\\nenv (str)\\\\ndefaultdb (Optional[str])\\\\ndefaultschema (Optional[str])\\\\ndefaultdialect (Optional[str])\\\\n\\\\n\\\\nReturn type\\\\ntagname (str)\\\\n\\\\nReturn type\\\\n\\\\ntagurn (str)\\\\nresourceurn (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nurn (str)\\\\nsaveresult (bool)\\\\nparameters (Optional[Dict[str, str]])\\\\nasyncflag (bool)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nurns (List[str])\\\\nsaveresult (bool)\\\\nparameters (Optional[Dict[str, str]])\\\\nasyncflag (bool)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nurn (str)\\\\ntagurns (Optional[List[str]])\\\\nparameters (Optional[Dict[str, str]])\\\\nasyncflag (bool)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentityname (str)\\\\nurns (List[str])\\\\naspects (Optional[List[str]])\\\\nwithsystemmetadata (bool)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nentityname (str) \\\\u2013 The entity type name\\\\nurns (List[str]) \\\\u2013 List of entity URNs to fetch\\\\naspects (Optional[List[str]]) \\\\u2013 Optional list of aspect names to fetch. If None, all aspects will be fetched.\\\\nwithsystemmetadata (bool) \\\\u2013 If True, return system metadata along with each aspect.\\\\n\\\\n\\\\nReturn type\\\\nA dictionary mapping URNs to a dictionary of aspect name to tuples of\\\\n(typed aspect object, system metadata). If withsystemmetadata is False,\\\\nthe system metadata in the tuple will be None.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nupsertcustomassertion(urn, entityurn, type, description, platformname=None, platformurn=None, fieldpath=None, externalurl=None, logic=None)\\\\n\\\\nParameters\\\\nDict\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nreportassertionresult(urn, timestampmillis, type, properties=None, externalurl=None, errortype=None, errormessage=None)\\\\n\\\\nParameters\\\\nbool\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclose()\\\\n\\\\nReturn type\\\\n\\\\nclientmode (Optional[ClientMode])\\\\ndatahubcomponent (Optional[str])\\\\n\\\\n\\\\nReturn type:\\\\nDataHubGraph\\\\n\\\\n\\\\n\\\\n\\\\n\\"}}>","sidebar":"overviewSidebar"},"python-sdk/models":{"id":"python-sdk/models","title":"Models","description":"\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AccessClass(roles=None)\\\\nBases\\\\nroles (Optional[List[RoleAssociationClass]])\\\\n\\\\n\\\\n\\\\n\\\\nproperty roles object\\\\nThe various access levels\\\\n\\\\n\\\\nPRIVATE = \'PRIVATE\'\\\\n\\\\n\\\\n\\\\nPUBLIC = \'PUBLIC\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ActorsClass(users=None)\\\\nBases\\\\nusers (Optional[List[RoleUserClass]])\\\\n\\\\n\\\\n\\\\n\\\\nproperty users DictWrapper\\\\nArray field type.\\\\n\\\\nParameters None | List[str]\\\\nList of types this array holds.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AspectBag\\\\nBases AccessClass\\\\n\\\\n\\\\n\\\\nactors AssertionActionsClass\\\\n\\\\n\\\\n\\\\nassertionInfo AssertionKeyClass\\\\n\\\\n\\\\n\\\\nassertionRunEvent BrowsePathsClass\\\\n\\\\n\\\\n\\\\nbrowsePathsV2 BusinessAttributeInfoClass\\\\n\\\\n\\\\n\\\\nbusinessAttributeKey BusinessAttributesClass\\\\n\\\\n\\\\n\\\\nchartInfo ChartKeyClass\\\\n\\\\n\\\\n\\\\nchartQuery ChartUsageStatisticsClass\\\\n\\\\n\\\\n\\\\ncontainer ContainerKeyClass\\\\n\\\\n\\\\n\\\\ncontainerProperties CorpGroupEditableInfoClass\\\\n\\\\n\\\\n\\\\ncorpGroupInfo CorpGroupKeyClass\\\\n\\\\n\\\\n\\\\ncorpUserCredentials CorpUserEditableInfoClass\\\\n\\\\n\\\\n\\\\ncorpUserInfo CorpUserKeyClass\\\\n\\\\n\\\\n\\\\ncorpUserSettings CorpUserStatusClass\\\\n\\\\n\\\\n\\\\ncost DashboardInfoClass\\\\n\\\\n\\\\n\\\\ndashboardKey DashboardUsageStatisticsClass\\\\n\\\\n\\\\n\\\\ndataContractKey DataContractPropertiesClass\\\\n\\\\n\\\\n\\\\ndataContractStatus DataFlowInfoClass\\\\n\\\\n\\\\n\\\\ndataFlowKey DataHubAccessTokenInfoClass\\\\n\\\\n\\\\n\\\\ndataHubAccessTokenKey DataHubActionKeyClass\\\\n\\\\n\\\\n\\\\ndataHubConnectionDetails DataHubConnectionKeyClass\\\\n\\\\n\\\\n\\\\ndataHubExecutionRequestInput ExecutionRequestKeyClass\\\\n\\\\n\\\\n\\\\ndataHubExecutionRequestResult ExecutionRequestSignalClass\\\\n\\\\n\\\\n\\\\ndataHubIngestionSourceInfo DataHubIngestionSourceKeyClass\\\\n\\\\n\\\\n\\\\ndataHubOpenAPISchemaKey DataHubPersonaInfoClass\\\\n\\\\n\\\\n\\\\ndataHubPersonaKey DataHubPolicyInfoClass\\\\n\\\\n\\\\n\\\\ndataHubPolicyKey DataHubRetentionConfigClass\\\\n\\\\n\\\\n\\\\ndataHubRetentionKey DataHubRoleInfoClass\\\\n\\\\n\\\\n\\\\ndataHubRoleKey DataHubSecretKeyClass\\\\n\\\\n\\\\n\\\\ndataHubSecretValue DataHubStepStateKeyClass\\\\n\\\\n\\\\n\\\\ndataHubStepStateProperties DataHubUpgradeKeyClass\\\\n\\\\n\\\\n\\\\ndataHubUpgradeRequest DataHubUpgradeResultClass\\\\n\\\\n\\\\n\\\\ndataHubViewInfo DataHubViewKeyClass\\\\n\\\\n\\\\n\\\\ndataJobInfo DataJobInputOutputClass\\\\n\\\\n\\\\n\\\\ndataJobKey DataPlatformInfoClass\\\\n\\\\n\\\\n\\\\ndataPlatformInstance DataPlatformInstanceKeyClass\\\\n\\\\n\\\\n\\\\ndataPlatformInstanceProperties DataPlatformKeyClass\\\\n\\\\n\\\\n\\\\ndataProcessInfo DataProcessInstanceInputClass\\\\n\\\\n\\\\n\\\\ndataProcessInstanceKey DataProcessInstanceOutputClass\\\\n\\\\n\\\\n\\\\ndataProcessInstanceProperties DataProcessInstanceRelationshipsClass\\\\n\\\\n\\\\n\\\\ndataProcessInstanceRunEvent DataProcessKeyClass\\\\n\\\\n\\\\n\\\\ndataProductKey DataProductPropertiesClass\\\\n\\\\n\\\\n\\\\ndataTransformLogic DataTypeInfoClass\\\\n\\\\n\\\\n\\\\ndataTypeKey DatahubIngestionCheckpointClass\\\\n\\\\n\\\\n\\\\ndatahubIngestionRunSummary DatasetDeprecationClass\\\\n\\\\n\\\\n\\\\ndatasetKey DatasetProfileClass\\\\n\\\\n\\\\n\\\\ndatasetProperties DatasetUpstreamLineageClass\\\\n\\\\n\\\\n\\\\ndatasetUsageStatistics DeprecationClass\\\\n\\\\n\\\\n\\\\ndisplayProperties DocumentationClass\\\\n\\\\n\\\\n\\\\ndomainKey DomainPropertiesClass\\\\n\\\\n\\\\n\\\\ndomains DynamicFormAssignmentClass\\\\n\\\\n\\\\n\\\\neditableChartProperties EditableContainerPropertiesClass\\\\n\\\\n\\\\n\\\\neditableDashboardProperties EditableDataFlowPropertiesClass\\\\n\\\\n\\\\n\\\\neditableDataJobProperties EditableDatasetPropertiesClass\\\\n\\\\n\\\\n\\\\neditableERModelRelationshipProperties EditableMLFeaturePropertiesClass\\\\n\\\\n\\\\n\\\\neditableMlFeatureTableProperties EditableMLModelGroupPropertiesClass\\\\n\\\\n\\\\n\\\\neditableMlModelProperties EditableMLPrimaryKeyPropertiesClass\\\\n\\\\n\\\\n\\\\neditableNotebookProperties EditableSchemaMetadataClass\\\\n\\\\n\\\\n\\\\nembed EntityTypeInfoClass\\\\n\\\\n\\\\n\\\\nentityTypeKey ERModelRelationshipKeyClass\\\\n\\\\n\\\\n\\\\nerModelRelationshipProperties FormInfoClass\\\\n\\\\n\\\\n\\\\nformKey FormsClass\\\\n\\\\n\\\\n\\\\nglobalSettingsInfo GlobalSettingsKeyClass\\\\n\\\\n\\\\n\\\\nglobalTags GlossaryNodeInfoClass\\\\n\\\\n\\\\n\\\\nglossaryNodeKey GlossaryRelatedTermsClass\\\\n\\\\n\\\\n\\\\nglossaryTermInfo GlossaryTermKeyClass\\\\n\\\\n\\\\n\\\\nglossaryTerms GroupMembershipClass\\\\n\\\\n\\\\n\\\\nicebergCatalogInfo IcebergWarehouseInfoClass\\\\n\\\\n\\\\n\\\\nincidentInfo IncidentKeyClass\\\\n\\\\n\\\\n\\\\nincidentSource IncidentsSummaryClass\\\\n\\\\n\\\\n\\\\ninputFields InstitutionalMemoryClass\\\\n\\\\n\\\\n\\\\nintendedUse InviteTokenClass\\\\n\\\\n\\\\n\\\\ninviteTokenKey MLFeatureKeyClass\\\\n\\\\n\\\\n\\\\nmlFeatureProperties MLFeatureTableKeyClass\\\\n\\\\n\\\\n\\\\nmlFeatureTableProperties MLHyperParamClass\\\\n\\\\n\\\\n\\\\nmlMetric CaveatsAndRecommendationsClass\\\\n\\\\n\\\\n\\\\nmlModelDeploymentKey MLModelDeploymentPropertiesClass\\\\n\\\\n\\\\n\\\\nmlModelEthicalConsiderations EvaluationDataClass\\\\n\\\\n\\\\n\\\\nmlModelFactorPrompts MLModelGroupKeyClass\\\\n\\\\n\\\\n\\\\nmlModelGroupProperties MLModelKeyClass\\\\n\\\\n\\\\n\\\\nmlModelMetrics MLModelPropertiesClass\\\\n\\\\n\\\\n\\\\nmlModelQuantitativeAnalyses TrainingDataClass\\\\n\\\\n\\\\n\\\\nmlPrimaryKeyKey MLPrimaryKeyPropertiesClass\\\\n\\\\n\\\\n\\\\nmlTrainingRunProperties NativeGroupMembershipClass\\\\n\\\\n\\\\n\\\\nnotebookContent NotebookInfoClass\\\\n\\\\n\\\\n\\\\nnotebookKey OperationClass\\\\n\\\\n\\\\n\\\\norigin OwnershipClass\\\\n\\\\n\\\\n\\\\nownershipTypeInfo OwnershipTypeKeyClass\\\\n\\\\n\\\\n\\\\npartitionsSummary PlatformResourceInfoClass\\\\n\\\\n\\\\n\\\\nplatformResourceKey PostInfoClass\\\\n\\\\n\\\\n\\\\npostKey StructuredPropertyDefinitionClass\\\\n\\\\n\\\\n\\\\nqueryKey QueryPropertiesClass\\\\n\\\\n\\\\n\\\\nquerySubjects QueryUsageStatisticsClass\\\\n\\\\n\\\\n\\\\nroleKey RoleMembershipClass\\\\n\\\\n\\\\n\\\\nroleProperties SchemaFieldAliasesClass\\\\n\\\\n\\\\n\\\\nschemaFieldKey SchemaMetadataClass\\\\n\\\\n\\\\n\\\\nschemafieldInfo SiblingsClass\\\\n\\\\n\\\\n\\\\nslackUserInfo SourceCodeClass\\\\n\\\\n\\\\n\\\\nstatus StructuredPropertiesClass\\\\n\\\\n\\\\n\\\\nstructuredPropertyKey StructuredPropertySettingsClass\\\\n\\\\n\\\\n\\\\nsubTypes SystemMetadataClass\\\\n\\\\n\\\\n\\\\ntagKey TagPropertiesClass\\\\n\\\\n\\\\n\\\\ntelemetryClientId TelemetryKeyClass\\\\n\\\\n\\\\n\\\\ntestInfo TestKeyClass\\\\n\\\\n\\\\n\\\\ntestResults UpstreamLineageClass\\\\n\\\\n\\\\n\\\\nversionInfo VersionPropertiesClass\\\\n\\\\n\\\\n\\\\nversionSetKey VersionSetPropertiesClass\\\\n\\\\n\\\\n\\\\nviewProperties DictWrapper\\\\nThe Actions about an Assertion.\\\\nIn the future, we\\\\u2019ll likely extend this model to support additional\\\\nparameters or options related to the assertion actions.\\\\n\\\\nParameters str | AssertionActionTypeClass\\\\nThe type of the Action\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionActionTypeClass\\\\nBases Aspect\\\\nThe Actions about an Assertion\\\\n\\\\nParameters List[AssertionActionClass]\\\\nActions to be executed on failed assertion run.\\\\n\\\\n\\\\n\\\\nproperty onSuccess Aspect\\\\nInformation about an assertion\\\\n\\\\nParameters None | CustomAssertionInfoClass\\\\nA Custom Assertion definition. This field is populated when type is CUSTOM.\\\\n\\\\n\\\\n\\\\nproperty customProperties None | DatasetAssertionInfoClass\\\\nA Dataset Assertion definition. This field is populated when the type is DATASET.\\\\n\\\\n\\\\n\\\\nproperty description None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty fieldAssertion None | FreshnessAssertionInfoClass\\\\nAn Freshness Assertion definition. This field is populated when the type is FRESHNESS.\\\\n\\\\n\\\\n\\\\nproperty lastUpdated None | SchemaAssertionInfoClass\\\\nAn schema Assertion definition. This field is populated when the type is DATASCHEMA\\\\n\\\\n\\\\n\\\\nproperty source None | SqlAssertionInfoClass\\\\nA SQL Assertion definition. This field is populated when the type is SQL.\\\\n\\\\n\\\\n\\\\nproperty type None | VolumeAssertionInfoClass\\\\nAn Volume Assertion definition. This field is populated when the type is VOLUME.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionKeyClass(assertionId)\\\\nBases\\\\nassertionId (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty assertionId DictWrapper\\\\nThe result of running an assertion\\\\n\\\\nParameters None | float\\\\nObserved aggregate value for evaluated batch\\\\n\\\\n\\\\n\\\\nproperty error None | str\\\\nExternal URL where full results are available. Only present when assertion source is not native.\\\\n\\\\n\\\\n\\\\nproperty missingCount None | Dict[str, str]\\\\nOther results of evaluation\\\\n\\\\n\\\\n\\\\nproperty rowCount str | AssertionResultTypeClass\\\\nThe final result, e.g. either SUCCESS, FAILURE, or ERROR.\\\\n\\\\n\\\\n\\\\nproperty unexpectedCount DictWrapper\\\\nAn error encountered when evaluating an AssertionResult\\\\n\\\\nParameters None | Dict[str, str]\\\\nAdditional metadata depending on the type of error\\\\n\\\\n\\\\n\\\\nproperty type object\\\\n\\\\n\\\\nCUSTOMSQLERROR = \'CUSTOMSQLERROR\'\\\\n\\\\n\\\\n\\\\nFIELDASSERTIONERROR = \'FIELDASSERTIONERROR\'\\\\n\\\\n\\\\n\\\\nINSUFFICIENTDATA = \'INSUFFICIENTDATA\'\\\\n\\\\n\\\\n\\\\nINVALIDPARAMETERS = \'INVALIDPARAMETERS\'\\\\n\\\\n\\\\n\\\\nINVALIDSOURCETYPE = \'INVALIDSOURCETYPE\'\\\\n\\\\n\\\\n\\\\nSOURCECONNECTIONERROR = \'SOURCECONNECTIONERROR\'\\\\n\\\\n\\\\n\\\\nSOURCEQUERYFAILED = \'SOURCEQUERYFAILED\'\\\\n\\\\n\\\\n\\\\nUNKNOWNERROR = \'UNKNOWNERROR\'\\\\n\\\\n\\\\n\\\\nUNSUPPORTEDPLATFORM = \'UNSUPPORTEDPLATFORM\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionResultTypeClass\\\\nBases Aspect\\\\nAn event representing the current status of evaluating an assertion on a batch.\\\\nAssertionRunEvent should be used for reporting the status of a run as an assertion evaluation progresses.\\\\n\\\\nParameters ClassVar[str] = \'timeseries\'\\\\n\\\\n\\\\n\\\\nproperty asserteeUrn str\\\\n\\\\n\\\\n\\\\nproperty batchSpec None | TimeWindowSizeClass\\\\nGranularity of the event if applicable\\\\n\\\\n\\\\n\\\\nproperty messageId PartitionSpecClass | None\\\\nThe optional partition specification.\\\\n\\\\n\\\\n\\\\nproperty result str\\\\nNative (platform-specific) identifier for this run\\\\n\\\\n\\\\n\\\\nproperty runtimeContext str | AssertionRunStatusClass\\\\nThe status of the assertion run as per this timeseries event.\\\\n\\\\n\\\\n\\\\nproperty timestampMillis object\\\\nThe lifecycle status of an assertion run.\\\\n\\\\n\\\\nCOMPLETE = \'COMPLETE\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionSourceClass(type, created=None)\\\\nBases\\\\n\\\\ntype (Union[str, AssertionSourceTypeClass])\\\\ncreated (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created str | AssertionSourceTypeClass\\\\nThe type of the Assertion Source\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionSourceTypeClass\\\\nBases object\\\\nThe function that is applied to the aggregation input (schema, rows, column values) before evaluating an operator.\\\\n\\\\n\\\\nCOLUMNS = \'COLUMNS\'\\\\n\\\\n\\\\n\\\\nCOLUMNCOUNT = \'COLUMNCOUNT\'\\\\n\\\\n\\\\n\\\\nIDENTITY = \'IDENTITY\'\\\\n\\\\n\\\\n\\\\nMAX = \'MAX\'\\\\n\\\\n\\\\n\\\\nMEAN = \'MEAN\'\\\\n\\\\n\\\\n\\\\nMEDIAN = \'MEDIAN\'\\\\n\\\\n\\\\n\\\\nMIN = \'MIN\'\\\\n\\\\n\\\\n\\\\nNULLCOUNT = \'NULLCOUNT\'\\\\n\\\\n\\\\n\\\\nNULLPROPORTION = \'NULLPROPORTION\'\\\\n\\\\n\\\\n\\\\nROWCOUNT = \'ROWCOUNT\'\\\\n\\\\n\\\\n\\\\nSTDDEV = \'STDDEV\'\\\\n\\\\n\\\\n\\\\nSUM = \'SUM\'\\\\n\\\\n\\\\n\\\\nUNIQUECOUNT = \'UNIQUECOUNT\'\\\\n\\\\n\\\\n\\\\nUNIQUEPROPORTION = \'UNIQUEPROPORTION\'\\\\n\\\\n\\\\n\\\\nUNIQUEPROPOTION = \'UNIQUEPROPOTION\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionStdOperatorClass\\\\nBases DictWrapper\\\\nSingle parameter for AssertionStdOperators.\\\\n\\\\nParameters str | AssertionStdParameterTypeClass\\\\nThe type of the parameter\\\\n\\\\n\\\\n\\\\nproperty value object\\\\n\\\\n\\\\nLIST = \'LIST\'\\\\n\\\\n\\\\n\\\\nNUMBER = \'NUMBER\'\\\\n\\\\n\\\\n\\\\nSET = \'SET\'\\\\n\\\\n\\\\n\\\\nSTRING = \'STRING\'\\\\n\\\\n\\\\n\\\\nUNKNOWN = \'UNKNOWN\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionStdParametersClass(value=None, maxValue=None, minValue=None)\\\\nBases\\\\n\\\\nvalue (Optional[AssertionStdParameterClass])\\\\nmaxValue (Optional[AssertionStdParameterClass])\\\\nminValue (Optional[AssertionStdParameterClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty maxValue None | AssertionStdParameterClass\\\\nThe minValue parameter of an assertion\\\\n\\\\n\\\\n\\\\nproperty value object\\\\n\\\\n\\\\nCUSTOM = \'CUSTOM\'\\\\n\\\\n\\\\n\\\\nDATASET = \'DATASET\'\\\\n\\\\n\\\\n\\\\nDATASCHEMA = \'DATASCHEMA\'\\\\n\\\\n\\\\n\\\\nFIELD = \'FIELD\'\\\\n\\\\n\\\\n\\\\nFRESHNESS = \'FRESHNESS\'\\\\n\\\\n\\\\n\\\\nSQL = \'SQL\'\\\\n\\\\n\\\\n\\\\nVOLUME = \'VOLUME\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AssertionValueChangeTypeClass\\\\nBases DictWrapper\\\\nData captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage.\\\\n\\\\nParameters str\\\\nThe entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change.\\\\n\\\\n\\\\n\\\\nproperty impersonator None | str\\\\nwas the change created by an automated process, or manually.\\\\n\\\\nType int\\\\nWhen did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.AzkabanJobTypeClass\\\\nBases DictWrapper\\\\nBaseData record\\\\n\\\\nParameters str\\\\nWhat dataset were used in the MLModel?\\\\n\\\\n\\\\n\\\\nproperty motivation None | List[str]\\\\nHow was the data preprocessed (e.g., tokenization of sentences, cropping of images, any filtering such as dropping images without faces)?\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BatchSpecClass(customProperties=None, nativeBatchId=None, query=None, limit=None)\\\\nBases\\\\n\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nnativeBatchId (Optional[str])\\\\nquery (Optional[str])\\\\nlimit (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty customProperties None | int\\\\nAny limit to the number of rows in the batch, if applied\\\\n\\\\n\\\\n\\\\nproperty nativeBatchId None | str\\\\nA query that identifies a batch of data\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BinaryJsonSchemaClass(schema)\\\\nBases\\\\nschema (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty schema DictWrapper\\\\nBoolean field type.\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BrowsePathEntryClass(id, urn=None)\\\\nBases\\\\n\\\\nid (str)\\\\nurn (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id None | str\\\\nOptional urn pointing to some entity in DataHub\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BrowsePathsClass(paths)\\\\nBases\\\\npaths (List[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty paths \\\\u2018prod/snowflake/datasetName\\\\u2019\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BrowsePathsV2Class(path)\\\\nBases\\\\npath (List[BrowsePathEntryClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty path DictWrapper\\\\n\\\\nParameters str\\\\nUrn of the applied businessAttribute\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BusinessAttributeInfoClass(fieldPath, name, description=None, globalTags=None, glossaryTerms=None, customProperties=None, created=None, lastModified=None, deleted=None, type=None)\\\\nBases\\\\n\\\\nfieldPath (str)\\\\nname (str)\\\\ndescription (Optional[str])\\\\nglobalTags (Optional[GlobalTagsClass])\\\\nglossaryTerms (Optional[GlossaryTermsClass])\\\\ncustomProperties (Optional[Dict[str, str]])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ntype (Optional[SchemaFieldDataTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty deleted None | str\\\\nDescription\\\\n\\\\n\\\\n\\\\nproperty fieldPath None | GlobalTagsClass\\\\nTags associated with the field\\\\n\\\\n\\\\n\\\\nproperty glossaryTerms AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty name None | SchemaFieldDataTypeClass\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BusinessAttributeKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nBusinessAttribute aspect used for applying it to an entity\\\\n\\\\nParameters None | BusinessAttributeAssociationClass\\\\nBusiness Attribute for this field.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.BytesTypeClass\\\\nBases object\\\\n\\\\n\\\\nDAY = \'DAY\'\\\\n\\\\n\\\\n\\\\nHOUR = \'HOUR\'\\\\n\\\\n\\\\n\\\\nMINUTE = \'MINUTE\'\\\\n\\\\n\\\\n\\\\nMONTH = \'MONTH\'\\\\n\\\\n\\\\n\\\\nQUARTER = \'QUARTER\'\\\\n\\\\n\\\\n\\\\nSECOND = \'SECOND\'\\\\n\\\\n\\\\n\\\\nWEEK = \'WEEK\'\\\\n\\\\n\\\\n\\\\nYEAR = \'YEAR\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CaveatDetailsClass(needsFurtherTesting=None, caveatDescription=None, groupsNotRepresented=None)\\\\nBases\\\\n\\\\nneedsFurtherTesting (Optional[bool])\\\\ncaveatDescription (Optional[str])\\\\ngroupsNotRepresented (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty caveatDescription Given gender classes are binary (male/not male), which we include as male/female. Further work needed to evaluate across a spectrum of genders.\\\\n\\\\n\\\\n\\\\nproperty groupsNotRepresented None | bool\\\\nDid the results suggest any further testing?\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CaveatsAndRecommendationsClass(caveats=None, recommendations=None, idealDatasetCharacteristics=None)\\\\nBases\\\\n\\\\ncaveats (Optional[CaveatDetailsClass])\\\\nrecommendations (Optional[str])\\\\nidealDatasetCharacteristics (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty caveats None | List[str]\\\\nIdeal characteristics of an evaluation dataset for this MLModel\\\\n\\\\n\\\\n\\\\nproperty recommendations DictWrapper\\\\nData captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into various lifecycle stages, and who acted to move it into those lifecycle stages. The recommended best practice is to include this record in your record schema, and annotate its fields as @readOnly in your resource. See linkedin/rest.li\\\\n\\\\nParameters AuditStampClass\\\\nAn AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty deleted AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ChangeTypeClass\\\\nBases DictWrapper\\\\nChart cell in a notebook, which will present content in chart format\\\\n\\\\nParameters str\\\\nUnique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as \\\\u2018querybook.com/notebook/773/?cellId=1234\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty cellTitle ChangeAuditStampsClass\\\\nCaptures information about who created/last modified/deleted this Notebook cell and when\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ChartInfoClass(title, description, lastModified, customProperties=None, externalUrl=None, chartUrl=None, inputs=None, inputEdges=None, type=None, access=None, lastRefreshed=None)\\\\nBases\\\\n\\\\ntitle (str)\\\\ndescription (str)\\\\nlastModified (ChangeAuditStampsClass)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\nchartUrl (Optional[str])\\\\ninputs (Optional[List[str]])\\\\ninputEdges (Optional[List[EdgeClass]])\\\\ntype (Union[None, str, ChartTypeClass])\\\\naccess (Union[None, str, AccessLevelClass])\\\\nlastRefreshed (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty access None | str\\\\nURL for the chart. This could be used as an external link on DataHub to allow users access/view the chart\\\\n\\\\n\\\\n\\\\nproperty customProperties str\\\\nDetailed description about the chart\\\\n\\\\n\\\\n\\\\nproperty externalUrl None | List[EdgeClass]\\\\nData sources for the chart\\\\n\\\\n\\\\n\\\\nproperty inputs ChangeAuditStampsClass\\\\nCaptures information about who created/last modified/deleted this chart and when\\\\n\\\\n\\\\n\\\\nproperty lastRefreshed str\\\\nTitle of the chart\\\\n\\\\n\\\\n\\\\nproperty type Aspect\\\\nKey for a Chart\\\\n\\\\nParameters str\\\\nUnique id for the chart. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, chart URL could be used here for Looker such as \\\\u2018looker.linkedin.com/looks/1234\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty dashboardTool Aspect\\\\nInformation for chart query which is used for getting data of the chart\\\\n\\\\nParameters str\\\\nRaw query to build a chart from input datasets\\\\n\\\\n\\\\n\\\\nproperty type object\\\\n\\\\n\\\\nLOOKML = \'LOOKML\'\\\\n\\\\n\\\\n\\\\nSQL = \'SQL\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ChartSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[ChartKeyClass, ChartInfoClass, ChartQueryClass, EditableChartPropertiesClass, OwnershipClass, StatusClass, GlobalTagsClass, BrowsePathsClass, GlossaryTermsClass, InstitutionalMemoryClass, DataPlatformInstanceClass, BrowsePathsV2Class]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ChartTypeClass\\\\nBases Aspect\\\\nExperimental (Subject to breaking change) \\\\u2013 Stats corresponding to chart\\\\u2019s usage.\\\\nIf this aspect represents the latest snapshot of the statistics about a Chart, the eventGranularity field should be null.\\\\nIf this aspect represents a bucketed window of usage statistics (e.g. over a day), then the eventGranularity field should be set accordingly.\\\\n\\\\nParameters ClassVar[str] = \'timeseries\'\\\\n\\\\n\\\\n\\\\nproperty eventGranularity None | str\\\\nThe optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.\\\\n\\\\n\\\\n\\\\nproperty partitionSpec int\\\\nThe event timestamp field as epoch at UTC in milli seconds.\\\\n\\\\n\\\\n\\\\nproperty uniqueUserCount None | List[ChartUserUsageCountsClass]\\\\nUsers within this bucket, with frequency counts\\\\n\\\\n\\\\n\\\\nproperty viewsCount DictWrapper\\\\nRecords a single user\\\\u2019s usage counts for a given resource\\\\n\\\\nParameters str\\\\nThe unique id of the user.\\\\n\\\\n\\\\n\\\\nproperty viewsCount object\\\\nThe matching condition in a filter criterion\\\\n\\\\n\\\\nANCESTORSINCL = \'ANCESTORSINCL\'\\\\n\\\\n\\\\n\\\\nCONTAIN = \'CONTAIN\'\\\\n\\\\n\\\\n\\\\nDESCENDANTSINCL = \'DESCENDANTSINCL\'\\\\n\\\\n\\\\n\\\\nENDWITH = \'ENDWITH\'\\\\n\\\\n\\\\n\\\\nEQUAL = \'EQUAL\'\\\\n\\\\n\\\\n\\\\nEXISTS = \'EXISTS\'\\\\n\\\\n\\\\n\\\\nGREATERTHAN = \'GREATERTHAN\'\\\\n\\\\n\\\\n\\\\nGREATERTHANOREQUALTO = \'GREATERTHANOREQUALTO\'\\\\n\\\\n\\\\n\\\\nIEQUAL = \'IEQUAL\'\\\\n\\\\n\\\\n\\\\nIN = \'IN\'\\\\n\\\\n\\\\n\\\\nISNULL = \'ISNULL\'\\\\n\\\\n\\\\n\\\\nLESSTHAN = \'LESSTHAN\'\\\\n\\\\n\\\\n\\\\nLESSTHANOREQUALTO = \'LESSTHANOREQUALTO\'\\\\n\\\\n\\\\n\\\\nRELATEDINCL = \'RELATEDINCL\'\\\\n\\\\n\\\\n\\\\nSTARTWITH = \'STARTWITH\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ConjunctiveCriterionClass(and)\\\\nBases\\\\nand (List[CriterionClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty and Aspect\\\\nLink from an asset to its parent container\\\\n\\\\nParameters str\\\\nThe parent container of an asset\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ContainerKeyClass(guid=None)\\\\nBases\\\\nguid (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty guid Aspect\\\\nInformation about a Asset Container as received from a 3rd party source system\\\\n\\\\nParameters None | TimeStampClass\\\\nA timestamp documenting when the asset was created in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nDescription of the Asset Container as it exists inside a source system\\\\n\\\\n\\\\n\\\\nproperty env None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty lastModified str\\\\nDisplay name of the Asset Container\\\\n\\\\n\\\\n\\\\nproperty qualifiedName Aspect\\\\nGroup information that can be edited from UI\\\\n\\\\nParameters None | str\\\\nA description of the group\\\\n\\\\n\\\\n\\\\nproperty email str\\\\nA URL which points to a picture which user wants to set as the photo for the group\\\\n\\\\n\\\\n\\\\nproperty slack Aspect\\\\nInformation about a Corp Group ingested from a third party source\\\\n\\\\nParameters List[str]\\\\nowners of this group\\\\nDeprecated! Replaced by Ownership aspect.\\\\n\\\\n\\\\n\\\\nproperty created None | str\\\\nA description of the group.\\\\n\\\\n\\\\n\\\\nproperty displayName None | str\\\\nemail of this group\\\\n\\\\n\\\\n\\\\nproperty groups List[str]\\\\nList of ldap urn in this group.\\\\nDeprecated! Replaced by GroupMembership aspect.\\\\n\\\\n\\\\n\\\\nproperty slack Aspect\\\\nKey for a CorpGroup\\\\n\\\\nParameters str\\\\nThe URL-encoded name of the AD/LDAP group. Serves as a globally unique identifier within DataHub.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CorpGroupSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[CorpGroupKeyClass, CorpGroupInfoClass, GlobalTagsClass, StatusClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CorpUserAppearanceSettingsClass(showSimplifiedHomepage=None, showThemeV2=None)\\\\nBases\\\\n\\\\nshowSimplifiedHomepage (Optional[bool])\\\\nshowThemeV2 (Optional[bool])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty showSimplifiedHomepage None | bool\\\\nFlag controlling whether the V2 UI for DataHub is shown.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CorpUserCredentialsClass(salt, hashedPassword, passwordResetToken=None, passwordResetTokenExpirationTimeMillis=None)\\\\nBases\\\\n\\\\nsalt (str)\\\\nhashedPassword (str)\\\\npasswordResetToken (Optional[str])\\\\npasswordResetTokenExpirationTimeMillis (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty hashedPassword None | str\\\\nOptional token needed to reset a user\\\\u2019s password. Can only be set by the admin.\\\\n\\\\n\\\\n\\\\nproperty passwordResetTokenExpirationTimeMillis str\\\\nSalt used to hash password\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CorpUserEditableInfoClass(aboutMe=None, teams=None, skills=None, pictureLink=None, displayName=None, title=None, platforms=None, persona=None, slack=None, phone=None, email=None, informationSources=None)\\\\nBases\\\\n\\\\naboutMe (Optional[str])\\\\nteams (Optional[List[str]])\\\\nskills (Optional[List[str]])\\\\npictureLink (Optional[str])\\\\ndisplayName (Optional[str])\\\\ntitle (Optional[str])\\\\nplatforms (Optional[List[str]])\\\\npersona (Optional[str])\\\\nslack (Optional[str])\\\\nphone (Optional[str])\\\\nemail (Optional[str])\\\\ninformationSources (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aboutMe None | str\\\\nDataHub-native display name\\\\n\\\\n\\\\n\\\\nproperty email None | List[str]\\\\nInformation sources that have been used to populate this CorpUserEditableInfo.\\\\nThese include platform resources, such as Slack members or Looker users.\\\\nThey can also refer to other semantic urns in the future.\\\\n\\\\n\\\\n\\\\nproperty persona None | str\\\\nPhone number to contact the user\\\\n\\\\n\\\\n\\\\nproperty pictureLink None | List[str]\\\\nThe platforms that the user commonly works with\\\\n\\\\n\\\\n\\\\nproperty skills None | str\\\\nSlack handle for the user\\\\n\\\\n\\\\n\\\\nproperty teams None | str\\\\nDataHub-native Title, e.g. \\\\u2018Software Engineer\\\\u2019\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CorpUserInfoClass(active, customProperties=None, displayName=None, email=None, title=None, managerUrn=None, departmentId=None, departmentName=None, firstName=None, lastName=None, fullName=None, countryCode=None, system=None)\\\\nBases\\\\n\\\\nactive (bool)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\ndisplayName (Optional[str])\\\\nemail (Optional[str])\\\\ntitle (Optional[str])\\\\nmanagerUrn (Optional[str])\\\\ndepartmentId (Optional[int])\\\\ndepartmentName (Optional[str])\\\\nfirstName (Optional[str])\\\\nlastName (Optional[str])\\\\nfullName (Optional[str])\\\\ncountryCode (Optional[str])\\\\nsystem (Optional[bool])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty active\\\\nDeprecated! Use CorpUserStatus instead. Whether the corpUser is active, ref\\\\n\\\\nType None | str\\\\ntwo uppercase letters country code. e.g.  US\\\\n\\\\n\\\\n\\\\nproperty customProperties None | int\\\\ndepartment id this user belong to\\\\n\\\\n\\\\n\\\\nproperty departmentName None | str\\\\ndisplayName of this user ,  e.g.  Hang Zhang(DataHQ)\\\\n\\\\n\\\\n\\\\nproperty email None | str\\\\nfirst name of this user\\\\n\\\\n\\\\n\\\\nproperty fullName None | str\\\\nlast name of this user\\\\n\\\\n\\\\n\\\\nproperty managerUrn bool | None\\\\nWhether the corpUser is a system user.\\\\n\\\\n\\\\n\\\\nproperty title Aspect\\\\nKey for a CorpUser\\\\n\\\\nParameters str\\\\nThe name of the AD/LDAP user.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CorpUserSettingsClass(appearance, views=None, notificationSettings=None)\\\\nBases\\\\n\\\\nappearance (CorpUserAppearanceSettingsClass)\\\\nviews (Optional[CorpUserViewsSettingsClass])\\\\nnotificationSettings (Optional[NotificationSettingsClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty appearance None | NotificationSettingsClass\\\\nNotification settings for a user\\\\n\\\\n\\\\n\\\\nproperty views DictWrapper\\\\nA metadata snapshot for a specific CorpUser entity.\\\\n\\\\nParameters List[CorpUserKeyClass | CorpUserInfoClass | CorpUserEditableInfoClass | CorpUserStatusClass | GroupMembershipClass | GlobalTagsClass | StatusClass]\\\\nThe list of metadata aspects associated with the CorpUser. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nThe status of the user, e.g. provisioned, active, suspended, etc.\\\\n\\\\nParameters AuditStampClass\\\\nAudit stamp containing who last modified the status and when.\\\\n\\\\n\\\\n\\\\nproperty status DictWrapper\\\\nSettings related to the \\\\u2018Views\\\\u2019 feature.\\\\n\\\\nParameters None | str\\\\nThe default View which is selected for the user.\\\\nIf none is chosen, then this value will be left blank.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CostClass(costType, cost)\\\\nBases\\\\n\\\\ncostType (Union[str, CostTypeClass])\\\\ncost (CostCostClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cost str | CostTypeClass\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CostCostClass(fieldDiscriminator, costId=None, costCode=None)\\\\nBases\\\\n\\\\nfieldDiscriminator (Union[str, CostCostDiscriminatorClass])\\\\ncostId (Optional[float])\\\\ncostCode (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty costCode None | float\\\\n\\\\n\\\\n\\\\nproperty fieldDiscriminator object\\\\n\\\\n\\\\ncostCode = \'costCode\'\\\\n\\\\n\\\\n\\\\ncostId = \'costId\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CostTypeClass\\\\nBases DictWrapper\\\\nA criterion for matching a field with given value\\\\n\\\\nParameters str | ConditionClass\\\\nThe condition for the criterion, e.g. EQUAL, STARTWITH\\\\n\\\\n\\\\n\\\\nproperty field bool\\\\nWhether the condition should be negated\\\\n\\\\n\\\\n\\\\nproperty value List[str]\\\\nValues. one of which the intended field should match\\\\nNote, if values is set, the above \\\\u201cvalue\\\\u201d field will be ignored\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.CustomAssertionInfoClass(type, entity, field=None, logic=None)\\\\nBases\\\\n\\\\ntype (str)\\\\nentity (str)\\\\nfield (Optional[str])\\\\nlogic (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity None | str\\\\ndataset schema field targeted by this assertion.\\\\nThis field is expected to be provided if the assertion is on dataset field\\\\n\\\\n\\\\n\\\\nproperty logic str\\\\nThe type of custom assertion.\\\\nThis is how your assertion will appear categorized in DataHub UI.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DashboardInfoClass(title, description, lastModified, customProperties=None, externalUrl=None, charts=None, chartEdges=None, datasets=None, datasetEdges=None, dashboards=None, dashboardUrl=None, access=None, lastRefreshed=None)\\\\nBases\\\\n\\\\ntitle (str)\\\\ndescription (str)\\\\nlastModified (ChangeAuditStampsClass)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\ncharts (Optional[List[str]])\\\\nchartEdges (Optional[List[EdgeClass]])\\\\ndatasets (Optional[List[str]])\\\\ndatasetEdges (Optional[List[EdgeClass]])\\\\ndashboards (Optional[List[EdgeClass]])\\\\ndashboardUrl (Optional[str])\\\\naccess (Union[None, str, AccessLevelClass])\\\\nlastRefreshed (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty access None | List[EdgeClass]\\\\nCharts in a dashboard\\\\n\\\\n\\\\n\\\\nproperty charts Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty dashboardUrl List[EdgeClass]\\\\nDashboards included by this dashboard.\\\\nSome dashboard entities (e.g. PowerBI Apps) can contain other dashboards.\\\\nThe Edge\\\\u2019s sourceUrn should never be set, as it will always be the base dashboard.\\\\n\\\\n\\\\n\\\\nproperty datasetEdges List[str]\\\\nDatasets consumed by a dashboard\\\\nDeprecated! Use datasetEdges instead.\\\\n\\\\n\\\\n\\\\nproperty description None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty lastModified None | int\\\\nThe time when this dashboard last refreshed\\\\n\\\\n\\\\n\\\\nproperty title Aspect\\\\nKey for a Dashboard\\\\n\\\\nParameters str\\\\nUnique id for the dashboard. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, dashboard URL could be used here for Looker such as \\\\u2018looker.linkedin.com/dashboards/1234\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty dashboardTool DictWrapper\\\\nA metadata snapshot for a specific Dashboard entity.\\\\n\\\\nParameters List[DashboardKeyClass | DashboardInfoClass | EditableDashboardPropertiesClass | OwnershipClass | StatusClass | GlobalTagsClass | BrowsePathsClass | GlossaryTermsClass | InstitutionalMemoryClass | DataPlatformInstanceClass | BrowsePathsV2Class]\\\\nThe list of metadata aspects associated with the dashboard. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nExperimental (Subject to breaking change) \\\\u2013 Stats corresponding to dashboard\\\\u2019s usage.\\\\nIf this aspect represents the latest snapshot of the statistics about a Dashboard, the eventGranularity field should be null.\\\\nIf this aspect represents a bucketed window of usage statistics (e.g. over a day), then the eventGranularity field should be set accordingly.\\\\n\\\\nParameters ClassVar[str] = \'timeseries\'\\\\n\\\\n\\\\n\\\\nproperty eventGranularity None | int\\\\nThe total number of dashboard executions (refreshes / syncs)\\\\n\\\\n\\\\n\\\\nproperty favoritesCount None | int\\\\nLast viewed at\\\\nThis should not be set in cases where statistics are windowed.\\\\n\\\\n\\\\n\\\\nproperty messageId PartitionSpecClass | None\\\\nThe optional partition specification.\\\\n\\\\n\\\\n\\\\nproperty timestampMillis None | int\\\\nUnique user count\\\\n\\\\n\\\\n\\\\nproperty userCounts None | int\\\\nThe total number of times dashboard has been viewed\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DashboardUserUsageCountsClass(user, viewsCount=None, executionsCount=None, usageCount=None, userEmail=None)\\\\nBases\\\\n\\\\nuser (str)\\\\nviewsCount (Optional[int])\\\\nexecutionsCount (Optional[int])\\\\nusageCount (Optional[int])\\\\nuserEmail (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty executionsCount None | int\\\\nNormalized numeric metric representing user\\\\u2019s dashboard usage \\\\u2013 the number of times the user executed or viewed the dashboard.\\\\n\\\\n\\\\n\\\\nproperty user None | str\\\\nIf useremail is set, we attempt to resolve the user\\\\u2019s urn upon ingest\\\\n\\\\n\\\\n\\\\nproperty viewsCount Aspect\\\\nKey for a Data Contract\\\\n\\\\nParameters str\\\\nUnique id for the contract\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataContractPropertiesClass(entity, schema=None, freshness=None, dataQuality=None, rawContract=None)\\\\nBases\\\\n\\\\nentity (str)\\\\nschema (Optional[List[SchemaContractClass]])\\\\nfreshness (Optional[List[FreshnessContractClass]])\\\\ndataQuality (Optional[List[DataQualityContractClass]])\\\\nrawContract (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty dataQuality str\\\\nThe entity that this contract is associated with. Currently, we only support Dataset contracts, but\\\\nin the future we may also support Data Product level contracts.\\\\n\\\\n\\\\n\\\\nproperty freshness None | str\\\\nYAML-formatted contract definition\\\\n\\\\n\\\\n\\\\nproperty schema object\\\\n\\\\n\\\\nACTIVE = \'ACTIVE\'\\\\n\\\\n\\\\n\\\\nPENDING = \'PENDING\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataContractStatusClass(state, customProperties=None)\\\\nBases\\\\n\\\\nstate (Union[str, DataContractStateClass])\\\\ncustomProperties (Optional[Dict[str, str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty customProperties str | DataContractStateClass\\\\nThe latest state of the data contract\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataFlowInfoClass(name, customProperties=None, externalUrl=None, description=None, project=None, created=None, lastModified=None, env=None)\\\\nBases\\\\n\\\\nname (str)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\ndescription (Optional[str])\\\\nproject (Optional[str])\\\\ncreated (Optional[TimeStampClass])\\\\nlastModified (Optional[TimeStampClass])\\\\nenv (Union[None, str, FabricTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty description None | str | FabricTypeClass\\\\nEnvironment for this flow\\\\n\\\\n\\\\n\\\\nproperty externalUrl None | TimeStampClass\\\\nA timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty name None | str\\\\nOptional project/namespace associated with the flow\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataFlowKeyClass(orchestrator, flowId, cluster)\\\\nBases\\\\n\\\\norchestrator (str)\\\\nflowId (str)\\\\ncluster (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cluster str\\\\nUnique Identifier of the data flow\\\\n\\\\n\\\\n\\\\nproperty orchestrator DictWrapper\\\\nA metadata snapshot for a specific DataFlow entity.\\\\n\\\\nParameters List[DataFlowKeyClass | DataFlowInfoClass | EditableDataFlowPropertiesClass | OwnershipClass | StatusClass | GlobalTagsClass | BrowsePathsClass | GlossaryTermsClass | InstitutionalMemoryClass | DataPlatformInstanceClass | BrowsePathsV2Class]\\\\nThe list of metadata aspects associated with the data flow. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nInformation about a DataHub Access Token\\\\n\\\\nParameters str\\\\nUrn of the actor to which this access token belongs to.\\\\n\\\\n\\\\n\\\\nproperty createdAt None | str\\\\nDescription of the token if defined.\\\\n\\\\n\\\\n\\\\nproperty expiresAt str\\\\nUser defined name for the access token if defined.\\\\n\\\\n\\\\n\\\\nproperty ownerUrn Aspect\\\\nKey for a DataHub Access Token\\\\n\\\\nParameters str\\\\nAccess token\\\\u2019s SHA-256 hashed JWT signature\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubActionKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\nInformation used to filter DataHub actors.\\\\n\\\\nParameters bool\\\\nWhether the filter should apply to all groups.\\\\n\\\\n\\\\n\\\\nproperty allUsers None | List[str]\\\\nA specific set of groups to apply the policy to (disjunctive)\\\\n\\\\n\\\\n\\\\nproperty resourceOwners None | List[str]\\\\nDefine type of ownership for the policy\\\\n\\\\n\\\\n\\\\nproperty roles None | List[str]\\\\nA specific set of users to apply the policy to (disjunctive)\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubConnectionDetailsClass(type, name=None, json=None)\\\\nBases\\\\n\\\\ntype (Union[str, DataHubConnectionDetailsTypeClass])\\\\nname (Optional[str])\\\\njson (Optional[DataHubJsonConnectionClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty json None | str\\\\nDisplay name of the connection\\\\n\\\\n\\\\n\\\\nproperty type object\\\\n\\\\n\\\\nJSON = \'JSON\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubConnectionKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\n\\\\nParameters None | bool\\\\nWhether or not to run this ingestion source in debug mode\\\\n\\\\n\\\\n\\\\nproperty executorId None | Dict[str, str]\\\\nExtra arguments for the ingestion run.\\\\n\\\\n\\\\n\\\\nproperty recipe None | str\\\\nThe PyPI version of the datahub CLI to use when executing a recipe\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubIngestionSourceInfoClass(name, type, config, platform=None, schedule=None, source=None)\\\\nBases\\\\n\\\\nname (str)\\\\ntype (str)\\\\nconfig (DataHubIngestionSourceConfigClass)\\\\nplatform (Optional[str])\\\\nschedule (Optional[DataHubIngestionSourceScheduleClass])\\\\nsource (Optional[DataHubIngestionSourceSourceClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty config str\\\\nThe display name of the ingestion source\\\\n\\\\n\\\\n\\\\nproperty platform None | DataHubIngestionSourceScheduleClass\\\\nThe schedule on which the ingestion source is executed\\\\n\\\\n\\\\n\\\\nproperty source str\\\\nThe type of the source itself, e.g. mysql, bigquery, bigquery-usage. Should match the recipe.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubIngestionSourceKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\nThe schedule associated with an ingestion source.\\\\n\\\\nParameters str\\\\nA cron-formatted execution interval, as a cron string, e.g. * * * * *\\\\n\\\\n\\\\n\\\\nproperty timezone DictWrapper\\\\n\\\\nParameters str | DataHubIngestionSourceSourceTypeClass\\\\nThe source type of the ingestion source\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubIngestionSourceSourceTypeClass\\\\nBases DictWrapper\\\\nA set of connection details consisting of an encrypted JSON blob.\\\\n\\\\nParameters str\\\\nThe encrypted JSON connection details.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubOpenAPISchemaKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nPlaceholder aspect for persona type info\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubPersonaKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nInformation about a DataHub (UI) access policy.\\\\n\\\\nParameters DataHubActorFilterClass\\\\nThe actors that the policy applies to.\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nDisplay name of the Policy\\\\n\\\\n\\\\n\\\\nproperty editable None | int\\\\nTimestamp when the policy was last updated\\\\n\\\\n\\\\n\\\\nproperty privileges None | DataHubResourceFilterClass\\\\nThe resource that the policy applies to. Not required for some \\\\u2018Platform\\\\u2019 privileges.\\\\n\\\\n\\\\n\\\\nproperty state str\\\\nThe type of policy\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubPolicyKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\nA metadata snapshot for DataHub Access Policy data.\\\\n\\\\nParameters List[DataHubPolicyKeyClass | DataHubPolicyInfoClass]\\\\nThe list of metadata aspects associated with the DataHub access policy.\\\\n\\\\n\\\\n\\\\nproperty urn DictWrapper\\\\nInformation used to filter DataHub resource.\\\\n\\\\nParameters bool\\\\nWhether the policy should be applied to all assets matching the filter.\\\\n\\\\n\\\\n\\\\nproperty filter None | List[str]\\\\nA specific set of resources to apply the policy to, e.g. asset urns\\\\n\\\\n\\\\n\\\\nproperty type Aspect\\\\n\\\\nParameters RetentionClass\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubRetentionKeyClass(entityName, aspectName)\\\\nBases\\\\n\\\\nentityName (str)\\\\naspectName (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspectName str\\\\nEntity name to apply retention to.  (or empty) for applying defaults.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubRetentionSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[DataHubRetentionKeyClass, DataHubRetentionConfigClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubRoleInfoClass(name, description, editable=None)\\\\nBases\\\\n\\\\nname (str)\\\\ndescription (str)\\\\neditable (Optional[bool])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty description bool\\\\nWhether the role should be editable via the UI\\\\n\\\\n\\\\n\\\\nproperty name Aspect\\\\nKey for a DataHub Role\\\\n\\\\nParameters str\\\\nA unique id for the DataHub role record. Generated on the server side at role creation time.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubSearchConfigClass(fieldName=None, fieldType=None, queryByDefault=None, enableAutocomplete=None, addToFilters=None, addHasValuesToFilters=None, filterNameOverride=None, hasValuesFilterNameOverride=None, boostScore=None, hasValuesFieldName=None, numValuesFieldName=None, weightsPerFieldValue=None, fieldNameAliases=None)\\\\nBases\\\\n\\\\nfieldName (Optional[str])\\\\nfieldType (Union[None, str, SearchFieldTypeClass])\\\\nqueryByDefault (Optional[bool])\\\\nenableAutocomplete (Optional[bool])\\\\naddToFilters (Optional[bool])\\\\naddHasValuesToFilters (Optional[bool])\\\\nfilterNameOverride (Optional[str])\\\\nhasValuesFilterNameOverride (Optional[str])\\\\nboostScore (Optional[float])\\\\nhasValuesFieldName (Optional[str])\\\\nnumValuesFieldName (Optional[str])\\\\nweightsPerFieldValue (Optional[Dict[str, float]])\\\\nfieldNameAliases (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty addHasValuesToFilters bool\\\\nWhether or not to add field to filters.\\\\n\\\\n\\\\n\\\\nproperty boostScore bool\\\\nWhether we should use the field for default autocomplete\\\\n\\\\n\\\\n\\\\nproperty fieldName None | List[str]\\\\n(Optional) Aliases for this given field that can be used for sorting etc.\\\\n\\\\n\\\\n\\\\nproperty fieldType None | str\\\\nDisplay name of the filter\\\\n\\\\n\\\\n\\\\nproperty hasValuesFieldName None | str\\\\nDisplay name of the has values filter\\\\n\\\\n\\\\n\\\\nproperty numValuesFieldName bool\\\\nWhether we should match the field for the default search query\\\\n\\\\n\\\\n\\\\nproperty weightsPerFieldValue Aspect\\\\nKey for a DataHub Secret\\\\n\\\\nParameters str\\\\nA unique id for the Secret\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubSecretValueClass(name, value, description=None, created=None)\\\\nBases\\\\n\\\\nname (str)\\\\nvalue (str)\\\\ndescription (Optional[str])\\\\ncreated (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | str\\\\nDescription of the secret\\\\n\\\\n\\\\n\\\\nproperty name str\\\\nThe AES-encrypted value of the DataHub secret.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubStepStateKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nThe properties associated with a DataHub step state\\\\n\\\\nParameters AuditStampClass\\\\nAudit stamp describing the last person to update it.\\\\n\\\\n\\\\n\\\\nproperty properties Aspect\\\\nKey for a DataHubUpgrade\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubUpgradeRequestClass(timestampMs, version)\\\\nBases\\\\n\\\\ntimestampMs (int)\\\\nversion (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty timestampMs str\\\\nVersion of this upgrade\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubUpgradeResultClass(timestampMs, state=None, result=None)\\\\nBases\\\\n\\\\ntimestampMs (int)\\\\nstate (Union[str, DataHubUpgradeStateClass, None])\\\\nresult (Optional[Dict[str, str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty result str | DataHubUpgradeStateClass | None\\\\nUpgrade state  UpgradeResult.Result\\\\n\\\\n\\\\n\\\\nproperty timestampMs object\\\\n\\\\n\\\\nABORTED = \'ABORTED\'\\\\n\\\\n\\\\n\\\\nFAILED = \'FAILED\'\\\\n\\\\n\\\\n\\\\nINPROGRESS = \'INPROGRESS\'\\\\n\\\\n\\\\n\\\\nSUCCEEDED = \'SUCCEEDED\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubViewDefinitionClass(entityTypes, filter)\\\\nBases\\\\n\\\\nentityTypes (List[str])\\\\nfilter (FilterClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityTypes FilterClass\\\\nThe filter criteria, which represents the view itself\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubViewInfoClass(name, type, definition, created, lastModified, description=None)\\\\nBases Understand whether an entity type filter is required.\\\\n\\\\nParameters AuditStampClass\\\\nAudit stamp capturing the time and actor who created the View.\\\\n\\\\n\\\\n\\\\nproperty definition None | str\\\\nDescription of the view\\\\n\\\\n\\\\n\\\\nproperty lastModified str\\\\nThe name of the View\\\\n\\\\n\\\\n\\\\nproperty type Aspect\\\\nKey for a DataHub View\\\\n\\\\nParameters str\\\\nA unique id for the View\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataHubViewTypeClass\\\\nBases Aspect\\\\nInformation about a Data processing job\\\\n\\\\nParameters None | TimeStampClass\\\\nA timestamp documenting when the asset was created in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nJob description\\\\n\\\\n\\\\n\\\\nproperty env None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty flowUrn None | TimeStampClass\\\\nA timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty name None | str | JobStatusClass\\\\nStatus of the job - Deprecated for Data Process Instance model.\\\\n\\\\n\\\\n\\\\nproperty type AzkabanJobType is deprecated. Please use strings instead.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataJobInputOutputClass(inputDatasets, outputDatasets, inputDatasetEdges=None, outputDatasetEdges=None, inputDatajobs=None, inputDatajobEdges=None, inputDatasetFields=None, outputDatasetFields=None, fineGrainedLineages=None)\\\\nBases\\\\n\\\\ninputDatasets (List[str])\\\\noutputDatasets (List[str])\\\\ninputDatasetEdges (Optional[List[EdgeClass]])\\\\noutputDatasetEdges (Optional[List[EdgeClass]])\\\\ninputDatajobs (Optional[List[str]])\\\\ninputDatajobEdges (Optional[List[EdgeClass]])\\\\ninputDatasetFields (Optional[List[str]])\\\\noutputDatasetFields (Optional[List[str]])\\\\nfineGrainedLineages (Optional[List[FineGrainedLineageClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty fineGrainedLineages None | List[EdgeClass]\\\\nInput datajobs that this data job depends on\\\\n\\\\n\\\\n\\\\nproperty inputDatajobs None | List[EdgeClass]\\\\nInput datasets consumed by the data job during processing\\\\n\\\\n\\\\n\\\\nproperty inputDatasetFields List[str]\\\\nInput datasets consumed by the data job during processing\\\\nDeprecated! Use inputDatasetEdges instead.\\\\n\\\\n\\\\n\\\\nproperty outputDatasetEdges None | List[str]\\\\nFields of the output datasets this job writes to\\\\n\\\\n\\\\n\\\\nproperty outputDatasets Aspect\\\\nKey for a Data Job\\\\n\\\\nParameters str\\\\nStandardized data processing flow urn representing the flow for the job\\\\n\\\\n\\\\n\\\\nproperty jobId DictWrapper\\\\nA metadata snapshot for a specific DataJob entity.\\\\n\\\\nParameters List[DataJobKeyClass | DataJobInfoClass | DataJobInputOutputClass | EditableDataJobPropertiesClass | OwnershipClass | StatusClass | GlobalTagsClass | BrowsePathsClass | GlossaryTermsClass | InstitutionalMemoryClass | DataPlatformInstanceClass | BrowsePathsV2Class]\\\\nThe list of metadata aspects associated with the data job. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nInformation about a data platform\\\\n\\\\nParameters str\\\\nThe delimiter in the dataset names on the data platform, e.g. \\\\u2018/\\\\u2019 for HDFS and \\\\u2018.\\\\u2019 for Oracle\\\\n\\\\n\\\\n\\\\nproperty displayName None | str\\\\nThe URL for a logo associated with the platform\\\\n\\\\n\\\\n\\\\nproperty name str | PlatformTypeClass\\\\nPlatform type this data platform describes\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataPlatformInstanceClass(platform, instance=None)\\\\nBases\\\\n\\\\nplatform (str)\\\\ninstance (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty instance str\\\\nData Platform\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataPlatformInstanceKeyClass(platform, instance)\\\\nBases\\\\n\\\\nplatform (str)\\\\ninstance (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty instance str\\\\nData platform urn associated with the instance\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataPlatformInstancePropertiesClass(customProperties=None, externalUrl=None, name=None, description=None)\\\\nBases\\\\n\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\nname (Optional[str])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nDocumentation of the Data Platform Instance\\\\n\\\\n\\\\n\\\\nproperty externalUrl None | str\\\\nDisplay name of the Data Platform Instance\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataPlatformKeyClass(platformName)\\\\nBases\\\\nplatformName (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty platformName DictWrapper\\\\nA metadata snapshot for a specific dataplatform entity.\\\\n\\\\nParameters List[DataPlatformKeyClass | DataPlatformInfoClass]\\\\nThe list of metadata aspects associated with the data platform. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nThe inputs and outputs of this data process\\\\n\\\\nParameters None | List[str]\\\\nthe inputs of the data process\\\\n\\\\n\\\\n\\\\nproperty outputs Aspect\\\\nInformation about the inputs datasets of a Data process\\\\n\\\\nParameters None | List[EdgeClass]\\\\nInput assets consumed by the data process instance, with additional metadata.\\\\nCounts as lineage.\\\\nWill eventually deprecate the inputs field.\\\\n\\\\n\\\\n\\\\nproperty inputs Aspect\\\\nKey for an Asset DataProcessInstance\\\\n\\\\nParameters str\\\\nA unique id for the DataProcessInstance . Should be separate from the name used for displaying a DataProcessInstance.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProcessInstanceOutputClass(outputs, outputEdges=None)\\\\nBases\\\\n\\\\noutputs (List[str])\\\\noutputEdges (Optional[List[EdgeClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty outputEdges List[str]\\\\nOutput assets produced\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProcessInstancePropertiesClass(name, created, customProperties=None, externalUrl=None, type=None)\\\\nBases\\\\n\\\\nname (str)\\\\ncreated (AuditStampClass)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\ntype (Union[None, str, DataProcessTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty externalUrl str\\\\nProcess name\\\\n\\\\n\\\\n\\\\nproperty type Aspect\\\\nInformation about Data process relationships\\\\n\\\\nParameters None | str\\\\nThe parent DataProcessInstance where it belongs to.\\\\nIf it is a Airflow Task then it should belong to an Airflow Dag run as well\\\\nwhich will be another DataProcessInstance\\\\n\\\\n\\\\n\\\\nproperty parentTemplate List[str]\\\\nInput DataProcessInstance which triggered this dataprocess instance\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProcessInstanceRunEventClass(timestampMillis, status, eventGranularity=None, partitionSpec=None, messageId=None, externalUrl=None, attempt=None, result=None, durationMillis=None)\\\\nBases\\\\n\\\\ntimestampMillis (int)\\\\nstatus (Union[str, DataProcessRunStatusClass])\\\\neventGranularity (Optional[TimeWindowSizeClass])\\\\npartitionSpec (Optional[PartitionSpecClass])\\\\nmessageId (Optional[str])\\\\nexternalUrl (Optional[str])\\\\nattempt (Optional[int])\\\\nresult (Optional[DataProcessInstanceRunResultClass])\\\\ndurationMillis (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nASPECTTYPE None | int\\\\nReturn the try number that this Instance Run is in\\\\n\\\\n\\\\n\\\\nproperty durationMillis None | TimeWindowSizeClass\\\\nGranularity of the event if applicable\\\\n\\\\n\\\\n\\\\nproperty externalUrl None | str\\\\nThe optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.\\\\n\\\\n\\\\n\\\\nproperty partitionSpec None | DataProcessInstanceRunResultClass\\\\nThe final result of the Data Processing run.\\\\n\\\\n\\\\n\\\\nproperty status int\\\\nThe event timestamp field as epoch at UTC in milli seconds.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProcessInstanceRunResultClass(type, nativeResultType)\\\\nBases\\\\n\\\\ntype (Union[str, RunResultTypeClass])\\\\nnativeResultType (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty nativeResultType str | RunResultTypeClass\\\\nThe final result, e.g. SUCCESS, FAILURE, SKIPPED, or UPFORRETRY.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProcessKeyClass(name, orchestrator, origin)\\\\nBases\\\\n\\\\nname (str)\\\\norchestrator (str)\\\\norigin (Union[str, FabricTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name str\\\\nStandardized Orchestrator where data process is defined.\\\\nTODO str | FabricTypeClass\\\\nFabric type where dataset belongs to or where it was generated.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProcessRunStatusClass\\\\nBases DictWrapper\\\\nA metadata snapshot for a specific Data process entity.\\\\n\\\\nParameters List[DataProcessKeyClass | OwnershipClass | DataProcessInfoClass | StatusClass]\\\\nThe list of metadata aspects associated with the data process. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn object\\\\n\\\\n\\\\nBATCHADHOC = \'BATCHADHOC\'\\\\n\\\\n\\\\n\\\\nBATCHSCHEDULED = \'BATCHSCHEDULED\'\\\\n\\\\n\\\\n\\\\nSTREAMING = \'STREAMING\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProductAssociationClass(destinationUrn, sourceUrn=None, created=None, lastModified=None, properties=None, outputPort=None)\\\\nBases\\\\n\\\\ndestinationUrn (str)\\\\nsourceUrn (Optional[str])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\nproperties (Optional[Dict[str, str]])\\\\noutputPort (Optional[bool])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created str\\\\nUrn of the destination of this relationship edge.\\\\n\\\\n\\\\n\\\\nproperty lastModified bool\\\\nIf set to true, this asset is an output port of the Data Product.\\\\n\\\\n\\\\n\\\\nproperty properties None | str\\\\nUrn of the source of this relationship edge.\\\\nIf not specified, assumed to be the entity that this aspect belongs to.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataProductKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nThe main properties of a Data Product\\\\n\\\\nParameters None | List[DataProductAssociationClass]\\\\nA list of assets that are part of this Data Product\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nDocumentation of the dataset\\\\n\\\\n\\\\n\\\\nproperty externalUrl None | str\\\\nDisplay name of the Data Product\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataQualityContractClass(assertion)\\\\nBases\\\\nassertion (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty assertion DictWrapper\\\\nInformation about a transformation. It may be a query,\\\\n\\\\nParameters None | QueryStatementClass\\\\nThe data transform may be defined by a query statement\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataTransformLogicClass(transforms)\\\\nBases\\\\ntransforms (List[DataTransformClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty transforms Aspect\\\\n\\\\nParameters None | str\\\\nAn optional description for the data type.\\\\n\\\\n\\\\n\\\\nproperty displayName str\\\\nThe qualified name for the data type. Usually a unique namespace + name, e.g. datahub.string\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DataTypeKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nCheckpoint of a datahub ingestion run for a given job.\\\\n\\\\nParameters ClassVar[str] = \'timeseries\'\\\\n\\\\n\\\\n\\\\nproperty config None | TimeWindowSizeClass\\\\nGranularity of the event if applicable\\\\n\\\\n\\\\n\\\\nproperty messageId PartitionSpecClass | None\\\\nThe optional partition specification.\\\\n\\\\n\\\\n\\\\nproperty pipelineName str\\\\nThe id of the instance against which the ingestion pipeline ran.\\\\ne.g. str\\\\nThe run identifier of this job.\\\\n\\\\n\\\\n\\\\nproperty state int\\\\nThe event timestamp field as epoch at UTC in milli seconds.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatahubIngestionRunSummaryClass(timestampMillis, pipelineName, platformInstanceId, runId, runStatus, eventGranularity=None, partitionSpec=None, messageId=None, numWorkUnitsCommitted=None, numWorkUnitsCreated=None, numEvents=None, numEntities=None, numAspects=None, numSourceAPICalls=None, totalLatencySourceAPICalls=None, numSinkAPICalls=None, totalLatencySinkAPICalls=None, numWarnings=None, numErrors=None, numEntitiesSkipped=None, config=None, customsummary=None, softwareVersion=None, systemHostName=None, operatingSystemName=None, numProcessors=None, totalMemory=None, availableMemory=None)\\\\nBases\\\\n\\\\ntimestampMillis (int)\\\\npipelineName (str)\\\\nplatformInstanceId (str)\\\\nrunId (str)\\\\nrunStatus (Union[str, JobStatusClass])\\\\neventGranularity (Optional[TimeWindowSizeClass])\\\\npartitionSpec (Optional[PartitionSpecClass])\\\\nmessageId (Optional[str])\\\\nnumWorkUnitsCommitted (Optional[int])\\\\nnumWorkUnitsCreated (Optional[int])\\\\nnumEvents (Optional[int])\\\\nnumEntities (Optional[int])\\\\nnumAspects (Optional[int])\\\\nnumSourceAPICalls (Optional[int])\\\\ntotalLatencySourceAPICalls (Optional[int])\\\\nnumSinkAPICalls (Optional[int])\\\\ntotalLatencySinkAPICalls (Optional[int])\\\\nnumWarnings (Optional[int])\\\\nnumErrors (Optional[int])\\\\nnumEntitiesSkipped (Optional[int])\\\\nconfig (Optional[str])\\\\ncustomsummary (Optional[str])\\\\nsoftwareVersion (Optional[str])\\\\nsystemHostName (Optional[str])\\\\noperatingSystemName (Optional[str])\\\\nnumProcessors (Optional[int])\\\\ntotalMemory (Optional[int])\\\\navailableMemory (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nASPECTTYPE None | int\\\\nThe available memory on the host the ingestion pipeline ran on.\\\\n\\\\n\\\\n\\\\nproperty config None | str\\\\nCustom value.\\\\n\\\\n\\\\n\\\\nproperty eventGranularity None | str\\\\nThe optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.\\\\n\\\\n\\\\n\\\\nproperty numAspects None | int\\\\nThe total number of entities produced (unique entity urns).\\\\n\\\\n\\\\n\\\\nproperty numEntitiesSkipped None | int\\\\nNumber of errors generated.\\\\n\\\\n\\\\n\\\\nproperty numEvents None | int\\\\nThe number of processors on the host the ingestion pipeline ran on.\\\\n\\\\n\\\\n\\\\nproperty numSinkAPICalls None | int\\\\nTotal number of source API calls.\\\\n\\\\n\\\\n\\\\nproperty numWarnings None | int\\\\nThe number of workunits written to sink.\\\\n\\\\n\\\\n\\\\nproperty numWorkUnitsCreated None | str\\\\nThe os the ingestion pipeline ran on.\\\\n\\\\n\\\\n\\\\nproperty partitionSpec str\\\\nThe name of the pipeline that ran ingestion, a stable unique user provided identifier.\\\\ne.g. mysnowflake1-to-datahub.\\\\n\\\\n\\\\n\\\\nproperty platformInstanceId Bigquery project ids, MySQL hostnames etc.\\\\n\\\\n\\\\n\\\\nproperty runId str | JobStatusClass\\\\nRun Status - Succeeded/Skipped/Failed etc.\\\\n\\\\n\\\\n\\\\nproperty softwareVersion None | str\\\\nThe hostname the ingestion pipeline ran on.\\\\n\\\\n\\\\n\\\\nproperty timestampMillis None | int\\\\nTotal latency across all sink API calls.\\\\n\\\\n\\\\n\\\\nproperty totalLatencySourceAPICalls None | int\\\\nThe total amount of memory on the host the ingestion pipeline ran on.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetAssertionInfoClass(dataset, scope, operator, fields=None, aggregation=None, parameters=None, nativeType=None, nativeParameters=None, logic=None)\\\\nBases\\\\n\\\\ndataset (str)\\\\nscope (Union[str, DatasetAssertionScopeClass])\\\\noperator (Union[str, AssertionStdOperatorClass])\\\\nfields (Optional[List[str]])\\\\naggregation (Union[None, str, AssertionStdAggregationClass])\\\\nparameters (Optional[AssertionStdParametersClass])\\\\nnativeType (Optional[str])\\\\nnativeParameters (Optional[Dict[str, str]])\\\\nlogic (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aggregation str\\\\nThe dataset targeted by this assertion.\\\\n\\\\n\\\\n\\\\nproperty fields None | str\\\\n\\\\n\\\\n\\\\nproperty nativeParameters None | str\\\\nNative assertion type\\\\n\\\\n\\\\n\\\\nproperty operator None | AssertionStdParametersClass\\\\nStandard parameters required for the assertion. e.g. minvalue, maxvalue, value, columns\\\\n\\\\n\\\\n\\\\nproperty scope object\\\\n\\\\n\\\\nDATASETCOLUMN = \'DATASETCOLUMN\'\\\\n\\\\n\\\\n\\\\nDATASETROWS = \'DATASETROWS\'\\\\n\\\\n\\\\n\\\\nDATASETSCHEMA = \'DATASETSCHEMA\'\\\\n\\\\n\\\\n\\\\nDATASETSTORAGESIZE = \'DATASETSTORAGESIZE\'\\\\n\\\\n\\\\n\\\\nUNKNOWN = \'UNKNOWN\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetDeprecationClass(deprecated, note, decommissionTime=None, actor=None)\\\\nBases\\\\n\\\\ndeprecated (bool)\\\\nnote (str)\\\\ndecommissionTime (Optional[int])\\\\nactor (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty actor None | int\\\\nThe time user plan to decommission this dataset.\\\\n\\\\n\\\\n\\\\nproperty deprecated str\\\\nAdditional information about the dataset deprecation plan, such as the wiki, doc, RB.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetFieldForeignKeyClass(parentDataset, currentFieldPaths, parentField)\\\\nBases\\\\n\\\\nparentDataset (str)\\\\ncurrentFieldPaths (List[str])\\\\nparentField (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty currentFieldPaths str\\\\ndataset that stores the resource.\\\\n\\\\n\\\\n\\\\nproperty parentField DictWrapper\\\\nRepresentation of mapping between fields in source dataset to the field in destination dataset\\\\n\\\\nParameters AuditStampClass\\\\nAudit stamp containing who reported the field mapping and when\\\\n\\\\n\\\\n\\\\nproperty destinationField List[str]\\\\nSource fields from which the fine grained lineage is derived\\\\n\\\\n\\\\n\\\\nproperty transformation DictWrapper\\\\nStats corresponding to fields in a dataset\\\\n\\\\nParameters None | List[ValueFrequencyClass]\\\\n\\\\n\\\\n\\\\nproperty fieldPath None | HistogramClass\\\\n\\\\n\\\\n\\\\nproperty max None | str\\\\n\\\\n\\\\n\\\\nproperty median None | str\\\\n\\\\n\\\\n\\\\nproperty nullCount None | float\\\\n\\\\n\\\\n\\\\nproperty quantiles None | List[str]\\\\n\\\\n\\\\n\\\\nproperty stdev None | int\\\\n\\\\n\\\\n\\\\nproperty uniqueProportion DictWrapper\\\\nRecords field-level usage counts for a given dataset\\\\n\\\\nParameters int\\\\nNumber of times the field has been used.\\\\n\\\\n\\\\n\\\\nproperty fieldPath DictWrapper\\\\nA definition of filters that should be used when\\\\nquerying an external Dataset or Table.\\\\nNote that this models should NOT be used for working with\\\\nsearch / filter on DataHub Platform itself.\\\\n\\\\nParameters None | str\\\\nThe raw where clause string which will be used for monitoring.\\\\nRequired if the type is SQL.\\\\n\\\\n\\\\n\\\\nproperty type object\\\\n\\\\n\\\\nSQL = \'SQL\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetKeyClass(platform, name, origin)\\\\nBases\\\\n\\\\nplatform (str)\\\\nname (str)\\\\norigin (Union[str, FabricTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name str | FabricTypeClass\\\\nFabric type where dataset belongs to or where it was generated.\\\\n\\\\n\\\\n\\\\nproperty platform object\\\\nThe various types of supported dataset lineage\\\\n\\\\n\\\\nCOPY = \'COPY\'\\\\n\\\\n\\\\n\\\\nTRANSFORMED = \'TRANSFORMED\'\\\\n\\\\n\\\\n\\\\nVIEW = \'VIEW\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetProfileClass(timestampMillis, eventGranularity=None, partitionSpec=None, messageId=None, rowCount=None, columnCount=None, fieldProfiles=None, sizeInBytes=None)\\\\nBases\\\\n\\\\ntimestampMillis (int)\\\\neventGranularity (Optional[TimeWindowSizeClass])\\\\npartitionSpec (Optional[PartitionSpecClass])\\\\nmessageId (Optional[str])\\\\nrowCount (Optional[int])\\\\ncolumnCount (Optional[int])\\\\nfieldProfiles (Optional[List[DatasetFieldProfileClass]])\\\\nsizeInBytes (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nASPECTTYPE None | int\\\\nThe total number of columns (or schema fields)\\\\n\\\\n\\\\n\\\\nproperty eventGranularity None | List[DatasetFieldProfileClass]\\\\nProfiles for each column (or schema field)\\\\n\\\\n\\\\n\\\\nproperty messageId PartitionSpecClass | None\\\\nThe optional partition specification.\\\\n\\\\n\\\\n\\\\nproperty rowCount None | int\\\\nStorage size in bytes\\\\n\\\\n\\\\n\\\\nproperty timestampMillis Aspect\\\\nProperties associated with a Dataset\\\\n\\\\nParameters None | TimeStampClass\\\\nA timestamp documenting when the asset was created in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nDocumentation of the dataset\\\\n\\\\n\\\\n\\\\nproperty externalUrl None | TimeStampClass\\\\nA timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty name None | str\\\\nFully-qualified name of the Dataset\\\\n\\\\n\\\\n\\\\nproperty tags None | str\\\\n///dir/filename. Uri should not include any environment specific properties. Some datasets might not have a standardized uri, which makes this field optional (i.e. kafka topic).\\\\n\\\\nType\\\\n///data/tracking/PageViewEvent, file\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[DatasetKeyClass, DatasetPropertiesClass, EditableDatasetPropertiesClass, DatasetDeprecationClass, DatasetUpstreamLineageClass, UpstreamLineageClass, InstitutionalMemoryClass, OwnershipClass, StatusClass, SchemaMetadataClass, EditableSchemaMetadataClass, GlobalTagsClass, GlossaryTermsClass, BrowsePathsClass, DataPlatformInstanceClass, ViewPropertiesClass, BrowsePathsV2Class]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DatasetUpstreamLineageClass(fieldMappings)\\\\nBases\\\\nfieldMappings (List[DatasetFieldMappingClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty fieldMappings Aspect\\\\nStats corresponding to dataset\\\\u2019s usage.\\\\n\\\\nParameters ClassVar[str] = \'timeseries\'\\\\n\\\\n\\\\n\\\\nproperty eventGranularity None | List[DatasetFieldUsageCountsClass]\\\\nField-level usage stats\\\\n\\\\n\\\\n\\\\nproperty messageId PartitionSpecClass | None\\\\nThe optional partition specification.\\\\n\\\\n\\\\n\\\\nproperty timestampMillis None | List[str]\\\\nFrequent SQL queries; mostly makes sense for datasets in SQL databases\\\\n\\\\n\\\\n\\\\nproperty totalSqlQueries None | int\\\\nUnique user count\\\\n\\\\n\\\\n\\\\nproperty userCounts DictWrapper\\\\nRecords a single user\\\\u2019s usage counts for a given resource\\\\n\\\\nParameters int\\\\nNumber of times the dataset has been used by the user.\\\\n\\\\n\\\\n\\\\nproperty user None | str\\\\nIf useremail is set, we attempt to resolve the user\\\\u2019s urn upon ingest\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DateTypeClass\\\\nBases object\\\\nModel endpoint statuses\\\\n\\\\n\\\\nCREATING = \'CREATING\'\\\\n\\\\n\\\\n\\\\nDELETING = \'DELETING\'\\\\n\\\\n\\\\n\\\\nFAILED = \'FAILED\'\\\\n\\\\n\\\\n\\\\nINSERVICE = \'INSERVICE\'\\\\n\\\\n\\\\n\\\\nOUTOFSERVICE = \'OUTOFSERVICE\'\\\\n\\\\n\\\\n\\\\nROLLINGBACK = \'ROLLINGBACK\'\\\\n\\\\n\\\\n\\\\nUNKNOWN = \'UNKNOWN\'\\\\n\\\\n\\\\n\\\\nUPDATING = \'UPDATING\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DeprecationClass(deprecated, note, actor, decommissionTime=None, replacement=None)\\\\nBases\\\\n\\\\ndeprecated (bool)\\\\nnote (str)\\\\nactor (str)\\\\ndecommissionTime (Optional[int])\\\\nreplacement (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty actor None | int\\\\nThe time user plan to decommission this entity.\\\\n\\\\n\\\\n\\\\nproperty deprecated str\\\\nAdditional information about the entity deprecation plan, such as the wiki, doc, RB.\\\\n\\\\n\\\\n\\\\nproperty replacement Aspect\\\\nProperties related to how the entity is displayed in the Datahub UI\\\\n\\\\nParameters None | str\\\\nThe color associated with the entity in Hex. For example #FFFFFF.\\\\n\\\\n\\\\n\\\\nproperty icon DictWrapper\\\\n\\\\nParameters bool\\\\n\\\\n\\\\n\\\\nproperty config None | str\\\\n\\\\nThe version of the configuration schema that has been used to serializethe config.\\\\n\\\\n\\\\nIf not provided, the version is assumed to be the latest version.\\\\n\\\\n\\\\n\\\\nproperty enabled DictWrapper\\\\nProperties of applied documentation including the attribution of the doc\\\\n\\\\nParameters None | MetadataAttributionClass\\\\nInformation about who, why, and how this metadata was applied\\\\n\\\\n\\\\n\\\\nproperty documentation Aspect\\\\nAspect used for storing all applicable documentations on assets.\\\\nThis aspect supports multiple documentations from different sources.\\\\nThere is an implicit assumption that there is only one documentation per\\\\n\\\\nsource.\\\\n\\\\n\\\\nFor example, if there are two documentations from the same source, thelatest one will overwrite the previous one.\\\\n\\\\nIf there are two documentations from different sources, both will bestored.\\\\n\\\\n\\\\nFuture evolution considerations\\\\ndocumentations (List[DocumentationAssociationClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty documentations Aspect\\\\nKey for an Asset Domain\\\\n\\\\nParameters str\\\\nA unique id for the domain. Should be separate from the name used for displaying a Domain.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DomainPropertiesClass(name, customProperties=None, description=None, created=None, parentDomain=None)\\\\nBases\\\\n\\\\nname (str)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\ndescription (Optional[str])\\\\ncreated (Optional[AuditStampClass])\\\\nparentDomain (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nDisplay name of the Domain\\\\n\\\\n\\\\n\\\\nproperty parentDomain\\\\nOptional\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.DomainsClass(domains)\\\\nBases\\\\ndomains (List[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty domains Aspect\\\\nInformation about how a form is assigned to entities dynamically. Provide a filter to\\\\nmatch a set of entities instead of explicitly applying a form to specific entities.\\\\n\\\\nParameters FilterClass\\\\nThe filter applied when assigning this form to entities. Entities that match this filter\\\\nwill have this form applied to them. Right now this filter only supports filtering by\\\\nplatform, entity type, container, and domain through the UI.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ERModelRelationshipCardinalityClass\\\\nBases Aspect\\\\nKey for a ERModelRelationship\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ERModelRelationshipPropertiesClass(name, source, destination, relationshipFieldMappings, customProperties=None, created=None, lastModified=None, cardinality=None)\\\\nBases\\\\n\\\\nname (str)\\\\nsource (str)\\\\ndestination (str)\\\\nrelationshipFieldMappings (List[RelationshipFieldMappingClass])\\\\ncustomProperties (Optional[Dict[str, str]])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ncardinality (Union[str, ERModelRelationshipCardinalityClass, None])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cardinality None | AuditStampClass\\\\nA timestamp documenting when the asset was created in the source Data Platform (not on DataHub)\\\\n\\\\n\\\\n\\\\nproperty customProperties str\\\\nSecond dataset in the erModelRelationship (no directionality)\\\\n\\\\n\\\\n\\\\nproperty lastModified str\\\\nName of the ERModelRelation\\\\n\\\\n\\\\n\\\\nproperty relationshipFieldMappings str\\\\nFirst dataset in the erModelRelationship (no directionality)\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EdgeClass(destinationUrn, sourceUrn=None, created=None, lastModified=None, properties=None)\\\\nBases\\\\n\\\\ndestinationUrn (str)\\\\nsourceUrn (Optional[str])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\nproperties (Optional[Dict[str, str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created str\\\\nUrn of the destination of this relationship edge.\\\\n\\\\n\\\\n\\\\nproperty lastModified None | Dict[str, str]\\\\nA generic properties bag that allows us to store specific information on this graph edge.\\\\n\\\\n\\\\n\\\\nproperty sourceUrn Aspect\\\\nStores editable changes made to properties. This separates changes made from\\\\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines\\\\n\\\\nParameters AuditStampClass\\\\nAn AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty deleted None | str\\\\nEdited documentation of the chart\\\\n\\\\n\\\\n\\\\nproperty lastModified Aspect\\\\nEditable information about an Asset Container as defined on the DataHub Platform\\\\n\\\\nParameters None | str\\\\nDescription of the Asset Container as its received on the DataHub Platform\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableDashboardPropertiesClass(created=None, lastModified=None, deleted=None, description=None)\\\\nBases\\\\n\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty description AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableDataFlowPropertiesClass(created=None, lastModified=None, deleted=None, description=None)\\\\nBases\\\\n\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty description AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableDataJobPropertiesClass(created=None, lastModified=None, deleted=None, description=None)\\\\nBases\\\\n\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty description AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableDatasetPropertiesClass(created=None, lastModified=None, deleted=None, description=None, name=None)\\\\nBases\\\\n\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ndescription (Optional[str])\\\\nname (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty description AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty name Aspect\\\\nEditableERModelRelationProperties stores editable changes made to erModelRelationship properties. This separates changes made from\\\\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines\\\\n\\\\nParameters AuditStampClass\\\\nAn AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty deleted None | str\\\\nDocumentation of the erModelRelationship\\\\n\\\\n\\\\n\\\\nproperty lastModified None | str\\\\nDisplay name of the ERModelRelation\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableMLFeaturePropertiesClass(description=None)\\\\nBases\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty description Aspect\\\\nProperties associated with a MLFeatureTable editable from the ui\\\\n\\\\nParameters None | str\\\\nDocumentation of the MLFeatureTable\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableMLModelGroupPropertiesClass(description=None)\\\\nBases\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty description Aspect\\\\nProperties associated with a ML Model editable from the UI\\\\n\\\\nParameters None | str\\\\nDocumentation of the ml model\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableMLPrimaryKeyPropertiesClass(description=None)\\\\nBases\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty description Aspect\\\\nStores editable changes made to properties. This separates changes made from\\\\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines\\\\nNote\\\\n\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty description AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableSchemaFieldInfoClass(fieldPath, description=None, globalTags=None, glossaryTerms=None)\\\\nBases\\\\n\\\\nfieldPath (str)\\\\ndescription (Optional[str])\\\\nglobalTags (Optional[GlobalTagsClass])\\\\nglossaryTerms (Optional[GlossaryTermsClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nFieldPath uniquely identifying the SchemaField this metadata is associated with\\\\n\\\\n\\\\n\\\\nproperty globalTags None | GlossaryTermsClass\\\\nGlossary terms associated with the field\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EditableSchemaMetadataClass(editableSchemaFieldInfo, created=None, lastModified=None, deleted=None)\\\\nBases\\\\n\\\\neditableSchemaFieldInfo (List[EditableSchemaFieldInfoClass])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty editableSchemaFieldInfo AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EmailNotificationSettingsClass(email)\\\\nBases\\\\nemail (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty email Aspect\\\\nInformation regarding rendering an embed for an asset.\\\\n\\\\nParameters None | str\\\\nAn embed URL to be rendered inside of an iframe.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EntityChangeEventClass(entityType, entityUrn, category, operation, auditStamp, version, modifier=None, parameters=None)\\\\nBases\\\\n\\\\nentityType (str)\\\\nentityUrn (str)\\\\ncategory (str)\\\\noperation (str)\\\\nauditStamp (AuditStampClass)\\\\nversion (int)\\\\nmodifier (Optional[str])\\\\nparameters (Optional[ParametersClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty auditStamp str\\\\nThe category type (TAG, GLOSSARYTERM, OWNERSHIP, TECHNICALSCHEMA, etc). This is used to determine what the rest of the schema will look like.\\\\n\\\\n\\\\n\\\\nproperty entityType str\\\\nThe urn of the entity which was affected.\\\\n\\\\n\\\\n\\\\nproperty modifier str\\\\nThe operation type. This is used to determine what the rest of the schema will look like.\\\\n\\\\n\\\\n\\\\nproperty parameters int\\\\nThe version of the event type, incremented in integers.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EntityTypeInfoClass(qualifiedName, displayName=None, description=None)\\\\nBases\\\\n\\\\nqualifiedName (str)\\\\ndisplayName (Optional[str])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty description\\\\nA description for the Entity Type\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty displayName str\\\\nThe fully qualified name for the entity type, which usually consists of a namespace\\\\nplus an identifier or name, e.g. datahub.dataset\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EntityTypeKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\nEnum field type.\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EspressoSchemaClass(documentSchema, tableSchema)\\\\nBases\\\\n\\\\ndocumentSchema (str)\\\\ntableSchema (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty documentSchema str\\\\nThe espresso table schema definition.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.EthicalConsiderationsClass(data=None, humanLife=None, mitigations=None, risksAndHarms=None, useCases=None)\\\\nBases\\\\n\\\\ndata (Optional[List[str]])\\\\nhumanLife (Optional[List[str]])\\\\nmitigations (Optional[List[str]])\\\\nrisksAndHarms (Optional[List[str]])\\\\nuseCases (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty data None | List[str]\\\\nIs the MLModel intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?\\\\n\\\\n\\\\n\\\\nproperty mitigations None | List[str]\\\\nWhat risks may be present in MLModel usage? Try to identify the potential recipients, likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown.\\\\n\\\\n\\\\n\\\\nproperty useCases Aspect\\\\nAll referenced datasets would ideally point to any set of documents that provide visibility into the source and composition of the dataset.\\\\n\\\\nParameters List[BaseDataClass]\\\\nDetails on the dataset(s) used for the quantitative analyses in the MLModel\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ExecutionRequestInputClass(task, args, executorId, source, requestedAt, actorUrn=None)\\\\nBases Determine who is responsible for emitting execution request success or failure. Executor?\\\\n\\\\nParameters None | str\\\\nUrn of the actor who created this execution request.\\\\n\\\\n\\\\n\\\\nproperty args str\\\\nspecify a specific executor to route the request to. If none is provided, a \\\\u201cdefault\\\\u201d executor is used.\\\\n\\\\nType int\\\\nTime at which the execution request input was created\\\\n\\\\n\\\\n\\\\nproperty source str\\\\nThe name of the task to execute, for example RUNINGEST\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ExecutionRequestKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nThe result of an execution request\\\\n\\\\nParameters None | int\\\\nDuration in milliseconds\\\\n\\\\n\\\\n\\\\nproperty report None | int\\\\nTime at which the request was created\\\\n\\\\n\\\\n\\\\nproperty status None | StructuredExecutionReportClass\\\\nA structured report if available.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ExecutionRequestSignalClass(signal, createdAt, executorId=None)\\\\nBases\\\\n\\\\nsignal (str)\\\\ncreatedAt (AuditStampClass)\\\\nexecutorId (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty createdAt None | str\\\\nspecify a specific executor to route the request to. If none is provided, a \\\\u201cdefault\\\\u201d executor is used.\\\\n\\\\nType str\\\\nThe signal to issue, e.g. KILL\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ExecutionRequestSourceClass(type, ingestionSource=None)\\\\nBases\\\\n\\\\ntype (str)\\\\ningestionSource (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty ingestionSource str\\\\nThe type of the execution request source, e.g. INGESTIONSOURCE\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FabricTypeClass\\\\nBases DictWrapper\\\\nAttributes defining a Field Assertion.\\\\n\\\\nParameters str\\\\nThe entity targeted by this Field check.\\\\n\\\\n\\\\n\\\\nproperty fieldMetricAssertion None | FieldValuesAssertionClass\\\\nThe definition of an assertion that validates individual values of a field / column for a set of rows.\\\\nThis type of assertion verifies that each column value meets a particular requirement.\\\\n\\\\n\\\\n\\\\nproperty filter str | FieldAssertionTypeClass\\\\nThe type of the field assertion being monitored.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FieldAssertionTypeClass\\\\nBases DictWrapper\\\\nInformation about the status of a particular prompt for a specific schema field\\\\non an entity.\\\\n\\\\nParameters str\\\\nThe field path on a schema field.\\\\n\\\\n\\\\n\\\\nproperty lastModified DictWrapper\\\\nAttributes defining a field metric assertion, which asserts an expectation against\\\\na common metric derived from the set of field / column values, for example\\\\n\\\\nfield (SchemaFieldSpecClass)\\\\nmetric (Union[str, FieldMetricTypeClass])\\\\noperator (Union[str, AssertionStdOperatorClass])\\\\nparameters (Optional[AssertionStdParametersClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty field str | FieldMetricTypeClass\\\\nThe specific metric to assert against. This is the value that\\\\nwill be obtained by applying a standard operation, such as an aggregation,\\\\nto the selected field.\\\\n\\\\n\\\\n\\\\nproperty operator None | AssertionStdParametersClass\\\\nStandard parameters required for the assertion. e.g. minvalue, maxvalue, value, columns\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FieldMetricTypeClass\\\\nBases DictWrapper\\\\nDefinition of a transform applied to the values of a column / field.\\\\nNote that the applicability of a field transform ultimately depends on the native type\\\\nof the field / column.\\\\nModel has single field to permit extension.\\\\n\\\\nParameters str | FieldTransformTypeClass\\\\nThe type of the field transform, e.g. the transformation\\\\nfunction / operator to apply.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FieldTransformTypeClass\\\\nBases DictWrapper\\\\nRecords field-level usage counts for a given resource\\\\n\\\\nParameters int\\\\n\\\\n\\\\n\\\\nproperty fieldName DictWrapper\\\\nAttributes defining a field values assertion, which asserts that the values for a field / column\\\\nof a dataset / table matches a set of expectations.\\\\nIn other words, this type of assertion acts as a semantic constraint applied to fields for a specific column.\\\\nTODO Determine whether we need an \\\\u201coperator\\\\u201d that can be applied to the field.\\\\n\\\\nParameters bool\\\\nWhether to ignore or allow nulls when running the values assertion. (i.e.\\\\nconsider only non-null values) using operators OTHER than the ISNULL operator.\\\\nDefaults to true, allowing null values.\\\\n\\\\n\\\\n\\\\nproperty failThreshold SchemaFieldSpecClass\\\\nThe field under evaluation\\\\n\\\\n\\\\n\\\\nproperty operator None | AssertionStdParametersClass\\\\nStandard parameters required for the assertion. e.g. minvalue, maxvalue, value, columns\\\\n\\\\n\\\\n\\\\nproperty transform DictWrapper\\\\n\\\\nParameters str | FieldValuesFailThresholdTypeClass\\\\nThe type of failure threshold. Either based on the number\\\\nof column values (rows) that fail the expectations, or the percentage\\\\nof the total rows under consideration.\\\\n\\\\n\\\\n\\\\nproperty value object\\\\n\\\\n\\\\nCOUNT = \'COUNT\'\\\\n\\\\n\\\\n\\\\nPERCENTAGE = \'PERCENTAGE\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FilterClass(or=None, criteria=None)\\\\nBases\\\\n\\\\nor (Optional[List[ConjunctiveCriterionClass]])\\\\ncriteria (Optional[List[CriterionClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty criteria None | List[ConjunctiveCriterionClass]\\\\nA list of disjunctive criterion for the filter. (or operation to combine filters)\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FineGrainedLineageClass(upstreamType, downstreamType, upstreams=None, downstreams=None, transformOperation=None, confidenceScore=None, query=None)\\\\nBases\\\\n\\\\nupstreamType (Union[str, FineGrainedLineageUpstreamTypeClass])\\\\ndownstreamType (Union[str, FineGrainedLineageDownstreamTypeClass])\\\\nupstreams (Optional[List[str]])\\\\ndownstreams (Optional[List[str]])\\\\ntransformOperation (Optional[str])\\\\nconfidenceScore (Optional[float])\\\\nquery (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty confidenceScore str | FineGrainedLineageDownstreamTypeClass\\\\nThe type of downstream field(s)\\\\n\\\\n\\\\n\\\\nproperty downstreams None | str\\\\nThe query that was used to generate this lineage.\\\\nPresent only if the lineage was generated from a detected query.\\\\n\\\\n\\\\n\\\\nproperty transformOperation str | FineGrainedLineageUpstreamTypeClass\\\\nThe type of upstream entity\\\\n\\\\n\\\\n\\\\nproperty upstreams object\\\\nThe type of downstream field(s) in a fine-grained lineage\\\\n\\\\n\\\\nFIELD = \'FIELD\'\\\\n\\\\n\\\\n\\\\nFIELDSET = \'FIELDSET\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FineGrainedLineageUpstreamTypeClass\\\\nBases DictWrapper\\\\nAttributes defining a relative fixed interval SLA schedule.\\\\n\\\\nParameters int\\\\nHow many units. Defaults to 1.\\\\n\\\\n\\\\n\\\\nproperty unit DictWrapper\\\\nFixed field type.\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ForeignKeyConstraintClass(name, foreignFields, sourceFields, foreignDataset)\\\\nBases\\\\n\\\\nname (str)\\\\nforeignFields (List[str])\\\\nsourceFields (List[str])\\\\nforeignDataset (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty foreignDataset List[str]\\\\nFields the constraint maps to on the foreign dataset\\\\n\\\\n\\\\n\\\\nproperty name List[str]\\\\nFields the constraint maps to on the source dataset\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.ForeignKeySpecClass(foreignKey)\\\\nBases\\\\nforeignKey (Union[DatasetFieldForeignKeyClass, UrnForeignKeyClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty foreignKey DictWrapper\\\\n\\\\nParameters None | List[str]\\\\nSpecific set of groups that are targeted by this form assignment.\\\\n\\\\nType bool\\\\nWhether the form should be assigned to the owners of assets that it is applied to.\\\\nThis is the default.\\\\n\\\\n\\\\n\\\\nproperty users\\\\nOptional\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FormAssociationClass(urn, incompletePrompts=None, completedPrompts=None)\\\\nBases\\\\n\\\\nurn (str)\\\\nincompletePrompts (Optional[List[FormPromptAssociationClass]])\\\\ncompletedPrompts (Optional[List[FormPromptAssociationClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty completedPrompts List[FormPromptAssociationClass]\\\\nA list of prompts that are not yet complete for this form.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nInformation about a form to help with filling out metadata on entities.\\\\n\\\\nParameters FormActorAssignmentClass\\\\nWho the form is assigned to, e.g. who should see the form when visiting the entity page or governance center\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nDisplay name of the form\\\\n\\\\n\\\\n\\\\nproperty prompts str | FormTypeClass\\\\nThe type of this form\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FormKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\nInformation about the status of a particular prompt.\\\\nNote that this is where we can add additional information about individual responses\\\\n\\\\nid (str)\\\\nlastModified (AuditStampClass)\\\\nfieldAssociations (Optional[FormPromptFieldAssociationsClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty fieldAssociations str\\\\nThe id for the prompt. This must be GLOBALLY UNIQUE.\\\\n\\\\n\\\\n\\\\nproperty lastModified DictWrapper\\\\nA prompt to present to the user to encourage filling out metadata\\\\n\\\\nParameters None | str\\\\nThe description of this prompt\\\\n\\\\n\\\\n\\\\nproperty id bool\\\\nWhether the prompt is required to be completed, in order for the form to be marked as complete.\\\\n\\\\n\\\\n\\\\nproperty structuredPropertyParams str\\\\nThe title of this prompt\\\\n\\\\n\\\\n\\\\nproperty type DictWrapper\\\\nInformation about the field-level prompt associations on a top-level prompt association.\\\\n\\\\nParameters None | List[FieldFormPromptAssociationClass]\\\\nA list of field-level prompt associations that are not yet complete for this form.\\\\n\\\\n\\\\n\\\\nproperty incompleteFieldPrompts object\\\\n\\\\n\\\\nFIELDSSTRUCTUREDPROPERTY = \'FIELDSSTRUCTUREDPROPERTY\'\\\\n\\\\n\\\\n\\\\nSTRUCTUREDPROPERTY = \'STRUCTUREDPROPERTY\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FormTypeClass\\\\nBases DictWrapper\\\\nAn association between a verification and an entity that has been granted\\\\nvia completion of one or more forms of type \\\\u2018VERIFICATION\\\\u2019.\\\\n\\\\nParameters str\\\\nThe urn of the form that granted this verification.\\\\n\\\\n\\\\n\\\\nproperty lastModified Aspect\\\\nForms that are assigned to this entity to be filled out\\\\n\\\\nParameters List[FormAssociationClass]\\\\nAll complete forms assigned to the entity.\\\\n\\\\n\\\\n\\\\nproperty incompleteForms List[FormVerificationAssociationClass]\\\\nVerifications that have been applied to the entity via completed forms.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FreshnessAssertionInfoClass(type, entity, schedule, filter=None)\\\\nBases\\\\n\\\\ntype (Union[str, FreshnessAssertionTypeClass])\\\\nentity (str)\\\\nschedule (FreshnessAssertionScheduleClass)\\\\nfilter (Optional[DatasetFilterClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity None | DatasetFilterClass\\\\nA definition of the specific filters that should be applied, when performing monitoring.\\\\nIf not provided, there is no filter, and the full table is under consideration.\\\\n\\\\n\\\\n\\\\nproperty schedule str | FreshnessAssertionTypeClass\\\\nThe type of the freshness assertion being monitored.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FreshnessAssertionScheduleClass(type, cron=None, fixedInterval=None)\\\\nBases\\\\n\\\\ntype (Union[str, FreshnessAssertionScheduleTypeClass])\\\\ncron (Optional[FreshnessCronScheduleClass])\\\\nfixedInterval (Optional[FixedIntervalScheduleClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cron None | FixedIntervalScheduleClass\\\\nA fixed interval schedule. This field is required when type is FIXEDINTERVAL.\\\\n\\\\n\\\\n\\\\nproperty type object\\\\n\\\\n\\\\nCRON = \'CRON\'\\\\n\\\\n\\\\n\\\\nFIXEDINTERVAL = \'FIXEDINTERVAL\'\\\\n\\\\n\\\\n\\\\nSINCETHELASTCHECK = \'SINCETHELASTCHECK\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FreshnessAssertionTypeClass\\\\nBases DictWrapper\\\\nA contract pertaining to the operational SLAs of a physical data asset\\\\n\\\\nParameters str\\\\nThe assertion representing the SLA contract.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.FreshnessCronScheduleClass(cron, timezone, windowStartOffsetMs=None)\\\\nBases\\\\n\\\\ncron (str)\\\\ntimezone (str)\\\\nwindowStartOffsetMs (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cron str\\\\nTimezone in which the cron interval applies, e.g. America/Los Angeles\\\\n\\\\n\\\\n\\\\nproperty windowStartOffsetMs DictWrapper\\\\nGeneric record structure for serializing an Aspect\\\\n\\\\nParameters str\\\\nThe content type, which represents the fashion in which the aspect was serialized.\\\\nThe only type currently supported is application/json.\\\\n\\\\n\\\\n\\\\nproperty value DictWrapper\\\\nGeneric payload record structure for serializing a Platform Event.\\\\n\\\\nParameters str\\\\nThe content type, which represents the fashion in which the event was serialized.\\\\nThe only type currently supported is application/json.\\\\n\\\\n\\\\n\\\\nproperty value Aspect\\\\nDataHub Global platform settings. Careful - these should not be modified by the outside world!\\\\n\\\\nParameters DocPropagationFeatureSettingsClass | None\\\\nSettings related to the documentation propagation feature\\\\n\\\\n\\\\n\\\\nproperty sso None | GlobalViewsSettingsClass\\\\nSettings related to the Views Feature\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.GlobalSettingsKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty idglobalSettings\\\\nId for the settings. There should be only 1 global settings urn\\\\n\\\\nType Aspect\\\\nTag aspect used for applying tags to an entity\\\\n\\\\nParameters List[TagAssociationClass]\\\\nTags associated with a given entity\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.GlobalViewsSettingsClass(defaultView=None)\\\\nBases\\\\ndefaultView (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty defaultView Aspect\\\\nProperties associated with a GlossaryNode\\\\n\\\\nParameters Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty definition None | str\\\\nOptional id for the GlossaryNode\\\\n\\\\n\\\\n\\\\nproperty name None | str\\\\nParent node of the glossary term\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.GlossaryNodeKeyClass(name)\\\\nBases\\\\nname (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty name DictWrapper\\\\nA metadata snapshot for a specific GlossaryNode entity.\\\\n\\\\nParameters List[GlossaryNodeKeyClass | GlossaryNodeInfoClass | OwnershipClass | StatusClass]\\\\nThe list of metadata aspects associated with the GlossaryNode. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nHas A / Is A lineage information about a glossary Term reporting the lineage\\\\n\\\\nParameters None | List[str]\\\\nThe relationship Has A with glossary term\\\\n\\\\n\\\\n\\\\nproperty isRelatedTerms None | List[str]\\\\nThe relationship isRelatedTo with glossary term\\\\n\\\\n\\\\n\\\\nproperty values DictWrapper\\\\nProperties of an applied glossary term.\\\\n\\\\nParameters None | str\\\\nThe user URN which will be credited for adding associating this term to the entity\\\\n\\\\n\\\\n\\\\nproperty attribution None | str\\\\nAdditional context about the association\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nProperties associated with a GlossaryTerm\\\\n\\\\nParameters Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty definition None | str\\\\nOptional id for the term\\\\n\\\\n\\\\n\\\\nproperty name None | str\\\\nParent node of the glossary term\\\\n\\\\n\\\\n\\\\nproperty rawSchema None | str\\\\nExternal Reference to the business-term\\\\n\\\\n\\\\n\\\\nproperty sourceUrl\\\\nThe abstracted URL such as https\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty termSource Aspect\\\\nKey for a GlossaryTerm\\\\n\\\\nParameters str\\\\nThe term name, which serves as a unique id\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.GlossaryTermSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[GlossaryTermKeyClass, GlossaryTermInfoClass, OwnershipClass, StatusClass, BrowsePathsClass, GlossaryRelatedTermsClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.GlossaryTermsClass(terms, auditStamp)\\\\nBases\\\\n\\\\nterms (List[GlossaryTermAssociationClass])\\\\nauditStamp (AuditStampClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty auditStamp List[GlossaryTermAssociationClass]\\\\nThe related business terms\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.GroupMembershipClass(groups)\\\\nBases\\\\ngroups (List[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty groups DictWrapper\\\\n\\\\nParameters List[str]\\\\n\\\\n\\\\n\\\\nproperty heights Aspect\\\\nIceberg Catalog metadata associated with an Iceberg table/view\\\\n\\\\nParameters None | str\\\\nWhen Datahub is the REST Catalog for an Iceberg Table, stores the current metadata pointer.\\\\nIf the Iceberg table is managed by an external catalog, the metadata pointer is not set.\\\\n\\\\n\\\\n\\\\nproperty view Aspect\\\\nAn Iceberg warehouse location and credentails whose read/writes are governed by datahub catalog.\\\\n\\\\nParameters str\\\\nclientId to be used to authenticate with storage hosting this warehouse\\\\n\\\\n\\\\n\\\\nproperty clientSecret str\\\\nPath of the root for the backing store of the tables in the warehouse.\\\\n\\\\n\\\\n\\\\nproperty env str\\\\nregion where the warehouse is located.\\\\n\\\\n\\\\n\\\\nproperty role None | int\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IconLibraryClass\\\\nBases DictWrapper\\\\nProperties describing an icon associated with an entity\\\\n\\\\nParameters str | IconLibraryClass\\\\ne.g. Antd, Material, etc\\\\n\\\\nType str\\\\nThe name of the icon\\\\n\\\\n\\\\n\\\\nproperty style DictWrapper\\\\nThe incident assignee type.\\\\nThis is in a record so that we can add additional fields if we need to later (e.g.\\\\nthe type of the assignee.\\\\n\\\\nParameters str\\\\nThe user or group assigned to the incident.\\\\n\\\\n\\\\n\\\\nproperty assignedAt Aspect\\\\nInformation about an incident raised on an asset.\\\\n\\\\nParameters None | List[IncidentAssigneeClass]\\\\nThe parties assigned with resolving the incident\\\\n\\\\n\\\\n\\\\nproperty created None | str\\\\nAn optional custom incident type. Present only if type is \\\\u2018CUSTOM\\\\u2019.\\\\n\\\\n\\\\n\\\\nproperty description List[str]\\\\nA reference to the entity associated with the incident.\\\\n\\\\n\\\\n\\\\nproperty priority 0 - CRITICAL, 1 - HIGH, 2 - MED, 3 - LOW\\\\n(We probably should have modeled as an enum)\\\\n\\\\n\\\\n\\\\nproperty source None | int\\\\nThe time at which the incident actually started (may be before the date it was raised).\\\\n\\\\n\\\\n\\\\nproperty status None | str\\\\nOptional title associated with the incident\\\\n\\\\n\\\\n\\\\nproperty type Aspect\\\\nKey for an asset Incident\\\\n\\\\nParameters str\\\\nA unique id for the incident. Generated on the server side at incident creation time.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IncidentSourceClass(type, sourceUrn=None)\\\\nBases\\\\n\\\\ntype (Union[str, IncidentSourceTypeClass])\\\\nsourceUrn (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty sourceUrn str | IncidentSourceTypeClass\\\\nMessage associated with the incident\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IncidentSourceTypeClass\\\\nBases object\\\\n\\\\n\\\\nFIXED = \'FIXED\'\\\\n\\\\n\\\\n\\\\nINVESTIGATION = \'INVESTIGATION\'\\\\n\\\\n\\\\n\\\\nNOACTIONREQUIRED = \'NOACTIONREQUIRED\'\\\\n\\\\n\\\\n\\\\nTRIAGE = \'TRIAGE\'\\\\n\\\\n\\\\n\\\\nWORKINPROGRESS = \'WORKINPROGRESS\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IncidentStateClass\\\\nBases DictWrapper\\\\nInformation about an incident raised on an asset\\\\n\\\\nParameters AuditStampClass\\\\nThe time at which the request was initially created\\\\n\\\\n\\\\n\\\\nproperty message None | str | IncidentStageClass\\\\nThe lifecycle stage for the incident - Null means no stage was assigned yet.\\\\nIn the future, we may add CUSTOM here with a customStage string field for user-defined stages.\\\\n\\\\n\\\\n\\\\nproperty state DictWrapper\\\\nSummary statistics about incidents on an entity.\\\\n\\\\nParameters int\\\\nThe time at which the incident was raised in milliseconds since epoch.\\\\n\\\\n\\\\n\\\\nproperty priority None | int\\\\nThe time at which the incident was marked as resolved in milliseconds since epoch. Null if the incident is still active.\\\\n\\\\n\\\\n\\\\nproperty type str\\\\nThe urn of the incident\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IncidentTypeClass\\\\nBases Aspect\\\\nSummary related incidents on an entity.\\\\n\\\\nParameters List[IncidentSummaryDetailsClass]\\\\nSummary details about the set of active incidents\\\\n\\\\n\\\\n\\\\nproperty activeIncidents List[IncidentSummaryDetailsClass]\\\\nSummary details about the set of resolved incidents\\\\n\\\\n\\\\n\\\\nproperty resolvedIncidents DictWrapper\\\\nThe definition of the transformer function  that should be applied to a given field / column value in a dataset\\\\nin order to determine the segment or bucket that it belongs to, which in turn is used to evaluate\\\\nvolume assertions.\\\\n\\\\nParameters None | str\\\\nThe \\\\u2018native\\\\u2019 transformer type, useful as a back door if a custom operator is required.\\\\nThis field is required if the type is NATIVE.\\\\n\\\\n\\\\n\\\\nproperty type object\\\\n\\\\n\\\\nCEILING = \'CEILING\'\\\\n\\\\n\\\\n\\\\nFLOOR = \'FLOOR\'\\\\n\\\\n\\\\n\\\\nNATIVE = \'NATIVE\'\\\\n\\\\n\\\\n\\\\nTIMESTAMPMSTODATE = \'TIMESTAMPMSTODATE\'\\\\n\\\\n\\\\n\\\\nTIMESTAMPMSTOHOUR = \'TIMESTAMPMSTOHOUR\'\\\\n\\\\n\\\\n\\\\nTIMESTAMPMSTOMINUTE = \'TIMESTAMPMSTOMINUTE\'\\\\n\\\\n\\\\n\\\\nTIMESTAMPMSTOMONTH = \'TIMESTAMPMSTOMONTH\'\\\\n\\\\n\\\\n\\\\nTIMESTAMPMSTOYEAR = \'TIMESTAMPMSTOYEAR\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IncrementingSegmentRowCountChangeClass(segment, type, operator, parameters)\\\\nBases\\\\n\\\\nsegment (IncrementingSegmentSpecClass)\\\\ntype (Union[str, AssertionValueChangeTypeClass])\\\\noperator (Union[str, AssertionStdOperatorClass])\\\\nparameters (AssertionStdParametersClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty operator\\\\nGREATERTHAN, GREATERTHANOREQUALTO, EQUALTO, LESSTHAN, LESSTHANOREQUALTO,\\\\nBETWEEN.\\\\n\\\\n\\\\n\\\\nproperty parameters NUMBER.\\\\n\\\\n\\\\n\\\\nproperty segment str | AssertionValueChangeTypeClass\\\\na fixed absolute value or a relative percentage.\\\\n\\\\nType DictWrapper\\\\nAttributes defining an INCREMENTINGSEGMENTROWCOUNTTOTAL volume assertion.\\\\n\\\\nParameters str | AssertionStdOperatorClass\\\\nThe operator you\\\\u2019d like to apply.\\\\nNote that only numeric operators are valid inputs AssertionStdParametersClass\\\\nThe parameters you\\\\u2019d like to provide as input to the operator.\\\\nNote that only numeric parameter types are valid inputs IncrementingSegmentSpecClass\\\\nA specification of how the \\\\u2018segment\\\\u2019 can be derived using a column and an optional transformer function.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IncrementingSegmentSpecClass(field, transformer=None)\\\\nBases\\\\n\\\\n\\\\nA field or column that represents the incrementing value. New rows that are inserted will be identified using this column.\\\\nNote that the value of this column may not by itself represent the \\\\u201cbucket\\\\u201d or the \\\\u201csegment\\\\u201d in which the row falls.\\\\n[Optional] An transformer function that may be applied to the selected column value in order\\\\nto obtain the final \\\\u201csegment identifier\\\\u201d or \\\\u201cbucket identifier\\\\u201d. Rows that have the same value after applying the transformation\\\\nwill be grouped into the same segment, using which the final value (e.g. row count) will be determined.\\\\n\\\\n\\\\n\\\\nParameters SchemaFieldSpecClass\\\\nThe field to use to generate segments. It must be constantly incrementing as new rows are inserted.\\\\n\\\\n\\\\n\\\\nproperty transformer DictWrapper\\\\nThe checkpoint state object of a datahub ingestion run for a given job.\\\\n\\\\nParameters str\\\\nThe version of the state format.\\\\n\\\\n\\\\n\\\\nproperty payload str\\\\nThe serialization/deserialization protocol.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.InputFieldClass(schemaFieldUrn, schemaField=None)\\\\nBases\\\\n\\\\nschemaFieldUrn (str)\\\\nschemaField (Optional[SchemaFieldClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty schemaField str\\\\nUrn of the schema being referenced for lineage purposes\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.InputFieldsClass(fields)\\\\nBases\\\\nfields (List[InputFieldClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty fields Aspect\\\\nInstitutional memory of an entity. This is a way to link to relevant documentation and provide description of the documentation. Institutional or tribal knowledge is very important for users to leverage the entity.\\\\n\\\\nParameters List[InstitutionalMemoryMetadataClass]\\\\nList of records that represent institutional memory of an entity. Each record consists of a link, description, creator and timestamps associated with that record.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.InstitutionalMemoryMetadataClass(url, description, createStamp)\\\\nBases\\\\n\\\\nurl (str)\\\\ndescription (str)\\\\ncreateStamp (AuditStampClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty createStamp str\\\\nDescription of the link.\\\\n\\\\n\\\\n\\\\nproperty url Aspect\\\\nIntended Use for the ML Model\\\\n\\\\nParameters None | List[str]\\\\nHighlight technology that the MLModel might easily be confused with, or related contexts that users could try to apply the MLModel to.\\\\n\\\\n\\\\n\\\\nproperty primaryUsers None | List[str]\\\\nPrimary Use cases for the MLModel.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.IntendedUserTypeClass\\\\nBases Aspect\\\\nAspect used to store invite tokens.\\\\n\\\\nParameters None | str\\\\nThe role that this invite token may be associated with\\\\n\\\\n\\\\n\\\\nproperty token Aspect\\\\nKey for an InviteToken.\\\\n\\\\nParameters str\\\\nA unique id for the invite token.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.JobStatusClass\\\\nBases DictWrapper\\\\nThis header records information about the context of an event as it is emitted into kafka and is intended to be used by the kafka audit application.  For more information see go/kafkaauditheader\\\\n\\\\nParameters str\\\\nThe name of the application from which the event is being emitted. see go/appname\\\\n\\\\n\\\\n\\\\nproperty auditVersion\\\\nThe version that is being used for auditing. In version 0, the audit trail buckets events into 10 minute audit windows based on the EventHeader timestamp. In version 1, the audit trail buckets events as follows\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty clusterConnectionString None | str\\\\nfabric\\\\nThe fabricUrn of the host from which the event is being emitted. Fabric Urn in the format of urn\\\\n\\\\nType None | str\\\\nThe instance on the server from which the event is being emitted. e.g. i001\\\\n\\\\n\\\\n\\\\nproperty messageId str\\\\nThe fully qualified name of the host from which the event is being emitted.\\\\n\\\\n\\\\n\\\\nproperty time DictWrapper\\\\nSchema holder for kafka schema.\\\\n\\\\nParameters str\\\\nThe native kafka document schema. This is a human readable avro document schema.\\\\n\\\\n\\\\n\\\\nproperty documentSchemaType None | str\\\\nThe native kafka key schema as retrieved from Schema Registry\\\\n\\\\n\\\\n\\\\nproperty keySchemaType DictWrapper\\\\nSchema text of a key-value store schema.\\\\n\\\\nParameters str\\\\nThe raw schema for the key in the key-value store.\\\\n\\\\n\\\\n\\\\nproperty valueSchema object\\\\nMLFeature Data Type\\\\n\\\\n\\\\nAUDIO = \'AUDIO\'\\\\n\\\\n\\\\n\\\\nBINARY = \'BINARY\'\\\\n\\\\n\\\\n\\\\nBYTE = \'BYTE\'\\\\n\\\\n\\\\n\\\\nCONTINUOUS = \'CONTINUOUS\'\\\\n\\\\n\\\\n\\\\nCOUNT = \'COUNT\'\\\\n\\\\n\\\\n\\\\nIMAGE = \'IMAGE\'\\\\n\\\\n\\\\n\\\\nINTERVAL = \'INTERVAL\'\\\\n\\\\n\\\\n\\\\nMAP = \'MAP\'\\\\n\\\\n\\\\n\\\\nNOMINAL = \'NOMINAL\'\\\\n\\\\n\\\\n\\\\nORDINAL = \'ORDINAL\'\\\\n\\\\n\\\\n\\\\nSEQUENCE = \'SEQUENCE\'\\\\n\\\\n\\\\n\\\\nSET = \'SET\'\\\\n\\\\n\\\\n\\\\nTEXT = \'TEXT\'\\\\n\\\\n\\\\n\\\\nTIME = \'TIME\'\\\\n\\\\n\\\\n\\\\nUNKNOWN = \'UNKNOWN\'\\\\n\\\\n\\\\n\\\\nUSELESS = \'USELESS\'\\\\n\\\\n\\\\n\\\\nVIDEO = \'VIDEO\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLFeatureKeyClass(featureNamespace, name)\\\\nBases\\\\n\\\\nfeatureNamespace (str)\\\\nname (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty featureNamespace str\\\\nName of the feature\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLFeaturePropertiesClass(customProperties=None, description=None, dataType=None, version=None, sources=None)\\\\nBases\\\\n\\\\ncustomProperties (Optional[Dict[str, str]])\\\\ndescription (Optional[str])\\\\ndataType (Union[None, str, MLFeatureDataTypeClass])\\\\nversion (Optional[VersionTagClass])\\\\nsources (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str | MLFeatureDataTypeClass\\\\nData Type of the MLFeature\\\\n\\\\n\\\\n\\\\nproperty description None | List[str]\\\\nSource of the MLFeature\\\\n\\\\n\\\\n\\\\nproperty version DictWrapper\\\\n\\\\nParameters List[MLFeatureKeyClass | MLFeaturePropertiesClass | OwnershipClass | InstitutionalMemoryClass | StatusClass | DeprecationClass | BrowsePathsClass | GlobalTagsClass | DataPlatformInstanceClass | BrowsePathsV2Class]\\\\nThe list of metadata aspects associated with the MLFeature. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nKey for an MLFeatureTable\\\\n\\\\nParameters str\\\\nName of the feature table\\\\n\\\\n\\\\n\\\\nproperty platform Aspect\\\\nProperties associated with a MLFeatureTable\\\\n\\\\nParameters Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty description None | List[str]\\\\nList of features contained in the feature table\\\\n\\\\n\\\\n\\\\nproperty mlPrimaryKeys DictWrapper\\\\n\\\\nParameters List[MLFeatureTableKeyClass | MLFeatureTablePropertiesClass | OwnershipClass | InstitutionalMemoryClass | StatusClass | DeprecationClass | BrowsePathsClass | GlobalTagsClass | DataPlatformInstanceClass | BrowsePathsV2Class]\\\\nThe list of metadata aspects associated with the MLFeatureTable. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nProperties associated with an ML Hyper Param\\\\n\\\\nParameters None | int\\\\nDate when the MLHyperParam was developed\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nName of the MLHyperParam\\\\n\\\\n\\\\n\\\\nproperty value Aspect\\\\nProperties associated with an ML Metric\\\\n\\\\nParameters None | int\\\\nDate when the mlMetric was developed\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nName of the mlMetric\\\\n\\\\n\\\\n\\\\nproperty value Aspect\\\\nKey for an ML model deployment\\\\n\\\\nParameters str\\\\nName of the MLModelDeployment\\\\n\\\\n\\\\n\\\\nproperty origin str\\\\nStandardized platform urn for the model Deployment\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelDeploymentPropertiesClass(customProperties=None, externalUrl=None, description=None, createdAt=None, version=None, status=None)\\\\nBases\\\\n\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\ndescription (Optional[str])\\\\ncreatedAt (Optional[int])\\\\nversion (Optional[VersionTagClass])\\\\nstatus (Union[None, str, DeploymentStatusClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty createdAt Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty description None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty status None | VersionTagClass\\\\nVersion of the MLModelDeployment\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelDeploymentSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[MLModelDeploymentKeyClass, MLModelDeploymentPropertiesClass, OwnershipClass, StatusClass, DeprecationClass, GlobalTagsClass, DataPlatformInstanceClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelFactorPromptsClass(relevantFactors=None, evaluationFactors=None)\\\\nBases\\\\n\\\\nrelevantFactors (Optional[List[MLModelFactorsClass]])\\\\nevaluationFactors (Optional[List[MLModelFactorsClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty evaluationFactors None | List[MLModelFactorsClass]\\\\nWhat are foreseeable salient factors for which MLModel performance may vary, and how were these determined?\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelFactorsClass(groups=None, instrumentation=None, environment=None)\\\\nBases\\\\n\\\\ngroups (Optional[List[str]])\\\\ninstrumentation (Optional[List[str]])\\\\nenvironment (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty environment None | List[str]\\\\nGroups refers to distinct categories with similar characteristics that are present in the evaluation data instances.\\\\nFor human-centric machine learning MLModels, groups are people who share one or multiple characteristics.\\\\n\\\\n\\\\n\\\\nproperty instrumentation Aspect\\\\nKey for an ML model group\\\\n\\\\nParameters str\\\\nName of the MLModelGroup\\\\n\\\\n\\\\n\\\\nproperty origin str\\\\nStandardized platform urn for the model group\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelGroupPropertiesClass(customProperties=None, trainingJobs=None, downstreamJobs=None, externalUrl=None, name=None, description=None, createdAt=None, created=None, lastModified=None, version=None)\\\\nBases\\\\n\\\\ncustomProperties (Optional[Dict[str, str]])\\\\ntrainingJobs (Optional[List[str]])\\\\ndownstreamJobs (Optional[List[str]])\\\\nexternalUrl (Optional[str])\\\\nname (Optional[str])\\\\ndescription (Optional[str])\\\\ncreatedAt (Optional[int])\\\\ncreated (Optional[TimeStampClass])\\\\nlastModified (Optional[TimeStampClass])\\\\nversion (Optional[VersionTagClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | int\\\\nDate when the MLModelGroup was developed\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nDocumentation of the MLModelGroup\\\\n\\\\n\\\\n\\\\nproperty downstreamJobs None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty lastModified None | str\\\\nDisplay name of the MLModelGroup\\\\n\\\\n\\\\n\\\\nproperty trainingJobs None | VersionTagClass\\\\nVersion of the MLModelGroup\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelGroupSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[MLModelGroupKeyClass, MLModelGroupPropertiesClass, OwnershipClass, StatusClass, DeprecationClass, BrowsePathsClass, GlobalTagsClass, DataPlatformInstanceClass, BrowsePathsV2Class]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLModelKeyClass(platform, name, origin)\\\\nBases\\\\n\\\\nplatform (str)\\\\nname (str)\\\\norigin (Union[str, FabricTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name str | FabricTypeClass\\\\nFabric type where model belongs to or where it was generated\\\\n\\\\n\\\\n\\\\nproperty platform Aspect\\\\nProperties associated with a ML Model\\\\n\\\\nParameters None | TimeStampClass\\\\nAudit stamp containing who created this and when\\\\n\\\\n\\\\n\\\\nproperty customProperties None | int\\\\nDate when the MLModel was developed\\\\n\\\\n\\\\n\\\\nproperty deployments None | str\\\\nDocumentation of the MLModel\\\\n\\\\n\\\\n\\\\nproperty downstreamJobs None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty groups None | Dict[str, str | int | float | bool]\\\\nHyper Parameters of the MLModel\\\\nNOTE None | List[MLHyperParamClass]\\\\nHyperparameters of the MLModel\\\\n\\\\n\\\\n\\\\nproperty lastModified None | List[str]\\\\nList of features used for MLModel training\\\\n\\\\n\\\\n\\\\nproperty name None | List[MLMetricClass]\\\\nMetrics of the MLModel used in production\\\\n\\\\n\\\\n\\\\nproperty tags None | List[str]\\\\nList of jobs or process instances (if any) used to train the model or group. Visible in Lineage. Note that ML Models can also be specified as the output of a specific Data Process Instances (runs) via the DataProcessInstanceOutputs aspect.\\\\n\\\\n\\\\n\\\\nproperty trainingMetrics None | str\\\\nType of Algorithm or MLModel such as whether it is a Naive Bayes classifier, Convolutional Neural Network, etc\\\\n\\\\n\\\\n\\\\nproperty version DictWrapper\\\\nMLModel Snapshot entity details.\\\\n\\\\nParameters List[MLModelKeyClass | OwnershipClass | MLModelPropertiesClass | IntendedUseClass | MLModelFactorPromptsClass | MetricsClass | EvaluationDataClass | TrainingDataClass | QuantitativeAnalysesClass | EthicalConsiderationsClass | CaveatsAndRecommendationsClass | InstitutionalMemoryClass | SourceCodeClass | StatusClass | CostClass | DeprecationClass | BrowsePathsClass | GlobalTagsClass | DataPlatformInstanceClass | BrowsePathsV2Class]\\\\nThe list of metadata aspects associated with the MLModel. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn Aspect\\\\nKey for an MLPrimaryKey\\\\n\\\\nParameters str\\\\nNamespace for the primary key\\\\n\\\\n\\\\n\\\\nproperty name Aspect\\\\nProperties associated with a MLPrimaryKey\\\\n\\\\nParameters Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty dataType None | str\\\\nDocumentation of the MLPrimaryKey\\\\n\\\\n\\\\n\\\\nproperty sources None | VersionTagClass\\\\nVersion of the MLPrimaryKey\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLPrimaryKeySnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[MLPrimaryKeyKeyClass, MLPrimaryKeyPropertiesClass, OwnershipClass, InstitutionalMemoryClass, StatusClass, DeprecationClass, GlobalTagsClass, DataPlatformInstanceClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MLTrainingRunPropertiesClass(customProperties=None, externalUrl=None, id=None, outputUrls=None, hyperParams=None, trainingMetrics=None)\\\\nBases\\\\n\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\nid (Optional[str])\\\\noutputUrls (Optional[List[str]])\\\\nhyperParams (Optional[List[MLHyperParamClass]])\\\\ntrainingMetrics (Optional[List[MLMetricClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty hyperParams None | str\\\\nRun Id of the ML Training Run\\\\n\\\\n\\\\n\\\\nproperty outputUrls None | List[MLMetricClass]\\\\nMetrics of the ML Training Run\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MapTypeClass(keyType=None, valueType=None)\\\\nBases\\\\n\\\\nkeyType (Optional[str])\\\\nvalueType (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty keyType None | str\\\\nType of the value in a map\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MediaClass(type, location)\\\\nBases\\\\n\\\\ntype (Union[str, MediaTypeClass])\\\\nlocation (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty location str | MediaTypeClass\\\\nType of content the Media is storing, e.g. image, video, etc.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MediaTypeClass\\\\nBases DictWrapper\\\\nInformation about who, why, and how this metadata was applied\\\\n\\\\nParameters str\\\\nThe entity (e.g. a member URN) responsible for applying the assocated metadata. This can\\\\neither be a user (in case of UI edits) or the datahub system for automation.\\\\n\\\\n\\\\n\\\\nproperty source Dict[str, str]\\\\nThe details associated with why this metadata was applied. For example, this could include\\\\nthe actual regex rule, sql statement, ingestion pipeline ID, etc.\\\\n\\\\n\\\\n\\\\nproperty time DictWrapper\\\\nKafka event for proposing a metadata change for an entity. A corresponding MetadataAuditEvent is emitted when the change is accepted and committed, otherwise a FailedMetadataChangeEvent will be emitted instead.\\\\n\\\\nParameters None | KafkaAuditHeaderClass\\\\nKafka audit header. See go/kafkaauditheader for more info.\\\\n\\\\n\\\\n\\\\nproperty proposedDelta ChartSnapshotClass | CorpGroupSnapshotClass | CorpUserSnapshotClass | DashboardSnapshotClass | DataFlowSnapshotClass | DataJobSnapshotClass | DatasetSnapshotClass | DataProcessSnapshotClass | DataPlatformSnapshotClass | MLModelSnapshotClass | MLPrimaryKeySnapshotClass | MLFeatureSnapshotClass | MLFeatureTableSnapshotClass | MLModelDeploymentSnapshotClass | MLModelGroupSnapshotClass | TagSnapshotClass | GlossaryTermSnapshotClass | GlossaryNodeSnapshotClass | DataHubPolicySnapshotClass | SchemaFieldSnapshotClass | DataHubRetentionSnapshotClass\\\\nSnapshot of the proposed metadata change. Include only the aspects affected by the change in the snapshot.\\\\n\\\\n\\\\n\\\\nproperty systemMetadata DictWrapper\\\\nKafka event for capturing update made to an entity\\\\u2019s metadata.\\\\n\\\\nParameters None | GenericAspectClass\\\\nThe value of the new aspect.\\\\n\\\\n\\\\n\\\\nproperty aspectName This is only valid for CREATE, UPSERT, and DELETE operations.\\\\n\\\\n\\\\n\\\\nproperty auditHeader str | ChangeTypeClass\\\\nType of change being proposed\\\\n\\\\n\\\\n\\\\nproperty created None | GenericAspectClass\\\\nKey aspect of the entity being written\\\\n\\\\n\\\\n\\\\nproperty entityType None | str\\\\nUrn of the entity being written\\\\n\\\\n\\\\n\\\\nproperty headers None | GenericAspectClass\\\\nThe previous value of the aspect that has changed.\\\\n\\\\n\\\\n\\\\nproperty previousSystemMetadata None | SystemMetadataClass\\\\nSystem properties that one might want to attach to an event\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MetadataChangeProposalClass(entityType, changeType, auditHeader=None, entityUrn=None, entityKeyAspect=None, aspectName=None, aspect=None, systemMetadata=None, headers=None)\\\\nBases\\\\n\\\\nentityType (str)\\\\nchangeType (Union[str, ChangeTypeClass])\\\\nauditHeader (Optional[KafkaAuditHeaderClass])\\\\nentityUrn (Optional[str])\\\\nentityKeyAspect (Optional[GenericAspectClass])\\\\naspectName (Optional[str])\\\\naspect (Optional[GenericAspectClass])\\\\nsystemMetadata (Optional[SystemMetadataClass])\\\\nheaders (Optional[Dict[str, str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspect None | str\\\\nAspect of the entity being written to\\\\nNot filling this out implies that the writer wants to affect the entire entity\\\\nNote None | KafkaAuditHeaderClass\\\\nKafka audit header. Currently remains unused in the open source.\\\\n\\\\n\\\\n\\\\nproperty changeType None | GenericAspectClass\\\\nKey aspect of the entity being written\\\\n\\\\n\\\\n\\\\nproperty entityType None | str\\\\nUrn of the entity being written\\\\n\\\\n\\\\n\\\\nproperty headers None | SystemMetadataClass\\\\nSystem properties that one might want to attach to an event\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MetricsClass(performanceMeasures=None, decisionThreshold=None)\\\\nBases\\\\n\\\\nperformanceMeasures (Optional[List[str]])\\\\ndecisionThreshold (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty decisionThreshold None | List[str]\\\\nMeasures of MLModel performance\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.MySqlDDLClass(tableSchema)\\\\nBases\\\\ntableSchema (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty tableSchema Aspect\\\\nCarries information about the native CorpGroups a user is in.\\\\n\\\\nParameters List[str]\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.NotebookCellClass(type, textCell=None, queryCell=None, chartCell=None)\\\\nBases\\\\n\\\\ntype (Union[str, NotebookCellTypeClass])\\\\ntextCell (Optional[TextCellClass])\\\\nqueryCell (Optional[QueryCellClass])\\\\nchartCell (Optional[ChartCellClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty chartCell None | QueryCellClass\\\\nThe query cell content. The will be non-null only when all other cell field is null.\\\\n\\\\n\\\\n\\\\nproperty textCell str | NotebookCellTypeClass\\\\nThe type of this Notebook cell\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.NotebookCellTypeClass\\\\nBases Aspect\\\\nContent in a Notebook\\\\nNote\\\\ncells (Optional[List[NotebookCellClass]])\\\\n\\\\n\\\\n\\\\n\\\\nproperty cells Aspect\\\\nInformation about a Notebook\\\\nNote\\\\n\\\\ntitle (str)\\\\nchangeAuditStamps (ChangeAuditStampsClass)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty changeAuditStamps Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty description None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty title Aspect\\\\nKey for a Notebook\\\\n\\\\nParameters str\\\\nUnique id for the Notebook. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as \\\\u2018querybook.com/notebook/773\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty notebookTool DictWrapper\\\\nNotification settings for an actor or subscription.\\\\n\\\\nParameters None | EmailNotificationSettingsClass\\\\nEmail Notification Settings\\\\n\\\\n\\\\n\\\\nproperty sinkTypes None | SlackNotificationSettingsClass\\\\nSlack Notification Settings\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.NotificationSinkTypeClass\\\\nBases DictWrapper\\\\nNull field type.\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.NumberTypeClass\\\\nBases long, integer, short, etc..\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OidcSettingsClass(enabled, clientId, clientSecret, discoveryUri, userNameClaim=None, userNameClaimRegex=None, scope=None, clientAuthenticationMethod=None, jitProvisioningEnabled=None, preProvisioningRequired=None, extractGroupsEnabled=None, groupsClaim=None, responseType=None, responseMode=None, useNonce=None, readTimeout=None, extractJwtAccessTokenClaims=None, preferredJwsAlgorithm=None, preferredJwsAlgorithm2=None)\\\\nBases\\\\n\\\\nenabled (bool)\\\\nclientId (str)\\\\nclientSecret (str)\\\\ndiscoveryUri (str)\\\\nuserNameClaim (Optional[str])\\\\nuserNameClaimRegex (Optional[str])\\\\nscope (Optional[str])\\\\nclientAuthenticationMethod (Optional[str])\\\\njitProvisioningEnabled (Optional[bool])\\\\npreProvisioningRequired (Optional[bool])\\\\nextractGroupsEnabled (Optional[bool])\\\\ngroupsClaim (Optional[str])\\\\nresponseType (Optional[str])\\\\nresponseMode (Optional[str])\\\\nuseNonce (Optional[bool])\\\\nreadTimeout (Optional[int])\\\\nextractJwtAccessTokenClaims (Optional[bool])\\\\npreferredJwsAlgorithm (Optional[str])\\\\npreferredJwsAlgorithm2 (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty clientAuthenticationMethod\\\\nADVANCED. Which authentication method to use to pass credentials (clientId and clientSecret) to the token endpoint\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty clientId str\\\\nUnique client secret issued by the identity provider.\\\\n\\\\n\\\\n\\\\nproperty discoveryUri bool\\\\nWhether OIDC SSO is enabled.\\\\n\\\\n\\\\n\\\\nproperty extractGroupsEnabled None | bool\\\\nADVANCED. Whether to extract claims from JWT access token.  Defaults to false.\\\\n\\\\n\\\\n\\\\nproperty groupsClaim None | bool\\\\nADVANCED. Whether DataHub users should be provisioned on login if they do not exist. Defaults to true.\\\\n\\\\n\\\\n\\\\nproperty preProvisioningRequired None | str\\\\nADVANCED. Which jws algorithm to use. Unused.\\\\n\\\\n\\\\n\\\\nproperty preferredJwsAlgorithm2 None | int\\\\nADVANCED. Read timeout.\\\\n\\\\n\\\\n\\\\nproperty responseMode None | str\\\\nADVANCED. Response type.\\\\n\\\\n\\\\n\\\\nproperty scope None | bool\\\\nADVANCED. Use Nonce.\\\\n\\\\n\\\\n\\\\nproperty userNameClaim None | str\\\\nADVANCED. TThe regex used to parse the DataHub username from the user name claim. Defaults to (.*) (all).\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OperationClass(timestampMillis, operationType, lastUpdatedTimestamp, eventGranularity=None, partitionSpec=None, messageId=None, actor=None, customOperationType=None, numAffectedRows=None, affectedDatasets=None, sourceType=None, customProperties=None)\\\\nBases\\\\n\\\\ntimestampMillis (int)\\\\noperationType (Union[str, OperationTypeClass])\\\\nlastUpdatedTimestamp (int)\\\\neventGranularity (Optional[TimeWindowSizeClass])\\\\npartitionSpec (Optional[PartitionSpecClass])\\\\nmessageId (Optional[str])\\\\nactor (Optional[str])\\\\ncustomOperationType (Optional[str])\\\\nnumAffectedRows (Optional[int])\\\\naffectedDatasets (Optional[List[str]])\\\\nsourceType (Union[None, str, OperationSourceTypeClass])\\\\ncustomProperties (Optional[Dict[str, str]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nASPECTTYPE None | str\\\\nActor who issued this operation.\\\\n\\\\n\\\\n\\\\nproperty affectedDatasets None | str\\\\nA custom type of operation. Required if operationType is CUSTOM.\\\\n\\\\n\\\\n\\\\nproperty customProperties None | TimeWindowSizeClass\\\\nGranularity of the event if applicable\\\\n\\\\n\\\\n\\\\nproperty lastUpdatedTimestamp None | str\\\\nThe optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.\\\\n\\\\n\\\\n\\\\nproperty numAffectedRows str | OperationTypeClass\\\\nOperation type of change.\\\\n\\\\n\\\\n\\\\nproperty partitionSpec None | str | OperationSourceTypeClass\\\\nSource Type\\\\n\\\\n\\\\n\\\\nproperty timestampMillis object\\\\nThe source of an operation\\\\n\\\\n\\\\nDATAPLATFORM = \'DATAPLATFORM\'\\\\n\\\\n\\\\n\\\\nDATAPROCESS = \'DATAPROCESS\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OperationTypeClass\\\\nBases DictWrapper\\\\nSchema holder for oracle data definition language that describes an oracle table.\\\\n\\\\nParameters str\\\\nThe native schema in the dataset\\\\u2019s platform. This is a human readable (json blob) table schema.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OrcSchemaClass(schema)\\\\nBases\\\\nschema (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty schema Aspect\\\\nCarries information about where an entity originated from.\\\\n\\\\nParameters None | str\\\\nOnly populated if type is EXTERNAL. The externalType of the entity, such as the name of the identity provider.\\\\n\\\\n\\\\n\\\\nproperty type object\\\\nEnum to define where an entity originated from.\\\\n\\\\n\\\\nEXTERNAL = \'EXTERNAL\'\\\\n\\\\n\\\\n\\\\nNATIVE = \'NATIVE\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OtherSchemaClass(rawSchema)\\\\nBases\\\\nrawSchema (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty rawSchema DictWrapper\\\\nOwnership information\\\\n\\\\nParameters str\\\\ncorpuserligroupname, and urnmultiProduct only corpuser is currently supported in the frontend.)\\\\n\\\\nType\\\\nli\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty source str | OwnershipTypeClass\\\\nThe type of the ownership\\\\n\\\\n\\\\n\\\\nproperty typeUrn Aspect\\\\nOwnership information of an entity.\\\\n\\\\nParameters AuditStampClass\\\\nAudit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty ownerTypes List[OwnerClass]\\\\nList of owners of the entity.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OwnershipSourceClass(type, url=None)\\\\nBases\\\\n\\\\ntype (Union[str, OwnershipSourceTypeClass])\\\\nurl (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty type None | str\\\\nA reference URL for the source\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OwnershipSourceTypeClass\\\\nBases object\\\\nAsset owner types\\\\n\\\\n\\\\nBUSINESSOWNER = \'BUSINESSOWNER\'\\\\n\\\\n\\\\n\\\\nCONSUMER = \'CONSUMER\'\\\\n\\\\n\\\\n\\\\nCUSTOM = \'CUSTOM\'\\\\n\\\\n\\\\n\\\\nDATAOWNER = \'DATAOWNER\'\\\\n\\\\n\\\\n\\\\nDATASTEWARD = \'DATASTEWARD\'\\\\n\\\\n\\\\n\\\\nDELEGATE = \'DELEGATE\'\\\\n\\\\n\\\\n\\\\nDEVELOPER = \'DEVELOPER\'\\\\n\\\\n\\\\n\\\\nNONE = \'NONE\'\\\\n\\\\n\\\\n\\\\nPRODUCER = \'PRODUCER\'\\\\n\\\\n\\\\n\\\\nSTAKEHOLDER = \'STAKEHOLDER\'\\\\n\\\\n\\\\n\\\\nTECHNICALOWNER = \'TECHNICALOWNER\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OwnershipTypeInfoClass(name, created, lastModified, description=None)\\\\nBases\\\\n\\\\nname (str)\\\\ncreated (AuditStampClass)\\\\nlastModified (AuditStampClass)\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | str\\\\nDescription of the Ownership Type\\\\n\\\\n\\\\n\\\\nproperty lastModified str\\\\nDisplay name of the Ownership Type\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.OwnershipTypeKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\nArbitrary key-value parameters for an Entity Change Event. (any record).\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PartitionSpecClass(partition, timePartition=None, type=None)\\\\nBases\\\\n\\\\npartition (str)\\\\ntimePartition (Optional[TimeWindowClass])\\\\ntype (Union[str, PartitionTypeClass, None])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty partition None | TimeWindowClass\\\\nTime window of the partition, if we are able to extract it from the partition key.\\\\n\\\\n\\\\n\\\\nproperty type DictWrapper\\\\nDefines how the data is partitioned\\\\n\\\\nParameters None | int\\\\nThe created time for a given partition.\\\\n\\\\n\\\\n\\\\nproperty lastModifiedTime str\\\\nA unique id / value for the partition for which statistics were collected,\\\\ngenerated by applying the key definition to a given row.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PartitionTypeClass\\\\nBases Aspect\\\\nDefines how the data is partitioned for Data Lake tables (e.g. Hive, S3, Iceberg, Delta, Hudi, etc).\\\\n\\\\nParameters None | PartitionSummaryClass\\\\nThe maximum partition as ordered\\\\n\\\\n\\\\n\\\\nproperty minPartition DictWrapper\\\\nA DataHub Platform Event.\\\\n\\\\nParameters PlatformEventHeaderClass\\\\nHeader information stored with the event.\\\\n\\\\n\\\\n\\\\nproperty name GenericPayloadClass\\\\nThe event payload.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PlatformEventHeaderClass(timestampMillis)\\\\nBases\\\\ntimestampMillis (int)\\\\n\\\\n\\\\n\\\\n\\\\nproperty timestampMillis Aspect\\\\nPlatform Resource Info.\\\\nThese entities are for miscelaneous data that is used in non-core parts of the system.\\\\nFor instance, if we want to persist &amp; retrieve data from auxiliary integrations such as Slack or Microsoft Teams.\\\\n\\\\nParameters str\\\\nThe primary key for this platform resource.\\\\ne.g. for a slack member this would be the memberID.\\\\nprimary keys specified here don\\\\u2019t need to include any additional specificity for the\\\\n\\\\ndataPlatform\\\\n\\\\nThe @PlatformResourceKey is supposed to represent that\\\\n\\\\n\\\\n\\\\nproperty resourceType conversation, user, grant, etc.\\\\nResource types are indexed for ease of access.\\\\ne.g. Get me all platform resources of type user for the platform looker\\\\n\\\\n\\\\n\\\\nproperty secondaryKeys None | SerializedValueClass\\\\nThe serialized value of this platform resource item.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PlatformResourceKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty idslack-instanceuser-info\\\\nor guid(slack, slack-instance, slack-user-id, user-info) etc.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PlatformTypeClass\\\\nBases object\\\\nThe matching condition in a filter criterion\\\\n\\\\n\\\\nEQUALS = \'EQUALS\'\\\\n\\\\n\\\\n\\\\nSTARTSWITH = \'STARTSWITH\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PolicyMatchCriterionClass(field, values, condition=None)\\\\nBases\\\\n\\\\nfield (str)\\\\nvalues (List[str])\\\\ncondition (Union[str, PolicyMatchConditionClass, None])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty condition str\\\\nThe name of the field that the criterion refers to\\\\n\\\\n\\\\n\\\\nproperty values DictWrapper\\\\nThe filter for specifying the resource or actor to apply privileges to\\\\n\\\\nParameters List[PolicyMatchCriterionClass]\\\\nA list of criteria to apply conjunctively (so all criteria must pass)\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PostContentClass(title, type, description=None, link=None, media=None)\\\\nBases\\\\n\\\\ntitle (str)\\\\ntype (Union[str, PostContentTypeClass])\\\\ndescription (Optional[str])\\\\nlink (Optional[str])\\\\nmedia (Optional[MediaClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty description None | str\\\\nOptional link that the post is associated with.\\\\n\\\\n\\\\n\\\\nproperty media str\\\\nTitle of the post.\\\\n\\\\n\\\\n\\\\nproperty type object\\\\nEnum defining the type of content held in a Post.\\\\n\\\\n\\\\nLINK = \'LINK\'\\\\n\\\\n\\\\n\\\\nTEXT = \'TEXT\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PostInfoClass(type, content, created, lastModified, auditStamp=None, target=None)\\\\nBases\\\\n\\\\ntype (Union[str, PostTypeClass])\\\\ncontent (PostContentClass)\\\\ncreated (int)\\\\nlastModified (int)\\\\nauditStamp (Optional[AuditStampClass])\\\\ntarget (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty auditStamp PostContentClass\\\\nContent stored in the post.\\\\n\\\\n\\\\n\\\\nproperty created int\\\\nThe time at which the post was last modified\\\\n\\\\n\\\\n\\\\nproperty target str | PostTypeClass\\\\nType of the Post.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PostKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id object\\\\nEnum defining types of Posts.\\\\n\\\\n\\\\nENTITYANNOUNCEMENT = \'ENTITYANNOUNCEMENT\'\\\\n\\\\n\\\\n\\\\nHOMEPAGEANNOUNCEMENT = \'HOMEPAGEANNOUNCEMENT\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PrestoDDLClass(rawSchema)\\\\nBases\\\\nrawSchema (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty rawSchema object\\\\n\\\\n\\\\nMULTIPLE = \'MULTIPLE\'\\\\n\\\\n\\\\n\\\\nSINGLE = \'SINGLE\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.PropertyValueClass(value, description=None)\\\\nBases\\\\n\\\\nvalue (Union[str, float])\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty description str | float\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QuantileClass(quantile, value)\\\\nBases\\\\n\\\\nquantile (str)\\\\nvalue (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty quantile str\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QuantitativeAnalysesClass(unitaryResults=None, intersectionalResults=None)\\\\nBases\\\\n\\\\nunitaryResults (Optional[str])\\\\nintersectionalResults (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty intersectionalResults None | str\\\\nLink to a dashboard with results showing how the MLModel performed with respect to each factor\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QueryCellClass(cellId, changeAuditStamps, rawQuery, cellTitle=None, lastExecuted=None)\\\\nBases\\\\n\\\\ncellId (str)\\\\nchangeAuditStamps (ChangeAuditStampsClass)\\\\nrawQuery (str)\\\\ncellTitle (Optional[str])\\\\nlastExecuted (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cellId None | str\\\\nTitle of the cell\\\\n\\\\n\\\\n\\\\nproperty changeAuditStamps None | AuditStampClass\\\\nCaptures information about who last executed this query cell and when\\\\n\\\\n\\\\n\\\\nproperty rawQuery Aspect\\\\nKey for a Query\\\\n\\\\nParameters str\\\\nA unique id for the Query.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QueryLanguageClass\\\\nBases Aspect\\\\nInformation about a Query against one or more data assets (e.g. Tables or Views).\\\\n\\\\nParameters AuditStampClass\\\\nAudit stamp capturing the time and actor who created the Query.\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nThe Query description.\\\\n\\\\n\\\\n\\\\nproperty lastModified None | str\\\\nOptional display name to identify the query.\\\\n\\\\n\\\\n\\\\nproperty origin str | QuerySourceClass\\\\nThe source of the Query\\\\n\\\\n\\\\n\\\\nproperty statement object\\\\n\\\\n\\\\nMANUAL = \'MANUAL\'\\\\n\\\\n\\\\n\\\\nSYSTEM = \'SYSTEM\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QueryStatementClass(value, language=None)\\\\nBases\\\\n\\\\nvalue (str)\\\\nlanguage (Union[str, QueryLanguageClass, None])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty language str\\\\nThe query text\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QuerySubjectClass(entity)\\\\nBases\\\\nentity (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity Aspect\\\\nInformation about the subjects of a particular Query, i.e. the assets\\\\nbeing queried.\\\\n\\\\nParameters List[QuerySubjectClass]\\\\nOne or more subjects of the query.\\\\nIn single-asset queries (e.g. table select), this will contain the Table reference\\\\nand optionally schema field references.\\\\nIn multi-asset queries (e.g. table joins), this may contain multiple Table references\\\\nand optionally schema field references.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.QueryUsageStatisticsClass(timestampMillis, eventGranularity=None, partitionSpec=None, messageId=None, queryCount=None, queryCost=None, lastExecutedAt=None, uniqueUserCount=None, userCounts=None)\\\\nBases\\\\n\\\\ntimestampMillis (int)\\\\neventGranularity (Optional[TimeWindowSizeClass])\\\\npartitionSpec (Optional[PartitionSpecClass])\\\\nmessageId (Optional[str])\\\\nqueryCount (Optional[int])\\\\nqueryCost (Optional[float])\\\\nlastExecutedAt (Optional[int])\\\\nuniqueUserCount (Optional[int])\\\\nuserCounts (Optional[List[DatasetUserUsageCountsClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nASPECTTYPE None | TimeWindowSizeClass\\\\nGranularity of the event if applicable\\\\n\\\\n\\\\n\\\\nproperty lastExecutedAt None | str\\\\nThe optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.\\\\n\\\\n\\\\n\\\\nproperty partitionSpec None | float\\\\nQuery cost for this query and bucket\\\\n\\\\n\\\\n\\\\nproperty queryCount int\\\\nThe event timestamp field as epoch at UTC in milli seconds.\\\\n\\\\n\\\\n\\\\nproperty uniqueUserCount None | List[DatasetUserUsageCountsClass]\\\\nUsers within this bucket, with frequency counts\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.RecordTypeClass\\\\nBases DictWrapper\\\\nIndividual Field Mapping of a relationship- one of several\\\\n\\\\nParameters str\\\\n1\\\\n\\\\nType str\\\\n1\\\\n\\\\nType DictWrapper\\\\nBase class that encapsulates different retention policies.\\\\nOnly one of the fields should be set\\\\n\\\\nParameters None | TimeBasedRetentionClass\\\\n\\\\n\\\\n\\\\nproperty version DictWrapper\\\\nProperties of an applied Role. For now, just an Urn\\\\n\\\\nParameters str\\\\nUrn of the External Role\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.RoleKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\nCarries information about which roles a user or group is assigned to.\\\\n\\\\nParameters List[str]\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.RolePropertiesClass(name, type, description=None, requestUrl=None, created=None)\\\\nBases\\\\n\\\\nname (str)\\\\ntype (str)\\\\ndescription (Optional[str])\\\\nrequestUrl (Optional[str])\\\\ncreated (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | str\\\\nDescription of the IAM Role\\\\n\\\\n\\\\n\\\\nproperty name None | str\\\\nLink to access external access management\\\\n\\\\n\\\\n\\\\nproperty type DictWrapper\\\\nProvisioned users of a role\\\\n\\\\nParameters str\\\\nLink provisioned corp user for a role\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.RowCountChangeClass(type, operator, parameters)\\\\nBases\\\\n\\\\ntype (Union[str, AssertionValueChangeTypeClass])\\\\noperator (Union[str, AssertionStdOperatorClass])\\\\nparameters (AssertionStdParametersClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty operator\\\\nGREATERTHAN, GREATERTHANOREQUALTO, EQUALTO, LESSTHAN, LESSTHANOREQUALTO,\\\\nBETWEEN.\\\\n\\\\n\\\\n\\\\nproperty parameters NUMBER.\\\\n\\\\n\\\\n\\\\nproperty type\\\\nThe type of the value used to evaluate the assertion\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.RowCountTotalClass(operator, parameters)\\\\nBases\\\\n\\\\noperator (Union[str, AssertionStdOperatorClass])\\\\nparameters (AssertionStdParametersClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty operator\\\\nGREATERTHAN, GREATERTHANOREQUALTO, EQUALTO, LESSTHAN, LESSTHANOREQUALTO,\\\\nBETWEEN.\\\\n\\\\n\\\\n\\\\nproperty parameters NUMBER.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.RunResultTypeClass\\\\nBases object\\\\n\\\\n\\\\nEXACTMATCH = \'EXACTMATCH\'\\\\n\\\\n\\\\n\\\\nSUBSET = \'SUBSET\'\\\\n\\\\n\\\\n\\\\nSUPERSET = \'SUPERSET\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SchemaAssertionInfoClass(entity, schema, compatibility=None)\\\\nBases\\\\n\\\\nentity (str)\\\\nschema (SchemaMetadataClass)\\\\ncompatibility (Union[str, SchemaAssertionCompatibilityClass, None])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty compatibility str\\\\nThe entity targeted by the assertion\\\\n\\\\n\\\\n\\\\nproperty schema DictWrapper\\\\nExpectations for a logical schema\\\\n\\\\nParameters str\\\\nThe assertion representing the schema contract.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SchemaFieldAliasesClass(aliases=None)\\\\nBases\\\\naliases (Optional[List[str]])\\\\n\\\\n\\\\n\\\\n\\\\nproperty aliases DictWrapper\\\\nSchemaField to describe metadata related to dataset schema.\\\\n\\\\nParameters None | AuditStampClass\\\\nAn AuditStamp corresponding to the creation of this schema field.\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nFlattened name of the field. Field is computed from jsonPath field.\\\\n\\\\n\\\\n\\\\nproperty globalTags None | GlossaryTermsClass\\\\nGlossary terms associated with the field\\\\n\\\\n\\\\n\\\\nproperty isPartOfKey None | bool\\\\nFor Datasets which are partitioned, this determines the partitioning key.\\\\nNote that multiple columns can be part of a partitioning key, but currently we do not support\\\\nrendering the ordered partitioning key.\\\\n\\\\n\\\\n\\\\nproperty jsonPath None | str\\\\nFor schema fields that have other properties that are not modeled explicitly,\\\\nuse this field to serialize those properties into a JSON string\\\\n\\\\n\\\\n\\\\nproperty label None | AuditStampClass\\\\nAn AuditStamp corresponding to the last modification of this schema field.\\\\n\\\\n\\\\n\\\\nproperty nativeDataType bool\\\\nIndicates if this field is optional or nullable\\\\n\\\\n\\\\n\\\\nproperty recursive SchemaFieldDataTypeClass\\\\nPlatform independent field type of the field.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SchemaFieldDataTypeClass(type)\\\\nBases\\\\ntype (Union[BooleanTypeClass, FixedTypeClass, StringTypeClass, BytesTypeClass, NumberTypeClass, DateTypeClass, TimeTypeClass, EnumTypeClass, NullTypeClass, MapTypeClass, ArrayTypeClass, UnionTypeClass, RecordTypeClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty type Aspect\\\\n\\\\nParameters None | str\\\\n\\\\n\\\\n\\\\nproperty schemaFieldAliases Aspect\\\\nKey for a SchemaField\\\\n\\\\nParameters str\\\\nfieldPath identifying the schema field\\\\n\\\\n\\\\n\\\\nproperty parent DictWrapper\\\\nA metadata snapshot for a specific schema field entity.\\\\n\\\\nParameters List[SchemaFieldKeyClass]\\\\nThe list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects.\\\\n\\\\n\\\\n\\\\nproperty urn DictWrapper\\\\nLightweight spec used for referencing a particular schema field.\\\\n\\\\nParameters str\\\\nThe native field type\\\\n\\\\n\\\\n\\\\nproperty path str\\\\nThe DataHub standard schema field type.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SchemaMetadataClass(schemaName, platform, version, hash, platformSchema, fields, created=None, lastModified=None, deleted=None, dataset=None, cluster=None, primaryKeys=None, foreignKeysSpecs=None, foreignKeys=None)\\\\nBases\\\\n\\\\nschemaName (str)\\\\nplatform (str)\\\\nversion (int)\\\\nhash (str)\\\\nplatformSchema (Union[EspressoSchemaClass, OracleDDLClass, MySqlDDLClass, PrestoDDLClass, KafkaSchemaClass, BinaryJsonSchemaClass, OrcSchemaClass, SchemalessClass, KeyValueSchemaClass, OtherSchemaClass])\\\\nfields (List[SchemaFieldClass])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\ndeleted (Optional[AuditStampClass])\\\\ndataset (Optional[str])\\\\ncluster (Optional[str])\\\\nprimaryKeys (Optional[List[str]])\\\\nforeignKeysSpecs (Optional[Dict[str, ForeignKeySpecClass]])\\\\nforeignKeys (Optional[List[ForeignKeyConstraintClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty cluster AuditStampClass\\\\nAn AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.\\\\n\\\\n\\\\n\\\\nproperty dataset None | AuditStampClass\\\\nAn AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.\\\\n\\\\n\\\\n\\\\nproperty fields None | List[ForeignKeyConstraintClass]\\\\nList of foreign key constraints for the schema\\\\n\\\\n\\\\n\\\\nproperty foreignKeysSpecs str\\\\nthe SHA1 hash of the schema content\\\\n\\\\n\\\\n\\\\nproperty lastModified str\\\\nplatform\\\\nStandardized platform urn where schema is defined. The data platform Urn (urn\\\\n\\\\nType EspressoSchemaClass | OracleDDLClass | MySqlDDLClass | PrestoDDLClass | KafkaSchemaClass | BinaryJsonSchemaClass | OrcSchemaClass | SchemalessClass | KeyValueSchemaClass | OtherSchemaClass\\\\nThe native schema in the dataset\\\\u2019s platform.\\\\n\\\\n\\\\n\\\\nproperty primaryKeys str\\\\nSchema name e.g. PageViewEvent, identity.Profile, ams.accountmanagementtracking\\\\n\\\\n\\\\n\\\\nproperty version DictWrapper\\\\nThe dataset has no specific schema associated with it\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SearchFieldTypeClass\\\\nBases DictWrapper\\\\nCaptures the serialized value of a (usually) schema-d blob.\\\\n\\\\nParameters bytes\\\\nThe serialized blob value.\\\\n\\\\n\\\\n\\\\nproperty contentType None | str\\\\nAn optional reference to the schema that models the object.\\\\ne.g., \\\\u2018com.linkedin.pegasus2avro.platformresource.slack.SlackConversation\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty schemaType object\\\\n\\\\n\\\\nBINARY = \'BINARY\'\\\\n\\\\n\\\\n\\\\nJSON = \'JSON\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SerializedValueSchemaTypeClass\\\\nBases Aspect\\\\nSiblings information of an entity.\\\\n\\\\nParameters bool\\\\nIf this is the leader entity of the set of siblings\\\\n\\\\n\\\\n\\\\nproperty siblings DictWrapper\\\\nSlack Notification settings for an actor.\\\\n\\\\nParameters None | List[str]\\\\nOptional list of channels to send notifications to\\\\n\\\\n\\\\n\\\\nproperty userHandle Aspect\\\\nInformation about a Slack user.\\\\n\\\\nParameters str\\\\nThe display name of the Slack member.\\\\n\\\\n\\\\n\\\\nproperty email str\\\\nThe unique identifier for the Slack member.\\\\n\\\\n\\\\n\\\\nproperty isAdmin bool\\\\nWhether the member is a bot.\\\\n\\\\n\\\\n\\\\nproperty isDeleted bool\\\\nWhether the member is an owner.\\\\n\\\\n\\\\n\\\\nproperty isPrimaryOwner None | int\\\\nThe timestamp of when the member was last updated. (in seconds)\\\\n\\\\n\\\\n\\\\nproperty name None | str\\\\nThe phone number of the Slack member.\\\\n\\\\n\\\\n\\\\nproperty profilePictureUrl str\\\\nThe real name of the Slack member.\\\\n\\\\n\\\\n\\\\nproperty slackInstance None | str\\\\nThe status emoji of the Slack member.\\\\n\\\\n\\\\n\\\\nproperty statusText str\\\\nThe ID associated with the Slack team.\\\\n\\\\n\\\\n\\\\nproperty timezone None | int\\\\nThe timezone offset of the Slack member.\\\\n\\\\n\\\\n\\\\nproperty title Aspect\\\\nSource Code\\\\n\\\\nParameters List[SourceCodeUrlClass]\\\\nSource Code along with types\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SourceCodeUrlClass(type, sourceCodeUrl)\\\\nBases\\\\n\\\\ntype (Union[str, SourceCodeUrlTypeClass])\\\\nsourceCodeUrl (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty sourceCodeUrl str | SourceCodeUrlTypeClass\\\\nSource Code Url Types\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SourceCodeUrlTypeClass\\\\nBases DictWrapper\\\\nAttributes defining a SQL Assertion\\\\n\\\\nParameters None | str | AssertionValueChangeTypeClass\\\\na fixed absolute value or a relative percentage.\\\\nThis value is required if the type is METRICCHANGE.\\\\n\\\\nType str\\\\nThe entity targeted by this SQL check.\\\\n\\\\n\\\\n\\\\nproperty operator\\\\nGREATERTHAN, GREATERTHANOREQUALTO, EQUALTO, LESSTHAN, LESSTHANOREQUALTO,\\\\nBETWEEN.\\\\n\\\\n\\\\n\\\\nproperty parameters NUMBER.\\\\n\\\\n\\\\n\\\\nproperty statement str | SqlAssertionTypeClass\\\\nThe type of the SQL assertion being monitored.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SqlAssertionTypeClass\\\\nBases DictWrapper\\\\nSSO Integrations, supported on the UI.\\\\n\\\\nParameters str\\\\nAuth base URL.\\\\n\\\\n\\\\n\\\\nproperty oidcSettings Aspect\\\\nThe lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\\\\nThis aspect is used to represent soft deletes conventionally.\\\\n\\\\nParameters bool\\\\nWhether the entity has been removed (soft-deleted).\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.StringTypeClass\\\\nBases DictWrapper\\\\nA flexible carrier for structured results of an execution request.\\\\nThe goal is to allow for free flow of structured responses from execution tasks to the orchestrator or observer.\\\\nThe full spectrum of different execution report types is not intended to be modeled by this object.\\\\n\\\\nParameters str\\\\nThe content-type of the serialized value (e.g. application/json, application/json;gzip etc.)\\\\n\\\\n\\\\n\\\\nproperty serializedValue str\\\\nThe type of the structured report. (e.g. INGESTIONREPORT, TESTCONNECTIONREPORT, etc.)\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.StructuredPropertiesClass(properties)\\\\nBases\\\\nproperties (List[StructuredPropertyValueAssignmentClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty properties Aspect\\\\n\\\\nParameters None | List[PropertyValueClass]\\\\nA list of allowed values that the property is allowed to take.\\\\nIf this is not specified, then the property can take any value of given type.\\\\n\\\\n\\\\n\\\\nproperty cardinality None | AuditStampClass\\\\nCreated Audit stamp\\\\n\\\\n\\\\n\\\\nproperty description None | str\\\\nThe display name of the property. This is the name that will be shown in the UI and can be used to look up the property id.\\\\n\\\\n\\\\n\\\\nproperty entityTypes bool\\\\nWhether the structured property value is immutable once applied to an entity.\\\\n\\\\n\\\\n\\\\nproperty lastModified str\\\\nThe fully qualified name of the property. e.g. io.acryl.datahub.myProperty\\\\n\\\\n\\\\n\\\\nproperty searchConfiguration None | Dict[str, List[str]]\\\\nA map that allows for type specialization of the valueType.\\\\ne.g. a valueType of urndataType [\\\\u201durnentityTypelidatahub.corpGroup\\\\u201d] }\\\\n\\\\n\\\\n\\\\nproperty valueTypelidatahub.date\\\\n\\\\n\\\\n\\\\nproperty version v1, v2\\\\n\\\\n20240610, 20240611\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.StructuredPropertyKeyClass(id)\\\\nBases\\\\nid (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty id DictWrapper\\\\n\\\\nParameters str\\\\nThe structured property that is required on this entity\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.StructuredPropertySettingsClass(isHidden=None, showInSearchFilters=None, showInAssetSummary=None, showAsAssetBadge=None, showInColumnsTable=None, lastModified=None)\\\\nBases\\\\n\\\\nisHidden (Optional[bool])\\\\nshowInSearchFilters (Optional[bool])\\\\nshowInAssetSummary (Optional[bool])\\\\nshowAsAssetBadge (Optional[bool])\\\\nshowInColumnsTable (Optional[bool])\\\\nlastModified (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty isHidden None | AuditStampClass\\\\nLast Modified Audit stamp\\\\n\\\\n\\\\n\\\\nproperty showAsAssetBadge bool\\\\nWhether or not this asset should be displayed in the asset sidebar\\\\n\\\\n\\\\n\\\\nproperty showInColumnsTable bool\\\\nWhether or not this asset should be displayed as a search filter\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.StructuredPropertyValueAssignmentClass(propertyUrn, values, created=None, lastModified=None)\\\\nBases\\\\n\\\\npropertyUrn (str)\\\\nvalues (List[Union[str, float]])\\\\ncreated (Optional[AuditStampClass])\\\\nlastModified (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty created None | AuditStampClass\\\\nAudit stamp containing who last modified this relationship edge and when\\\\n\\\\n\\\\n\\\\nproperty propertyUrn List[str | float]\\\\nThe value assigned to the property.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.SubTypesClass(typeNames)\\\\nBases\\\\ntypeNames (List[str])\\\\n\\\\n\\\\n\\\\n\\\\nproperty typeNames Aspect\\\\nMetadata associated with each metadata change that is processed by the system\\\\n\\\\nParameters int | None\\\\nThe timestamp the metadata was observed at\\\\n\\\\n\\\\n\\\\nproperty lastRunId None | str\\\\nThe ingestion pipeline id that produced the metadata. Populated in case of batch ingestion.\\\\n\\\\n\\\\n\\\\nproperty properties None | str\\\\nThe model registry name that was used to process this event\\\\n\\\\n\\\\n\\\\nproperty registryVersion str | None\\\\nThe original run id that produced the metadata. Populated in case of batch-ingestion.\\\\n\\\\n\\\\n\\\\nproperty version DictWrapper\\\\nProperties of an applied tag. For now, just an Urn. In the future we can extend this with other properties, e.g.\\\\npropagation parameters.\\\\n\\\\nParameters None | MetadataAttributionClass\\\\nInformation about who, why, and how this metadata was applied\\\\n\\\\n\\\\n\\\\nproperty context str\\\\nUrn of the applied tag\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TagKeyClass(name)\\\\nBases\\\\nname (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty name Aspect\\\\nProperties associated with a Tag\\\\n\\\\nParameters None | str\\\\nThe color associated with the Tag in Hex. For example #FFFFFF.\\\\n\\\\n\\\\n\\\\nproperty description str\\\\nDisplay name of the tag\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TagSnapshotClass(urn, aspects)\\\\nBases\\\\n\\\\nurn (str)\\\\naspects (List[Union[TagKeyClass, OwnershipClass, TagPropertiesClass, StatusClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aspects str\\\\nURN for the entity the metadata snapshot is associated with.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TelemetryClientIdClass(clientId)\\\\nBases\\\\nclientId (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty clientId Aspect\\\\nKey for the telemetry client ID, only one should ever exist\\\\n\\\\nParameters str\\\\nThe telemetry entity name, which serves as a unique id\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TestDefinitionClass(type, json=None)\\\\nBases\\\\n\\\\ntype (Union[str, TestDefinitionTypeClass])\\\\njson (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty json str | TestDefinitionTypeClass\\\\nThe Test Definition Type\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TestDefinitionTypeClass\\\\nBases Aspect\\\\nInformation about a DataHub Test\\\\n\\\\nParameters str\\\\nCategory of the test\\\\n\\\\n\\\\n\\\\nproperty definition None | str\\\\nDescription of the test\\\\n\\\\n\\\\n\\\\nproperty name Aspect\\\\nKey for a Test\\\\n\\\\nParameters str\\\\nUnique id for the test\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TestResultClass(test, type, testDefinitionMd5=None, lastComputed=None)\\\\nBases\\\\n\\\\ntest (str)\\\\ntype (Union[str, TestResultTypeClass])\\\\ntestDefinitionMd5 (Optional[str])\\\\nlastComputed (Optional[AuditStampClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty lastComputed str\\\\nThe urn of the test\\\\n\\\\n\\\\n\\\\nproperty testDefinitionMd5 str | TestResultTypeClass\\\\nThe type of the result\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TestResultTypeClass\\\\nBases Aspect\\\\nInformation about a Test Result\\\\n\\\\nParameters List[TestResultClass]\\\\nResults that are failing\\\\n\\\\n\\\\n\\\\nproperty passing DictWrapper\\\\nText cell in a Notebook, which will present content in text format\\\\n\\\\nParameters str\\\\nUnique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as \\\\u2018querybook.com/notebook/773/?cellId=1234\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty cellTitle ChangeAuditStampsClass\\\\nCaptures information about who created/last modified/deleted this Notebook cell and when\\\\n\\\\n\\\\n\\\\nproperty text DictWrapper\\\\nKeep records that are less than X seconds old\\\\n\\\\nParameters int\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TimeStampClass(time, actor=None)\\\\nBases\\\\n\\\\ntime (int)\\\\nactor (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty actor\\\\nOptional\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty time DictWrapper\\\\nTime field type. This should also be used for datetimes.\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TimeWindowClass(startTimeMillis, length)\\\\nBases\\\\n\\\\nstartTimeMillis (int)\\\\nlength (TimeWindowSizeClass)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty length int\\\\nStart time as epoch at UTC.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TimeWindowSizeClass(unit, multiple=None)\\\\nBases\\\\n\\\\nunit (Union[str, CalendarIntervalClass])\\\\nmultiple (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty multiple str | CalendarIntervalClass\\\\nInterval unit such as minute/hour/day etc.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.TrainingDataClass(trainingData)\\\\nBases\\\\ntrainingData (List[BaseDataClass])\\\\n\\\\n\\\\n\\\\n\\\\nproperty trainingData object\\\\nType of the transformation involved in generating destination fields from source fields.\\\\n\\\\n\\\\nBLACKBOX = \'BLACKBOX\'\\\\n\\\\n\\\\n\\\\nIDENTITY = \'IDENTITY\'\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.UDFTransformerClass(udf)\\\\nBases\\\\nudf (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty udf DictWrapper\\\\nUnion field type.\\\\n\\\\nParameters None | List[str]\\\\nList of types in union type.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.UpstreamClass(dataset, type, auditStamp=None, created=None, properties=None, query=None)\\\\nBases\\\\n\\\\ndataset (str)\\\\ntype (Union[str, DatasetLineageTypeClass])\\\\nauditStamp (Optional[AuditStampClass])\\\\ncreated (Optional[AuditStampClass])\\\\nproperties (Optional[Dict[str, str]])\\\\nquery (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty auditStamp None | AuditStampClass\\\\nAudit stamp containing who created the lineage and when.\\\\n\\\\n\\\\n\\\\nproperty dataset None | Dict[str, str]\\\\nA generic properties bag that allows us to store specific information on this graph edge.\\\\n\\\\n\\\\n\\\\nproperty query str | DatasetLineageTypeClass\\\\nThe type of the lineage\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.UpstreamLineageClass(upstreams, fineGrainedLineages=None)\\\\nBases\\\\n\\\\nupstreams (List[UpstreamClass])\\\\nfineGrainedLineages (Optional[List[FineGrainedLineageClass]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty fineGrainedLineages List[UpstreamClass]\\\\nList of upstream dataset lineage information\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.UrnForeignKeyClass(currentFieldPath)\\\\nBases\\\\ncurrentFieldPath (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty currentFieldPath DictWrapper\\\\nUsage data for a given resource, rolled up into a bucket.\\\\n\\\\nParameters int\\\\nBucket start time in milliseconds\\\\n\\\\n\\\\n\\\\nproperty duration UsageAggregationMetricsClass\\\\nMetrics associated with this bucket\\\\n\\\\n\\\\n\\\\nproperty resource DictWrapper\\\\nMetrics for usage data for a given resource and bucket. Not all fields\\\\nmake sense for all buckets, so every field is optional.\\\\n\\\\nParameters None | List[FieldUsageCountsClass]\\\\nField-level usage stats\\\\n\\\\n\\\\n\\\\nproperty topSqlQueries None | int\\\\nTotal SQL query count\\\\n\\\\n\\\\n\\\\nproperty uniqueUserCount None | List[UserUsageCountsClass]\\\\nUsers within this bucket, with frequency counts\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.UserUsageCountsClass(count, user=None, userEmail=None)\\\\nBases\\\\n\\\\ncount (int)\\\\nuser (Optional[str])\\\\nuserEmail (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty count None | str\\\\n\\\\n\\\\n\\\\nproperty userEmail DictWrapper\\\\n\\\\nParameters int\\\\n\\\\n\\\\n\\\\nproperty value DictWrapper\\\\nKeep max N latest records\\\\n\\\\nParameters int\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.VersionInfoClass(version, versionType, customProperties=None, externalUrl=None)\\\\nBases\\\\n\\\\nversion (str)\\\\nversionType (str)\\\\ncustomProperties (Optional[Dict[str, str]])\\\\nexternalUrl (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty customProperties None | str\\\\nURL where the reference exist\\\\n\\\\n\\\\n\\\\nproperty version str\\\\nThe type of the version like git hash or md5 hash\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.VersionPropertiesClass(versionSet, version, sortId, aliases=None, comment=None, versioningScheme=None, sourceCreatedTimestamp=None, metadataCreatedTimestamp=None, isLatest=None)\\\\nBases\\\\n\\\\nversionSet (str)\\\\nversion (VersionTagClass)\\\\nsortId (str)\\\\naliases (Optional[List[VersionTagClass]])\\\\ncomment (Optional[str])\\\\nversioningScheme (Union[str, VersioningSchemeClass, None])\\\\nsourceCreatedTimestamp (Optional[AuditStampClass])\\\\nmetadataCreatedTimestamp (Optional[AuditStampClass])\\\\nisLatest (Optional[bool])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty aliases None | str\\\\nComment documenting what this version was created for, changes, or represents\\\\n\\\\n\\\\n\\\\nproperty isLatest None | AuditStampClass\\\\nTimestamp reflecting when the metadata for this version was created in DataHub\\\\n\\\\n\\\\n\\\\nproperty sortId None | AuditStampClass\\\\nTimestamp reflecting when this asset version was created in the source system.\\\\n\\\\n\\\\n\\\\nproperty version str\\\\nThe linked Version Set entity that ties multiple versioned assets together\\\\n\\\\n\\\\n\\\\nproperty versioningScheme Aspect\\\\nKey for a Version Set entity\\\\n\\\\nParameters str\\\\nType of entities included in version set, limits to a single entity type between linked versioned entities\\\\n\\\\n\\\\n\\\\nproperty id Aspect\\\\n\\\\nParameters Dict[str, str]\\\\nCustom property bag.\\\\n\\\\n\\\\n\\\\nproperty latest str | VersioningSchemeClass\\\\nWhat versioning scheme is being utilized for the versioned entities sort criterion. Static once set\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.VersionTagClass(versionTag=None, metadataAttribution=None)\\\\nBases\\\\n\\\\nversionTag (Optional[str])\\\\nmetadataAttribution (Optional[MetadataAttributionClass])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty metadataAttribution None | str\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.VersioningSchemeClass\\\\nBases Aspect\\\\nDetails about a View.\\\\ne.g. Gets activated when subTypes is view\\\\n\\\\nParameters None | str\\\\nThe formatted view logic. This is particularly used for SQL sources, where the SQL\\\\nlogic is formatted for better readability, and with dbt, where this contains the\\\\ncompiled SQL logic.\\\\n\\\\n\\\\n\\\\nproperty materialized str\\\\nThe view logic language / dialect\\\\n\\\\n\\\\n\\\\nproperty viewLogic DictWrapper\\\\nAttributes defining a dataset Volume Assertion\\\\n\\\\nParameters str\\\\nThe entity targeted by this Volume check.\\\\n\\\\n\\\\n\\\\nproperty filter None | IncrementingSegmentRowCountChangeClass\\\\nProduce FAILURE Assertion Result if the asset\\\\u2019s incrementing segment row count delta\\\\ndoes not meet specific requirements. Required if type is \\\\u2018INCREMENTINGSEGMENTROWCOUNTCHANGE\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty incrementingSegmentRowCountTotal None | RowCountChangeClass\\\\nProduce FAILURE Assertion Result if the delta row count of the asset does not meet specific requirements\\\\nwithin a given period of time.\\\\nRequired if type is \\\\u2018ROWCOUNTCHANGE\\\\u2019\\\\n\\\\n\\\\n\\\\nproperty rowCountTotal str | VolumeAssertionTypeClass\\\\nThe type of the volume assertion being monitored.\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.schemaclasses.VolumeAssertionTypeClass\\\\nBases object\\\\nEnum to define the length of a bucket when doing aggregations\\\\n\\\\n\\\\nDAY = \'DAY\'\\\\n\\\\n\\\\n\\\\nHOUR = \'HOUR\'\\\\n\\\\n\\\\n\\\\nMONTH = \'MONTH\'\\\\n\\\\n\\\\n\\\\nWEEK = \'WEEK\'\\\\n\\\\n\\\\n\\\\nYEAR = \'YEAR\'\\\\n\\\\n\\\\n\\\\n\\\\ndatahub.metadata.schemaclasses.getschematype(fullname)\\\\n\\\\nParameters\\\\nRecordSchema\\\\n\\\\n\\\\n\\\\n\\\\n\\"}}>","sidebar":"overviewSidebar"},"python-sdk/urns":{"id":"python-sdk/urns","title":"URNs","description":"\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.AssertionUrn(assertionid, *, allowcoercion=True)\\\\nBases\\\\n\\\\nassertionid (Union[AssertionUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE str\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nAssertionUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'businessAttribute\']] = \'businessAttribute\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nBusinessAttributeUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nBusinessAttributeKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.ChartUrn(dashboard_tool, chart_id, , allowcoercion=True)\\\\nBases\\\\n\\\\ndashboardtool (str)\\\\nchartid (str)\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE str\\\\n\\\\n\\\\n\\\\nclassmethod createfromids(platform, name, platforminstance=None)\\\\n\\\\nParameters\\\\nChartUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty dashboardtool List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (ChartKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nChartKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.ContainerUrn(guid, *, allowcoercion=True)\\\\nBases\\\\n\\\\nguid (Union[ContainerUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (ContainerKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'corpGroup\']] = \'corpGroup\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_id(id)\\\\n\\\\nDeprecated since version 0.12.0.2\\\\nid (str)\\\\n\\\\nReturn type\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (CorpGroupKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'corpuser\']] = \'corpuser\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromid(id)\\\\n\\\\nDeprecated since version 0.12.0.2\\\\nid (str)\\\\n\\\\nReturn type\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (CorpUserKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nCorpUserKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty username SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dashboard\']] = \'dashboard\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromids(platform, name, platforminstance=None)\\\\n\\\\nParameters\\\\nDashboardUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty dashboardid str\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDashboardUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataContract\']] = \'dataContract\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nDataContractUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nDataContractKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataFlowUrn(orchestrator, flow_id, cluster, , allowcoercion=True)\\\\nBases\\\\n\\\\norchestrator (str)\\\\nflowid (str)\\\\ncluster (str)\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE str\\\\n\\\\n\\\\n\\\\nclassmethod createfromids(orchestrator, flowid, env, platforminstance=None)\\\\n\\\\nParameters\\\\nDataFlowUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nproperty flowid\\\\nkeyaspect (DataFlowKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type Use .cluster instead\\\\n\\\\n\\\\nReturn type Use .flowid instead\\\\n\\\\n\\\\nReturn type Use .orchestrator instead\\\\n\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubAccessToken\']] = \'dataHubAccessToken\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataHubAccessTokenUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nDataHubAccessTokenKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataHubActionUrn(id, , _allow_coercion=True)\\\\nBases\\\\n\\\\nid (Union[DataHubActionUrn, str])\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (DataHubActionKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubConnection\']] = \'dataHubConnection\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataHubConnectionUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nDataHubConnectionKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataHubExecutionRequestUrn(id, *, allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[DataHubExecutionRequestUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (ExecutionRequestKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubIngestionSource\']] = \'dataHubIngestionSource\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nDataHubIngestionSourceUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nDataHubIngestionSourceKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataHubOpenAPISchemaUrn(id, , allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[DataHubOpenAPISchemaUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (DataHubOpenAPISchemaKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubPersona\']] = \'dataHubPersona\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataHubPersonaUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nDataHubPersonaKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataHubPolicyUrn(id, , _allow_coercion=True)\\\\nBases\\\\n\\\\nid (Union[DataHubPolicyUrn, str])\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (DataHubPolicyKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubRetention\']] = \'dataHubRetention\'\\\\n\\\\n\\\\n\\\\nproperty aspectname\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entityname str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataHubRetentionUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubRole\']] = \'dataHubRole\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataHubRoleUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nDataHubRoleKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataHubSecretUrn(id, , _allow_coercion=True)\\\\nBases\\\\n\\\\nid (Union[DataHubSecretUrn, str])\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (DataHubSecretKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubStepState\']] = \'dataHubStepState\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataHubStepStateUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nDataHubStepStateKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataHubUpgradeUrn(id, *, allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[DataHubUpgradeUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (DataHubUpgradeKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataHubView\']] = \'dataHubView\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nDataHubViewUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nDataHubViewKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataJobUrn(flow, job_id, , allowcoercion=True)\\\\nBases\\\\n\\\\nflow (Union[DataFlowUrn, str])\\\\njobid (str)\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\n\\\\ndataflowurn (str)\\\\njobid (str)\\\\n\\\\n\\\\nReturn type\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataJobUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetdataflowurn()\\\\n\\\\nReturn type\\\\nurn (str)\\\\n\\\\nReturn type Use .jobid instead\\\\n\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataPlatformInstance\']] = \'dataPlatformInstance\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDataPlatformInstanceUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty instance\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataPlatform\']] = \'dataPlatform\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromid(id)\\\\n\\\\nDeprecated since version 0.12.0.2\\\\nid (str)\\\\n\\\\nReturn type\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (DataPlatformKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataProcessInstance\']] = \'dataProcessInstance\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_id(id)\\\\n\\\\nDeprecated since version 0.12.0.2\\\\nid (str)\\\\n\\\\nReturn type\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (DataProcessInstanceKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type Use .id instead\\\\n\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataProcess\']] = \'dataProcess\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nproperty env\\\\nkeyaspect (DataProcessKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nproperty orchestrator\\\\nDataProcessKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DataProductUrn(id, *, allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[DataProductUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (DataProductKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'dataType\']] = \'dataType\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nDataTypeUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nDataTypeKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.DatasetUrn(platform, name, env=\'PROD\', , allowcoercion=True)\\\\nBases\\\\n\\\\nplatform (Union[DataPlatformUrn, str])\\\\nname (str)\\\\nenv (str)\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\n\\\\nplatformid (str)\\\\ntablename (str)\\\\nenv (str)\\\\nplatforminstance (Optional[str])\\\\n\\\\n\\\\nReturn type\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nDatasetUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ngetdataplatformurn()\\\\n\\\\nReturn type\\\\nurn (str)\\\\n\\\\nReturn type Use .name instead\\\\n\\\\n\\\\nReturn type Use .env instead\\\\n\\\\n\\\\nReturn type Use the function from the fieldpaths module instead\\\\n\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'domain\']] = \'domain\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_id(id)\\\\n\\\\nDeprecated since version 0.12.0.2\\\\nid (str)\\\\n\\\\nReturn type\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (DomainKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'entityType\']] = \'entityType\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nEntityTypeUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nEntityTypeKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.ErModelRelationshipUrn(id, *, allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[ErModelRelationshipUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (ERModelRelationshipKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'form\']] = \'form\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nFormUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nFormKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.GlobalSettingsUrn(id, , allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[GlobalSettingsUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (GlobalSettingsKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'glossaryNode\']] = \'glossaryNode\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nGlossaryNodeUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name\\\\nGlossaryNodeKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.GlossaryTermUrn(name, , _allow_coercion=True)\\\\nBases\\\\n\\\\nname (Union[GlossaryTermUrn, str])\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (GlossaryTermKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'incident\']] = \'incident\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nIncidentUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nIncidentKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.InviteTokenUrn(id, *, allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[InviteTokenUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (InviteTokenKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'mlFeatureTable\']] = \'mlFeatureTable\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nMlFeatureTableUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name str\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'mlFeature\']] = \'mlFeature\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nproperty featurenamespace\\\\nkeyaspect (MLFeatureKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'mlModelDeployment\']] = \'mlModelDeployment\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nproperty env\\\\nkeyaspect (MLModelDeploymentKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nproperty platform\\\\nMLModelDeploymentKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.MlModelGroupUrn(platform, name, env=\'PROD\', , _allow_coercion=True)\\\\nBases\\\\n\\\\nplatform (Union[DataPlatformUrn, str])\\\\nname (str)\\\\nenv (str)\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nMlModelGroupUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name str\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'mlModel\']] = \'mlModel\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nproperty env\\\\nkeyaspect (MLModelKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nproperty platform\\\\nMLModelKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.MlPrimaryKeyUrn(featurenamespace, name, , _allow_coercion=True)\\\\nBases\\\\n\\\\nfeature_namespace (str)\\\\nname (str)\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nMlPrimaryKeyUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name\\\\nMLPrimaryKeyKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.NotebookUrn(notebook_tool, notebook_id, , allowcoercion=True)\\\\nBases\\\\n\\\\nnotebooktool (str)\\\\nnotebookid (str)\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (NotebookKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type Use .notebookid instead\\\\n\\\\n\\\\nReturn type Use .notebooktool instead\\\\n\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nproperty notebooktool\\\\nNotebookKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.OwnershipTypeUrn(id, *, allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[OwnershipTypeUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (OwnershipTypeKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type _SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'platformResource\']] = \'platformResource\'\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nPlatformResourceUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentity_type (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructured_property (str)\\\\n\\\\nReturn type\\\\nPlatformResourceKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.PostUrn(id, , allowcoercion=True)\\\\nBases\\\\n\\\\nid (Union[PostUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (PostKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic makedatatypeurn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeentitytypeurn(entitytype)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makeformurn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic makestructuredpropertyurn(structuredproperty)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'query\']] = \'query\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nQueryUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nQueryKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.RoleUrn(id, , _allow_coercion=True)\\\\nBases\\\\n\\\\nid (Union[RoleUrn, str])\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE\\\\nurn_str (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entity_type\\\\nkey_aspect (RoleKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurn_str (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nto_key_aspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn_url_encoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'schemaField\']] = \'schemaField\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nproperty fieldpath\\\\nkeyaspect (SchemaFieldKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'structuredProperty\']] = \'structuredProperty\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nStructuredPropertyUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nStructuredPropertyKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.TagUrn(name, , _allow_coercion=True)\\\\nBases\\\\n\\\\nname (Union[TagUrn, str])\\\\n_allow_coercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITY_TYPE Use the constructor instead\\\\n\\\\n\\\\nParameters\\\\nTagUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod create_from_string(urn_str)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entity_ids str\\\\n\\\\n\\\\n\\\\nclassmethod from_key_aspect(key_aspect)\\\\n\\\\nParameters\\\\nTagUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod from_string(urn_str, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.from_string(urn_str)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.from_string), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urn_str = \'urndatasetlisnowflake,my_db.my_schema.my_table,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.from_string(urn_str)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic get_data_type_from_urn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_data_type_urn(type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_entity_type_urn(entity_type)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_form_urn(form)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic make_structured_property_urn(structured_property)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty name\\\\nTagKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.TelemetryUrn(name, , allowcoercion=True)\\\\nBases\\\\n\\\\nname (Union[TelemetryUrn, str])\\\\nallowcoercion (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nENTITYTYPE\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytype\\\\nkeyaspect (TelemetryKeyClass)\\\\n\\\\nReturn typeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type str\\\\n\\\\n\\\\n\\\\ntokeyaspect()\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'test\']] = \'test\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nTestUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nTestKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass datahub.metadata.urns.Urn(entitytype, entityid)\\\\nBasesli&lt;id&gt; or urn&lt;type&gt; certain characters, particularly commas and parentheses, are\\\\nnot allowed in string portions of the URN. However, these are allowed when the urn\\\\nhas another urn embedded within it. The main URN class ignores this possibility,\\\\nand assumes that the user provides a valid URN string. However, the specific URN\\\\nclasses, such as DatasetUrn, will automatically encode these characters using\\\\nurl-encoding when the URN is created and allowcoercion is enabled (the default).\\\\nHowever, all fromstring methods will try to preserve the string as-is, and will\\\\nraise an error if the string is invalid.\\\\n\\\\nParameters\\\\nurnstr (str)\\\\n\\\\nReturn type List[str]\\\\n\\\\n\\\\n\\\\nproperty entitytypeli(urndataPlatformli(urndataPlatform\\\\nurnstr (Union[str, Urn]) \\\\u2013 The string representation of the urn. Also accepts an existing Urn instance.\\\\n\\\\nReturn type\\\\nUrn of the given string representation.\\\\n\\\\nRaises\\\\nurn (str)\\\\n\\\\nReturn type\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurnurlencoded()\\\\n\\\\nReturn type SpecificUrn\\\\n\\\\nParameters ClassVar[Literal[\'versionSet\']] = \'versionSet\'\\\\n\\\\n\\\\n\\\\nclassmethod createfromstring(urnstr)\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty entityids str\\\\n\\\\n\\\\n\\\\nclassmethod fromkeyaspect(keyaspect)\\\\n\\\\nParameters\\\\nVersionSetUrn\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromstring(urnstr, /)\\\\nCreate an Urn from its string representation.\\\\nWhen called against the base Urn class, this method will return a more specific Urn type where possible.\\\\n&gt;&gt;&gt; from datahub.metadata.urns import DatasetUrn, Urn\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; urn = Urn.fromstring(urnstr)\\\\n&gt;&gt;&gt; assert isinstance(urn, DatasetUrn)\\\\n\\\\n\\\\nWhen called against a specific Urn type (e.g. DatasetUrn.fromstring), this method can\\\\nalso be used for type narrowing.\\\\n&gt;&gt;&gt; urnstr = \'urndatasetlisnowflake,mydb.myschema.mytable,PROD)\'\\\\n&gt;&gt;&gt; assert DatasetUrn.fromstring(urnstr)\\\\n\\\\n\\\\n\\\\nParameters\\\\nSelf\\\\n\\\\nReturns\\\\nInvalidUrnError \\\\u2013 If the string representation is in invalid format.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nstatic getdatatypefromurn(urn)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproperty id\\\\ntype (str)\\\\n\\\\nReturn type\\\\nentitytype (str)\\\\n\\\\nReturn type\\\\nform (str)\\\\n\\\\nReturn type\\\\nstructuredproperty (str)\\\\n\\\\nReturn type\\\\nVersionSetKeyClass\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nurn()\\\\nGet the string representation of the urn.\\\\n\\\\nReturn type\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\"}}>","sidebar":"overviewSidebar"},"README":{"id":"README","title":"Introduction","description":"DataHub is a data discovery application built on an extensible metadata platform that helps you tame the complexity of diverse data ecosystems."},"releases":{"id":"releases","title":"DataHub Releases","description":"Summary","sidebar":"overviewSidebar"},"SECURITY":{"id":"SECURITY","title":"Reporting Security Issues","description":"If you think you have found a security vulnerability, please send a report to security@datahubproject.io. This address can be used for all of DataHub\u2019s open source and commercial products (including but not limited to DataHub Core and DataHub Cloud). We can accept only vulnerability reports at this address.","sidebar":"overviewSidebar"},"smoke-test/tests/cypress/README":{"id":"smoke-test/tests/cypress/README","title":"Quick Run Tests with UI","description":"1. Run quickstart"},"smoke-test/tests/openapi/README":{"id":"smoke-test/tests/openapi/README","title":"Goal","description":"This test is configuration driven by json files which contain request/response sequences intended to"}}}')}}]);