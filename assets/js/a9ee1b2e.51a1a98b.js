"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[39425],{42947:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>m,contentTitle:()=>u,default:()=>h,frontMatter:()=>p,metadata:()=>c,toc:()=>d});t(96540);var a=t(15680),i=t(53720),r=t(5400);function l(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function s(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))})),e}function o(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}const p={sidebar_position:5,title:"DataProcessInstance",slug:"/generated/metamodel/entities/dataprocessinstance",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/dataProcessInstance.md"},u="DataProcessInstance",c={unversionedId:"docs/generated/metamodel/entities/dataProcessInstance",id:"docs/generated/metamodel/entities/dataProcessInstance",title:"DataProcessInstance",description:"DataProcessInstance represents an individual execution run of a data pipeline or data processing task. While DataJob and DataFlow entities define the structure and logic of your data pipelines, DataProcessInstance captures the runtime behavior, tracking each specific execution with its inputs, outputs, status, and timing information.",source:"@site/genDocs/docs/generated/metamodel/entities/dataProcessInstance.md",sourceDirName:"docs/generated/metamodel/entities",slug:"/generated/metamodel/entities/dataprocessinstance",permalink:"/docs/generated/metamodel/entities/dataprocessinstance",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/dataProcessInstance.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5,title:"DataProcessInstance",slug:"/generated/metamodel/entities/dataprocessinstance",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/metamodel/entities/dataProcessInstance.md"},sidebar:"overviewSidebar",previous:{title:"DataProcess",permalink:"/docs/generated/metamodel/entities/dataprocess"},next:{title:"Chart",permalink:"/docs/generated/metamodel/entities/chart"}},m={},d=[{value:"Identity",id:"identity",level:2},{value:"Relationship to DataFlow and DataJob",id:"relationship-to-dataflow-and-datajob",level:3},{value:"Important Capabilities",id:"important-capabilities",level:2},{value:"Execution Tracking and Monitoring",id:"execution-tracking-and-monitoring",level:3},{value:"Run Status",id:"run-status",level:4},{value:"Run Results",id:"run-results",level:4},{value:"Execution Metadata",id:"execution-metadata",level:4},{value:"Process Properties",id:"process-properties",level:3},{value:"Instance-Level Lineage",id:"instance-level-lineage",level:3},{value:"Input Tracking",id:"input-tracking",level:4},{value:"Output Tracking",id:"output-tracking",level:4},{value:"Hierarchical Process Relationships",id:"hierarchical-process-relationships",level:3},{value:"Parent Instance",id:"parent-instance",level:4},{value:"Upstream Instances",id:"upstream-instances",level:4},{value:"Container-Based Processes",id:"container-based-processes",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Creating and Tracking a Process Instance",id:"creating-and-tracking-a-process-instance",level:3},{value:"Tracking a Failed Process with Retry",id:"tracking-a-failed-process-with-retry",level:3},{value:"Creating a DataFlow Instance (DAG Run)",id:"creating-a-dataflow-instance-dag-run",level:3},{value:"Tracking Hierarchical Process Instances",id:"tracking-hierarchical-process-instances",level:3},{value:"Tracking ML Training Run in a Container",id:"tracking-ml-training-run-in-a-container",level:3},{value:"Querying Process Instance History via REST API",id:"querying-process-instance-history-via-rest-api",level:3},{value:"Querying Process Instance Run Events",id:"querying-process-instance-run-events",level:3},{value:"Integration Points",id:"integration-points",level:2},{value:"Orchestration Platforms",id:"orchestration-platforms",level:3},{value:"Airflow Integration",id:"airflow-integration",level:4},{value:"Other Orchestrators",id:"other-orchestrators",level:4},{value:"Relationship to DataJob and DataFlow",id:"relationship-to-datajob-and-dataflow",level:3},{value:"Relationship to Datasets",id:"relationship-to-datasets",level:3},{value:"GraphQL Resolvers",id:"graphql-resolvers",level:3},{value:"Notable Exceptions",id:"notable-exceptions",level:2},{value:"Instance vs Definition Distinction",id:"instance-vs-definition-distinction",level:3},{value:"Execution Status Lifecycle",id:"execution-status-lifecycle",level:3},{value:"Historical Data Retention",id:"historical-data-retention",level:3},{value:"Instance URN Stability",id:"instance-urn-stability",level:3},{value:"Technical Reference Guide",id:"technical-reference-guide",level:2},{value:"Reading the Field Tables",id:"reading-the-field-tables",level:3},{value:"Aspects",id:"aspects",level:3},{value:"dataProcessInstanceInput",id:"dataprocessinstanceinput",level:4},{value:"dataProcessInstanceOutput",id:"dataprocessinstanceoutput",level:4},{value:"dataProcessInstanceProperties",id:"dataprocessinstanceproperties",level:4},{value:"dataProcessInstanceRelationships",id:"dataprocessinstancerelationships",level:4},{value:"status",id:"status",level:4},{value:"testResults",id:"testresults",level:4},{value:"dataPlatformInstance",id:"dataplatforminstance",level:4},{value:"subTypes",id:"subtypes",level:4},{value:"container",id:"container",level:4},{value:"mlTrainingRunProperties",id:"mltrainingrunproperties",level:4},{value:"dataProcessInstanceRunEvent (Timeseries)",id:"dataprocessinstancerunevent-timeseries",level:4},{value:"Common Types",id:"common-types",level:3},{value:"AuditStamp",id:"auditstamp",level:4},{value:"Edge",id:"edge",level:4},{value:"TestResult",id:"testresult",level:4},{value:"Relationships",id:"relationships",level:3},{value:"Self",id:"self",level:4},{value:"Outgoing",id:"outgoing",level:4},{value:"Global Metadata Model",id:"global-metadata-model",level:3}],g={toc:d},y="wrapper";function h(e){var{components:n}=e,t=o(e,["components"]);return(0,a.yg)(y,s(function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{},a=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),a.forEach((function(n){l(e,n,t[n])}))}return e}({},g,t),{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"dataprocessinstance"},"DataProcessInstance"),(0,a.yg)("p",null,"DataProcessInstance represents an individual execution run of a data pipeline or data processing task. While DataJob and DataFlow entities define the structure and logic of your data pipelines, DataProcessInstance captures the runtime behavior, tracking each specific execution with its inputs, outputs, status, and timing information."),(0,a.yg)("p",null,"Think of it this way: if a DataJob is a recipe, a DataProcessInstance is one particular time you followed that recipe, recording when you started, what ingredients you used, what you produced, and whether it succeeded or failed."),(0,a.yg)("h2",{id:"identity"},"Identity"),(0,a.yg)("p",null,"DataProcessInstance entities are uniquely identified by a single field: an id string. This makes the identifier structure simpler than other entities but requires careful consideration when generating IDs."),(0,a.yg)("p",null,"The URN format is:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"urn:li:dataProcessInstance:<id>\n")),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"<id>")," field should be globally unique across all process instances and typically encodes information about the orchestrator, execution context, and run identifier. The Python SDK provides a helper that generates this ID from three components:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"orchestrator"),": The platform executing the process (e.g., ",(0,a.yg)("inlineCode",{parentName:"li"},"airflow"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"spark"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"dagster"),")"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"cluster"),": Optional environment identifier (e.g., ",(0,a.yg)("inlineCode",{parentName:"li"},"prod"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"dev"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"staging"),")"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"id"),": The execution-specific identifier (e.g., DAG run ID, job execution ID)")),(0,a.yg)("p",null,"Example URNs:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"urn:li:dataProcessInstance:abc123def456...\n")),(0,a.yg)("p",null,"The actual ID is a deterministic GUID generated from the orchestrator, cluster, and execution id:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.api.entities.dataprocess.dataprocess_instance import DataProcessInstance\n\n# The ID is automatically generated from these fields\ninstance = DataProcessInstance(\n    id="scheduled__2024-01-15T10:00:00+00:00",\n    orchestrator="airflow",\n    cluster="prod"\n)\n# Results in: urn:li:dataProcessInstance:<deterministic-guid>\n')),(0,a.yg)("h3",{id:"relationship-to-dataflow-and-datajob"},"Relationship to DataFlow and DataJob"),(0,a.yg)("p",null,"DataProcessInstance entities are linked to their template definitions through the ",(0,a.yg)("inlineCode",{parentName:"p"},"parentTemplate")," field in the ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceRelationships")," aspect:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DataJob Instance"),": When tracking a specific task execution, the ",(0,a.yg)("inlineCode",{parentName:"li"},"parentTemplate")," points to the DataJob URN"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DataFlow Instance"),": When tracking an entire pipeline run (like an Airflow DAG run), the ",(0,a.yg)("inlineCode",{parentName:"li"},"parentTemplate")," points to the DataFlow URN"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Standalone Process"),": For ad-hoc or containerized processes, ",(0,a.yg)("inlineCode",{parentName:"li"},"parentTemplate")," can be null")),(0,a.yg)("p",null,"This relationship enables several important capabilities:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Navigate from a job definition to all its historical runs"),(0,a.yg)("li",{parentName:"ul"},"Aggregate metrics across runs of the same job"),(0,a.yg)("li",{parentName:"ul"},"Compare current execution with historical patterns"),(0,a.yg)("li",{parentName:"ul"},"Debug failures by examining past successful runs")),(0,a.yg)("h2",{id:"important-capabilities"},"Important Capabilities"),(0,a.yg)("h3",{id:"execution-tracking-and-monitoring"},"Execution Tracking and Monitoring"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceRunEvent")," aspect (a timeseries aspect) tracks the lifecycle of each execution with high granularity:"),(0,a.yg)("h4",{id:"run-status"},"Run Status"),(0,a.yg)("p",null,"Process instances move through a simple lifecycle:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"STARTED"),": Process execution has begun"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"COMPLETE"),": Process execution has finished (with a result)")),(0,a.yg)("h4",{id:"run-results"},"Run Results"),(0,a.yg)("p",null,"When a process completes, the result type indicates the outcome:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"SUCCESS"),": Process completed successfully"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"FAILURE"),": Process failed with errors"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"SKIPPED"),": Process was skipped (e.g., due to conditions not being met)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"UP_FOR_RETRY"),": Process failed but will be retried")),(0,a.yg)("h4",{id:"execution-metadata"},"Execution Metadata"),(0,a.yg)("p",null,"Each run event captures:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"timestampMillis"),": When the status change occurred"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"attempt"),": The attempt number (for retries)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"durationMillis"),": Total execution time in milliseconds"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"nativeResultType"),': The platform-specific result status (e.g., "success" from Airflow)')),(0,a.yg)("p",null,"This enables monitoring dashboards to:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Track real-time execution status"),(0,a.yg)("li",{parentName:"ul"},"Calculate success rates and failure patterns"),(0,a.yg)("li",{parentName:"ul"},"Identify performance degradation"),(0,a.yg)("li",{parentName:"ul"},"Alert on execution duration anomalies")),(0,a.yg)("h3",{id:"process-properties"},"Process Properties"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceProperties")," aspect captures metadata about the execution:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"name"),": Human-readable name for the execution"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"type"),": Process type - BATCH_SCHEDULED, BATCH_AD_HOC, or STREAMING"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"created"),": Audit stamp indicating when the instance was created"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"customProperties"),": Arbitrary key-value pairs for platform-specific metadata"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"externalUrl"),": Link to the execution in the orchestration platform (e.g., Airflow task instance page)")),(0,a.yg)("p",null,"Example use cases for customProperties:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'properties={\n    "airflow_version": "2.7.0",\n    "executor": "CeleryExecutor",\n    "pool": "default_pool",\n    "queue": "default",\n    "operator": "PythonOperator"\n}\n')),(0,a.yg)("h3",{id:"instance-level-lineage"},"Instance-Level Lineage"),(0,a.yg)("p",null,"Unlike DataJob, which defines static lineage relationships, DataProcessInstance captures the actual inputs and outputs consumed and produced during a specific execution."),(0,a.yg)("h4",{id:"input-tracking"},"Input Tracking"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceInput")," aspect records:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"inputs"),": URNs of datasets or ML models consumed during this run"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"inputEdges"),": Rich edge information including timestamps and custom properties")),(0,a.yg)("h4",{id:"output-tracking"},"Output Tracking"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceOutput")," aspect records:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"outputs"),": URNs of datasets or ML models produced during this run"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"outputEdges"),": Rich edge information including timestamps and custom properties")),(0,a.yg)("p",null,"This enables powerful capabilities:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Point-in-time lineage"),": See exactly which data versions were used in a specific run"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Impact analysis"),": When a run fails, identify downstream processes that depend on its outputs"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Data quality tracking"),": Correlate data quality issues with specific process executions"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Reproducibility"),": Recreate exact execution conditions by knowing precise inputs")),(0,a.yg)("p",null,"Example: An Airflow task that succeeded might show it read from ",(0,a.yg)("inlineCode",{parentName:"p"},"dataset_v1")," and wrote to ",(0,a.yg)("inlineCode",{parentName:"p"},"dataset_v2"),", while a retry might show different input/output datasets if the data evolved."),(0,a.yg)("h3",{id:"hierarchical-process-relationships"},"Hierarchical Process Relationships"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceRelationships")," aspect supports complex execution hierarchies:"),(0,a.yg)("h4",{id:"parent-instance"},"Parent Instance"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"parentInstance")," field links nested executions:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"DataFlow Instance (DAG Run)\n\u2514\u2500\u2500 DataJob Instance 1 (Task Run 1)\n\u2514\u2500\u2500 DataJob Instance 2 (Task Run 2)\n\u2514\u2500\u2500 DataJob Instance 3 (Task Run 3)\n")),(0,a.yg)("p",null,"This enables:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Viewing all task runs within a DAG run"),(0,a.yg)("li",{parentName:"ul"},"Aggregating metrics at the DAG run level"),(0,a.yg)("li",{parentName:"ul"},"Understanding failure propagation in multi-stage pipelines")),(0,a.yg)("h4",{id:"upstream-instances"},"Upstream Instances"),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"upstreamInstances")," field creates dependencies between process instances:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"Process Instance A (completed) \u2192 Process Instance B (triggered)\n")),(0,a.yg)("p",null,"This captures dynamic execution dependencies, such as:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Event-driven triggers"),(0,a.yg)("li",{parentName:"ul"},"Cross-DAG dependencies"),(0,a.yg)("li",{parentName:"ul"},"Dynamic fan-out/fan-in patterns")),(0,a.yg)("h3",{id:"container-based-processes"},"Container-Based Processes"),(0,a.yg)("p",null,"DataProcessInstance can represent processes that run within a Container (like an ML experiment) without being tied to a specific DataJob or DataFlow:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from datahub.emitter.mcp_builder import ContainerKey\n\ncontainer_key = ContainerKey(\n    platform="urn:li:dataPlatform:mlflow",\n    name="experiment_123",\n    env="PROD"\n)\n\ninstance = DataProcessInstance.from_container(\n    container_key=container_key,\n    id="training_run_456"\n)\n')),(0,a.yg)("p",null,"This is useful for:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"ML training runs in experiment tracking systems"),(0,a.yg)("li",{parentName:"ul"},"Notebook executions"),(0,a.yg)("li",{parentName:"ul"},"Ad-hoc data processing scripts"),(0,a.yg)("li",{parentName:"ul"},"Lambda/serverless function invocations")),(0,a.yg)("h2",{id:"code-examples"},"Code Examples"),(0,a.yg)("h3",{id:"creating-and-tracking-a-process-instance"},"Creating and Tracking a Process Instance"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Create and track a simple process instance"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/data_process_instance_create_simple.py\nimport time\n\nfrom datahub.api.entities.dataprocess.dataprocess_instance import (\n    DataProcessInstance,\n    InstanceRunResult,\n)\nfrom datahub.emitter.mcp import MetadataChangeProposalWrapper\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import DataProcessTypeClass\nfrom datahub.utilities.urns.data_job_urn import DataJobUrn\nfrom datahub.utilities.urns.dataset_urn import DatasetUrn\n\n# Create REST emitter\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\n# Define the parent DataJob that this instance is executing\nparent_job_urn = DataJobUrn.create_from_string(\n    "urn:li:dataJob:(urn:li:dataFlow:(airflow,sales_pipeline,prod),process_sales_data)"\n)\n\n# Create a process instance for a specific execution\n# This might represent an Airflow task run on 2024-01-15 at 10:00:00\ninstance = DataProcessInstance(\n    id="scheduled__2024-01-15T10:00:00+00:00",\n    orchestrator="airflow",\n    cluster="prod",\n    template_urn=parent_job_urn,\n    type=DataProcessTypeClass.BATCH_SCHEDULED,\n    properties={\n        "airflow_version": "2.7.0",\n        "executor": "CeleryExecutor",\n        "pool": "default_pool",\n    },\n    url="https://airflow.company.com/dags/sales_pipeline/grid?dag_run_id=scheduled__2024-01-15T10:00:00+00:00&task_id=process_sales_data",\n    inlets=[\n        DatasetUrn.create_from_string(\n            "urn:li:dataset:(urn:li:dataPlatform:postgres,sales_db.raw_orders,PROD)"\n        )\n    ],\n    outlets=[\n        DatasetUrn.create_from_string(\n            "urn:li:dataset:(urn:li:dataPlatform:postgres,sales_db.processed_orders,PROD)"\n        )\n    ],\n)\n\n# Record the start of execution\nstart_time = int(time.time() * 1000)\ninstance.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=start_time,\n    attempt=1,\n    emit_template=True,\n    materialize_iolets=True,\n)\n\nprint(f"Started tracking process instance: {instance.urn}")\n\n# Simulate process execution\nprint("Process is running...")\ntime.sleep(2)\n\n# Record the end of execution\nend_time = int(time.time() * 1000)\ninstance.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=end_time,\n    result=InstanceRunResult.SUCCESS,\n    result_type="airflow",\n    attempt=1,\n    start_timestamp_millis=start_time,\n)\n\nprint(f"Completed tracking process instance with result: SUCCESS")\nprint(f"Duration: {end_time - start_time}ms")\n'))),(0,a.yg)("h3",{id:"tracking-a-failed-process-with-retry"},"Tracking a Failed Process with Retry"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Track a failed process execution and retry"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/data_process_instance_create_with_retry.py\nimport time\n\nfrom datahub.api.entities.dataprocess.dataprocess_instance import (\n    DataProcessInstance,\n    InstanceRunResult,\n)\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import DataProcessTypeClass\nfrom datahub.utilities.urns.data_job_urn import DataJobUrn\nfrom datahub.utilities.urns.dataset_urn import DatasetUrn\n\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\nparent_job_urn = DataJobUrn.create_from_string(\n    "urn:li:dataJob:(urn:li:dataFlow:(airflow,etl_pipeline,prod),load_customer_data)"\n)\n\ninstance = DataProcessInstance(\n    id="scheduled__2024-01-15T14:30:00+00:00",\n    orchestrator="airflow",\n    cluster="prod",\n    template_urn=parent_job_urn,\n    type=DataProcessTypeClass.BATCH_SCHEDULED,\n    inlets=[\n        DatasetUrn.create_from_string(\n            "urn:li:dataset:(urn:li:dataPlatform:s3,customer_exports,PROD)"\n        )\n    ],\n    outlets=[\n        DatasetUrn.create_from_string(\n            "urn:li:dataset:(urn:li:dataPlatform:snowflake,analytics.customers,PROD)"\n        )\n    ],\n)\n\n# First attempt\nstart_time_attempt1 = int(time.time() * 1000)\ninstance.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=start_time_attempt1,\n    attempt=1,\n    emit_template=True,\n    materialize_iolets=True,\n)\nprint("Attempt 1 started...")\n\ntime.sleep(1)\n\n# First attempt fails\nend_time_attempt1 = int(time.time() * 1000)\ninstance.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=end_time_attempt1,\n    result=InstanceRunResult.UP_FOR_RETRY,\n    result_type="airflow",\n    attempt=1,\n    start_timestamp_millis=start_time_attempt1,\n)\nprint("Attempt 1 failed, will retry...")\n\ntime.sleep(2)\n\n# Second attempt (retry)\nstart_time_attempt2 = int(time.time() * 1000)\ninstance.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=start_time_attempt2,\n    attempt=2,\n    emit_template=False,\n    materialize_iolets=False,\n)\nprint("Attempt 2 started (retry)...")\n\ntime.sleep(1)\n\n# Second attempt succeeds\nend_time_attempt2 = int(time.time() * 1000)\ninstance.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=end_time_attempt2,\n    result=InstanceRunResult.SUCCESS,\n    result_type="airflow",\n    attempt=2,\n    start_timestamp_millis=start_time_attempt2,\n)\nprint("Attempt 2 succeeded!")\n'))),(0,a.yg)("h3",{id:"creating-a-dataflow-instance-dag-run"},"Creating a DataFlow Instance (DAG Run)"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Track an entire workflow execution"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/data_process_instance_create_from_dataflow.py\nimport time\n\nfrom datahub.api.entities.datajob import DataFlow\nfrom datahub.api.entities.dataprocess.dataprocess_instance import (\n    DataProcessInstance,\n    InstanceRunResult,\n)\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\n\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\n# Define the DataFlow (Airflow DAG)\ndataflow = DataFlow(\n    orchestrator="airflow",\n    id="daily_reporting_pipeline",\n    env="prod",\n    description="Daily reporting pipeline that aggregates metrics",\n)\n\n# Create a DataProcessInstance for a specific DAG run\ndag_run_instance = DataProcessInstance.from_dataflow(\n    dataflow=dataflow,\n    id="scheduled__2024-01-15T00:00:00+00:00"\n)\n\n# Set properties specific to this DAG run\ndag_run_instance.properties = {\n    "execution_date": "2024-01-15",\n    "run_type": "scheduled",\n    "external_trigger": "false",\n}\ndag_run_instance.url = "https://airflow.company.com/dags/daily_reporting_pipeline/grid?dag_run_id=scheduled__2024-01-15T00:00:00+00:00"\n\n# Track DAG run start\nstart_time = int(time.time() * 1000)\ndag_run_instance.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=start_time,\n    attempt=1,\n    emit_template=True,\n    materialize_iolets=True,\n)\nprint(f"DAG run started: {dag_run_instance.urn}")\n\n# Simulate DAG execution\ntime.sleep(3)\n\n# Track DAG run completion\nend_time = int(time.time() * 1000)\ndag_run_instance.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=end_time,\n    result=InstanceRunResult.SUCCESS,\n    result_type="airflow",\n    attempt=1,\n    start_timestamp_millis=start_time,\n)\nprint(f"DAG run completed successfully in {end_time - start_time}ms")\n'))),(0,a.yg)("h3",{id:"tracking-hierarchical-process-instances"},"Tracking Hierarchical Process Instances"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Track a DAG run with child task instances"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/data_process_instance_create_hierarchical.py\nimport time\n\nfrom datahub.api.entities.datajob import DataFlow, DataJob\nfrom datahub.api.entities.dataprocess.dataprocess_instance import (\n    DataProcessInstance,\n    InstanceRunResult,\n)\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.utilities.urns.dataset_urn import DatasetUrn\n\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\n# Define the DataFlow (Airflow DAG)\ndataflow = DataFlow(\n    orchestrator="airflow",\n    id="etl_pipeline",\n    env="prod",\n    description="ETL pipeline with multiple tasks",\n)\n\n# Define DataJobs (Tasks in the DAG)\nextract_job = DataJob(\n    id="extract_data",\n    flow_urn=dataflow.urn,\n    description="Extract data from source",\n)\n\n# Create a DAG run instance (parent)\ndag_run_id = "scheduled__2024-01-15T12:00:00+00:00"\ndag_run_instance = DataProcessInstance.from_dataflow(dataflow=dataflow, id=dag_run_id)\n\n# Track DAG run start\ndag_start_time = int(time.time() * 1000)\ndag_run_instance.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=dag_start_time,\n    attempt=1,\n    emit_template=True,\n    materialize_iolets=False,\n)\nprint(f"DAG run started: {dag_run_instance.urn}")\n\n# Create task instance for extract_data (child of DAG run)\nextract_instance = DataProcessInstance.from_datajob(\n    datajob=extract_job,\n    id=f"{dag_run_id}__extract_data",\n)\nextract_instance.parent_instance = dag_run_instance.urn\nextract_instance.inlets = [\n    DatasetUrn.create_from_string(\n        "urn:li:dataset:(urn:li:dataPlatform:postgres,raw_db.orders,PROD)"\n    )\n]\nextract_instance.outlets = [\n    DatasetUrn.create_from_string(\n        "urn:li:dataset:(urn:li:dataPlatform:s3,staging/orders,PROD)"\n    )\n]\n\n# Track extract task execution\nextract_start_time = int(time.time() * 1000)\nextract_instance.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=extract_start_time,\n    attempt=1,\n    emit_template=True,\n    materialize_iolets=True,\n)\ntime.sleep(1)\nextract_end_time = int(time.time() * 1000)\nextract_instance.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=extract_end_time,\n    result=InstanceRunResult.SUCCESS,\n    attempt=1,\n    start_timestamp_millis=extract_start_time,\n)\n\n# Track DAG run completion\ndag_end_time = int(time.time() * 1000)\ndag_run_instance.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=dag_end_time,\n    result=InstanceRunResult.SUCCESS,\n    attempt=1,\n    start_timestamp_millis=dag_start_time,\n)\nprint(f"DAG run completed successfully")\n'))),(0,a.yg)("h3",{id:"tracking-ml-training-run-in-a-container"},"Tracking ML Training Run in a Container"),(0,a.yg)("p",null,"ML training runs are a specialized use case of DataProcessInstance entities. In addition to standard process instance aspects, training runs can use ML-specific aspects:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Subtype"),": ",(0,a.yg)("inlineCode",{parentName:"li"},"MLAssetSubTypes.MLFLOW_TRAINING_RUN")," to identify the process as an ML training run"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"mlTrainingRunProperties"),": ML-specific metadata including training metrics, hyperparameters, and output URLs"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Relationships"),": Links to ML models (via ",(0,a.yg)("inlineCode",{parentName:"li"},"mlModelProperties.trainingJobs"),") and experiments (via ",(0,a.yg)("inlineCode",{parentName:"li"},"container")," aspect)")),(0,a.yg)("p",null,"For comprehensive documentation on ML training runs, including the complete workflow with experiments, models, and datasets, see the ",(0,a.yg)("a",{parentName:"p",href:"/docs/generated/metamodel/entities/mlmodel#training-runs-and-experiments"},"ML Model entity documentation"),"."),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Python SDK: Track a standalone ML training run"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# metadata-ingestion/examples/library/data_process_instance_create_ml_training.py\nimport time\n\nfrom datahub.api.entities.dataprocess.dataprocess_instance import (\n    DataProcessInstance,\n    InstanceRunResult,\n)\nfrom datahub.emitter.mcp_builder import ContainerKey\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\nfrom datahub.metadata.schema_classes import DataProcessTypeClass\nfrom datahub.utilities.urns.dataset_urn import DatasetUrn\n\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\n# Define the ML experiment container\nexperiment_container = ContainerKey(\n    platform="urn:li:dataPlatform:mlflow",\n    name="customer_churn_experiment",\n    env="PROD"\n)\n\n# Create a process instance for a training run\ntraining_run = DataProcessInstance.from_container(\n    container_key=experiment_container,\n    id="run_abc123def456"\n)\n\n# Set training-specific properties\ntraining_run.type = DataProcessTypeClass.BATCH_AD_HOC\ntraining_run.properties = {\n    "model_type": "RandomForestClassifier",\n    "hyperparameters": "n_estimators=100,max_depth=10",\n    "framework": "scikit-learn",\n    "framework_version": "1.3.0",\n}\ntraining_run.url = "https://mlflow.company.com/experiments/5/runs/abc123def456"\n\n# Set training data inputs\ntraining_run.inlets = [\n    DatasetUrn.create_from_string(\n        "urn:li:dataset:(urn:li:dataPlatform:snowflake,ml.training_data,PROD)"\n    )\n]\n\n# Set model output\ntraining_run.outlets = [\n    DatasetUrn.create_from_string(\n        "urn:li:mlModel:(urn:li:dataPlatform:mlflow,customer_churn_model_v2,PROD)"\n    )\n]\n\n# Track training start\nstart_time = int(time.time() * 1000)\ntraining_run.emit_process_start(\n    emitter=emitter,\n    start_timestamp_millis=start_time,\n    attempt=1,\n    emit_template=False,\n    materialize_iolets=True,\n)\nprint("ML training run started...")\n\n# Simulate training\ntime.sleep(5)\n\n# Track training completion\nend_time = int(time.time() * 1000)\ntraining_run.emit_process_end(\n    emitter=emitter,\n    end_timestamp_millis=end_time,\n    result=InstanceRunResult.SUCCESS,\n    result_type="mlflow",\n    attempt=1,\n    start_timestamp_millis=start_time,\n)\nprint(f"ML training completed in {(end_time - start_time)/1000:.2f}s")\n'))),(0,a.yg)("h3",{id:"querying-process-instance-history-via-rest-api"},"Querying Process Instance History via REST API"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"REST API: Query execution history for a DataJob"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"# Get all process instances for a specific DataJob\ncurl -X GET 'http://localhost:8080/relationships?direction=INCOMING&urn=urn%3Ali%3AdataJob%3A%28urn%3Ali%3AdataFlow%3A%28airflow%2Csales_pipeline%2Cprod%29%2Cprocess_sales_data%29&types=InstanceOf'\n")),(0,a.yg)("p",null,"Response:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "start": 0,\n  "count": 10,\n  "relationships": [\n    {\n      "type": "InstanceOf",\n      "entity": "urn:li:dataProcessInstance:abc123..."\n    },\n    {\n      "type": "InstanceOf",\n      "entity": "urn:li:dataProcessInstance:def456..."\n    }\n  ],\n  "total": 25\n}\n')),(0,a.yg)("p",null,"To get full details of each instance, fetch the entities:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"curl 'http://localhost:8080/entities/urn%3Ali%3AdataProcessInstance%3Aabc123...'\n")),(0,a.yg)("p",null,"Response includes all aspects:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "urn": "urn:li:dataProcessInstance:abc123...",\n  "aspects": {\n    "dataProcessInstanceProperties": {\n      "name": "scheduled__2024-01-15T10:00:00+00:00",\n      "type": "BATCH_SCHEDULED",\n      "created": {\n        "time": 1705318800000,\n        "actor": "urn:li:corpuser:datahub"\n      },\n      "customProperties": {\n        "airflow_version": "2.7.0"\n      }\n    },\n    "dataProcessInstanceInput": {\n      "inputs": [\n        "urn:li:dataset:(urn:li:dataPlatform:postgres,sales_db.raw_orders,PROD)"\n      ]\n    },\n    "dataProcessInstanceOutput": {\n      "outputs": [\n        "urn:li:dataset:(urn:li:dataPlatform:postgres,sales_db.processed_orders,PROD)"\n      ]\n    },\n    "dataProcessInstanceRelationships": {\n      "parentTemplate": "urn:li:dataJob:(urn:li:dataFlow:(airflow,sales_pipeline,prod),process_sales_data)"\n    }\n  }\n}\n'))),(0,a.yg)("h3",{id:"querying-process-instance-run-events"},"Querying Process Instance Run Events"),(0,a.yg)("details",null,(0,a.yg)("summary",null,"GraphQL: Query run history with status and timing"),(0,a.yg)("p",null,"The DataHub GraphQL API provides a ",(0,a.yg)("inlineCode",{parentName:"p"},"runs")," field on DataJob entities to query execution history:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'query GetJobRuns {\n  dataJob(\n    urn: "urn:li:dataJob:(urn:li:dataFlow:(airflow,sales_pipeline,prod),process_sales_data)"\n  ) {\n    runs(start: 0, count: 10) {\n      total\n      runs {\n        urn\n        created {\n          time\n        }\n        properties {\n          name\n          type\n          externalUrl\n          customProperties {\n            key\n            value\n          }\n        }\n        relationships {\n          parentTemplate\n          parentInstance\n        }\n        inputs {\n          urn\n          type\n        }\n        outputs {\n          urn\n          type\n        }\n      }\n    }\n  }\n}\n')),(0,a.yg)("p",null,"Note: The timeseries ",(0,a.yg)("inlineCode",{parentName:"p"},"dataProcessInstanceRunEvent")," aspect contains the actual run status, timing, and results. To query this timeseries data, use the timeseries aggregation APIs or directly query the timeseries index.")),(0,a.yg)("h2",{id:"integration-points"},"Integration Points"),(0,a.yg)("h3",{id:"orchestration-platforms"},"Orchestration Platforms"),(0,a.yg)("p",null,"DataProcessInstance is the bridge between orchestration platforms and DataHub's metadata layer:"),(0,a.yg)("h4",{id:"airflow-integration"},"Airflow Integration"),(0,a.yg)("p",null,"The DataHub Airflow plugin automatically creates DataProcessInstance entities for:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DAG runs"),": Each Airflow DagRun becomes a DataProcessInstance with the DataFlow as its parent"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Task runs"),": Each TaskInstance becomes a DataProcessInstance with the DataJob as its parent")),(0,a.yg)("p",null,"The plugin tracks:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Start and end times from TaskInstance"),(0,a.yg)("li",{parentName:"ul"},"Success/failure status"),(0,a.yg)("li",{parentName:"ul"},"Retry attempts"),(0,a.yg)("li",{parentName:"ul"},"Actual datasets read/written (via lineage backend)")),(0,a.yg)("p",null,"Configuration example:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},"from datahub_airflow_plugin.datahub_listener import DatahubListener\n\n# In your airflow.cfg or environment:\n# AIRFLOW__DATAHUB__ENABLED=true\n# AIRFLOW__DATAHUB__DATAHUB_CONN_ID=datahub_rest_default\n")),(0,a.yg)("h4",{id:"other-orchestrators"},"Other Orchestrators"),(0,a.yg)("p",null,"Similar patterns apply for:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Dagster"),": Dagster runs and step executions"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Prefect"),": Flow runs and task runs"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Spark"),": Spark application executions"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"dbt"),": dbt run executions"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Fivetran"),": Sync executions")),(0,a.yg)("h3",{id:"relationship-to-datajob-and-dataflow"},"Relationship to DataJob and DataFlow"),(0,a.yg)("p",null,"DataProcessInstance complements DataJob and DataFlow entities:"),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Entity"),(0,a.yg)("th",{parentName:"tr",align:null},"Purpose"),(0,a.yg)("th",{parentName:"tr",align:null},"Cardinality"),(0,a.yg)("th",{parentName:"tr",align:null},"Example"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"DataFlow"),(0,a.yg)("td",{parentName:"tr",align:null},"Pipeline definition"),(0,a.yg)("td",{parentName:"tr",align:null},"1 per logical pipeline"),(0,a.yg)("td",{parentName:"tr",align:null},'Airflow DAG "sales_pipeline"')),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"DataJob"),(0,a.yg)("td",{parentName:"tr",align:null},"Task definition"),(0,a.yg)("td",{parentName:"tr",align:null},"N per DataFlow"),(0,a.yg)("td",{parentName:"tr",align:null},'Airflow Task "process_sales_data"')),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"DataProcessInstance"),(0,a.yg)("td",{parentName:"tr",align:null},"Execution run"),(0,a.yg)("td",{parentName:"tr",align:null},"M per DataJob/DataFlow"),(0,a.yg)("td",{parentName:"tr",align:null},"Task run on 2024-01-15 10:00")))),(0,a.yg)("p",null,"Key differences:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Static vs Dynamic"),": DataJob/DataFlow define what should happen; DataProcessInstance records what did happen"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Lineage"),": DataJob defines expected lineage; DataProcessInstance captures actual lineage for that run"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Metadata"),": DataJob describes the task; DataProcessInstance describes the execution")),(0,a.yg)("h3",{id:"relationship-to-datasets"},"Relationship to Datasets"),(0,a.yg)("p",null,"DataProcessInstance creates instance-level lineage to datasets:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"Dataset Version 1 \u2500\u2510\n                   \u251c\u2500> DataProcessInstance (Run #1) \u2500> Dataset Version 2\nDataset Version 1 \u2500\u2518\n\nDataset Version 2 \u2500\u2510\n                   \u251c\u2500> DataProcessInstance (Run #2) \u2500> Dataset Version 3\nDataset Version 2 \u2500\u2518\n")),(0,a.yg)("p",null,"This enables:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Point-in-time lineage"),": Which data version was used in which run"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Data provenance"),": Trace data quality issues to specific executions"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Reproducibility"),": Understand exact conditions of past runs")),(0,a.yg)("h3",{id:"graphql-resolvers"},"GraphQL Resolvers"),(0,a.yg)("p",null,"DataProcessInstance entities are exposed via GraphQL through several resolvers:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"DataJobRunsResolver"),": Fetches process instances for a DataJob"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Queries by ",(0,a.yg)("inlineCode",{parentName:"li"},"parentTemplate")," field"),(0,a.yg)("li",{parentName:"ul"},"Sorts by creation time (most recent first)"),(0,a.yg)("li",{parentName:"ul"},"Returns only instances with run events"))),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"EntityRunsResolver"),": Generic resolver for any entity's runs"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Used for DataFlow runs"),(0,a.yg)("li",{parentName:"ul"},"Similar filtering and sorting logic"))),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"DataProcessInstanceMapper"),": Converts internal representation to GraphQL type"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Maps all aspects to GraphQL fields"),(0,a.yg)("li",{parentName:"ul"},"Handles relationships to parent entities")))),(0,a.yg)("p",null,"The GraphQL schema exposes:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},"type DataJob {\n  runs(start: Int, count: Int): DataProcessInstanceResult\n}\n\ntype DataFlow {\n  runs(start: Int, count: Int): DataProcessInstanceResult\n}\n\ntype DataProcessInstance {\n  urn: String!\n  properties: DataProcessInstanceProperties\n  relationships: DataProcessInstanceRelationships\n  inputs: [Entity]\n  outputs: [Entity]\n  # Note: Run events are in timeseries data\n}\n")),(0,a.yg)("h2",{id:"notable-exceptions"},"Notable Exceptions"),(0,a.yg)("h3",{id:"instance-vs-definition-distinction"},"Instance vs Definition Distinction"),(0,a.yg)("p",null,"A common pitfall is confusing instance-level metadata with definition-level metadata:"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Wrong"),": Attaching tags to a DataProcessInstance"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Don\'t do this - tags belong on the DataJob\ninstance = DataProcessInstance(...)\n# instance.tags = ["pii", "critical"]  # This doesn\'t exist\n')),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Right"),": Attach tags to the DataJob, use properties for run-specific metadata"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Tag the DataJob definition\ndatajob.tags = ["pii", "critical"]\n\n# Use properties for run-specific metadata\ninstance = DataProcessInstance(...)\ninstance.properties = {"data_size_mb": "150", "row_count": "1000000"}\n')),(0,a.yg)("h3",{id:"execution-status-lifecycle"},"Execution Status Lifecycle"),(0,a.yg)("p",null,"DataProcessInstance status follows a simple state machine:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"STARTED event emitted when execution begins"),(0,a.yg)("li",{parentName:"ol"},"COMPLETE event emitted when execution finishes (with SUCCESS/FAILURE/SKIPPED/UP_FOR_RETRY result)")),(0,a.yg)("p",null,"Common mistakes:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Forgetting to emit COMPLETE"),": Always emit both START and END events"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Multiple COMPLETE events"),": Retries should have the same instance but different attempt numbers"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Wrong result types"),": UP_FOR_RETRY is for transient failures that will retry; FAILURE is final")),(0,a.yg)("h3",{id:"historical-data-retention"},"Historical Data Retention"),(0,a.yg)("p",null,"DataProcessInstance entities can accumulate quickly in high-frequency pipelines:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"A pipeline running every 5 minutes creates 288 instances per day"),(0,a.yg)("li",{parentName:"ul"},"A pipeline with 10 tasks creates 2,880 instances per day"),(0,a.yg)("li",{parentName:"ul"},"Over a year, this could be over 1 million instances")),(0,a.yg)("p",null,"Considerations:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Retention policies"),": Consider implementing retention policies to delete old instances"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Aggregation"),": For long-term analytics, aggregate instance data into summary metrics"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Sampling"),": For very high-frequency processes, consider sampling (e.g., track every 10th execution)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Storage costs"),": Timeseries data (run events) can grow large; monitor index sizes")),(0,a.yg)("p",null,"DataHub does not automatically clean up old DataProcessInstance entities. You should implement cleanup based on your needs:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Example: Cleanup instances older than 90 days\nimport datetime\nfrom datahub.emitter.rest_emitter import DatahubRestEmitter\n\nemitter = DatahubRestEmitter(gms_server="http://localhost:8080")\n\ncutoff_time = int((datetime.datetime.now() - datetime.timedelta(days=90)).timestamp() * 1000)\n\n# Query for old instances and soft-delete them\n# (Implementation depends on your retention requirements)\n')),(0,a.yg)("h3",{id:"instance-urn-stability"},"Instance URN Stability"),(0,a.yg)("p",null,"The DataProcessInstance URN is generated from the orchestrator, cluster, and id fields. This means:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Same id = Same URN"),": Reusing the same id overwrites the previous instance"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Unique ids required"),": Each execution must have a unique id"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Orchestrator changes"),": Changing the orchestrator name creates a new entity lineage")),(0,a.yg)("p",null,"Best practices:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Use execution-specific IDs (timestamps, run IDs, UUIDs)"),(0,a.yg)("li",{parentName:"ul"},"Don't reuse IDs across different executions"),(0,a.yg)("li",{parentName:"ul"},"Keep orchestrator names consistent"),(0,a.yg)("li",{parentName:"ul"},"Include environment (cluster) in the ID if running the same pipeline in multiple environments")),(0,a.yg)("h2",{id:"technical-reference-guide"},"Technical Reference Guide"),(0,a.yg)("p",null,"The sections above provide an overview of how to use this entity. The following sections provide detailed technical information about how metadata is stored and represented in DataHub."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Aspects")," are the individual pieces of metadata that can be attached to an entity. Each aspect contains specific information (like ownership, tags, or properties) and is stored as a separate record, allowing for flexible and incremental metadata updates."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Relationships")," show how this entity connects to other entities in the metadata graph. These connections are derived from the fields within each aspect and form the foundation of DataHub's knowledge graph."),(0,a.yg)("h3",{id:"reading-the-field-tables"},"Reading the Field Tables"),(0,a.yg)("p",null,"Each aspect's field table includes an ",(0,a.yg)("strong",{parentName:"p"},"Annotations")," column that provides additional metadata about how fields are used:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u26a0\ufe0f Deprecated"),": This field is deprecated and may be removed in a future version. Check the description for the recommended alternative"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Searchable"),": This field is indexed and can be searched in DataHub's search interface"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Searchable (fieldname)"),": When the field name in parentheses is shown, it indicates the field is indexed under a different name in the search index. For example, ",(0,a.yg)("inlineCode",{parentName:"li"},"dashboardTool")," is indexed as ",(0,a.yg)("inlineCode",{parentName:"li"},"tool")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u2192 RelationshipName"),": This field creates a relationship to another entity. The arrow indicates this field contains a reference (URN) to another entity, and the name indicates the type of relationship (e.g., ",(0,a.yg)("inlineCode",{parentName:"li"},"\u2192 Contains"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"\u2192 OwnedBy"),")")),(0,a.yg)("p",null,"Fields with complex types (like ",(0,a.yg)("inlineCode",{parentName:"p"},"Edge"),", ",(0,a.yg)("inlineCode",{parentName:"p"},"AuditStamp"),") link to their definitions in the ",(0,a.yg)("a",{parentName:"p",href:"#common-types"},"Common Types")," section below."),(0,a.yg)("h3",{id:"aspects"},"Aspects"),(0,a.yg)("h4",{id:"dataprocessinstanceinput"},"dataProcessInstanceInput"),(0,a.yg)("p",null,"Information about the inputs datasets of a Data process"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"inputs"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Input assets consumed"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 Consumes")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"inputEdges"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#edge"},"Edge"),"[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Input assets consumed by the data process instance, with additional metadata. Counts as lineage. ..."),(0,a.yg)("td",{parentName:"tr",align:null},"\u2192 DataProcessInstanceConsumes"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessInstanceInput"\n  },\n  "name": "DataProcessInstanceInput",\n  "namespace": "com.linkedin.dataprocess",\n  "fields": [\n    {\n      "Relationship": {\n        "/*": {\n          "entityTypes": [\n            "dataset",\n            "mlModel"\n          ],\n          "name": "Consumes"\n        }\n      },\n      "Searchable": {\n        "/*": {\n          "addToFilters": true,\n          "fieldName": "inputs",\n          "fieldType": "URN",\n          "numValuesFieldName": "numInputs",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "string"\n      },\n      "name": "inputs",\n      "doc": "Input assets consumed"\n    },\n    {\n      "Relationship": {\n        "/*/destinationUrn": {\n          "createdActor": "inputEdges/*/created/actor",\n          "createdOn": "inputEdges/*/created/time",\n          "entityTypes": [\n            "dataset",\n            "mlModel",\n            "dataProcessInstance"\n          ],\n          "isLineage": true,\n          "name": "DataProcessInstanceConsumes",\n          "properties": "inputEdges/*/properties",\n          "updatedActor": "inputEdges/*/lastModified/actor",\n          "updatedOn": "inputEdges/*/lastModified/time"\n        }\n      },\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": {\n            "type": "record",\n            "name": "Edge",\n            "namespace": "com.linkedin.common",\n            "fields": [\n              {\n                "java": {\n                  "class": "com.linkedin.common.urn.Urn"\n                },\n                "type": [\n                  "null",\n                  "string"\n                ],\n                "name": "sourceUrn",\n                "default": null,\n                "doc": "Urn of the source of this relationship edge.\\nIf not specified, assumed to be the entity that this aspect belongs to."\n              },\n              {\n                "java": {\n                  "class": "com.linkedin.common.urn.Urn"\n                },\n                "type": "string",\n                "name": "destinationUrn",\n                "doc": "Urn of the destination of this relationship edge."\n              },\n              {\n                "type": [\n                  "null",\n                  {\n                    "type": "record",\n                    "name": "AuditStamp",\n                    "namespace": "com.linkedin.common",\n                    "fields": [\n                      {\n                        "type": "long",\n                        "name": "time",\n                        "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."\n                      },\n                      {\n                        "java": {\n                          "class": "com.linkedin.common.urn.Urn"\n                        },\n                        "type": "string",\n                        "name": "actor",\n                        "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."\n                      },\n                      {\n                        "java": {\n                          "class": "com.linkedin.common.urn.Urn"\n                        },\n                        "type": [\n                          "null",\n                          "string"\n                        ],\n                        "name": "impersonator",\n                        "default": null,\n                        "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."\n                      },\n                      {\n                        "type": [\n                          "null",\n                          "string"\n                        ],\n                        "name": "message",\n                        "default": null,\n                        "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."\n                      }\n                    ],\n                    "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."\n                  }\n                ],\n                "name": "created",\n                "default": null,\n                "doc": "Audit stamp containing who created this relationship edge and when"\n              },\n              {\n                "type": [\n                  "null",\n                  "com.linkedin.common.AuditStamp"\n                ],\n                "name": "lastModified",\n                "default": null,\n                "doc": "Audit stamp containing who last modified this relationship edge and when"\n              },\n              {\n                "type": [\n                  "null",\n                  {\n                    "type": "map",\n                    "values": "string"\n                  }\n                ],\n                "name": "properties",\n                "default": null,\n                "doc": "A generic properties bag that allows us to store specific information on this graph edge."\n              }\n            ],\n            "doc": "A common structure to represent all edges to entities when used inside aspects as collections\\nThis ensures that all edges have common structure around audit-stamps and will support PATCH, time-travel automatically."\n          }\n        }\n      ],\n      "name": "inputEdges",\n      "default": null,\n      "doc": "Input assets consumed by the data process instance, with additional metadata.\\nCounts as lineage.\\nWill eventually deprecate the inputs field."\n    }\n  ],\n  "doc": "Information about the inputs datasets of a Data process"\n}\n')))),(0,a.yg)("h4",{id:"dataprocessinstanceoutput"},"dataProcessInstanceOutput"),(0,a.yg)("p",null,"Information about the outputs of a Data process"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"outputs"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Output assets produced"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 Produces")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"outputEdges"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#edge"},"Edge"),"[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Output assets produced by the data process instance during processing, with additional metadata. ..."),(0,a.yg)("td",{parentName:"tr",align:null},"\u2192 DataProcessInstanceProduces"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessInstanceOutput"\n  },\n  "name": "DataProcessInstanceOutput",\n  "namespace": "com.linkedin.dataprocess",\n  "fields": [\n    {\n      "Relationship": {\n        "/*": {\n          "entityTypes": [\n            "dataset",\n            "mlModel"\n          ],\n          "name": "Produces"\n        }\n      },\n      "Searchable": {\n        "/*": {\n          "addToFilters": true,\n          "fieldName": "outputs",\n          "fieldType": "URN",\n          "numValuesFieldName": "numOutputs",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "string"\n      },\n      "name": "outputs",\n      "doc": "Output assets produced"\n    },\n    {\n      "Relationship": {\n        "/*/destinationUrn": {\n          "createdActor": "outputEdges/*/created/actor",\n          "createdOn": "outputEdges/*/created/time",\n          "entityTypes": [\n            "dataset",\n            "mlModel",\n            "dataProcessInstance"\n          ],\n          "isLineage": true,\n          "isUpstream": false,\n          "name": "DataProcessInstanceProduces",\n          "properties": "outputEdges/*/properties",\n          "updatedActor": "outputEdges/*/lastModified/actor",\n          "updatedOn": "outputEdges/*/lastModified/time"\n        }\n      },\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": {\n            "type": "record",\n            "name": "Edge",\n            "namespace": "com.linkedin.common",\n            "fields": [\n              {\n                "java": {\n                  "class": "com.linkedin.common.urn.Urn"\n                },\n                "type": [\n                  "null",\n                  "string"\n                ],\n                "name": "sourceUrn",\n                "default": null,\n                "doc": "Urn of the source of this relationship edge.\\nIf not specified, assumed to be the entity that this aspect belongs to."\n              },\n              {\n                "java": {\n                  "class": "com.linkedin.common.urn.Urn"\n                },\n                "type": "string",\n                "name": "destinationUrn",\n                "doc": "Urn of the destination of this relationship edge."\n              },\n              {\n                "type": [\n                  "null",\n                  {\n                    "type": "record",\n                    "name": "AuditStamp",\n                    "namespace": "com.linkedin.common",\n                    "fields": [\n                      {\n                        "type": "long",\n                        "name": "time",\n                        "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."\n                      },\n                      {\n                        "java": {\n                          "class": "com.linkedin.common.urn.Urn"\n                        },\n                        "type": "string",\n                        "name": "actor",\n                        "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."\n                      },\n                      {\n                        "java": {\n                          "class": "com.linkedin.common.urn.Urn"\n                        },\n                        "type": [\n                          "null",\n                          "string"\n                        ],\n                        "name": "impersonator",\n                        "default": null,\n                        "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."\n                      },\n                      {\n                        "type": [\n                          "null",\n                          "string"\n                        ],\n                        "name": "message",\n                        "default": null,\n                        "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."\n                      }\n                    ],\n                    "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."\n                  }\n                ],\n                "name": "created",\n                "default": null,\n                "doc": "Audit stamp containing who created this relationship edge and when"\n              },\n              {\n                "type": [\n                  "null",\n                  "com.linkedin.common.AuditStamp"\n                ],\n                "name": "lastModified",\n                "default": null,\n                "doc": "Audit stamp containing who last modified this relationship edge and when"\n              },\n              {\n                "type": [\n                  "null",\n                  {\n                    "type": "map",\n                    "values": "string"\n                  }\n                ],\n                "name": "properties",\n                "default": null,\n                "doc": "A generic properties bag that allows us to store specific information on this graph edge."\n              }\n            ],\n            "doc": "A common structure to represent all edges to entities when used inside aspects as collections\\nThis ensures that all edges have common structure around audit-stamps and will support PATCH, time-travel automatically."\n          }\n        }\n      ],\n      "name": "outputEdges",\n      "default": null,\n      "doc": "Output assets produced by the data process instance during processing, with additional metadata.\\nCounts as lineage.\\nWill eventually deprecate the outputs field."\n    }\n  ],\n  "doc": "Information about the outputs of a Data process"\n}\n')))),(0,a.yg)("h4",{id:"dataprocessinstanceproperties"},"dataProcessInstanceProperties"),(0,a.yg)("p",null,"The inputs and outputs of this data process"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"customProperties"),(0,a.yg)("td",{parentName:"tr",align:null},"map"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Custom property bag."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"externalUrl"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"URL where the reference exist"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"name"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Process name"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"type"),(0,a.yg)("td",{parentName:"tr",align:null},"DataProcessType"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Process type"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable (processType)")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"created"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#auditstamp"},"AuditStamp")),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Audit stamp containing who reported the lineage and when"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessInstanceProperties"\n  },\n  "name": "DataProcessInstanceProperties",\n  "namespace": "com.linkedin.dataprocess",\n  "fields": [\n    {\n      "Searchable": {\n        "/*": {\n          "fieldType": "TEXT",\n          "queryByDefault": true\n        }\n      },\n      "type": {\n        "type": "map",\n        "values": "string"\n      },\n      "name": "customProperties",\n      "default": {},\n      "doc": "Custom property bag."\n    },\n    {\n      "Searchable": {\n        "fieldType": "KEYWORD"\n      },\n      "java": {\n        "class": "com.linkedin.common.url.Url",\n        "coercerClass": "com.linkedin.common.url.UrlCoercer"\n      },\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "externalUrl",\n      "default": null,\n      "doc": "URL where the reference exist"\n    },\n    {\n      "Searchable": {\n        "boostScore": 10.0,\n        "enableAutocomplete": true,\n        "fieldType": "WORD_GRAM"\n      },\n      "type": "string",\n      "name": "name",\n      "doc": "Process name"\n    },\n    {\n      "Searchable": {\n        "addToFilters": true,\n        "fieldName": "processType",\n        "fieldType": "KEYWORD",\n        "filterNameOverride": "Process Type"\n      },\n      "type": [\n        "null",\n        {\n          "type": "enum",\n          "name": "DataProcessType",\n          "namespace": "com.linkedin.dataprocess",\n          "symbols": [\n            "BATCH_SCHEDULED",\n            "BATCH_AD_HOC",\n            "STREAMING"\n          ]\n        }\n      ],\n      "name": "type",\n      "default": null,\n      "doc": "Process type"\n    },\n    {\n      "Searchable": {\n        "/time": {\n          "fieldName": "created",\n          "fieldType": "COUNT",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "record",\n        "name": "AuditStamp",\n        "namespace": "com.linkedin.common",\n        "fields": [\n          {\n            "type": "long",\n            "name": "time",\n            "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."\n          },\n          {\n            "java": {\n              "class": "com.linkedin.common.urn.Urn"\n            },\n            "type": "string",\n            "name": "actor",\n            "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."\n          },\n          {\n            "java": {\n              "class": "com.linkedin.common.urn.Urn"\n            },\n            "type": [\n              "null",\n              "string"\n            ],\n            "name": "impersonator",\n            "default": null,\n            "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."\n          },\n          {\n            "type": [\n              "null",\n              "string"\n            ],\n            "name": "message",\n            "default": null,\n            "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."\n          }\n        ],\n        "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."\n      },\n      "name": "created",\n      "doc": "Audit stamp containing who reported the lineage and when"\n    }\n  ],\n  "doc": "The inputs and outputs of this data process"\n}\n')))),(0,a.yg)("h4",{id:"dataprocessinstancerelationships"},"dataProcessInstanceRelationships"),(0,a.yg)("p",null,"Information about Data process relationships"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"parentTemplate"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"The parent entity whose run instance it is"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 InstanceOf")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"parentInstance"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"The parent DataProcessInstance where it belongs to. If it is a Airflow Task then it should belong..."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 ChildOf")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"upstreamInstances"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Input DataProcessInstance which triggered this dataprocess instance"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 UpstreamOf"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessInstanceRelationships"\n  },\n  "name": "DataProcessInstanceRelationships",\n  "namespace": "com.linkedin.dataprocess",\n  "fields": [\n    {\n      "Relationship": {\n        "entityTypes": [\n          "dataJob",\n          "dataFlow",\n          "dataset"\n        ],\n        "name": "InstanceOf"\n      },\n      "Searchable": {\n        "/*": {\n          "fieldName": "parentTemplate",\n          "fieldType": "URN",\n          "queryByDefault": false\n        }\n      },\n      "java": {\n        "class": "com.linkedin.common.urn.Urn"\n      },\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "parentTemplate",\n      "default": null,\n      "doc": "The parent entity whose run instance it is"\n    },\n    {\n      "Relationship": {\n        "entityTypes": [\n          "dataProcessInstance"\n        ],\n        "name": "ChildOf"\n      },\n      "Searchable": {\n        "/*": {\n          "fieldName": "parentInstance",\n          "fieldType": "URN",\n          "queryByDefault": false\n        }\n      },\n      "java": {\n        "class": "com.linkedin.common.urn.Urn"\n      },\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "parentInstance",\n      "default": null,\n      "doc": "The parent DataProcessInstance where it belongs to.\\nIf it is a Airflow Task then it should belong to an Airflow Dag run as well\\nwhich will be another DataProcessInstance"\n    },\n    {\n      "Relationship": {\n        "/*": {\n          "entityTypes": [\n            "dataProcessInstance"\n          ],\n          "name": "UpstreamOf"\n        }\n      },\n      "Searchable": {\n        "/*": {\n          "fieldName": "upstream",\n          "fieldType": "URN",\n          "numValuesFieldName": "numUpstreams",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "string"\n      },\n      "name": "upstreamInstances",\n      "doc": "Input DataProcessInstance which triggered this dataprocess instance"\n    }\n  ],\n  "doc": "Information about Data process relationships"\n}\n')))),(0,a.yg)("h4",{id:"status"},"status"),(0,a.yg)("p",null,"The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\nThis aspect is used to represent soft deletes conventionally."),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"removed"),(0,a.yg)("td",{parentName:"tr",align:null},"boolean"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Whether the entity has been removed (soft-deleted)."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "status"\n  },\n  "name": "Status",\n  "namespace": "com.linkedin.common",\n  "fields": [\n    {\n      "Searchable": {\n        "fieldType": "BOOLEAN"\n      },\n      "type": "boolean",\n      "name": "removed",\n      "default": false,\n      "doc": "Whether the entity has been removed (soft-deleted)."\n    }\n  ],\n  "doc": "The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\\nThis aspect is used to represent soft deletes conventionally."\n}\n')))),(0,a.yg)("h4",{id:"testresults"},"testResults"),(0,a.yg)("p",null,"Information about a Test Result"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"failing"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#testresult"},"TestResult"),"[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Results that are failing"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 IsFailing")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"passing"),(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("a",{parentName:"td",href:"#testresult"},"TestResult"),"[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Results that are passing"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 IsPassing"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "testResults"\n  },\n  "name": "TestResults",\n  "namespace": "com.linkedin.test",\n  "fields": [\n    {\n      "Relationship": {\n        "/*/test": {\n          "entityTypes": [\n            "test"\n          ],\n          "name": "IsFailing"\n        }\n      },\n      "Searchable": {\n        "/*/test": {\n          "fieldName": "failingTests",\n          "fieldType": "URN",\n          "hasValuesFieldName": "hasFailingTests",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": {\n          "type": "record",\n          "name": "TestResult",\n          "namespace": "com.linkedin.test",\n          "fields": [\n            {\n              "java": {\n                "class": "com.linkedin.common.urn.Urn"\n              },\n              "type": "string",\n              "name": "test",\n              "doc": "The urn of the test"\n            },\n            {\n              "type": {\n                "type": "enum",\n                "symbolDocs": {\n                  "FAILURE": " The Test Failed",\n                  "SUCCESS": " The Test Succeeded"\n                },\n                "name": "TestResultType",\n                "namespace": "com.linkedin.test",\n                "symbols": [\n                  "SUCCESS",\n                  "FAILURE"\n                ]\n              },\n              "name": "type",\n              "doc": "The type of the result"\n            },\n            {\n              "type": [\n                "null",\n                "string"\n              ],\n              "name": "testDefinitionMd5",\n              "default": null,\n              "doc": "The md5 of the test definition that was used to compute this result.\\nSee TestInfo.testDefinition.md5 for more information."\n            },\n            {\n              "type": [\n                "null",\n                {\n                  "type": "record",\n                  "name": "AuditStamp",\n                  "namespace": "com.linkedin.common",\n                  "fields": [\n                    {\n                      "type": "long",\n                      "name": "time",\n                      "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."\n                    },\n                    {\n                      "java": {\n                        "class": "com.linkedin.common.urn.Urn"\n                      },\n                      "type": "string",\n                      "name": "actor",\n                      "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."\n                    },\n                    {\n                      "java": {\n                        "class": "com.linkedin.common.urn.Urn"\n                      },\n                      "type": [\n                        "null",\n                        "string"\n                      ],\n                      "name": "impersonator",\n                      "default": null,\n                      "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."\n                    },\n                    {\n                      "type": [\n                        "null",\n                        "string"\n                      ],\n                      "name": "message",\n                      "default": null,\n                      "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."\n                    }\n                  ],\n                  "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."\n                }\n              ],\n              "name": "lastComputed",\n              "default": null,\n              "doc": "The audit stamp of when the result was computed, including the actor who computed it."\n            }\n          ],\n          "doc": "Information about a Test Result"\n        }\n      },\n      "name": "failing",\n      "doc": "Results that are failing"\n    },\n    {\n      "Relationship": {\n        "/*/test": {\n          "entityTypes": [\n            "test"\n          ],\n          "name": "IsPassing"\n        }\n      },\n      "Searchable": {\n        "/*/test": {\n          "fieldName": "passingTests",\n          "fieldType": "URN",\n          "hasValuesFieldName": "hasPassingTests",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "com.linkedin.test.TestResult"\n      },\n      "name": "passing",\n      "doc": "Results that are passing"\n    }\n  ],\n  "doc": "Information about a Test Result"\n}\n')))),(0,a.yg)("h4",{id:"dataplatforminstance"},"dataPlatformInstance"),(0,a.yg)("p",null,"The specific instance of the data platform that this entity belongs to"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"platform"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Data Platform"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"instance"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Instance of the data platform (e.g. db instance)"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable (platformInstance)"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataPlatformInstance"\n  },\n  "name": "DataPlatformInstance",\n  "namespace": "com.linkedin.common",\n  "fields": [\n    {\n      "Searchable": {\n        "addToFilters": true,\n        "fieldType": "URN",\n        "filterNameOverride": "Platform"\n      },\n      "java": {\n        "class": "com.linkedin.common.urn.Urn"\n      },\n      "type": "string",\n      "name": "platform",\n      "doc": "Data Platform"\n    },\n    {\n      "Searchable": {\n        "addToFilters": true,\n        "fieldName": "platformInstance",\n        "fieldType": "URN",\n        "filterNameOverride": "Platform Instance"\n      },\n      "java": {\n        "class": "com.linkedin.common.urn.Urn"\n      },\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "instance",\n      "default": null,\n      "doc": "Instance of the data platform (e.g. db instance)"\n    }\n  ],\n  "doc": "The specific instance of the data platform that this entity belongs to"\n}\n')))),(0,a.yg)("h4",{id:"subtypes"},"subTypes"),(0,a.yg)("p",null,"Sub Types. Use this aspect to specialize a generic Entity\ne.g. Making a Dataset also be a View or also be a LookerExplore"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"typeNames"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"The names of the specific types."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "subTypes"\n  },\n  "name": "SubTypes",\n  "namespace": "com.linkedin.common",\n  "fields": [\n    {\n      "Searchable": {\n        "/*": {\n          "addToFilters": true,\n          "fieldType": "KEYWORD",\n          "filterNameOverride": "Sub Type",\n          "queryByDefault": false\n        }\n      },\n      "type": {\n        "type": "array",\n        "items": "string"\n      },\n      "name": "typeNames",\n      "doc": "The names of the specific types."\n    }\n  ],\n  "doc": "Sub Types. Use this aspect to specialize a generic Entity\\ne.g. Making a Dataset also be a View or also be a LookerExplore"\n}\n')))),(0,a.yg)("h4",{id:"container"},"container"),(0,a.yg)("p",null,"Link from an asset to its parent container"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"container"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"The parent container of an asset"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable, \u2192 IsPartOf"))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "container"\n  },\n  "name": "Container",\n  "namespace": "com.linkedin.container",\n  "fields": [\n    {\n      "Relationship": {\n        "entityTypes": [\n          "container"\n        ],\n        "name": "IsPartOf"\n      },\n      "Searchable": {\n        "addToFilters": true,\n        "fieldName": "container",\n        "fieldType": "URN",\n        "filterNameOverride": "Container",\n        "hasValuesFieldName": "hasContainer"\n      },\n      "java": {\n        "class": "com.linkedin.common.urn.Urn"\n      },\n      "type": "string",\n      "name": "container",\n      "doc": "The parent container of an asset"\n    }\n  ],\n  "doc": "Link from an asset to its parent container"\n}\n')))),(0,a.yg)("h4",{id:"mltrainingrunproperties"},"mlTrainingRunProperties"),(0,a.yg)("p",null,"The inputs and outputs of this training run"),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"customProperties"),(0,a.yg)("td",{parentName:"tr",align:null},"map"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"Custom property bag."),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"externalUrl"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"URL where the reference exist"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"id"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Run Id of the ML Training Run"),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"outputUrls"),(0,a.yg)("td",{parentName:"tr",align:null},"string[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"List of URLs for the Outputs of the ML Training Run"),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"hyperParams"),(0,a.yg)("td",{parentName:"tr",align:null},"MLHyperParam[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Hyperparameters of the ML Training Run"),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"trainingMetrics"),(0,a.yg)("td",{parentName:"tr",align:null},"MLMetric[]"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Metrics of the ML Training Run"),(0,a.yg)("td",{parentName:"tr",align:null}))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "mlTrainingRunProperties"\n  },\n  "name": "MLTrainingRunProperties",\n  "namespace": "com.linkedin.ml.metadata",\n  "fields": [\n    {\n      "Searchable": {\n        "/*": {\n          "fieldType": "TEXT",\n          "queryByDefault": true\n        }\n      },\n      "type": {\n        "type": "map",\n        "values": "string"\n      },\n      "name": "customProperties",\n      "default": {},\n      "doc": "Custom property bag."\n    },\n    {\n      "Searchable": {\n        "fieldType": "KEYWORD"\n      },\n      "java": {\n        "class": "com.linkedin.common.url.Url",\n        "coercerClass": "com.linkedin.common.url.UrlCoercer"\n      },\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "externalUrl",\n      "default": null,\n      "doc": "URL where the reference exist"\n    },\n    {\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "id",\n      "default": null,\n      "doc": "Run Id of the ML Training Run"\n    },\n    {\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": "string"\n        }\n      ],\n      "name": "outputUrls",\n      "default": null,\n      "doc": "List of URLs for the Outputs of the ML Training Run"\n    },\n    {\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": {\n            "type": "record",\n            "Aspect": {\n              "name": "mlHyperParam"\n            },\n            "name": "MLHyperParam",\n            "namespace": "com.linkedin.ml.metadata",\n            "fields": [\n              {\n                "type": "string",\n                "name": "name",\n                "doc": "Name of the MLHyperParam"\n              },\n              {\n                "type": [\n                  "null",\n                  "string"\n                ],\n                "name": "description",\n                "default": null,\n                "doc": "Documentation of the MLHyperParam"\n              },\n              {\n                "type": [\n                  "null",\n                  "string"\n                ],\n                "name": "value",\n                "default": null,\n                "doc": "The value of the MLHyperParam"\n              },\n              {\n                "type": [\n                  "null",\n                  "long"\n                ],\n                "name": "createdAt",\n                "default": null,\n                "doc": "Date when the MLHyperParam was developed"\n              }\n            ],\n            "doc": "Properties associated with an ML Hyper Param"\n          }\n        }\n      ],\n      "name": "hyperParams",\n      "default": null,\n      "doc": "Hyperparameters of the ML Training Run"\n    },\n    {\n      "type": [\n        "null",\n        {\n          "type": "array",\n          "items": {\n            "type": "record",\n            "Aspect": {\n              "name": "mlMetric"\n            },\n            "name": "MLMetric",\n            "namespace": "com.linkedin.ml.metadata",\n            "fields": [\n              {\n                "type": "string",\n                "name": "name",\n                "doc": "Name of the mlMetric"\n              },\n              {\n                "type": [\n                  "null",\n                  "string"\n                ],\n                "name": "description",\n                "default": null,\n                "doc": "Documentation of the mlMetric"\n              },\n              {\n                "type": [\n                  "null",\n                  "string"\n                ],\n                "name": "value",\n                "default": null,\n                "doc": "The value of the mlMetric"\n              },\n              {\n                "type": [\n                  "null",\n                  "long"\n                ],\n                "name": "createdAt",\n                "default": null,\n                "doc": "Date when the mlMetric was developed"\n              }\n            ],\n            "doc": "Properties associated with an ML Metric"\n          }\n        }\n      ],\n      "name": "trainingMetrics",\n      "default": null,\n      "doc": "Metrics of the ML Training Run"\n    }\n  ],\n  "doc": "The inputs and outputs of this training run"\n}\n')))),(0,a.yg)("h4",{id:"dataprocessinstancerunevent-timeseries"},"dataProcessInstanceRunEvent (Timeseries)"),(0,a.yg)("p",null,"An event representing the current status of data process run.\nDataProcessRunEvent should be used for reporting the status of a dataProcess' run."),(0,a.yg)(i.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"fields",label:"Fields",default:!0,mdxType:"TabItem"},(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},"Field"),(0,a.yg)("th",{parentName:"tr",align:null},"Type"),(0,a.yg)("th",{parentName:"tr",align:null},"Required"),(0,a.yg)("th",{parentName:"tr",align:null},"Description"),(0,a.yg)("th",{parentName:"tr",align:null},"Annotations"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"timestampMillis"),(0,a.yg)("td",{parentName:"tr",align:null},"long"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null},"The event timestamp field as epoch at UTC in milli seconds."),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"eventGranularity"),(0,a.yg)("td",{parentName:"tr",align:null},"TimeWindowSize"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Granularity of the event if applicable"),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"partitionSpec"),(0,a.yg)("td",{parentName:"tr",align:null},"PartitionSpec"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"The optional partition specification."),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"messageId"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"The optional messageId, if provided serves as a custom user-defined unique identifier for an aspe..."),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"externalUrl"),(0,a.yg)("td",{parentName:"tr",align:null},"string"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"URL where the reference exist"),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"status"),(0,a.yg)("td",{parentName:"tr",align:null},"DataProcessRunStatus"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2713"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Searchable")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"attempt"),(0,a.yg)("td",{parentName:"tr",align:null},"int"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"Return the try number that this Instance Run is in"),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"result"),(0,a.yg)("td",{parentName:"tr",align:null},"DataProcessInstanceRunResult"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"The final result of the Data Processing run."),(0,a.yg)("td",{parentName:"tr",align:null})),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"durationMillis"),(0,a.yg)("td",{parentName:"tr",align:null},"long"),(0,a.yg)("td",{parentName:"tr",align:null}),(0,a.yg)("td",{parentName:"tr",align:null},"The duration of the run in milliseconds."),(0,a.yg)("td",{parentName:"tr",align:null}))))),(0,a.yg)(r.A,{value:"raw",label:"Raw Schema",mdxType:"TabItem"},(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "type": "record",\n  "Aspect": {\n    "name": "dataProcessInstanceRunEvent",\n    "type": "timeseries"\n  },\n  "name": "DataProcessInstanceRunEvent",\n  "namespace": "com.linkedin.dataprocess",\n  "fields": [\n    {\n      "type": "long",\n      "name": "timestampMillis",\n      "doc": "The event timestamp field as epoch at UTC in milli seconds."\n    },\n    {\n      "type": [\n        "null",\n        {\n          "type": "record",\n          "name": "TimeWindowSize",\n          "namespace": "com.linkedin.timeseries",\n          "fields": [\n            {\n              "type": {\n                "type": "enum",\n                "name": "CalendarInterval",\n                "namespace": "com.linkedin.timeseries",\n                "symbols": [\n                  "SECOND",\n                  "MINUTE",\n                  "HOUR",\n                  "DAY",\n                  "WEEK",\n                  "MONTH",\n                  "QUARTER",\n                  "YEAR"\n                ]\n              },\n              "name": "unit",\n              "doc": "Interval unit such as minute/hour/day etc."\n            },\n            {\n              "type": "int",\n              "name": "multiple",\n              "default": 1,\n              "doc": "How many units. Defaults to 1."\n            }\n          ],\n          "doc": "Defines the size of a time window."\n        }\n      ],\n      "name": "eventGranularity",\n      "default": null,\n      "doc": "Granularity of the event if applicable"\n    },\n    {\n      "type": [\n        {\n          "type": "record",\n          "name": "PartitionSpec",\n          "namespace": "com.linkedin.timeseries",\n          "fields": [\n            {\n              "TimeseriesField": {},\n              "type": "string",\n              "name": "partition",\n              "doc": "A unique id / value for the partition for which statistics were collected,\\ngenerated by applying the key definition to a given row."\n            },\n            {\n              "type": [\n                "null",\n                {\n                  "type": "record",\n                  "name": "TimeWindow",\n                  "namespace": "com.linkedin.timeseries",\n                  "fields": [\n                    {\n                      "type": "long",\n                      "name": "startTimeMillis",\n                      "doc": "Start time as epoch at UTC."\n                    },\n                    {\n                      "type": "com.linkedin.timeseries.TimeWindowSize",\n                      "name": "length",\n                      "doc": "The length of the window."\n                    }\n                  ]\n                }\n              ],\n              "name": "timePartition",\n              "default": null,\n              "doc": "Time window of the partition, if we are able to extract it from the partition key."\n            },\n            {\n              "deprecated": true,\n              "type": {\n                "type": "enum",\n                "name": "PartitionType",\n                "namespace": "com.linkedin.timeseries",\n                "symbols": [\n                  "FULL_TABLE",\n                  "QUERY",\n                  "PARTITION"\n                ]\n              },\n              "name": "type",\n              "default": "PARTITION",\n              "doc": "Unused!"\n            }\n          ],\n          "doc": "A reference to a specific partition in a dataset."\n        },\n        "null"\n      ],\n      "name": "partitionSpec",\n      "default": {\n        "partition": "FULL_TABLE_SNAPSHOT",\n        "type": "FULL_TABLE",\n        "timePartition": null\n      },\n      "doc": "The optional partition specification."\n    },\n    {\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "messageId",\n      "default": null,\n      "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."\n    },\n    {\n      "Searchable": {\n        "fieldType": "KEYWORD"\n      },\n      "java": {\n        "class": "com.linkedin.common.url.Url",\n        "coercerClass": "com.linkedin.common.url.UrlCoercer"\n      },\n      "type": [\n        "null",\n        "string"\n      ],\n      "name": "externalUrl",\n      "default": null,\n      "doc": "URL where the reference exist"\n    },\n    {\n      "Searchable": {\n        "hasValuesFieldName": "hasRunEvents"\n      },\n      "TimeseriesField": {},\n      "type": {\n        "type": "enum",\n        "symbolDocs": {\n          "STARTED": "The status where the Data processing run is in."\n        },\n        "name": "DataProcessRunStatus",\n        "namespace": "com.linkedin.dataprocess",\n        "symbols": [\n          "STARTED",\n          "COMPLETE"\n        ]\n      },\n      "name": "status"\n    },\n    {\n      "type": [\n        "null",\n        "int"\n      ],\n      "name": "attempt",\n      "default": null,\n      "doc": "Return the try number that this Instance Run is in"\n    },\n    {\n      "TimeseriesField": {},\n      "type": [\n        "null",\n        {\n          "type": "record",\n          "name": "DataProcessInstanceRunResult",\n          "namespace": "com.linkedin.dataprocess",\n          "fields": [\n            {\n              "type": {\n                "type": "enum",\n                "symbolDocs": {\n                  "FAILURE": " The Run Failed",\n                  "SKIPPED": " The Run Skipped",\n                  "SUCCESS": " The Run Succeeded",\n                  "UP_FOR_RETRY": " The Run Failed and will Retry"\n                },\n                "name": "RunResultType",\n                "namespace": "com.linkedin.dataprocess",\n                "symbols": [\n                  "SUCCESS",\n                  "FAILURE",\n                  "SKIPPED",\n                  "UP_FOR_RETRY"\n                ]\n              },\n              "name": "type",\n              "doc": " The final result, e.g. SUCCESS, FAILURE, SKIPPED, or UP_FOR_RETRY."\n            },\n            {\n              "type": "string",\n              "name": "nativeResultType",\n              "doc": "It identifies the system where the native result comes from like Airflow, Azkaban, etc.."\n            }\n          ]\n        }\n      ],\n      "name": "result",\n      "default": null,\n      "doc": "The final result of the Data Processing run."\n    },\n    {\n      "type": [\n        "null",\n        "long"\n      ],\n      "name": "durationMillis",\n      "default": null,\n      "doc": "The duration of the run in milliseconds."\n    }\n  ],\n  "doc": "An event representing the current status of data process run.\\nDataProcessRunEvent should be used for reporting the status of a dataProcess\' run."\n}\n')))),(0,a.yg)("h3",{id:"common-types"},"Common Types"),(0,a.yg)("p",null,"These types are used across multiple aspects in this entity."),(0,a.yg)("h4",{id:"auditstamp"},"AuditStamp"),(0,a.yg)("p",null,"Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Fields:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"time")," (long): When did the resource/association/sub-resource move into the specific lifecyc..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"actor")," (string): The entity (e.g. a member URN) which will be credited for moving the resource..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"impersonator")," (string?): The entity (e.g. a service URN) which performs the change on behalf of the Ac..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"message")," (string?): Additional context around how DataHub was informed of the particular change. ...")),(0,a.yg)("h4",{id:"edge"},"Edge"),(0,a.yg)("p",null,"A common structure to represent all edges to entities when used inside aspects as collections\nThis ensures that all edges have common structure around audit-stamps and will support PATCH, time-travel automatically."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Fields:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"sourceUrn")," (string?): Urn of the source of this relationship edge. If not specified, assumed to be ..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"destinationUrn")," (string): Urn of the destination of this relationship edge."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"created")," (AuditStamp?): Audit stamp containing who created this relationship edge and when"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"lastModified")," (AuditStamp?): Audit stamp containing who last modified this relationship edge and when"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"properties")," (map?): A generic properties bag that allows us to store specific information on this...")),(0,a.yg)("h4",{id:"testresult"},"TestResult"),(0,a.yg)("p",null,"Information about a Test Result"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Fields:")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"test")," (string): The urn of the test"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"type")," (TestResultType): The type of the result"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"testDefinitionMd5")," (string?): The md5 of the test definition that was used to compute this result. See Test..."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"lastComputed")," (AuditStamp?): The audit stamp of when the result was computed, including the actor who comp...")),(0,a.yg)("h3",{id:"relationships"},"Relationships"),(0,a.yg)("h4",{id:"self"},"Self"),(0,a.yg)("p",null,"These are the relationships to itself, stored in this entity's aspects"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"DataProcessInstanceConsumes (via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput.inputEdges"),")"),(0,a.yg)("li",{parentName:"ul"},"DataProcessInstanceProduces (via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput.outputEdges"),")"),(0,a.yg)("li",{parentName:"ul"},"ChildOf (via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceRelationships.parentInstance"),")"),(0,a.yg)("li",{parentName:"ul"},"UpstreamOf (via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceRelationships.upstreamInstances"),")")),(0,a.yg)("h4",{id:"outgoing"},"Outgoing"),(0,a.yg)("p",null,"These are the relationships stored in this entity's aspects"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Consumes"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput.inputs")),(0,a.yg)("li",{parentName:"ul"},"MlModel via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput.inputs")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"DataProcessInstanceConsumes"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput.inputEdges")),(0,a.yg)("li",{parentName:"ul"},"MlModel via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceInput.inputEdges")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Produces"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput.outputs")),(0,a.yg)("li",{parentName:"ul"},"MlModel via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput.outputs")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"DataProcessInstanceProduces"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput.outputEdges")),(0,a.yg)("li",{parentName:"ul"},"MlModel via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceOutput.outputEdges")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"InstanceOf"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"DataJob via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceRelationships.parentTemplate")),(0,a.yg)("li",{parentName:"ul"},"DataFlow via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceRelationships.parentTemplate")),(0,a.yg)("li",{parentName:"ul"},"Dataset via ",(0,a.yg)("inlineCode",{parentName:"li"},"dataProcessInstanceRelationships.parentTemplate")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"IsFailing"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Test via ",(0,a.yg)("inlineCode",{parentName:"li"},"testResults.failing")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"IsPassing"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Test via ",(0,a.yg)("inlineCode",{parentName:"li"},"testResults.passing")))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"IsPartOf"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Container via ",(0,a.yg)("inlineCode",{parentName:"li"},"container.container"))))),(0,a.yg)("h3",{id:"global-metadata-model"},(0,a.yg)("a",{parentName:"h3",href:"https://github.com/datahub-project/static-assets/raw/main/imgs/datahub-metadata-model.png"},"Global Metadata Model")),(0,a.yg)("p",null,(0,a.yg)("img",{parentName:"p",src:"https://github.com/datahub-project/static-assets/raw/main/imgs/datahub-metadata-model.png",alt:"Global Graph"})))}h.isMDXComponent=!0}}]);