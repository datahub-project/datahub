"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[268],{15680:(e,n,t)=>{t.d(n,{xA:()=>p,yg:()=>u});var a=t(96540);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),c=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},p=function(e){var n=c(e.components);return a.createElement(s.Provider,{value:n},e.children)},g="mdxType",y={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),g=c(t),m=r,u=g["".concat(s,".").concat(m)]||g[m]||y[m]||i;return t?a.createElement(u,o(o({ref:n},p),{},{components:t})):a.createElement(u,o({ref:n},p))}));function u(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=m;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[g]="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=t[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},72678:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>s,default:()=>u,frontMatter:()=>l,metadata:()=>c,toc:()=>g});t(96540);var a=t(15680);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){return n=null!=n?n:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):function(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))})),e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}const l={title:"Kafka Connect Lineage Extraction - Production Architecture",slug:"/metadata-ingestion/kafka_connect_lineage",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/KAFKA_CONNECT_LINEAGE.md"},s="Kafka Connect Lineage Extraction - Production Architecture",c={unversionedId:"metadata-ingestion/KAFKA_CONNECT_LINEAGE",id:"metadata-ingestion/KAFKA_CONNECT_LINEAGE",title:"Kafka Connect Lineage Extraction - Production Architecture",description:"Overview",source:"@site/genDocs/metadata-ingestion/KAFKA_CONNECT_LINEAGE.md",sourceDirName:"metadata-ingestion",slug:"/metadata-ingestion/kafka_connect_lineage",permalink:"/docs/metadata-ingestion/kafka_connect_lineage",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/KAFKA_CONNECT_LINEAGE.md",tags:[],version:"current",frontMatter:{title:"Kafka Connect Lineage Extraction - Production Architecture",slug:"/metadata-ingestion/kafka_connect_lineage",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/KAFKA_CONNECT_LINEAGE.md"}},p={},g=[{value:"Overview",id:"overview",level:2},{value:"Production Architecture",id:"production-architecture",level:2},{value:"Key Components",id:"key-components",level:3},{value:"1. Type-Safe Factory Pattern Implementation",id:"1-type-safe-factory-pattern-implementation",level:4},{value:"2. Connector Class Architecture",id:"2-connector-class-architecture",level:4},{value:"3. Environment-Aware Lineage Extraction",id:"3-environment-aware-lineage-extraction",level:4},{value:"4. Transform Pipeline",id:"4-transform-pipeline",level:4},{value:"5. BigQuery Sink Enhancements",id:"5-bigquery-sink-enhancements",level:4},{value:"6. Centralized Constants",id:"6-centralized-constants",level:4},{value:"7. Advanced Type Safety Implementation",id:"7-advanced-type-safety-implementation",level:4},{value:"Lineage Matching Process Flow",id:"lineage-matching-process-flow",level:2},{value:"Source Connector Flow",id:"source-connector-flow",level:3},{value:"Sink Connector Flow (Reverse Direction)",id:"sink-connector-flow-reverse-direction",level:3},{value:"Environment-Specific Matching Strategies",id:"environment-specific-matching-strategies",level:3},{value:"Self-hosted Kafka Connect",id:"self-hosted-kafka-connect",level:4},{value:"Confluent Cloud Environment",id:"confluent-cloud-environment",level:4},{value:"Transform Processing Pipeline",id:"transform-processing-pipeline",level:3},{value:"Handler Selection Logic",id:"handler-selection-logic",level:3},{value:"Current Lineage Extraction Strategies",id:"current-lineage-extraction-strategies",level:2},{value:"Strategy 1: Environment-Aware Extraction (Primary)",id:"strategy-1-environment-aware-extraction-primary",level:3},{value:"Strategy 2: Transform Pipeline Processing",id:"strategy-2-transform-pipeline-processing",level:3},{value:"Strategy 3: Cloud Transform Pipeline (New)",id:"strategy-3-cloud-transform-pipeline-new",level:3},{value:"Strategy 4: Graceful Fallback Hierarchy",id:"strategy-4-graceful-fallback-hierarchy",level:3},{value:"Production Features &amp; Quality Metrics",id:"production-features--quality-metrics",level:2},{value:"\u2705 <strong>Production-Ready Implementation</strong>",id:"-production-ready-implementation",level:3},{value:"\ud83d\udcca <strong>Quality Metrics</strong>",id:"-quality-metrics",level:3},{value:"\ud83c\udfd7\ufe0f <strong>Architecture Strengths</strong>",id:"\ufe0f-architecture-strengths",level:3},{value:"Current Performance and Reliability",id:"current-performance-and-reliability",level:2},{value:"Actual Measured Performance",id:"actual-measured-performance",level:3},{value:"Reliability Features",id:"reliability-features",level:3},{value:"\ud83c\udff7\ufe0f <strong>Type Safety Implementation</strong>",id:"\ufe0f-type-safety-implementation",level:2},{value:"<strong>100% Type Annotation Coverage</strong>",id:"100-type-annotation-coverage",level:3},{value:"<strong>Advanced Type Features Used</strong>",id:"advanced-type-features-used",level:3},{value:"<strong>Benefits for Kafka Connect Developers</strong>",id:"benefits-for-kafka-connect-developers",level:3},{value:"<strong>MyPy Compliance Verification</strong>",id:"mypy-compliance-verification",level:3},{value:"<strong>Type Safety Best Practices Demonstrated</strong>",id:"type-safety-best-practices-demonstrated",level:3}],y={toc:g},m="wrapper";function u(e){var{components:n}=e,t=o(e,["components"]);return(0,a.yg)(m,i(function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{},a=Object.keys(t);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(t).filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})))),a.forEach((function(n){r(e,n,t[n])}))}return e}({},y,t),{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"kafka-connect-lineage-extraction---production-architecture"},"Kafka Connect Lineage Extraction - Production Architecture"),(0,a.yg)("h2",{id:"overview"},"Overview"),(0,a.yg)("p",null,"DataHub extracts lineage from Kafka Connect by mapping source tables to Kafka topics. The current implementation provides ",(0,a.yg)("strong",{parentName:"p"},"production-ready")," support for both ",(0,a.yg)("strong",{parentName:"p"},"Confluent Cloud")," and ",(0,a.yg)("strong",{parentName:"p"},"Self-hosted Kafka Connect")," environments with comprehensive type safety, robust error handling, and extensive test coverage."),(0,a.yg)("h2",{id:"production-architecture"},"Production Architecture"),(0,a.yg)("h3",{id:"key-components"},"Key Components"),(0,a.yg)("h4",{id:"1-type-safe-factory-pattern-implementation"},"1. Type-Safe Factory Pattern Implementation"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Connector Factory")," (",(0,a.yg)("inlineCode",{parentName:"p"},"common.py"),"):"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u2705 PRODUCTION READY"),": Type-safe connector instantiation with full MyPy compliance"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Factory Methods"),":",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"extract_lineages()"),": Creates connector instance and extracts lineages"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"_get_connector_class_type()"),": Determines connector type from configuration"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"_get_source_connector_type()"),": Routes to appropriate source connector class"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"_get_sink_connector_type()"),": Routes to appropriate sink connector class")))),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"JDBC Configuration Parsing")," (",(0,a.yg)("inlineCode",{parentName:"p"},"source_connectors.py"),"):"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u2705 IMPLEMENTED"),": Unified parsing for Platform and Cloud configurations"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Purpose"),": Handles both Platform (",(0,a.yg)("inlineCode",{parentName:"li"},"connection.url"),") and Cloud (individual fields) configurations"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Features"),": Robust URL validation, quoted identifier support, comprehensive error handling")),(0,a.yg)("h4",{id:"2-connector-class-architecture"},"2. Connector Class Architecture"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Source Connectors"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"ConfluentJDBCSourceConnector")," - JDBC connectors (Platform & Cloud)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"DebeziumSourceConnector")," - CDC connectors (MySQL, PostgreSQL, etc.)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"MongoSourceConnector")," - MongoDB source connectors")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Sink Connectors"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"BigQuerySinkConnector")," - BigQuery sink with table name sanitization"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"ConfluentS3SinkConnector")," - S3 sink connector"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"SnowflakeSinkConnector")," - Snowflake sink connector")),(0,a.yg)("h4",{id:"3-environment-aware-lineage-extraction"},"3. Environment-Aware Lineage Extraction"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 IMPLEMENTED"),": Environment detection and strategy selection"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Cloud Detection"),": Uses ",(0,a.yg)("inlineCode",{parentName:"li"},"CLOUD_JDBC_SOURCE_CLASSES")," for automatic detection"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Strategy Selection"),":",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Cloud: Config-based inference with prefix matching fallback"),(0,a.yg)("li",{parentName:"ul"},"Platform: API-based topic retrieval with transform pipeline")))),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'def _extract_lineages_with_environment_awareness(self, parser: JdbcParser) -> List[KafkaConnectLineage]:\n    connector_class = self.connector_manifest.config.get(CONNECTOR_CLASS, "")\n    is_cloud_environment = connector_class in CLOUD_JDBC_SOURCE_CLASSES\n\n    if is_cloud_environment:\n        return self._extract_lineages_cloud_environment(parser)\n    else:\n        return self._extract_lineages_platform_environment(parser)\n')),(0,a.yg)("h4",{id:"4-transform-pipeline"},"4. Transform Pipeline"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 IMPLEMENTED"),": ",(0,a.yg)("inlineCode",{parentName:"p"},"TransformPipeline")," class with forward transform application"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Supported Transforms"),":",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"RegexRouter")," - Pattern-based topic renaming (\u2705 Working)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"EventRouter")," - Outbox pattern for CDC (\u26a0\ufe0f Limited - warns about unpredictability)"))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Features"),":",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Forward pipeline: Source tables \u2192 transforms \u2192 final topics"),(0,a.yg)("li",{parentName:"ul"},"Connector-specific topic naming strategies"),(0,a.yg)("li",{parentName:"ul"},"Java regex compatibility for exact Kafka Connect behavior")))),(0,a.yg)("h4",{id:"5-bigquery-sink-enhancements"},"5. BigQuery Sink Enhancements"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 IMPLEMENTED"),": Official Kafka Connect compatible table name sanitization"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Follows"),": Aiven and Confluent BigQuery connector implementations"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Rules"),": Invalid character replacement, digit handling, length limits"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u2705 COMPREHENSIVE TESTING"),": 15 test methods covering all edge cases")),(0,a.yg)("h4",{id:"6-centralized-constants"},"6. Centralized Constants"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 IMPLEMENTED"),": ",(0,a.yg)("inlineCode",{parentName:"p"},"connector_constants.py")," module"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Contents"),":",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Connector class constants"),(0,a.yg)("li",{parentName:"ul"},"Transform type classifications"),(0,a.yg)("li",{parentName:"ul"},"Platform-specific constants (2-level container detection)"),(0,a.yg)("li",{parentName:"ul"},"Utility functions for transform classification")))),(0,a.yg)("h4",{id:"7-advanced-type-safety-implementation"},"7. Advanced Type Safety Implementation"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 PRODUCTION EXCELLENCE"),": Full type annotation coverage with 100% MyPy compliance"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Type Safety Features"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Function Signatures"),": Every function has complete parameter and return type annotations"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Generic Types"),": Proper use of ",(0,a.yg)("inlineCode",{parentName:"li"},"List[str]"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"Dict[str, str]"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"Optional[T]")," throughout"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Union Types"),": Explicit handling of multiple possible types with ",(0,a.yg)("inlineCode",{parentName:"li"},"Union[]")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Type Guards"),": Runtime type checking with ",(0,a.yg)("inlineCode",{parentName:"li"},"isinstance()")," and proper type narrowing"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Protocol Usage"),": Interface definitions for extensible architecture"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Dataclass Integration"),": Structured data with automatic type validation")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Benefits for Developers"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"IDE Support"),": Full autocomplete, type hints, and error detection in VS Code/PyCharm"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Runtime Safety"),": Early detection of type mismatches during development"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Documentation"),": Type annotations serve as inline documentation"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Refactoring Safety"),": Confident code changes with type-aware refactoring tools"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Team Collaboration"),": Clear contracts between functions and modules")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Example Type Safety Implementation"),":"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from typing import Dict, List, Optional, Union\nfrom dataclasses import dataclass\n\n@dataclass\nclass ConnectorManifest:\n    name: str\n    type: str\n    config: Dict[str, str]\n    tasks: List[Dict[str, dict]]\n    topic_names: List[str] = field(default_factory=list)\n\n    def extract_lineages(\n        self,\n        config: "KafkaConnectSourceConfig",\n        report: "KafkaConnectSourceReport"\n    ) -> List[KafkaConnectLineage]:\n        """Type-safe lineage extraction with full annotation coverage."""\n        connector_class_type = self._get_connector_class_type()\n        if not connector_class_type:\n            return []\n\n        connector_instance = connector_class_type(self, config, report)\n        return connector_instance.extract_lineages()\n')),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"MyPy Compliance"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"\u2705 ",(0,a.yg)("strong",{parentName:"li"},"0 errors")," across all 9 source files (5,713+ lines of code)"),(0,a.yg)("li",{parentName:"ul"},"\u2705 ",(0,a.yg)("strong",{parentName:"li"},"Strict mode compatible")," with comprehensive type checking"),(0,a.yg)("li",{parentName:"ul"},"\u2705 ",(0,a.yg)("strong",{parentName:"li"},"CI/CD integrated")," with automated type checking in build pipeline")),(0,a.yg)("h2",{id:"lineage-matching-process-flow"},"Lineage Matching Process Flow"),(0,a.yg)("h3",{id:"source-connector-flow"},"Source Connector Flow"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Database      \u2502    \u2502  Kafka Connect   \u2502    \u2502   Kafka Topics  \u2502\n\u2502                 \u2502    \u2502    Connector     \u2502    \u2502                 \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502                  \u2502    \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502 schema.users\u2502 \u2502\u2500\u2500\u2500\u25b6\u2502  Extract Config  \u2502\u2500\u2500\u2500\u25b6\u2502 \u2502finance_users\u2502 \u2502\n\u2502 \u2502schema.orders\u2502 \u2502    \u2502                  \u2502    \u2502 \u2502finance_orders\u2502 \u2502\n\u2502 \u2502schema.items \u2502 \u2502    \u2502  Apply Transforms\u2502    \u2502 \u2502finance_items \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502  (RegexRouter)   \u2502    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                        \u2502                        \u2502\n        \u25bc                        \u25bc                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Source Dataset   \u2502    \u2502 Lineage Mapping  \u2502    \u2502Target Dataset   \u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502                 \u2502\n\u2502mydb.schema.users\u2502\u25c0\u2500\u2500\u2500\u2524  Source \u2192 Topic  \u251c\u2500\u2500\u2500\u25b6\u2502 kafka:finance_  \u2502\n\u2502mydb.schema.orders\u2502    \u2502                  \u2502    \u2502       users     \u2502\n\u2502mydb.schema.items\u2502    \u2502  DataHub Lineage \u2502    \u2502 kafka:finance_  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502   Representation \u2502    \u2502       orders    \u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 kafka:finance_  \u2502\n                                               \u2502       items     \u2502\n                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h3",{id:"sink-connector-flow-reverse-direction"},"Sink Connector Flow (Reverse Direction)"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Kafka Topics  \u2502    \u2502  Kafka Connect   \u2502    \u2502  Target System  \u2502\n\u2502                 \u2502    \u2502    Connector     \u2502    \u2502                 \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502                  \u2502    \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502  user_events\u2502 \u2502\u2500\u2500\u2500\u25b6\u2502  Topic Config    \u2502\u2500\u2500\u2500\u25b6\u2502 \u2502   users     \u2502 \u2502\n\u2502 \u2502order_events \u2502 \u2502    \u2502                  \u2502    \u2502 \u2502   orders    \u2502 \u2502\n\u2502 \u2502product_data \u2502 \u2502    \u2502  Table Mapping   \u2502    \u2502 \u2502   products  \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502  (Sanitization)  \u2502    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                        \u2502                        \u2502\n        \u25bc                        \u25bc                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Source Dataset   \u2502    \u2502 Lineage Mapping  \u2502    \u2502Target Dataset   \u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502                 \u2502\n\u2502kafka:user_events\u2502\u2500\u2500\u2500\u25b6\u2524  Topic \u2192 Table   \u251c\u2500\u2500\u2500\u25b6\u2502bq:project.      \u2502\n\u2502kafka:order_events\u2502    \u2502                  \u2502    \u2502   dataset.users \u2502\n\u2502kafka:product_data\u2502    \u2502  DataHub Lineage \u2502    \u2502bq:project.      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502   Representation \u2502    \u2502   dataset.orders\u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502bq:project.      \u2502\n                                               \u2502   dataset.products\u2502\n                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h3",{id:"environment-specific-matching-strategies"},"Environment-Specific Matching Strategies"),(0,a.yg)("h4",{id:"self-hosted-kafka-connect"},"Self-hosted Kafka Connect"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Self-hosted Environment                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Connector   \u2502\u2500\u2500\u2500\u25b6\u2502 Connect API Call \u2502\u2500\u2500\u2500\u25b6\u2502 Actual Topics\u2502   \u2502\n\u2502  \u2502 Configuration\u2502    \u2502/connectors/{name}\u2502    \u2502   List       \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    /topics       \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502         \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502          \u2502\n\u2502         \u25bc                                            \u25bc          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502Parse Source  \u2502           \u2502      Direct Topic Mapping      \u2502 \u2502\n\u2502  \u2502Tables/Config \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   (Highest Accuracy: 95-98%)   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h4",{id:"confluent-cloud-environment"},"Confluent Cloud Environment"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Confluent Cloud Environment                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502 \u2502  Connector   \u2502\u2500\u2500\u2500\u25b6\u2502Transform Pipeline\u2502\u2500\u2500\u2500\u25b6\u2502Predicted     \u2502    \u2502\n\u2502 \u2502Configuration \u2502    \u2502   Prediction     \u2502    \u2502Topics        \u2502    \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502        \u2502                      \u2502                     \u2502           \u2502\n\u2502        \u25bc                      \u25bc                     \u25bc           \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502 \u2502Parse Source  \u2502    \u2502   Kafka REST     \u2502    \u2502  Validate &  \u2502    \u2502\n\u2502 \u2502Tables/Config \u2502    \u2502   API v3 Call    \u2502    \u2502   Filter     \u2502    \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 (All Topics)     \u2502    \u2502   Topics     \u2502    \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                     \u2502           \u2502\n\u2502                              \u25bc                     \u25bc           \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502                     \u2502   Transform-Aware Strategy            \u2502 \u2502\n\u2502                     \u2502 (Accuracy: 90-95% with fallback)     \u2502 \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,a.yg)("h3",{id:"transform-processing-pipeline"},"Transform Processing Pipeline"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},'Original Source Tables    Transform Pipeline         Final Topics\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502      \u2502                     \u2502    \u2502                 \u2502\n\u2502 schema.users    \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   1. Generate       \u2502\u2500\u2500\u2500\u25b6\u2502 finance_users   \u2502\n\u2502 schema.orders   \u2502      \u2502      Original       \u2502    \u2502 finance_orders  \u2502\n\u2502 schema.products \u2502      \u2502      Topic Names    \u2502    \u2502 finance_products\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502                     \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502   2. Apply Regex    \u2502\nTopic Prefix: "finance_" \u2502      Router         \u2502    RegexRouter Applied:\nTable Include List       \u2502      Transform      \u2502    "finance_(.*)" \u2192 "$1"\n                         \u2502                     \u2502\n                         \u2502   3. Apply Other    \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                         \u2502      Transforms     \u2502\u2500\u2500\u2500\u25b6\u2502 users           \u2502\n                         \u2502      (if supported) \u2502    \u2502 orders          \u2502\n                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502 products        \u2502\n                                                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n')),(0,a.yg)("h3",{id:"handler-selection-logic"},"Handler Selection Logic"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},'Connector Class Detection\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Handler Selection                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502 "io.confluent.connect.jdbc.JdbcSourceConnector"               \u2502\n\u2502                     \u2502                                           \u2502\n\u2502                     \u25bc                                           \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502           \u2502JDBCSourceTopic   \u2502                                  \u2502\n\u2502           \u2502Handler           \u2502                                  \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                                                 \u2502\n\u2502 "io.debezium.connector.mysql.MySqlConnector"                  \u2502\n\u2502                     \u2502                                           \u2502\n\u2502                     \u25bc                                           \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502           \u2502DebeziumSource    \u2502                                  \u2502\n\u2502           \u2502TopicHandler      \u2502                                  \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                                                 \u2502\n\u2502 "PostgresCdcSource" (Cloud)                                    \u2502\n\u2502                     \u2502                                           \u2502\n\u2502                     \u25bc                                           \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502           \u2502CloudJDBCSource   \u2502                                  \u2502\n\u2502           \u2502TopicHandler      \u2502                                  \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                                                 \u2502\n\u2502 Unknown Connector                                               \u2502\n\u2502                     \u2502                                           \u2502\n\u2502                     \u25bc                                           \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502           \u2502GenericConnector  \u2502                                  \u2502\n\u2502           \u2502TopicHandler      \u2502                                  \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n')),(0,a.yg)("h2",{id:"current-lineage-extraction-strategies"},"Current Lineage Extraction Strategies"),(0,a.yg)("h3",{id:"strategy-1-environment-aware-extraction-primary"},"Strategy 1: Environment-Aware Extraction (Primary)"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 CURRENTLY ACTIVE"),": Automatic environment detection and strategy selection"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Self-hosted Environment"),":"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"API-Based Resolution"),": Uses ",(0,a.yg)("inlineCode",{parentName:"li"},"/connectors/{name}/topics")," endpoint"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Transform Application"),": Applies configured transforms to actual topics"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Direct Mapping"),": Creates lineage from actual topics to source tables")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Confluent Cloud Environment"),":"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Transform-Aware Resolution"),": Applies transform pipelines to predict expected topics"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Topic Validation"),": Validates predicted topics against actual cluster topics from Kafka REST API"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Config-Based Fallback"),": Falls back to configuration-based inference when transforms fail"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"1:1 Mapping Detection"),": Handles explicit table-to-topic mappings")),(0,a.yg)("h3",{id:"strategy-2-transform-pipeline-processing"},"Strategy 2: Transform Pipeline Processing"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 IMPLEMENTED"),": Forward transform pipeline with predictable transforms only"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Process"),":"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"Extract source tables from configuration"),(0,a.yg)("li",{parentName:"ol"},"Generate original topic names using connector-specific naming"),(0,a.yg)("li",{parentName:"ol"},"Apply RegexRouter transforms (other transforms skipped with warnings)"),(0,a.yg)("li",{parentName:"ol"},"Create lineage mappings from sources to final topics")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Transform Support"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u2705 RegexRouter"),": Full support with Java regex compatibility"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u26a0\ufe0f EventRouter"),": Warns about unpredictability, provides safe fallback"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"\u274c Custom Transforms"),": Recommends explicit ",(0,a.yg)("inlineCode",{parentName:"li"},"generic_connectors")," mapping")),(0,a.yg)("h3",{id:"strategy-3-cloud-transform-pipeline-new"},"Strategy 3: Cloud Transform Pipeline (New)"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 NEW FEATURE"),": Transform-aware lineage extraction for Confluent Cloud connectors"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Key Capabilities"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Full Transform Support"),": Cloud connectors now support complete transform pipelines (previously missing)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Source Table Extraction"),": Extracts tables from Cloud connector configuration (",(0,a.yg)("inlineCode",{parentName:"li"},"table.include.list"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"query")," modes)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Forward Transform Application"),": Applies RegexRouter and other transforms to predict expected topics"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Topic Validation"),": Validates predicted topics against actual cluster topics from Kafka REST API"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Graceful Fallback"),": Falls back to config-based strategies when transforms can't be applied")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Implementation Details"),":"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'def _extract_lineages_cloud_with_transforms(\n    self, all_topics: List[str], parser: JdbcParser\n) -> List[KafkaConnectLineage]:\n    """Cloud-specific transform-aware lineage extraction."""\n    source_tables = self._get_source_tables_from_config()\n    expected_topics = self._apply_forward_transforms(source_tables, parser)\n    connector_topics = [topic for topic in expected_topics if topic in all_topics]\n    # Create lineages from source tables to validated topics\n    return self._create_lineages_from_tables_to_topics(source_tables, connector_topics, parser)\n')),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Benefits"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"90-95% Accuracy"),": Significant improvement over previous config-only approach (80-85%)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Complex Transform Support"),": Handles multi-step RegexRouter transforms correctly"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Schema Preservation"),": Maintains full schema information (e.g., ",(0,a.yg)("inlineCode",{parentName:"li"},"public.users"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"inventory.products"),")"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Production Ready"),": 8 comprehensive test methods covering all scenarios")),(0,a.yg)("h3",{id:"strategy-4-graceful-fallback-hierarchy"},"Strategy 4: Graceful Fallback Hierarchy"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u2705 IMPLEMENTED"),": Multiple fallback levels for reliability"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Primary"),": Cloud transform-aware extraction (for Cloud connectors)"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Secondary"),": Environment-aware extraction"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Tertiary"),": Unified configuration-based approach"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Final"),": Default lineage extraction with warnings")),(0,a.yg)("h2",{id:"production-features--quality-metrics"},"Production Features & Quality Metrics"),(0,a.yg)("h3",{id:"-production-ready-implementation"},"\u2705 ",(0,a.yg)("strong",{parentName:"h3"},"Production-Ready Implementation")),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Type-Safe Architecture"),": 100% type annotation coverage with MyPy compliance (0 errors)"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Factory Pattern Implementation"),": Clean separation of concerns with connector-specific factories"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Comprehensive Testing"),": 117 test methods across 27 test classes (3,799 lines of tests with comprehensive coverage across all connector types)"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Environment Detection"),": Automatic Cloud vs Platform detection and strategy selection"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Transform Pipeline"),": Fully functional forward transform pipeline with Java regex compatibility"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"BigQuery Sink Enhancement"),": Official Kafka Connect compatible table name sanitization"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Robust Error Handling"),": 124+ try/catch blocks with graceful degradation"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Comprehensive Logging"),": 138+ structured log statements for monitoring and debugging")),(0,a.yg)("h3",{id:"-quality-metrics"},"\ud83d\udcca ",(0,a.yg)("strong",{parentName:"h3"},"Quality Metrics")),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"th"},"Metric")),(0,a.yg)("th",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"th"},"Value")),(0,a.yg)("th",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"th"},"Status")))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"td"},"Lines of Code")),(0,a.yg)("td",{parentName:"tr",align:null},"5,713+ lines across 9 files"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2705 Production Scale")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"td"},"Type Safety")),(0,a.yg)("td",{parentName:"tr",align:null},"0 MyPy errors"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2705 Full Compliance")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"td"},"Test Coverage")),(0,a.yg)("td",{parentName:"tr",align:null},"117 test methods, 27 test classes"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2705 Comprehensive")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"td"},"Code Quality")),(0,a.yg)("td",{parentName:"tr",align:null},"All Ruff checks passing"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2705 Clean Code")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"td"},"Error Handling")),(0,a.yg)("td",{parentName:"tr",align:null},"124 exception handlers"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2705 Robust")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"td"},"Logging Coverage")),(0,a.yg)("td",{parentName:"tr",align:null},"138 log statements"),(0,a.yg)("td",{parentName:"tr",align:null},"\u2705 Observable")))),(0,a.yg)("h3",{id:"\ufe0f-architecture-strengths"},"\ud83c\udfd7\ufe0f ",(0,a.yg)("strong",{parentName:"h3"},"Architecture Strengths")),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Type Safety Excellence"),": Every function, parameter, and return type annotated"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Modular Design"),": Clear separation between source/sink connectors and transform logic"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Environment Awareness"),": Intelligent detection and handling of Platform vs Cloud environments"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Configuration Robustness"),": Comprehensive validation with helpful error messages"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Transform Support"),": Java regex compatibility ensures exact Kafka Connect behavior match"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Testing Quality"),": Real-world scenarios, edge cases, and integration testing coverage")),(0,a.yg)("h2",{id:"current-performance-and-reliability"},"Current Performance and Reliability"),(0,a.yg)("h3",{id:"actual-measured-performance"},"Actual Measured Performance"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"MyPy"),": 0 errors across 9 source files"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Ruff"),": All linting checks pass"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Tests"),": BigQuery sanitization - 15/15 tests passing"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Core Tests"),": 67/67 Kafka Connect core tests passing")),(0,a.yg)("h3",{id:"reliability-features"},"Reliability Features"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Graceful Degradation"),": Multiple fallback strategies prevent complete failure"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Type Safety"),": Runtime type safety through comprehensive annotations"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Error Logging"),": Detailed logging for troubleshooting and monitoring"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Configuration Validation"),": Input validation for JDBC URLs, topic names, etc.")),(0,a.yg)("h2",{id:"\ufe0f-type-safety-implementation"},"\ud83c\udff7\ufe0f ",(0,a.yg)("strong",{parentName:"h2"},"Type Safety Implementation")),(0,a.yg)("p",null,"The Kafka Connect implementation serves as an ",(0,a.yg)("strong",{parentName:"p"},"exemplary model")," for type safety in DataHub ingestion sources."),(0,a.yg)("h3",{id:"100-type-annotation-coverage"},(0,a.yg)("strong",{parentName:"h3"},"100% Type Annotation Coverage")),(0,a.yg)("p",null,"Every function, parameter, and return value is fully annotated:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# Example from source_connectors.py\ndef _extract_lineages_with_environment_awareness(\n    self,\n    parser: JdbcParser\n) -> List[KafkaConnectLineage]:\n    """Environment-aware lineage extraction with complete type safety."""\n    connector_class = self.connector_manifest.config.get(CONNECTOR_CLASS, "")\n    is_cloud_environment = connector_class in CLOUD_JDBC_SOURCE_CLASSES\n\n    if is_cloud_environment:\n        return self._extract_lineages_cloud_environment(parser)\n    else:\n        return self._extract_lineages_platform_environment(parser)\n')),(0,a.yg)("h3",{id:"advanced-type-features-used"},(0,a.yg)("strong",{parentName:"h3"},"Advanced Type Features Used")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Generic Types"),": ",(0,a.yg)("inlineCode",{parentName:"li"},"List[KafkaConnectLineage]"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"Dict[str, str]"),", ",(0,a.yg)("inlineCode",{parentName:"li"},"Optional[TableId]")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Union Types"),": ",(0,a.yg)("inlineCode",{parentName:"li"},"Union[str, List[str]]")," for flexible parameter types"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Type Guards"),": Runtime type checking with ",(0,a.yg)("inlineCode",{parentName:"li"},"isinstance()")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Dataclasses"),": Structured data with automatic type validation"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Protocol Usage"),": Interface definitions for extensible architecture")),(0,a.yg)("h3",{id:"benefits-for-kafka-connect-developers"},(0,a.yg)("strong",{parentName:"h3"},"Benefits for Kafka Connect Developers")),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"IDE Autocomplete"),": Full IntelliSense support in VS Code/PyCharm"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Error Prevention"),": Type mismatches caught before runtime"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Self-Documenting Code"),": Types serve as inline documentation"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Refactoring Safety"),": Confident code changes with type-aware tools"),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Team Collaboration"),": Clear contracts between connector components")),(0,a.yg)("h3",{id:"mypy-compliance-verification"},(0,a.yg)("strong",{parentName:"h3"},"MyPy Compliance Verification")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"# Verify type safety (should show 0 errors)\nmypy src/datahub/ingestion/source/kafka_connect/\n\n# Integration with build system\n./gradlew :metadata-ingestion:lint  # Includes type checking\n")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Result"),": \u2705 ",(0,a.yg)("strong",{parentName:"p"},"0 MyPy errors across 5,713+ lines of Kafka Connect code")),(0,a.yg)("h3",{id:"type-safety-best-practices-demonstrated"},(0,a.yg)("strong",{parentName:"h3"},"Type Safety Best Practices Demonstrated")),(0,a.yg)("p",null,"The implementation showcases several type safety best practices:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'# 1. Structured data with dataclasses\n@dataclass\nclass TransformResult:\n    source_table: str\n    schema: str\n    final_topics: List[str]\n    original_topic: str\n\n# 2. Factory methods with proper typing\ndef _get_connector_class_type(self) -> Optional[Type["BaseConnector"]]:\n    """Factory method with type-safe returns."""\n    pass\n\n# 3. Configuration parsing with validation\ndef parse_comma_separated_list(value: str) -> List[str]:\n    """Type-safe configuration parsing with validation."""\n    if not value or not value.strip():\n        return []\n    return [item.strip() for item in value.split(",") if item.strip()]\n')),(0,a.yg)("p",null,"This comprehensive type safety implementation makes the Kafka Connect source one of the most maintainable and developer-friendly components in the DataHub ingestion framework."),(0,a.yg)("hr",null),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"This document reflects the actual current implementation as of the latest code analysis and removes inaccurate claims from the previous documentation.")))}u.isMDXComponent=!0}}]);